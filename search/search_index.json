{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"How to eat Pytorch in 20 days ?\ud83d\udd25\ud83d\udd25 # \u4e2d\u6587 \u300a20\u5929\u5403\u6389\u90a3\u53eaPytorch\u300b * \ud83d\ude80 github\u9879\u76ee\u5730\u5740: https://github.com/lyhue1991/eat_pytorch_in_20_days * \ud83d\udc33 \u548c\u9cb8\u4e13\u680f\u5730\u5740: https://www.kesci.com/home/column/5f2ac5d8af3980002cb1bc08 \u3010\u4ee3\u7801\u53ef\u76f4\u63a5fork\u540e\u4e91\u7aef\u8fd0\u884c\uff0c\u65e0\u9700\u914d\u7f6e\u73af\u5883\u3011 \u300a30\u5929\u5403\u6389\u90a3\u53eaTensorFlow2\u300b * \ud83d\ude80 github\u9879\u76ee\u5730\u5740: https://github.com/lyhue1991/eat_tensorflow2_in_30_days * \ud83d\udc33 \u548c\u9cb8\u4e13\u680f\u5730\u5740: https://www.kesci.com/home/column/5d8ef3c3037db3002d3aa3a0 \u3010\u4ee3\u7801\u53ef\u76f4\u63a5fork\u540e\u4e91\u7aef\u8fd0\u884c\uff0c\u65e0\u9700\u914d\u7f6e\u73af\u5883\u3011 \u4e00\uff0c Pytorch\ud83d\udd25 or TensorFlow2 \ud83c\udf4e # \u5148\u8bf4\u7ed3\u8bba: \u5982\u679c\u662f\u5de5\u7a0b\u5e08\uff0c\u5e94\u8be5\u4f18\u5148\u9009TensorFlow2. \u5982\u679c\u662f\u5b66\u751f\u6216\u8005\u7814\u7a76\u4eba\u5458\uff0c\u5e94\u8be5\u4f18\u5148\u9009\u62e9Pytorch. \u5982\u679c\u65f6\u95f4\u8db3\u591f\uff0c\u6700\u597dTensorFlow2\u548cPytorch\u90fd\u8981\u5b66\u4e60\u638c\u63e1\u3002 \u7406\u7531\u5982\u4e0b\uff1a 1\uff0c \u5728\u5de5\u4e1a\u754c\u6700\u91cd\u8981\u7684\u662f\u6a21\u578b\u843d\u5730\uff0c\u76ee\u524d\u56fd\u5185\u7684\u5927\u90e8\u5206\u4e92\u8054\u7f51\u4f01\u4e1a\u53ea\u652f\u6301TensorFlow\u6a21\u578b\u7684\u5728\u7ebf\u90e8\u7f72\uff0c\u4e0d\u652f\u6301Pytorch\u3002 \u5e76\u4e14\u5de5\u4e1a\u754c\u66f4\u52a0\u6ce8\u91cd\u7684\u662f\u6a21\u578b\u7684\u9ad8\u53ef\u7528\u6027\uff0c\u8bb8\u591a\u65f6\u5019\u4f7f\u7528\u7684\u90fd\u662f\u6210\u719f\u7684\u6a21\u578b\u67b6\u6784\uff0c\u8c03\u8bd5\u9700\u6c42\u5e76\u4e0d\u5927\u3002 2\uff0c \u7814\u7a76\u4eba\u5458\u6700\u91cd\u8981\u7684\u662f\u5feb\u901f\u8fed\u4ee3\u53d1\u8868\u6587\u7ae0\uff0c\u9700\u8981\u5c1d\u8bd5\u4e00\u4e9b\u8f83\u65b0\u7684\u6a21\u578b\u67b6\u6784\u3002\u800cPytorch\u5728\u6613\u7528\u6027\u4e0a\u76f8\u6bd4TensorFlow2\u6709\u4e00\u4e9b\u4f18\u52bf\uff0c\u66f4\u52a0\u65b9\u4fbf\u8c03\u8bd5\u3002 \u5e76\u4e14\u57282019\u5e74\u4ee5\u6765\u5728\u5b66\u672f\u754c\u5360\u9886\u4e86\u5927\u534a\u58c1\u6c5f\u5c71\uff0c\u80fd\u591f\u627e\u5230\u7684\u76f8\u5e94\u6700\u65b0\u7814\u7a76\u6210\u679c\u66f4\u591a\u3002 3\uff0cTensorFlow2\u548cPytorch\u5b9e\u9645\u4e0a\u6574\u4f53\u98ce\u683c\u5df2\u7ecf\u975e\u5e38\u76f8\u4f3c\u4e86\uff0c\u5b66\u4f1a\u4e86\u5176\u4e2d\u4e00\u4e2a\uff0c\u5b66\u4e60\u53e6\u5916\u4e00\u4e2a\u5c06\u6bd4\u8f83\u5bb9\u6613\u3002\u4e24\u79cd\u6846\u67b6\u90fd\u638c\u63e1\u7684\u8bdd\uff0c\u80fd\u591f\u53c2\u8003\u7684\u5f00\u6e90\u6a21\u578b\u6848\u4f8b\u66f4\u591a\uff0c\u5e76\u4e14\u53ef\u4ee5\u65b9\u4fbf\u5730\u5728\u4e24\u79cd\u6846\u67b6\u4e4b\u95f4\u5207\u6362\u3002 \u672c\u4e66\u7684TensorFlow\u955c\u50cf\u6559\u7a0b\uff1a \ud83c\udf4a\u300a30\u5929\u5403\u6389\u90a3\u53eaTensorFlow2\u300b\uff1a https://github.com/lyhue1991/eat_tensorflow2_in_30_days # \u4e8c\uff0c\u672c\u4e66\ud83d\udcd6\u9762\u5411\u8bfb\u8005 \ud83d\udc7c # \u672c\u4e66\u5047\u5b9a\u8bfb\u8005\u6709\u4e00\u5b9a\u7684\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\uff0c\u4f7f\u7528\u8fc7Keras\u6216TensorFlow\u6216Pytorch\u642d\u5efa\u8bad\u7ec3\u8fc7\u7b80\u5355\u7684\u6a21\u578b\u3002 \u5bf9\u4e8e\u6ca1\u6709\u4efb\u4f55\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u7684\u540c\u5b66\uff0c\u5efa\u8bae\u5728\u5b66\u4e60\u672c\u4e66\u65f6\u540c\u6b65\u53c2\u8003\u9605\u8bfb\u300aPython\u6df1\u5ea6\u5b66\u4e60\u300b\u4e00\u4e66\u7684\u7b2c\u4e00\u90e8\u5206\"\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\"\u5185\u5bb9\u3002 \u300aPython\u6df1\u5ea6\u5b66\u4e60\u300b\u8fd9\u672c\u4e66\u662fKeras\u4e4b\u7236Francois Chollet\u6240\u8457\uff0c\u8be5\u4e66\u5047\u5b9a\u8bfb\u8005\u65e0\u4efb\u4f55\u673a\u5668\u5b66\u4e60\u77e5\u8bc6\uff0c\u4ee5Keras\u4e3a\u5de5\u5177\uff0c \u4f7f\u7528\u4e30\u5bcc\u7684\u8303\u4f8b\u793a\u8303\u6df1\u5ea6\u5b66\u4e60\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u8be5\u4e66\u901a\u4fd7\u6613\u61c2\uff0c \u5168\u4e66\u6ca1\u6709\u4e00\u4e2a\u6570\u5b66\u516c\u5f0f\uff0c\u6ce8\u91cd\u57f9\u517b\u8bfb\u8005\u7684\u6df1\u5ea6\u5b66\u4e60\u76f4\u89c9\u3002 \u3002 \u300aPython\u6df1\u5ea6\u5b66\u4e60\u300b\u4e00\u4e66\u7684\u7b2c\u4e00\u90e8\u5206\u76844\u4e2a\u7ae0\u8282\u5185\u5bb9\u5982\u4e0b\uff0c\u9884\u8ba1\u8bfb\u8005\u53ef\u4ee5\u572820\u5c0f\u65f6\u4e4b\u5185\u5b66\u5b8c\u3002 1\uff0c\u4ec0\u4e48\u662f\u6df1\u5ea6\u5b66\u4e60 2\uff0c\u795e\u7ecf\u7f51\u7edc\u7684\u6570\u5b66\u57fa\u7840 3\uff0c\u795e\u7ecf\u7f51\u7edc\u5165\u95e8 4\uff0c\u673a\u5668\u5b66\u4e60\u57fa\u7840 \u4e09\uff0c\u672c\u4e66\u5199\u4f5c\u98ce\u683c \ud83c\udf49 # \u672c\u4e66\u662f\u4e00\u672c\u5bf9\u4eba\u7c7b\u7528\u6237\u6781\u5176\u53cb\u5584\u7684Pytorch\u5165\u95e8\u5de5\u5177\u4e66\uff0cDon't let me think\u662f\u672c\u4e66\u7684\u6700\u9ad8\u8ffd\u6c42\u3002 \u672c\u4e66\u4e3b\u8981\u662f\u5728\u53c2\u8003Pytorch\u5b98\u65b9\u6587\u6863\u548c\u51fd\u6570doc\u6587\u6863\u57fa\u7840\u4e0a\u6574\u7406\u5199\u6210\u7684\u3002 \u5c3d\u7ba1Pytorch\u5b98\u65b9\u6587\u6863\u5df2\u7ecf\u76f8\u5f53\u7b80\u660e\u6e05\u6670\uff0c\u4f46\u672c\u4e66\u5728\u7bc7\u7ae0\u7ed3\u6784\u548c\u8303\u4f8b\u9009\u53d6\u4e0a\u505a\u4e86\u5927\u91cf\u7684\u4f18\u5316\uff0c\u5728\u7528\u6237\u53cb\u597d\u5ea6\u65b9\u9762\u66f4\u80dc\u4e00\u7b79\u3002 \u672c\u4e66\u6309\u7167\u5185\u5bb9\u96be\u6613\u7a0b\u5ea6\u3001\u8bfb\u8005\u68c0\u7d22\u4e60\u60ef\u548cPytorch\u81ea\u8eab\u7684\u5c42\u6b21\u7ed3\u6784\u8bbe\u8ba1\u5185\u5bb9\uff0c\u5faa\u5e8f\u6e10\u8fdb\uff0c\u5c42\u6b21\u6e05\u6670\uff0c\u65b9\u4fbf\u6309\u7167\u529f\u80fd\u67e5\u627e\u76f8\u5e94\u8303\u4f8b\u3002 \u672c\u4e66\u5728\u8303\u4f8b\u8bbe\u8ba1\u4e0a\u5c3d\u53ef\u80fd\u7b80\u7ea6\u5316\u548c\u7ed3\u6784\u5316\uff0c\u589e\u5f3a\u8303\u4f8b\u6613\u8bfb\u6027\u548c\u901a\u7528\u6027\uff0c\u5927\u90e8\u5206\u4ee3\u7801\u7247\u6bb5\u5728\u5b9e\u8df5\u4e2d\u53ef\u5373\u53d6\u5373\u7528\u3002 \u5982\u679c\u8bf4\u901a\u8fc7\u5b66\u4e60Pytorch\u5b98\u65b9\u6587\u6863\u638c\u63e1Pytorch\u7684\u96be\u5ea6\u5927\u6982\u662f5\uff0c\u90a3\u4e48\u901a\u8fc7\u672c\u4e66\u5b66\u4e60\u638c\u63e1Pytorch\u7684\u96be\u5ea6\u5e94\u8be5\u5927\u6982\u662f2. \u4ec5\u4ee5\u4e0b\u56fe\u5bf9\u6bd4Pytorch\u5b98\u65b9\u6587\u6863\u4e0e\u672c\u4e66\u300a20\u5929\u5403\u6389\u90a3\u53eaPytorch\u300b\u7684\u5dee\u5f02\u3002 \u56db\uff0c\u672c\u4e66\u5b66\u4e60\u65b9\u6848 \u23f0 # 1\uff0c\u5b66\u4e60\u8ba1\u5212 \u672c\u4e66\u662f\u4f5c\u8005\u5229\u7528\u5de5\u4f5c\u4e4b\u4f59\u5927\u69823\u4e2a\u6708\u5199\u6210\u7684\uff0c\u5927\u90e8\u5206\u8bfb\u8005\u5e94\u8be5\u572820\u5929\u53ef\u4ee5\u5b8c\u5168\u5b66\u4f1a\u3002 \u9884\u8ba1\u6bcf\u5929\u82b1\u8d39\u7684\u5b66\u4e60\u65f6\u95f4\u572830\u5206\u949f\u52302\u4e2a\u5c0f\u65f6\u4e4b\u95f4\u3002 \u5f53\u7136\uff0c\u672c\u4e66\u4e5f\u975e\u5e38\u9002\u5408\u4f5c\u4e3aPytorch\u7684\u5de5\u5177\u624b\u518c\u5728\u5de5\u7a0b\u843d\u5730\u65f6\u4f5c\u4e3a\u8303\u4f8b\u5e93\u53c2\u8003\u3002 \u70b9\u51fb\u5b66\u4e60\u5185\u5bb9\u84dd\u8272\u6807\u9898\u5373\u53ef\u8fdb\u5165\u8be5\u7ae0\u8282\u3002 \u65e5\u671f \u5b66\u4e60\u5185\u5bb9 \u5185\u5bb9\u96be\u5ea6 \u9884\u8ba1\u5b66\u4e60\u65f6\u95f4 \u66f4\u65b0\u72b6\u6001 \u4e00\u3001Pytorch\u7684\u5efa\u6a21\u6d41\u7a0b \u2b50\ufe0f 0hour \u2705 day1 1-1,\u7ed3\u6784\u5316\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day2 1-2,\u56fe\u7247\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day3 1-3,\u6587\u672c\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day4 1-4,\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 \u4e8c\u3001Pytorch\u7684\u6838\u5fc3\u6982\u5ff5 \u2b50\ufe0f 0hour \u2705 day5 2-1,\u5f20\u91cf\u6570\u636e\u7ed3\u6784 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day6 2-2,\u81ea\u52a8\u5fae\u5206\u673a\u5236 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day7 2-3,\u52a8\u6001\u8ba1\u7b97\u56fe \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 \u4e09\u3001Pytorch\u7684\u5c42\u6b21\u7ed3\u6784 \u2b50\ufe0f 0hour \u2705 day8 3-1,\u4f4e\u9636API\u793a\u8303 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day9 3-2,\u4e2d\u9636API\u793a\u8303 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day10 3-3,\u9ad8\u9636API\u793a\u8303 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 \u56db\u3001Pytorch\u7684\u4f4e\u9636API \u2b50\ufe0f 0hour \u2705 day11 4-1,\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day12 4-2,\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day13 4-3,nn.functional\u548cnn.Module \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 \u4e94\u3001Pytorch\u7684\u4e2d\u9636API \u2b50\ufe0f 0hour \u2705 day14 5-1,Dataset\u548cDataLoader \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day15 5-2,\u6a21\u578b\u5c42 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day16 5-3,\u635f\u5931\u51fd\u6570 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day17 5-4,TensorBoard\u53ef\u89c6\u5316 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 \u516d\u3001Pytorch\u7684\u9ad8\u9636API \u2b50\ufe0f 0hour \u2705 day18 6-1,\u6784\u5efa\u6a21\u578b\u76843\u79cd\u65b9\u6cd5 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day19 6-2,\u8bad\u7ec3\u6a21\u578b\u76843\u79cd\u65b9\u6cd5 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day20 6-3,\u4f7f\u7528GPU\u8bad\u7ec3\u6a21\u578b \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 2\uff0c\u5b66\u4e60\u73af\u5883 \u672c\u4e66\u5168\u90e8\u6e90\u7801\u5728jupyter\u4e2d\u7f16\u5199\u6d4b\u8bd5\u901a\u8fc7\uff0c\u5efa\u8bae\u901a\u8fc7git\u514b\u9686\u5230\u672c\u5730\uff0c\u5e76\u5728jupyter\u4e2d\u4ea4\u4e92\u5f0f\u8fd0\u884c\u5b66\u4e60\u3002 \u4e3a\u4e86\u76f4\u63a5\u80fd\u591f\u5728jupyter\u4e2d\u6253\u5f00markdown\u6587\u4ef6\uff0c\u5efa\u8bae\u5b89\u88c5jupytext\uff0c\u5c06markdown\u8f6c\u6362\u6210ipynb\u6587\u4ef6\u3002 #\u514b\u9686\u672c\u4e66\u6e90\u7801\u5230\u672c\u5730,\u4f7f\u7528\u7801\u4e91\u955c\u50cf\u4ed3\u5e93\u56fd\u5185\u4e0b\u8f7d\u901f\u5ea6\u66f4\u5feb #!git clone https://gitee.com/Python_Ai_Road/eat_pytorch_in_20_days #\u5efa\u8bae\u5728jupyter notebook \u4e0a\u5b89\u88c5jupytext\uff0c\u4ee5\u4fbf\u80fd\u591f\u5c06\u672c\u4e66\u5404\u7ae0\u8282markdown\u6587\u4ef6\u89c6\u4f5cipynb\u6587\u4ef6\u8fd0\u884c #!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U jupytext #\u5efa\u8bae\u5728jupyter notebook \u4e0a\u5b89\u88c5\u6700\u65b0\u7248\u672cpytorch \u6d4b\u8bd5\u672c\u4e66\u4e2d\u7684\u4ee3\u7801 #!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U torch torchvision torchtext torchkeras import torch from torch import nn print ( \"torch version:\" , torch . __version__ ) a = torch . tensor ([[ 2 , 1 ]]) b = torch . tensor ([[ - 1 , 2 ]]) c = a @b . t () print ( \"[[2,1]]@[[-1],[2]] =\" , c . item ()) torch version: 1.5.0 [[2,1]]@[[-1],[2]] = 0 \u4e94\uff0c\u9f13\u52b1\u548c\u8054\u7cfb\u4f5c\u8005 \ud83c\udf88\ud83c\udf88 # \u5982\u679c\u672c\u4e66\u5bf9\u4f60\u6709\u6240\u5e2e\u52a9\uff0c\u60f3\u9f13\u52b1\u4e00\u4e0b\u4f5c\u8005\uff0c\u8bb0\u5f97\u7ed9\u672c\u9879\u76ee\u52a0\u4e00\u9897\u661f\u661fstar\u2b50\ufe0f\uff0c\u5e76\u5206\u4eab\u7ed9\u4f60\u7684\u670b\u53cb\u4eec\u5594\ud83d\ude0a! \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002 English \"Eat Pytorch in 20 Days\" * \ud83d\ude80 github project address: https://github.com/lyhue1991/eat_pytorch_in_20_days * \ud83d\udc33 Column address: https://www.kesci.com/home/column/5f2ac5d8af3980002cb1bc08 \u3010Code can be run directly in the cloud after fork, no need to configure the environment\u3011 \"Eat TensorFlow 2 in 30 Days\" * \ud83d\ude80 github project address: https://github.com/lyhue1991/eat_tensorflow2_in_30_days * \ud83d\udc33 Column address: https://www.kesci.com/home/column/5d8ef3c3037db3002d3aa3a0 \u3010The code can be run directly in the cloud after fork, no need to configure the environment\u3011 1. Pytorch\ud83d\udd25 or TensorFlow2 \ud83c\udf4e # Conclusion first: If you are an engineer, TensorFlow2 should be preferred. If you are a student or researcher, Pytorch should be preferred. If there is enough time, it is best to learn and master both TensorFlow2 and Pytorch. Why to master both? The most important thing in the industry is the production of models. At present, most domestic Internet companies only support the online deployment of TensorFlow models, not Pytorch. And the industry pays more attention to the high availability of the model. Many times, the mature model architectures are used, and the need for debugging is not really large. In research, the most important thing is to publish articles quickly, and they need to try some newer model architectures. Pytorch has some advantages over TensorFlow2 in terms of ease of use and is more convenient for debugging. Pytorch has occupied more than half of the academic world since 2019 with more cutting-edge research results. TensorFlow2 and Pytorch are actually very similar in overall style. After learning one, it will be easier to learn the other. Mastering both frameworks provides you oppurtunities to contribute to more open source model cases. For mastering Tensorflow: \ud83c\udf4a \"Eat TensorFlow2 in 30 days\"\uff1a https://github.com/lyhue1991/eat_tensorflow2_in_30_days # 2. What Should You Know Before Reading This Book? \ud83d\udc7c # This book assumes that the reader has a certain foundation of machine learning and deep learning, and has used Keras or TensorFlow or Pytorch to build and train simple models. For students who do not have any machine learning and deep learning foundations, it is recommended to read the first part of the book \"Deep Learning with Python\" when studying this book. The book \"Deep Learning with Python\" is written by Francois Chollet, the father of Keras. The book assumes that the reader has no machine learning knowledge and uses Keras as a tool. It uses many examples to demonstrate the best practices of deep learning. The book is easy to understand as there is no mathematical formula in the book. The book mainly focuses on cultivating readers' deep learning intuition. The contents of the 4 chapters of the first part of the book \"Deep Learning for python\" are as follows: What is deep learning The mathematical building blocks of neural networks Getting started with Neural Networks Fundamentals of Machine learning 3. Writing style of this book \ud83c\udf49 # This book is a Pytorch introductory tool that is extremely friendly to human users. \"Don't let the readers think\" is the highest pursuit of this book. This book is mainly organized and written on the basis of referring to Pytorch official documentation together with its functions. Although the official Pytorch documentation is quite concise and clear, this book has made a lot of optimizations in the chapter structure and selection of examples, which is more user-friendly. This book is designed in accordance with the difficulty of the content, the reader's search habits and Pytorch's own hierarchical structure. The content is designed step by step, with clear levels, and it is convenient to find corresponding examples according to functions. This book is as simple and structured as possible in the design of examples to enhance the legibility and versatility of examples. Most of the code snippets are ready to use in practice. If the difficulty of mastering Pytorch by learning the official Pytorch documentation is about 5, then the difficulty of learning to master Pytorch through this book should be about 2. 4. How to use this Book? \u23f0 # 1. Study Plan Number of days required to eat this book: This book was written by the author about 3 months after work, and most readers should be able to learn it in 20 days . How many hours a day should you spend: It is estimated that the study time spent every day is between 30 minutes and 2 hours. Note: This book is also very suitable as a reference for Pytorch's tool manual when the project is implemented. Click the blue title of the learning content to enter the chapter. Date Contents Difficulty Est. Time Update Status 1. Pytorch's modeling process \u2b50\ufe0f 0hour \u2705 day1 1-1. Example of structured data modeling process \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day2 1-2. Example of image data modeling process \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day3 1-3. Example of text data modeling process \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day4 1-4. Example of time series data modeling process \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 2. The core concept of Pytorch \u2b50\ufe0f 0hour \u2705 day5 2-1. Tensor data structure \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day6 2-2. Automatic differentiation mechanism \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day7 2-3. Dynamic calculation diagram \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 3. The hierarchy of Pytorch \u2b50\ufe0f 0hour \u2705 day8 3-1. Low-level API demonstration \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day9 3-2. Intermediate API demonstration \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day10 3-3. High-level API demonstration \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 4. Pytorch's low-level API \u2b50\ufe0f 0hour \u2705 day11 4-1. Tensor structure operation \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day12 4-2. Mathematical operations of tensors \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day13 4-3. nn.functional and nn.Module \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 5. Pytorch's intermediate-level API \u2b50\ufe0f 0hour \u2705 day14 5-1. Dataset and DataLoader \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day15 5-2. Model layer \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day16 5-3. Loss function \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day17 5-4. TensorBoard TensorBoard visualization \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 6. Pytorch's high-level API \u2b50\ufe0f 0hour \u2705 day18 6-1. 3 ways to build a model \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day19 6-2. 3 ways to train a model \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day20 6-3. Use GPU to train model \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 2. Learning environment All the source code of this book has been written and tested in jupyter. It is recommended to clone to the local through git and run and learn interactively in jupyter. In order to directly open the markdown file in jupyter, it is recommended to install jupytext and convert the markdown to an ipynb file. #clone the source code of this book to local, use the code cloud mirror warehouse to download faster in china #!git clone https://gitee.com/Python_Ai_Road/eat_pytorch_in_20_days #it is recommended to install jupytext on jupyter notebook so that the markdown files of each chapter of this book can be run as ipynb files #!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U jupytext #it is recommended to install the latest version of pytorch on jupyter notebook to test the code in this book #!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U torch torchvision torchtext torchkeras import torch from torch import nn print ( \"torch version:\" , torch . __version__ ) a = torch . tensor ([[ 2 , 1 ]]) b = torch . tensor ([[ - 1 , 2 ]]) c = a @b . t () print ( \"[[2,1]]@[[-1],[2]] =\" , c . item ()) torch version: 1.5.0 [[2,1]]@[[-1],[2]] = 0 5. Contact and support the author \ud83c\udf88\ud83c\udf88 # If this book is helpful to you and want to encourage the author, remember to add a star\u2b50\ufe0f to this project and share it with your friends\ud83d\ude0a! If you need to further communicate with the author on the understanding of the content of this book, please leave a message under the public account \"The Beauty of Python and Algorithms\". The author has limited time and energy and will respond as appropriate. You can also reply to keywords in the background of the official account: add group, join the reader exchange group and discuss with you.","title":"How to eat Pytorch in 20 days ?\ud83d\udd25\ud83d\udd25"},{"location":"#how-to-eat-pytorch-in-20-days-","text":"\u4e2d\u6587 \u300a20\u5929\u5403\u6389\u90a3\u53eaPytorch\u300b * \ud83d\ude80 github\u9879\u76ee\u5730\u5740: https://github.com/lyhue1991/eat_pytorch_in_20_days * \ud83d\udc33 \u548c\u9cb8\u4e13\u680f\u5730\u5740: https://www.kesci.com/home/column/5f2ac5d8af3980002cb1bc08 \u3010\u4ee3\u7801\u53ef\u76f4\u63a5fork\u540e\u4e91\u7aef\u8fd0\u884c\uff0c\u65e0\u9700\u914d\u7f6e\u73af\u5883\u3011 \u300a30\u5929\u5403\u6389\u90a3\u53eaTensorFlow2\u300b * \ud83d\ude80 github\u9879\u76ee\u5730\u5740: https://github.com/lyhue1991/eat_tensorflow2_in_30_days * \ud83d\udc33 \u548c\u9cb8\u4e13\u680f\u5730\u5740: https://www.kesci.com/home/column/5d8ef3c3037db3002d3aa3a0 \u3010\u4ee3\u7801\u53ef\u76f4\u63a5fork\u540e\u4e91\u7aef\u8fd0\u884c\uff0c\u65e0\u9700\u914d\u7f6e\u73af\u5883\u3011","title":"How to eat Pytorch in 20 days ?\ud83d\udd25\ud83d\udd25"},{"location":"#\u4e00-pytorch--or-tensorflow2-","text":"\u5148\u8bf4\u7ed3\u8bba: \u5982\u679c\u662f\u5de5\u7a0b\u5e08\uff0c\u5e94\u8be5\u4f18\u5148\u9009TensorFlow2. \u5982\u679c\u662f\u5b66\u751f\u6216\u8005\u7814\u7a76\u4eba\u5458\uff0c\u5e94\u8be5\u4f18\u5148\u9009\u62e9Pytorch. \u5982\u679c\u65f6\u95f4\u8db3\u591f\uff0c\u6700\u597dTensorFlow2\u548cPytorch\u90fd\u8981\u5b66\u4e60\u638c\u63e1\u3002 \u7406\u7531\u5982\u4e0b\uff1a 1\uff0c \u5728\u5de5\u4e1a\u754c\u6700\u91cd\u8981\u7684\u662f\u6a21\u578b\u843d\u5730\uff0c\u76ee\u524d\u56fd\u5185\u7684\u5927\u90e8\u5206\u4e92\u8054\u7f51\u4f01\u4e1a\u53ea\u652f\u6301TensorFlow\u6a21\u578b\u7684\u5728\u7ebf\u90e8\u7f72\uff0c\u4e0d\u652f\u6301Pytorch\u3002 \u5e76\u4e14\u5de5\u4e1a\u754c\u66f4\u52a0\u6ce8\u91cd\u7684\u662f\u6a21\u578b\u7684\u9ad8\u53ef\u7528\u6027\uff0c\u8bb8\u591a\u65f6\u5019\u4f7f\u7528\u7684\u90fd\u662f\u6210\u719f\u7684\u6a21\u578b\u67b6\u6784\uff0c\u8c03\u8bd5\u9700\u6c42\u5e76\u4e0d\u5927\u3002 2\uff0c \u7814\u7a76\u4eba\u5458\u6700\u91cd\u8981\u7684\u662f\u5feb\u901f\u8fed\u4ee3\u53d1\u8868\u6587\u7ae0\uff0c\u9700\u8981\u5c1d\u8bd5\u4e00\u4e9b\u8f83\u65b0\u7684\u6a21\u578b\u67b6\u6784\u3002\u800cPytorch\u5728\u6613\u7528\u6027\u4e0a\u76f8\u6bd4TensorFlow2\u6709\u4e00\u4e9b\u4f18\u52bf\uff0c\u66f4\u52a0\u65b9\u4fbf\u8c03\u8bd5\u3002 \u5e76\u4e14\u57282019\u5e74\u4ee5\u6765\u5728\u5b66\u672f\u754c\u5360\u9886\u4e86\u5927\u534a\u58c1\u6c5f\u5c71\uff0c\u80fd\u591f\u627e\u5230\u7684\u76f8\u5e94\u6700\u65b0\u7814\u7a76\u6210\u679c\u66f4\u591a\u3002 3\uff0cTensorFlow2\u548cPytorch\u5b9e\u9645\u4e0a\u6574\u4f53\u98ce\u683c\u5df2\u7ecf\u975e\u5e38\u76f8\u4f3c\u4e86\uff0c\u5b66\u4f1a\u4e86\u5176\u4e2d\u4e00\u4e2a\uff0c\u5b66\u4e60\u53e6\u5916\u4e00\u4e2a\u5c06\u6bd4\u8f83\u5bb9\u6613\u3002\u4e24\u79cd\u6846\u67b6\u90fd\u638c\u63e1\u7684\u8bdd\uff0c\u80fd\u591f\u53c2\u8003\u7684\u5f00\u6e90\u6a21\u578b\u6848\u4f8b\u66f4\u591a\uff0c\u5e76\u4e14\u53ef\u4ee5\u65b9\u4fbf\u5730\u5728\u4e24\u79cd\u6846\u67b6\u4e4b\u95f4\u5207\u6362\u3002 \u672c\u4e66\u7684TensorFlow\u955c\u50cf\u6559\u7a0b\uff1a","title":"\u4e00\uff0c Pytorch\ud83d\udd25  or TensorFlow2 \ud83c\udf4e"},{"location":"#30\u5929\u5403\u6389\u90a3\u53eatensorflow2httpsgithubcomlyhue1991eat_tensorflow2_in_30_days","text":"","title":"\ud83c\udf4a\u300a30\u5929\u5403\u6389\u90a3\u53eaTensorFlow2\u300b\uff1ahttps://github.com/lyhue1991/eat_tensorflow2_in_30_days"},{"location":"#\u4e8c\u672c\u4e66\u9762\u5411\u8bfb\u8005-","text":"\u672c\u4e66\u5047\u5b9a\u8bfb\u8005\u6709\u4e00\u5b9a\u7684\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\uff0c\u4f7f\u7528\u8fc7Keras\u6216TensorFlow\u6216Pytorch\u642d\u5efa\u8bad\u7ec3\u8fc7\u7b80\u5355\u7684\u6a21\u578b\u3002 \u5bf9\u4e8e\u6ca1\u6709\u4efb\u4f55\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u7684\u540c\u5b66\uff0c\u5efa\u8bae\u5728\u5b66\u4e60\u672c\u4e66\u65f6\u540c\u6b65\u53c2\u8003\u9605\u8bfb\u300aPython\u6df1\u5ea6\u5b66\u4e60\u300b\u4e00\u4e66\u7684\u7b2c\u4e00\u90e8\u5206\"\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\"\u5185\u5bb9\u3002 \u300aPython\u6df1\u5ea6\u5b66\u4e60\u300b\u8fd9\u672c\u4e66\u662fKeras\u4e4b\u7236Francois Chollet\u6240\u8457\uff0c\u8be5\u4e66\u5047\u5b9a\u8bfb\u8005\u65e0\u4efb\u4f55\u673a\u5668\u5b66\u4e60\u77e5\u8bc6\uff0c\u4ee5Keras\u4e3a\u5de5\u5177\uff0c \u4f7f\u7528\u4e30\u5bcc\u7684\u8303\u4f8b\u793a\u8303\u6df1\u5ea6\u5b66\u4e60\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u8be5\u4e66\u901a\u4fd7\u6613\u61c2\uff0c \u5168\u4e66\u6ca1\u6709\u4e00\u4e2a\u6570\u5b66\u516c\u5f0f\uff0c\u6ce8\u91cd\u57f9\u517b\u8bfb\u8005\u7684\u6df1\u5ea6\u5b66\u4e60\u76f4\u89c9\u3002 \u3002 \u300aPython\u6df1\u5ea6\u5b66\u4e60\u300b\u4e00\u4e66\u7684\u7b2c\u4e00\u90e8\u5206\u76844\u4e2a\u7ae0\u8282\u5185\u5bb9\u5982\u4e0b\uff0c\u9884\u8ba1\u8bfb\u8005\u53ef\u4ee5\u572820\u5c0f\u65f6\u4e4b\u5185\u5b66\u5b8c\u3002 1\uff0c\u4ec0\u4e48\u662f\u6df1\u5ea6\u5b66\u4e60 2\uff0c\u795e\u7ecf\u7f51\u7edc\u7684\u6570\u5b66\u57fa\u7840 3\uff0c\u795e\u7ecf\u7f51\u7edc\u5165\u95e8 4\uff0c\u673a\u5668\u5b66\u4e60\u57fa\u7840","title":"\u4e8c\uff0c\u672c\u4e66\ud83d\udcd6\u9762\u5411\u8bfb\u8005 \ud83d\udc7c"},{"location":"#\u4e09\u672c\u4e66\u5199\u4f5c\u98ce\u683c-","text":"\u672c\u4e66\u662f\u4e00\u672c\u5bf9\u4eba\u7c7b\u7528\u6237\u6781\u5176\u53cb\u5584\u7684Pytorch\u5165\u95e8\u5de5\u5177\u4e66\uff0cDon't let me think\u662f\u672c\u4e66\u7684\u6700\u9ad8\u8ffd\u6c42\u3002 \u672c\u4e66\u4e3b\u8981\u662f\u5728\u53c2\u8003Pytorch\u5b98\u65b9\u6587\u6863\u548c\u51fd\u6570doc\u6587\u6863\u57fa\u7840\u4e0a\u6574\u7406\u5199\u6210\u7684\u3002 \u5c3d\u7ba1Pytorch\u5b98\u65b9\u6587\u6863\u5df2\u7ecf\u76f8\u5f53\u7b80\u660e\u6e05\u6670\uff0c\u4f46\u672c\u4e66\u5728\u7bc7\u7ae0\u7ed3\u6784\u548c\u8303\u4f8b\u9009\u53d6\u4e0a\u505a\u4e86\u5927\u91cf\u7684\u4f18\u5316\uff0c\u5728\u7528\u6237\u53cb\u597d\u5ea6\u65b9\u9762\u66f4\u80dc\u4e00\u7b79\u3002 \u672c\u4e66\u6309\u7167\u5185\u5bb9\u96be\u6613\u7a0b\u5ea6\u3001\u8bfb\u8005\u68c0\u7d22\u4e60\u60ef\u548cPytorch\u81ea\u8eab\u7684\u5c42\u6b21\u7ed3\u6784\u8bbe\u8ba1\u5185\u5bb9\uff0c\u5faa\u5e8f\u6e10\u8fdb\uff0c\u5c42\u6b21\u6e05\u6670\uff0c\u65b9\u4fbf\u6309\u7167\u529f\u80fd\u67e5\u627e\u76f8\u5e94\u8303\u4f8b\u3002 \u672c\u4e66\u5728\u8303\u4f8b\u8bbe\u8ba1\u4e0a\u5c3d\u53ef\u80fd\u7b80\u7ea6\u5316\u548c\u7ed3\u6784\u5316\uff0c\u589e\u5f3a\u8303\u4f8b\u6613\u8bfb\u6027\u548c\u901a\u7528\u6027\uff0c\u5927\u90e8\u5206\u4ee3\u7801\u7247\u6bb5\u5728\u5b9e\u8df5\u4e2d\u53ef\u5373\u53d6\u5373\u7528\u3002 \u5982\u679c\u8bf4\u901a\u8fc7\u5b66\u4e60Pytorch\u5b98\u65b9\u6587\u6863\u638c\u63e1Pytorch\u7684\u96be\u5ea6\u5927\u6982\u662f5\uff0c\u90a3\u4e48\u901a\u8fc7\u672c\u4e66\u5b66\u4e60\u638c\u63e1Pytorch\u7684\u96be\u5ea6\u5e94\u8be5\u5927\u6982\u662f2. \u4ec5\u4ee5\u4e0b\u56fe\u5bf9\u6bd4Pytorch\u5b98\u65b9\u6587\u6863\u4e0e\u672c\u4e66\u300a20\u5929\u5403\u6389\u90a3\u53eaPytorch\u300b\u7684\u5dee\u5f02\u3002","title":"\u4e09\uff0c\u672c\u4e66\u5199\u4f5c\u98ce\u683c \ud83c\udf49"},{"location":"#\u56db\u672c\u4e66\u5b66\u4e60\u65b9\u6848-","text":"1\uff0c\u5b66\u4e60\u8ba1\u5212 \u672c\u4e66\u662f\u4f5c\u8005\u5229\u7528\u5de5\u4f5c\u4e4b\u4f59\u5927\u69823\u4e2a\u6708\u5199\u6210\u7684\uff0c\u5927\u90e8\u5206\u8bfb\u8005\u5e94\u8be5\u572820\u5929\u53ef\u4ee5\u5b8c\u5168\u5b66\u4f1a\u3002 \u9884\u8ba1\u6bcf\u5929\u82b1\u8d39\u7684\u5b66\u4e60\u65f6\u95f4\u572830\u5206\u949f\u52302\u4e2a\u5c0f\u65f6\u4e4b\u95f4\u3002 \u5f53\u7136\uff0c\u672c\u4e66\u4e5f\u975e\u5e38\u9002\u5408\u4f5c\u4e3aPytorch\u7684\u5de5\u5177\u624b\u518c\u5728\u5de5\u7a0b\u843d\u5730\u65f6\u4f5c\u4e3a\u8303\u4f8b\u5e93\u53c2\u8003\u3002 \u70b9\u51fb\u5b66\u4e60\u5185\u5bb9\u84dd\u8272\u6807\u9898\u5373\u53ef\u8fdb\u5165\u8be5\u7ae0\u8282\u3002 \u65e5\u671f \u5b66\u4e60\u5185\u5bb9 \u5185\u5bb9\u96be\u5ea6 \u9884\u8ba1\u5b66\u4e60\u65f6\u95f4 \u66f4\u65b0\u72b6\u6001 \u4e00\u3001Pytorch\u7684\u5efa\u6a21\u6d41\u7a0b \u2b50\ufe0f 0hour \u2705 day1 1-1,\u7ed3\u6784\u5316\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day2 1-2,\u56fe\u7247\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day3 1-3,\u6587\u672c\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day4 1-4,\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 \u4e8c\u3001Pytorch\u7684\u6838\u5fc3\u6982\u5ff5 \u2b50\ufe0f 0hour \u2705 day5 2-1,\u5f20\u91cf\u6570\u636e\u7ed3\u6784 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day6 2-2,\u81ea\u52a8\u5fae\u5206\u673a\u5236 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day7 2-3,\u52a8\u6001\u8ba1\u7b97\u56fe \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 \u4e09\u3001Pytorch\u7684\u5c42\u6b21\u7ed3\u6784 \u2b50\ufe0f 0hour \u2705 day8 3-1,\u4f4e\u9636API\u793a\u8303 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day9 3-2,\u4e2d\u9636API\u793a\u8303 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day10 3-3,\u9ad8\u9636API\u793a\u8303 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 \u56db\u3001Pytorch\u7684\u4f4e\u9636API \u2b50\ufe0f 0hour \u2705 day11 4-1,\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day12 4-2,\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day13 4-3,nn.functional\u548cnn.Module \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 \u4e94\u3001Pytorch\u7684\u4e2d\u9636API \u2b50\ufe0f 0hour \u2705 day14 5-1,Dataset\u548cDataLoader \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day15 5-2,\u6a21\u578b\u5c42 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day16 5-3,\u635f\u5931\u51fd\u6570 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day17 5-4,TensorBoard\u53ef\u89c6\u5316 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 \u516d\u3001Pytorch\u7684\u9ad8\u9636API \u2b50\ufe0f 0hour \u2705 day18 6-1,\u6784\u5efa\u6a21\u578b\u76843\u79cd\u65b9\u6cd5 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day19 6-2,\u8bad\u7ec3\u6a21\u578b\u76843\u79cd\u65b9\u6cd5 \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day20 6-3,\u4f7f\u7528GPU\u8bad\u7ec3\u6a21\u578b \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 2\uff0c\u5b66\u4e60\u73af\u5883 \u672c\u4e66\u5168\u90e8\u6e90\u7801\u5728jupyter\u4e2d\u7f16\u5199\u6d4b\u8bd5\u901a\u8fc7\uff0c\u5efa\u8bae\u901a\u8fc7git\u514b\u9686\u5230\u672c\u5730\uff0c\u5e76\u5728jupyter\u4e2d\u4ea4\u4e92\u5f0f\u8fd0\u884c\u5b66\u4e60\u3002 \u4e3a\u4e86\u76f4\u63a5\u80fd\u591f\u5728jupyter\u4e2d\u6253\u5f00markdown\u6587\u4ef6\uff0c\u5efa\u8bae\u5b89\u88c5jupytext\uff0c\u5c06markdown\u8f6c\u6362\u6210ipynb\u6587\u4ef6\u3002 #\u514b\u9686\u672c\u4e66\u6e90\u7801\u5230\u672c\u5730,\u4f7f\u7528\u7801\u4e91\u955c\u50cf\u4ed3\u5e93\u56fd\u5185\u4e0b\u8f7d\u901f\u5ea6\u66f4\u5feb #!git clone https://gitee.com/Python_Ai_Road/eat_pytorch_in_20_days #\u5efa\u8bae\u5728jupyter notebook \u4e0a\u5b89\u88c5jupytext\uff0c\u4ee5\u4fbf\u80fd\u591f\u5c06\u672c\u4e66\u5404\u7ae0\u8282markdown\u6587\u4ef6\u89c6\u4f5cipynb\u6587\u4ef6\u8fd0\u884c #!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U jupytext #\u5efa\u8bae\u5728jupyter notebook \u4e0a\u5b89\u88c5\u6700\u65b0\u7248\u672cpytorch \u6d4b\u8bd5\u672c\u4e66\u4e2d\u7684\u4ee3\u7801 #!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U torch torchvision torchtext torchkeras import torch from torch import nn print ( \"torch version:\" , torch . __version__ ) a = torch . tensor ([[ 2 , 1 ]]) b = torch . tensor ([[ - 1 , 2 ]]) c = a @b . t () print ( \"[[2,1]]@[[-1],[2]] =\" , c . item ()) torch version: 1.5.0 [[2,1]]@[[-1],[2]] = 0","title":"\u56db\uff0c\u672c\u4e66\u5b66\u4e60\u65b9\u6848 \u23f0"},{"location":"#\u4e94\u9f13\u52b1\u548c\u8054\u7cfb\u4f5c\u8005-","text":"\u5982\u679c\u672c\u4e66\u5bf9\u4f60\u6709\u6240\u5e2e\u52a9\uff0c\u60f3\u9f13\u52b1\u4e00\u4e0b\u4f5c\u8005\uff0c\u8bb0\u5f97\u7ed9\u672c\u9879\u76ee\u52a0\u4e00\u9897\u661f\u661fstar\u2b50\ufe0f\uff0c\u5e76\u5206\u4eab\u7ed9\u4f60\u7684\u670b\u53cb\u4eec\u5594\ud83d\ude0a! \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002 English \"Eat Pytorch in 20 Days\" * \ud83d\ude80 github project address: https://github.com/lyhue1991/eat_pytorch_in_20_days * \ud83d\udc33 Column address: https://www.kesci.com/home/column/5f2ac5d8af3980002cb1bc08 \u3010Code can be run directly in the cloud after fork, no need to configure the environment\u3011 \"Eat TensorFlow 2 in 30 Days\" * \ud83d\ude80 github project address: https://github.com/lyhue1991/eat_tensorflow2_in_30_days * \ud83d\udc33 Column address: https://www.kesci.com/home/column/5d8ef3c3037db3002d3aa3a0 \u3010The code can be run directly in the cloud after fork, no need to configure the environment\u3011","title":"\u4e94\uff0c\u9f13\u52b1\u548c\u8054\u7cfb\u4f5c\u8005 \ud83c\udf88\ud83c\udf88"},{"location":"#1-pytorch--or-tensorflow2-","text":"Conclusion first: If you are an engineer, TensorFlow2 should be preferred. If you are a student or researcher, Pytorch should be preferred. If there is enough time, it is best to learn and master both TensorFlow2 and Pytorch. Why to master both? The most important thing in the industry is the production of models. At present, most domestic Internet companies only support the online deployment of TensorFlow models, not Pytorch. And the industry pays more attention to the high availability of the model. Many times, the mature model architectures are used, and the need for debugging is not really large. In research, the most important thing is to publish articles quickly, and they need to try some newer model architectures. Pytorch has some advantages over TensorFlow2 in terms of ease of use and is more convenient for debugging. Pytorch has occupied more than half of the academic world since 2019 with more cutting-edge research results. TensorFlow2 and Pytorch are actually very similar in overall style. After learning one, it will be easier to learn the other. Mastering both frameworks provides you oppurtunities to contribute to more open source model cases. For mastering Tensorflow:","title":"1. Pytorch\ud83d\udd25  or TensorFlow2 \ud83c\udf4e"},{"location":"#-eat-tensorflow2-in-30-days-httpsgithubcomlyhue1991eat_tensorflow2_in_30_days","text":"","title":"\ud83c\udf4a \"Eat TensorFlow2 in 30 days\"\uff1a https://github.com/lyhue1991/eat_tensorflow2_in_30_days"},{"location":"#2-what-should-you-know-before-reading-this-book-","text":"This book assumes that the reader has a certain foundation of machine learning and deep learning, and has used Keras or TensorFlow or Pytorch to build and train simple models. For students who do not have any machine learning and deep learning foundations, it is recommended to read the first part of the book \"Deep Learning with Python\" when studying this book. The book \"Deep Learning with Python\" is written by Francois Chollet, the father of Keras. The book assumes that the reader has no machine learning knowledge and uses Keras as a tool. It uses many examples to demonstrate the best practices of deep learning. The book is easy to understand as there is no mathematical formula in the book. The book mainly focuses on cultivating readers' deep learning intuition. The contents of the 4 chapters of the first part of the book \"Deep Learning for python\" are as follows: What is deep learning The mathematical building blocks of neural networks Getting started with Neural Networks Fundamentals of Machine learning","title":"2. What Should You Know Before Reading This Book? \ud83d\udc7c"},{"location":"#3-writing-style-of-this-book-","text":"This book is a Pytorch introductory tool that is extremely friendly to human users. \"Don't let the readers think\" is the highest pursuit of this book. This book is mainly organized and written on the basis of referring to Pytorch official documentation together with its functions. Although the official Pytorch documentation is quite concise and clear, this book has made a lot of optimizations in the chapter structure and selection of examples, which is more user-friendly. This book is designed in accordance with the difficulty of the content, the reader's search habits and Pytorch's own hierarchical structure. The content is designed step by step, with clear levels, and it is convenient to find corresponding examples according to functions. This book is as simple and structured as possible in the design of examples to enhance the legibility and versatility of examples. Most of the code snippets are ready to use in practice. If the difficulty of mastering Pytorch by learning the official Pytorch documentation is about 5, then the difficulty of learning to master Pytorch through this book should be about 2.","title":"3. Writing style of this book \ud83c\udf49"},{"location":"#4-how-to-use-this-book-","text":"1. Study Plan Number of days required to eat this book: This book was written by the author about 3 months after work, and most readers should be able to learn it in 20 days . How many hours a day should you spend: It is estimated that the study time spent every day is between 30 minutes and 2 hours. Note: This book is also very suitable as a reference for Pytorch's tool manual when the project is implemented. Click the blue title of the learning content to enter the chapter. Date Contents Difficulty Est. Time Update Status 1. Pytorch's modeling process \u2b50\ufe0f 0hour \u2705 day1 1-1. Example of structured data modeling process \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day2 1-2. Example of image data modeling process \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day3 1-3. Example of text data modeling process \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day4 1-4. Example of time series data modeling process \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 2. The core concept of Pytorch \u2b50\ufe0f 0hour \u2705 day5 2-1. Tensor data structure \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day6 2-2. Automatic differentiation mechanism \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day7 2-3. Dynamic calculation diagram \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 3. The hierarchy of Pytorch \u2b50\ufe0f 0hour \u2705 day8 3-1. Low-level API demonstration \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day9 3-2. Intermediate API demonstration \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day10 3-3. High-level API demonstration \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 4. Pytorch's low-level API \u2b50\ufe0f 0hour \u2705 day11 4-1. Tensor structure operation \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day12 4-2. Mathematical operations of tensors \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day13 4-3. nn.functional and nn.Module \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 5. Pytorch's intermediate-level API \u2b50\ufe0f 0hour \u2705 day14 5-1. Dataset and DataLoader \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 2hour \u2705 day15 5-2. Model layer \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day16 5-3. Loss function \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day17 5-4. TensorBoard TensorBoard visualization \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 6. Pytorch's high-level API \u2b50\ufe0f 0hour \u2705 day18 6-1. 3 ways to build a model \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day19 6-2. 3 ways to train a model \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 day20 6-3. Use GPU to train model \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f 1hour \u2705 2. Learning environment All the source code of this book has been written and tested in jupyter. It is recommended to clone to the local through git and run and learn interactively in jupyter. In order to directly open the markdown file in jupyter, it is recommended to install jupytext and convert the markdown to an ipynb file. #clone the source code of this book to local, use the code cloud mirror warehouse to download faster in china #!git clone https://gitee.com/Python_Ai_Road/eat_pytorch_in_20_days #it is recommended to install jupytext on jupyter notebook so that the markdown files of each chapter of this book can be run as ipynb files #!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U jupytext #it is recommended to install the latest version of pytorch on jupyter notebook to test the code in this book #!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U torch torchvision torchtext torchkeras import torch from torch import nn print ( \"torch version:\" , torch . __version__ ) a = torch . tensor ([[ 2 , 1 ]]) b = torch . tensor ([[ - 1 , 2 ]]) c = a @b . t () print ( \"[[2,1]]@[[-1],[2]] =\" , c . item ()) torch version: 1.5.0 [[2,1]]@[[-1],[2]] = 0","title":"4. How to use this Book? \u23f0"},{"location":"#5-contact-and-support-the-author-","text":"If this book is helpful to you and want to encourage the author, remember to add a star\u2b50\ufe0f to this project and share it with your friends\ud83d\ude0a! If you need to further communicate with the author on the understanding of the content of this book, please leave a message under the public account \"The Beauty of Python and Algorithms\". The author has limited time and energy and will respond as appropriate. You can also reply to keywords in the background of the official account: add group, join the reader exchange group and discuss with you.","title":"5. Contact and support the author \ud83c\udf88\ud83c\udf88"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/","text":"\u4e00\u3001Pytorch\u7684\u5efa\u6a21\u6d41\u7a0b # \u4f7f\u7528Pytorch\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u4e00\u822c\u6d41\u7a0b\u5305\u62ec\uff1a 1\uff0c\u51c6\u5907\u6570\u636e 2\uff0c\u5b9a\u4e49\u6a21\u578b 3\uff0c\u8bad\u7ec3\u6a21\u578b 4\uff0c\u8bc4\u4f30\u6a21\u578b 5\uff0c\u4f7f\u7528\u6a21\u578b 6\uff0c\u4fdd\u5b58\u6a21\u578b\u3002 \u5bf9\u65b0\u624b\u6765\u8bf4\uff0c\u5176\u4e2d\u6700\u56f0\u96be\u7684\u90e8\u5206\u5b9e\u9645\u4e0a\u662f\u51c6\u5907\u6570\u636e\u8fc7\u7a0b\u3002 \u6211\u4eec\u5728\u5b9e\u8df5\u4e2d\u901a\u5e38\u4f1a\u9047\u5230\u7684\u6570\u636e\u7c7b\u578b\u5305\u62ec\u7ed3\u6784\u5316\u6570\u636e\uff0c\u56fe\u7247\u6570\u636e\uff0c\u6587\u672c\u6570\u636e\uff0c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002 \u6211\u4eec\u5c06\u5206\u522b\u4ee5titanic\u751f\u5b58\u9884\u6d4b\u95ee\u9898\uff0ccifar2\u56fe\u7247\u5206\u7c7b\u95ee\u9898\uff0cimdb\u7535\u5f71\u8bc4\u8bba\u5206\u7c7b\u95ee\u9898\uff0c\u56fd\u5185\u65b0\u51a0\u75ab\u60c5\u7ed3\u675f\u65f6\u95f4\u9884\u6d4b\u95ee\u9898\u4e3a\u4f8b\uff0c\u6f14\u793a\u5e94\u7528Pytorch\u5bf9\u8fd9\u56db\u7c7b\u6570\u636e\u7684\u5efa\u6a21\u65b9\u6cd5\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e00\u3001Pytorch\u7684\u5efa\u6a21\u6d41\u7a0b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/#\u4e00pytorch\u7684\u5efa\u6a21\u6d41\u7a0b","text":"\u4f7f\u7528Pytorch\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u4e00\u822c\u6d41\u7a0b\u5305\u62ec\uff1a 1\uff0c\u51c6\u5907\u6570\u636e 2\uff0c\u5b9a\u4e49\u6a21\u578b 3\uff0c\u8bad\u7ec3\u6a21\u578b 4\uff0c\u8bc4\u4f30\u6a21\u578b 5\uff0c\u4f7f\u7528\u6a21\u578b 6\uff0c\u4fdd\u5b58\u6a21\u578b\u3002 \u5bf9\u65b0\u624b\u6765\u8bf4\uff0c\u5176\u4e2d\u6700\u56f0\u96be\u7684\u90e8\u5206\u5b9e\u9645\u4e0a\u662f\u51c6\u5907\u6570\u636e\u8fc7\u7a0b\u3002 \u6211\u4eec\u5728\u5b9e\u8df5\u4e2d\u901a\u5e38\u4f1a\u9047\u5230\u7684\u6570\u636e\u7c7b\u578b\u5305\u62ec\u7ed3\u6784\u5316\u6570\u636e\uff0c\u56fe\u7247\u6570\u636e\uff0c\u6587\u672c\u6570\u636e\uff0c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002 \u6211\u4eec\u5c06\u5206\u522b\u4ee5titanic\u751f\u5b58\u9884\u6d4b\u95ee\u9898\uff0ccifar2\u56fe\u7247\u5206\u7c7b\u95ee\u9898\uff0cimdb\u7535\u5f71\u8bc4\u8bba\u5206\u7c7b\u95ee\u9898\uff0c\u56fd\u5185\u65b0\u51a0\u75ab\u60c5\u7ed3\u675f\u65f6\u95f4\u9884\u6d4b\u95ee\u9898\u4e3a\u4f8b\uff0c\u6f14\u793a\u5e94\u7528Pytorch\u5bf9\u8fd9\u56db\u7c7b\u6570\u636e\u7684\u5efa\u6a21\u65b9\u6cd5\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e00\u3001Pytorch\u7684\u5efa\u6a21\u6d41\u7a0b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-1%2C%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/","text":"1-1,\u7ed3\u6784\u5316\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b # import os import datetime #\u6253\u5370\u65f6\u95f4 def printbar (): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) #mac\u7cfb\u7edf\u4e0apytorch\u548cmatplotlib\u5728jupyter\u4e2d\u540c\u65f6\u8dd1\u9700\u8981\u66f4\u6539\u73af\u5883\u53d8\u91cf os . environ [ \"KMP_DUPLICATE_LIB_OK\" ] = \"TRUE\" \u4e00\uff0c\u51c6\u5907\u6570\u636e # titanic\u6570\u636e\u96c6\u7684\u76ee\u6807\u662f\u6839\u636e\u4e58\u5ba2\u4fe1\u606f\u9884\u6d4b\u4ed6\u4eec\u5728Titanic\u53f7\u649e\u51fb\u51b0\u5c71\u6c89\u6ca1\u540e\u80fd\u5426\u751f\u5b58\u3002 \u7ed3\u6784\u5316\u6570\u636e\u4e00\u822c\u4f1a\u4f7f\u7528Pandas\u4e2d\u7684DataFrame\u8fdb\u884c\u9884\u5904\u7406\u3002 import numpy as np import pandas as pd import matplotlib.pyplot as plt import torch from torch import nn from torch.utils.data import Dataset , DataLoader , TensorDataset dftrain_raw = pd . read_csv ( '../data/titanic/train.csv' ) dftest_raw = pd . read_csv ( '../data/titanic/test.csv' ) dftrain_raw . head ( 10 ) \u5b57\u6bb5\u8bf4\u660e\uff1a Survived:0\u4ee3\u8868\u6b7b\u4ea1\uff0c1\u4ee3\u8868\u5b58\u6d3b\u3010y\u6807\u7b7e\u3011 Pclass:\u4e58\u5ba2\u6240\u6301\u7968\u7c7b\uff0c\u6709\u4e09\u79cd\u503c(1,2,3) \u3010\u8f6c\u6362\u6210onehot\u7f16\u7801\u3011 Name:\u4e58\u5ba2\u59d3\u540d \u3010\u820d\u53bb\u3011 Sex:\u4e58\u5ba2\u6027\u522b \u3010\u8f6c\u6362\u6210bool\u7279\u5f81\u3011 Age:\u4e58\u5ba2\u5e74\u9f84(\u6709\u7f3a\u5931) \u3010\u6570\u503c\u7279\u5f81\uff0c\u6dfb\u52a0\u201c\u5e74\u9f84\u662f\u5426\u7f3a\u5931\u201d\u4f5c\u4e3a\u8f85\u52a9\u7279\u5f81\u3011 SibSp:\u4e58\u5ba2\u5144\u5f1f\u59d0\u59b9/\u914d\u5076\u7684\u4e2a\u6570(\u6574\u6570\u503c) \u3010\u6570\u503c\u7279\u5f81\u3011 Parch:\u4e58\u5ba2\u7236\u6bcd/\u5b69\u5b50\u7684\u4e2a\u6570(\u6574\u6570\u503c)\u3010\u6570\u503c\u7279\u5f81\u3011 Ticket:\u7968\u53f7(\u5b57\u7b26\u4e32)\u3010\u820d\u53bb\u3011 Fare:\u4e58\u5ba2\u6240\u6301\u7968\u7684\u4ef7\u683c(\u6d6e\u70b9\u6570\uff0c0-500\u4e0d\u7b49) \u3010\u6570\u503c\u7279\u5f81\u3011 Cabin:\u4e58\u5ba2\u6240\u5728\u8239\u8231(\u6709\u7f3a\u5931) \u3010\u6dfb\u52a0\u201c\u6240\u5728\u8239\u8231\u662f\u5426\u7f3a\u5931\u201d\u4f5c\u4e3a\u8f85\u52a9\u7279\u5f81\u3011 Embarked:\u4e58\u5ba2\u767b\u8239\u6e2f\u53e3:S\u3001C\u3001Q(\u6709\u7f3a\u5931)\u3010\u8f6c\u6362\u6210onehot\u7f16\u7801\uff0c\u56db\u7ef4\u5ea6 S,C,Q,nan\u3011 \u5229\u7528Pandas\u7684\u6570\u636e\u53ef\u89c6\u5316\u529f\u80fd\u6211\u4eec\u53ef\u4ee5\u7b80\u5355\u5730\u8fdb\u884c\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790EDA\uff08Exploratory Data Analysis\uff09\u3002 label\u5206\u5e03\u60c5\u51b5 % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw [ 'Survived' ] . value_counts () . plot ( kind = 'bar' , figsize = ( 12 , 8 ), fontsize = 15 , rot = 0 ) ax . set_ylabel ( 'Counts' , fontsize = 15 ) ax . set_xlabel ( 'Survived' , fontsize = 15 ) plt . show () \u5e74\u9f84\u5206\u5e03\u60c5\u51b5 % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw [ 'Age' ] . plot ( kind = 'hist' , bins = 20 , color = 'purple' , figsize = ( 12 , 8 ), fontsize = 15 ) ax . set_ylabel ( 'Frequency' , fontsize = 15 ) ax . set_xlabel ( 'Age' , fontsize = 15 ) plt . show () \u5e74\u9f84\u548clabel\u7684\u76f8\u5173\u6027 % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw . query ( 'Survived == 0' )[ 'Age' ] . plot ( kind = 'density' , figsize = ( 12 , 8 ), fontsize = 15 ) dftrain_raw . query ( 'Survived == 1' )[ 'Age' ] . plot ( kind = 'density' , figsize = ( 12 , 8 ), fontsize = 15 ) ax . legend ([ 'Survived==0' , 'Survived==1' ], fontsize = 12 ) ax . set_ylabel ( 'Density' , fontsize = 15 ) ax . set_xlabel ( 'Age' , fontsize = 15 ) plt . show () \u4e0b\u9762\u4e3a\u6b63\u5f0f\u7684\u6570\u636e\u9884\u5904\u7406 def preprocessing ( dfdata ): dfresult = pd . DataFrame () #Pclass dfPclass = pd . get_dummies ( dfdata [ 'Pclass' ]) dfPclass . columns = [ 'Pclass_' + str ( x ) for x in dfPclass . columns ] dfresult = pd . concat ([ dfresult , dfPclass ], axis = 1 ) #Sex dfSex = pd . get_dummies ( dfdata [ 'Sex' ]) dfresult = pd . concat ([ dfresult , dfSex ], axis = 1 ) #Age dfresult [ 'Age' ] = dfdata [ 'Age' ] . fillna ( 0 ) dfresult [ 'Age_null' ] = pd . isna ( dfdata [ 'Age' ]) . astype ( 'int32' ) #SibSp,Parch,Fare dfresult [ 'SibSp' ] = dfdata [ 'SibSp' ] dfresult [ 'Parch' ] = dfdata [ 'Parch' ] dfresult [ 'Fare' ] = dfdata [ 'Fare' ] #Carbin dfresult [ 'Cabin_null' ] = pd . isna ( dfdata [ 'Cabin' ]) . astype ( 'int32' ) #Embarked dfEmbarked = pd . get_dummies ( dfdata [ 'Embarked' ], dummy_na = True ) dfEmbarked . columns = [ 'Embarked_' + str ( x ) for x in dfEmbarked . columns ] dfresult = pd . concat ([ dfresult , dfEmbarked ], axis = 1 ) return ( dfresult ) x_train = preprocessing ( dftrain_raw ) . values y_train = dftrain_raw [[ 'Survived' ]] . values x_test = preprocessing ( dftest_raw ) . values y_test = dftest_raw [[ 'Survived' ]] . values print ( \"x_train.shape =\" , x_train . shape ) print ( \"x_test.shape =\" , x_test . shape ) print ( \"y_train.shape =\" , y_train . shape ) print ( \"y_test.shape =\" , y_test . shape ) x_train.shape = (712, 15) x_test.shape = (179, 15) y_train.shape = (712, 1) y_test.shape = (179, 1) \u8fdb\u4e00\u6b65\u4f7f\u7528DataLoader\u548cTensorDataset\u5c01\u88c5\u6210\u53ef\u4ee5\u8fed\u4ee3\u7684\u6570\u636e\u7ba1\u9053\u3002 dl_train = DataLoader ( TensorDataset ( torch . tensor ( x_train ) . float (), torch . tensor ( y_train ) . float ()), shuffle = True , batch_size = 8 ) dl_valid = DataLoader ( TensorDataset ( torch . tensor ( x_test ) . float (), torch . tensor ( y_test ) . float ()), shuffle = False , batch_size = 8 ) # \u6d4b\u8bd5\u6570\u636e\u7ba1\u9053 for features , labels in dl_train : print ( features , labels ) break tensor([[ 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 7.8958, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000], [ 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 30.5000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000], [ 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 31.0000, 0.0000, 1.0000, 0.0000, 113.2750, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000], [ 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 60.0000, 0.0000, 0.0000, 0.0000, 26.5500, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000], [ 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 28.0000, 0.0000, 0.0000, 0.0000, 22.5250, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000], [ 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 32.0000, 0.0000, 0.0000, 0.0000, 8.3625, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000], [ 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 28.0000, 0.0000, 0.0000, 0.0000, 13.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000], [ 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 36.0000, 0.0000, 0.0000, 1.0000, 512.3292, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000]]) tensor([[0.], [1.], [1.], [0.], [0.], [0.], [1.], [1.]]) \u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b # \u4f7f\u7528Pytorch\u901a\u5e38\u6709\u4e09\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528nn.Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u6a21\u578b\u5e76\u8f85\u52a9\u5e94\u7528\u6a21\u578b\u5bb9\u5668\u8fdb\u884c\u5c01\u88c5\u3002 \u6b64\u5904\u9009\u62e9\u4f7f\u7528\u6700\u7b80\u5355\u7684nn.Sequential\uff0c\u6309\u5c42\u987a\u5e8f\u6a21\u578b\u3002 def create_net (): net = nn . Sequential () net . add_module ( \"linear1\" , nn . Linear ( 15 , 20 )) net . add_module ( \"relu1\" , nn . ReLU ()) net . add_module ( \"linear2\" , nn . Linear ( 20 , 15 )) net . add_module ( \"relu2\" , nn . ReLU ()) net . add_module ( \"linear3\" , nn . Linear ( 15 , 1 )) net . add_module ( \"sigmoid\" , nn . Sigmoid ()) return net net = create_net () print ( net ) Sequential( (linear1): Linear(in_features=15, out_features=20, bias=True) (relu1): ReLU() (linear2): Linear(in_features=20, out_features=15, bias=True) (relu2): ReLU() (linear3): Linear(in_features=15, out_features=1, bias=True) (sigmoid): Sigmoid() ) from torchkeras import summary summary ( net , input_shape = ( 15 ,)) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Linear-1 [-1, 20] 320 ReLU-2 [-1, 20] 0 Linear-3 [-1, 15] 315 ReLU-4 [-1, 15] 0 Linear-5 [-1, 1] 16 Sigmoid-6 [-1, 1] 0 ================================================================ Total params: 651 Trainable params: 651 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.000057 Forward/backward pass size (MB): 0.000549 Params size (MB): 0.002483 Estimated Total Size (MB): 0.003090 ---------------------------------------------------------------- \u4e09\uff0c\u8bad\u7ec3\u6a21\u578b # Pytorch\u901a\u5e38\u9700\u8981\u7528\u6237\u7f16\u5199\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\uff0c\u8bad\u7ec3\u5faa\u73af\u7684\u4ee3\u7801\u98ce\u683c\u56e0\u4eba\u800c\u5f02\u3002 \u67093\u7c7b\u5178\u578b\u7684\u8bad\u7ec3\u5faa\u73af\u4ee3\u7801\u98ce\u683c\uff1a\u811a\u672c\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u51fd\u6570\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u7c7b\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\u3002 \u6b64\u5904\u4ecb\u7ecd\u4e00\u79cd\u8f83\u901a\u7528\u7684\u811a\u672c\u5f62\u5f0f\u3002 from sklearn.metrics import accuracy_score loss_func = nn . BCELoss () optimizer = torch . optim . Adam ( params = net . parameters (), lr = 0.01 ) metric_func = lambda y_pred , y_true : accuracy_score ( y_true . data . numpy (), y_pred . data . numpy () > 0.5 ) metric_name = \"accuracy\" epochs = 10 log_step_freq = 30 dfhistory = pd . DataFrame ( columns = [ \"epoch\" , \"loss\" , metric_name , \"val_loss\" , \"val_\" + metric_name ]) print ( \"Start Training...\" ) nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \"==========\" * 8 + \" %s \" % nowtime ) for epoch in range ( 1 , epochs + 1 ): # 1\uff0c\u8bad\u7ec3\u5faa\u73af------------------------------------------------- net . train () loss_sum = 0.0 metric_sum = 0.0 step = 1 for step , ( features , labels ) in enumerate ( dl_train , 1 ): # \u68af\u5ea6\u6e05\u96f6 optimizer . zero_grad () # \u6b63\u5411\u4f20\u64ad\u6c42\u635f\u5931 predictions = net ( features ) loss = loss_func ( predictions , labels ) metric = metric_func ( predictions , labels ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 loss . backward () optimizer . step () # \u6253\u5370batch\u7ea7\u522b\u65e5\u5fd7 loss_sum += loss . item () metric_sum += metric . item () if step % log_step_freq == 0 : print (( \"[step = %d ] loss: %.3f , \" + metric_name + \": %.3f \" ) % ( step , loss_sum / step , metric_sum / step )) # 2\uff0c\u9a8c\u8bc1\u5faa\u73af------------------------------------------------- net . eval () val_loss_sum = 0.0 val_metric_sum = 0.0 val_step = 1 for val_step , ( features , labels ) in enumerate ( dl_valid , 1 ): # \u5173\u95ed\u68af\u5ea6\u8ba1\u7b97 with torch . no_grad (): predictions = net ( features ) val_loss = loss_func ( predictions , labels ) val_metric = metric_func ( predictions , labels ) val_loss_sum += val_loss . item () val_metric_sum += val_metric . item () # 3\uff0c\u8bb0\u5f55\u65e5\u5fd7------------------------------------------------- info = ( epoch , loss_sum / step , metric_sum / step , val_loss_sum / val_step , val_metric_sum / val_step ) dfhistory . loc [ epoch - 1 ] = info # \u6253\u5370epoch\u7ea7\u522b\u65e5\u5fd7 print (( \" \\n EPOCH = %d , loss = %.3f ,\" + metric_name + \\ \" = %.3f , val_loss = %.3f , \" + \"val_\" + metric_name + \" = %.3f \" ) % info ) nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) print ( 'Finished Training...' ) Start Training... ================================================================================2020-06-17 20:53:49 [step = 30] loss: 0.703, accuracy: 0.583 [step = 60] loss: 0.629, accuracy: 0.675 EPOCH = 1, loss = 0.643,accuracy = 0.673, val_loss = 0.621, val_accuracy = 0.725 ================================================================================2020-06-17 20:53:49 [step = 30] loss: 0.653, accuracy: 0.662 [step = 60] loss: 0.624, accuracy: 0.673 EPOCH = 2, loss = 0.621,accuracy = 0.669, val_loss = 0.519, val_accuracy = 0.708 ================================================================================2020-06-17 20:53:49 [step = 30] loss: 0.582, accuracy: 0.688 [step = 60] loss: 0.555, accuracy: 0.723 EPOCH = 3, loss = 0.543,accuracy = 0.740, val_loss = 0.516, val_accuracy = 0.741 ================================================================================2020-06-17 20:53:49 [step = 30] loss: 0.563, accuracy: 0.721 [step = 60] loss: 0.528, accuracy: 0.752 EPOCH = 4, loss = 0.515,accuracy = 0.764, val_loss = 0.471, val_accuracy = 0.777 ================================================================================2020-06-17 20:53:50 [step = 30] loss: 0.433, accuracy: 0.783 [step = 60] loss: 0.477, accuracy: 0.785 EPOCH = 5, loss = 0.489,accuracy = 0.785, val_loss = 0.447, val_accuracy = 0.804 ================================================================================2020-06-17 20:53:50 [step = 30] loss: 0.460, accuracy: 0.812 [step = 60] loss: 0.477, accuracy: 0.798 EPOCH = 6, loss = 0.474,accuracy = 0.798, val_loss = 0.451, val_accuracy = 0.772 ================================================================================2020-06-17 20:53:50 [step = 30] loss: 0.516, accuracy: 0.792 [step = 60] loss: 0.496, accuracy: 0.779 EPOCH = 7, loss = 0.473,accuracy = 0.794, val_loss = 0.485, val_accuracy = 0.783 ================================================================================2020-06-17 20:53:50 [step = 30] loss: 0.472, accuracy: 0.779 [step = 60] loss: 0.487, accuracy: 0.794 EPOCH = 8, loss = 0.474,accuracy = 0.791, val_loss = 0.446, val_accuracy = 0.788 ================================================================================2020-06-17 20:53:50 [step = 30] loss: 0.492, accuracy: 0.771 [step = 60] loss: 0.445, accuracy: 0.800 EPOCH = 9, loss = 0.464,accuracy = 0.796, val_loss = 0.519, val_accuracy = 0.746 ================================================================================2020-06-17 20:53:50 [step = 30] loss: 0.436, accuracy: 0.796 [step = 60] loss: 0.460, accuracy: 0.794 EPOCH = 10, loss = 0.462,accuracy = 0.787, val_loss = 0.415, val_accuracy = 0.810 ================================================================================2020-06-17 20:53:51 Finished Training... \u56db\uff0c\u8bc4\u4f30\u6a21\u578b # \u6211\u4eec\u9996\u5148\u8bc4\u4f30\u4e00\u4e0b\u6a21\u578b\u5728\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6548\u679c\u3002 dfhistory % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( dfhistory , metric ): train_metrics = dfhistory [ metric ] val_metrics = dfhistory [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( dfhistory , \"loss\" ) plot_metric ( dfhistory , \"accuracy\" ) \u4e94\uff0c\u4f7f\u7528\u6a21\u578b # #\u9884\u6d4b\u6982\u7387 y_pred_probs = net ( torch . tensor ( x_test [ 0 : 10 ]) . float ()) . data y_pred_probs tensor([[0.0119], [0.6029], [0.2970], [0.5717], [0.5034], [0.8655], [0.0572], [0.9182], [0.5038], [0.1739]]) #\u9884\u6d4b\u7c7b\u522b y_pred = torch . where ( y_pred_probs > 0.5 , torch . ones_like ( y_pred_probs ), torch . zeros_like ( y_pred_probs )) y_pred tensor([[0.], [1.], [0.], [1.], [1.], [1.], [0.], [1.], [1.], [0.]]) \u516d\uff0c\u4fdd\u5b58\u6a21\u578b # Pytorch \u6709\u4e24\u79cd\u4fdd\u5b58\u6a21\u578b\u7684\u65b9\u5f0f\uff0c\u90fd\u662f\u901a\u8fc7\u8c03\u7528pickle\u5e8f\u5217\u5316\u65b9\u6cd5\u5b9e\u73b0\u7684\u3002 \u7b2c\u4e00\u79cd\u65b9\u6cd5\u53ea\u4fdd\u5b58\u6a21\u578b\u53c2\u6570\u3002 \u7b2c\u4e8c\u79cd\u65b9\u6cd5\u4fdd\u5b58\u5b8c\u6574\u6a21\u578b\u3002 \u63a8\u8350\u4f7f\u7528\u7b2c\u4e00\u79cd\uff0c\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u53ef\u80fd\u5728\u5207\u6362\u8bbe\u5907\u548c\u76ee\u5f55\u7684\u65f6\u5019\u51fa\u73b0\u5404\u79cd\u95ee\u9898\u3002 1\uff0c\u4fdd\u5b58\u6a21\u578b\u53c2\u6570(\u63a8\u8350) print ( net . state_dict () . keys ()) odict_keys(['linear1.weight', 'linear1.bias', 'linear2.weight', 'linear2.bias', 'linear3.weight', 'linear3.bias']) # \u4fdd\u5b58\u6a21\u578b\u53c2\u6570 torch . save ( net . state_dict (), \"../data/net_parameter.pkl\" ) net_clone = create_net () net_clone . load_state_dict ( torch . load ( \"../data/net_parameter.pkl\" )) net_clone . forward ( torch . tensor ( x_test [ 0 : 10 ]) . float ()) . data tensor([[0.0119], [0.6029], [0.2970], [0.5717], [0.5034], [0.8655], [0.0572], [0.9182], [0.5038], [0.1739]]) 2\uff0c\u4fdd\u5b58\u5b8c\u6574\u6a21\u578b(\u4e0d\u63a8\u8350) torch . save ( net , '../data/net_model.pkl' ) net_loaded = torch . load ( '../data/net_model.pkl' ) net_loaded ( torch . tensor ( x_test [ 0 : 10 ]) . float ()) . data tensor([[0.0119], [0.6029], [0.2970], [0.5717], [0.5034], [0.8655], [0.0572], [0.9182], [0.5038], [0.1739]]) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"1-1,\u7ed3\u6784\u5316\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-1%2C%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#1-1\u7ed3\u6784\u5316\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b","text":"import os import datetime #\u6253\u5370\u65f6\u95f4 def printbar (): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) #mac\u7cfb\u7edf\u4e0apytorch\u548cmatplotlib\u5728jupyter\u4e2d\u540c\u65f6\u8dd1\u9700\u8981\u66f4\u6539\u73af\u5883\u53d8\u91cf os . environ [ \"KMP_DUPLICATE_LIB_OK\" ] = \"TRUE\"","title":"1-1,\u7ed3\u6784\u5316\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-1%2C%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e00\u51c6\u5907\u6570\u636e","text":"titanic\u6570\u636e\u96c6\u7684\u76ee\u6807\u662f\u6839\u636e\u4e58\u5ba2\u4fe1\u606f\u9884\u6d4b\u4ed6\u4eec\u5728Titanic\u53f7\u649e\u51fb\u51b0\u5c71\u6c89\u6ca1\u540e\u80fd\u5426\u751f\u5b58\u3002 \u7ed3\u6784\u5316\u6570\u636e\u4e00\u822c\u4f1a\u4f7f\u7528Pandas\u4e2d\u7684DataFrame\u8fdb\u884c\u9884\u5904\u7406\u3002 import numpy as np import pandas as pd import matplotlib.pyplot as plt import torch from torch import nn from torch.utils.data import Dataset , DataLoader , TensorDataset dftrain_raw = pd . read_csv ( '../data/titanic/train.csv' ) dftest_raw = pd . read_csv ( '../data/titanic/test.csv' ) dftrain_raw . head ( 10 ) \u5b57\u6bb5\u8bf4\u660e\uff1a Survived:0\u4ee3\u8868\u6b7b\u4ea1\uff0c1\u4ee3\u8868\u5b58\u6d3b\u3010y\u6807\u7b7e\u3011 Pclass:\u4e58\u5ba2\u6240\u6301\u7968\u7c7b\uff0c\u6709\u4e09\u79cd\u503c(1,2,3) \u3010\u8f6c\u6362\u6210onehot\u7f16\u7801\u3011 Name:\u4e58\u5ba2\u59d3\u540d \u3010\u820d\u53bb\u3011 Sex:\u4e58\u5ba2\u6027\u522b \u3010\u8f6c\u6362\u6210bool\u7279\u5f81\u3011 Age:\u4e58\u5ba2\u5e74\u9f84(\u6709\u7f3a\u5931) \u3010\u6570\u503c\u7279\u5f81\uff0c\u6dfb\u52a0\u201c\u5e74\u9f84\u662f\u5426\u7f3a\u5931\u201d\u4f5c\u4e3a\u8f85\u52a9\u7279\u5f81\u3011 SibSp:\u4e58\u5ba2\u5144\u5f1f\u59d0\u59b9/\u914d\u5076\u7684\u4e2a\u6570(\u6574\u6570\u503c) \u3010\u6570\u503c\u7279\u5f81\u3011 Parch:\u4e58\u5ba2\u7236\u6bcd/\u5b69\u5b50\u7684\u4e2a\u6570(\u6574\u6570\u503c)\u3010\u6570\u503c\u7279\u5f81\u3011 Ticket:\u7968\u53f7(\u5b57\u7b26\u4e32)\u3010\u820d\u53bb\u3011 Fare:\u4e58\u5ba2\u6240\u6301\u7968\u7684\u4ef7\u683c(\u6d6e\u70b9\u6570\uff0c0-500\u4e0d\u7b49) \u3010\u6570\u503c\u7279\u5f81\u3011 Cabin:\u4e58\u5ba2\u6240\u5728\u8239\u8231(\u6709\u7f3a\u5931) \u3010\u6dfb\u52a0\u201c\u6240\u5728\u8239\u8231\u662f\u5426\u7f3a\u5931\u201d\u4f5c\u4e3a\u8f85\u52a9\u7279\u5f81\u3011 Embarked:\u4e58\u5ba2\u767b\u8239\u6e2f\u53e3:S\u3001C\u3001Q(\u6709\u7f3a\u5931)\u3010\u8f6c\u6362\u6210onehot\u7f16\u7801\uff0c\u56db\u7ef4\u5ea6 S,C,Q,nan\u3011 \u5229\u7528Pandas\u7684\u6570\u636e\u53ef\u89c6\u5316\u529f\u80fd\u6211\u4eec\u53ef\u4ee5\u7b80\u5355\u5730\u8fdb\u884c\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790EDA\uff08Exploratory Data Analysis\uff09\u3002 label\u5206\u5e03\u60c5\u51b5 % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw [ 'Survived' ] . value_counts () . plot ( kind = 'bar' , figsize = ( 12 , 8 ), fontsize = 15 , rot = 0 ) ax . set_ylabel ( 'Counts' , fontsize = 15 ) ax . set_xlabel ( 'Survived' , fontsize = 15 ) plt . show () \u5e74\u9f84\u5206\u5e03\u60c5\u51b5 % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw [ 'Age' ] . plot ( kind = 'hist' , bins = 20 , color = 'purple' , figsize = ( 12 , 8 ), fontsize = 15 ) ax . set_ylabel ( 'Frequency' , fontsize = 15 ) ax . set_xlabel ( 'Age' , fontsize = 15 ) plt . show () \u5e74\u9f84\u548clabel\u7684\u76f8\u5173\u6027 % matplotlib inline % config InlineBackend . figure_format = 'png' ax = dftrain_raw . query ( 'Survived == 0' )[ 'Age' ] . plot ( kind = 'density' , figsize = ( 12 , 8 ), fontsize = 15 ) dftrain_raw . query ( 'Survived == 1' )[ 'Age' ] . plot ( kind = 'density' , figsize = ( 12 , 8 ), fontsize = 15 ) ax . legend ([ 'Survived==0' , 'Survived==1' ], fontsize = 12 ) ax . set_ylabel ( 'Density' , fontsize = 15 ) ax . set_xlabel ( 'Age' , fontsize = 15 ) plt . show () \u4e0b\u9762\u4e3a\u6b63\u5f0f\u7684\u6570\u636e\u9884\u5904\u7406 def preprocessing ( dfdata ): dfresult = pd . DataFrame () #Pclass dfPclass = pd . get_dummies ( dfdata [ 'Pclass' ]) dfPclass . columns = [ 'Pclass_' + str ( x ) for x in dfPclass . columns ] dfresult = pd . concat ([ dfresult , dfPclass ], axis = 1 ) #Sex dfSex = pd . get_dummies ( dfdata [ 'Sex' ]) dfresult = pd . concat ([ dfresult , dfSex ], axis = 1 ) #Age dfresult [ 'Age' ] = dfdata [ 'Age' ] . fillna ( 0 ) dfresult [ 'Age_null' ] = pd . isna ( dfdata [ 'Age' ]) . astype ( 'int32' ) #SibSp,Parch,Fare dfresult [ 'SibSp' ] = dfdata [ 'SibSp' ] dfresult [ 'Parch' ] = dfdata [ 'Parch' ] dfresult [ 'Fare' ] = dfdata [ 'Fare' ] #Carbin dfresult [ 'Cabin_null' ] = pd . isna ( dfdata [ 'Cabin' ]) . astype ( 'int32' ) #Embarked dfEmbarked = pd . get_dummies ( dfdata [ 'Embarked' ], dummy_na = True ) dfEmbarked . columns = [ 'Embarked_' + str ( x ) for x in dfEmbarked . columns ] dfresult = pd . concat ([ dfresult , dfEmbarked ], axis = 1 ) return ( dfresult ) x_train = preprocessing ( dftrain_raw ) . values y_train = dftrain_raw [[ 'Survived' ]] . values x_test = preprocessing ( dftest_raw ) . values y_test = dftest_raw [[ 'Survived' ]] . values print ( \"x_train.shape =\" , x_train . shape ) print ( \"x_test.shape =\" , x_test . shape ) print ( \"y_train.shape =\" , y_train . shape ) print ( \"y_test.shape =\" , y_test . shape ) x_train.shape = (712, 15) x_test.shape = (179, 15) y_train.shape = (712, 1) y_test.shape = (179, 1) \u8fdb\u4e00\u6b65\u4f7f\u7528DataLoader\u548cTensorDataset\u5c01\u88c5\u6210\u53ef\u4ee5\u8fed\u4ee3\u7684\u6570\u636e\u7ba1\u9053\u3002 dl_train = DataLoader ( TensorDataset ( torch . tensor ( x_train ) . float (), torch . tensor ( y_train ) . float ()), shuffle = True , batch_size = 8 ) dl_valid = DataLoader ( TensorDataset ( torch . tensor ( x_test ) . float (), torch . tensor ( y_test ) . float ()), shuffle = False , batch_size = 8 ) # \u6d4b\u8bd5\u6570\u636e\u7ba1\u9053 for features , labels in dl_train : print ( features , labels ) break tensor([[ 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 7.8958, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000], [ 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 30.5000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000], [ 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 31.0000, 0.0000, 1.0000, 0.0000, 113.2750, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000], [ 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 60.0000, 0.0000, 0.0000, 0.0000, 26.5500, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000], [ 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 28.0000, 0.0000, 0.0000, 0.0000, 22.5250, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000], [ 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 32.0000, 0.0000, 0.0000, 0.0000, 8.3625, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000], [ 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 28.0000, 0.0000, 0.0000, 0.0000, 13.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000], [ 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 36.0000, 0.0000, 0.0000, 1.0000, 512.3292, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000]]) tensor([[0.], [1.], [1.], [0.], [0.], [0.], [1.], [1.]])","title":"\u4e00\uff0c\u51c6\u5907\u6570\u636e"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-1%2C%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e8c\u5b9a\u4e49\u6a21\u578b","text":"\u4f7f\u7528Pytorch\u901a\u5e38\u6709\u4e09\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528nn.Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u6a21\u578b\u5e76\u8f85\u52a9\u5e94\u7528\u6a21\u578b\u5bb9\u5668\u8fdb\u884c\u5c01\u88c5\u3002 \u6b64\u5904\u9009\u62e9\u4f7f\u7528\u6700\u7b80\u5355\u7684nn.Sequential\uff0c\u6309\u5c42\u987a\u5e8f\u6a21\u578b\u3002 def create_net (): net = nn . Sequential () net . add_module ( \"linear1\" , nn . Linear ( 15 , 20 )) net . add_module ( \"relu1\" , nn . ReLU ()) net . add_module ( \"linear2\" , nn . Linear ( 20 , 15 )) net . add_module ( \"relu2\" , nn . ReLU ()) net . add_module ( \"linear3\" , nn . Linear ( 15 , 1 )) net . add_module ( \"sigmoid\" , nn . Sigmoid ()) return net net = create_net () print ( net ) Sequential( (linear1): Linear(in_features=15, out_features=20, bias=True) (relu1): ReLU() (linear2): Linear(in_features=20, out_features=15, bias=True) (relu2): ReLU() (linear3): Linear(in_features=15, out_features=1, bias=True) (sigmoid): Sigmoid() ) from torchkeras import summary summary ( net , input_shape = ( 15 ,)) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Linear-1 [-1, 20] 320 ReLU-2 [-1, 20] 0 Linear-3 [-1, 15] 315 ReLU-4 [-1, 15] 0 Linear-5 [-1, 1] 16 Sigmoid-6 [-1, 1] 0 ================================================================ Total params: 651 Trainable params: 651 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.000057 Forward/backward pass size (MB): 0.000549 Params size (MB): 0.002483 Estimated Total Size (MB): 0.003090 ----------------------------------------------------------------","title":"\u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-1%2C%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e09\u8bad\u7ec3\u6a21\u578b","text":"Pytorch\u901a\u5e38\u9700\u8981\u7528\u6237\u7f16\u5199\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\uff0c\u8bad\u7ec3\u5faa\u73af\u7684\u4ee3\u7801\u98ce\u683c\u56e0\u4eba\u800c\u5f02\u3002 \u67093\u7c7b\u5178\u578b\u7684\u8bad\u7ec3\u5faa\u73af\u4ee3\u7801\u98ce\u683c\uff1a\u811a\u672c\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u51fd\u6570\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u7c7b\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\u3002 \u6b64\u5904\u4ecb\u7ecd\u4e00\u79cd\u8f83\u901a\u7528\u7684\u811a\u672c\u5f62\u5f0f\u3002 from sklearn.metrics import accuracy_score loss_func = nn . BCELoss () optimizer = torch . optim . Adam ( params = net . parameters (), lr = 0.01 ) metric_func = lambda y_pred , y_true : accuracy_score ( y_true . data . numpy (), y_pred . data . numpy () > 0.5 ) metric_name = \"accuracy\" epochs = 10 log_step_freq = 30 dfhistory = pd . DataFrame ( columns = [ \"epoch\" , \"loss\" , metric_name , \"val_loss\" , \"val_\" + metric_name ]) print ( \"Start Training...\" ) nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \"==========\" * 8 + \" %s \" % nowtime ) for epoch in range ( 1 , epochs + 1 ): # 1\uff0c\u8bad\u7ec3\u5faa\u73af------------------------------------------------- net . train () loss_sum = 0.0 metric_sum = 0.0 step = 1 for step , ( features , labels ) in enumerate ( dl_train , 1 ): # \u68af\u5ea6\u6e05\u96f6 optimizer . zero_grad () # \u6b63\u5411\u4f20\u64ad\u6c42\u635f\u5931 predictions = net ( features ) loss = loss_func ( predictions , labels ) metric = metric_func ( predictions , labels ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 loss . backward () optimizer . step () # \u6253\u5370batch\u7ea7\u522b\u65e5\u5fd7 loss_sum += loss . item () metric_sum += metric . item () if step % log_step_freq == 0 : print (( \"[step = %d ] loss: %.3f , \" + metric_name + \": %.3f \" ) % ( step , loss_sum / step , metric_sum / step )) # 2\uff0c\u9a8c\u8bc1\u5faa\u73af------------------------------------------------- net . eval () val_loss_sum = 0.0 val_metric_sum = 0.0 val_step = 1 for val_step , ( features , labels ) in enumerate ( dl_valid , 1 ): # \u5173\u95ed\u68af\u5ea6\u8ba1\u7b97 with torch . no_grad (): predictions = net ( features ) val_loss = loss_func ( predictions , labels ) val_metric = metric_func ( predictions , labels ) val_loss_sum += val_loss . item () val_metric_sum += val_metric . item () # 3\uff0c\u8bb0\u5f55\u65e5\u5fd7------------------------------------------------- info = ( epoch , loss_sum / step , metric_sum / step , val_loss_sum / val_step , val_metric_sum / val_step ) dfhistory . loc [ epoch - 1 ] = info # \u6253\u5370epoch\u7ea7\u522b\u65e5\u5fd7 print (( \" \\n EPOCH = %d , loss = %.3f ,\" + metric_name + \\ \" = %.3f , val_loss = %.3f , \" + \"val_\" + metric_name + \" = %.3f \" ) % info ) nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) print ( 'Finished Training...' ) Start Training... ================================================================================2020-06-17 20:53:49 [step = 30] loss: 0.703, accuracy: 0.583 [step = 60] loss: 0.629, accuracy: 0.675 EPOCH = 1, loss = 0.643,accuracy = 0.673, val_loss = 0.621, val_accuracy = 0.725 ================================================================================2020-06-17 20:53:49 [step = 30] loss: 0.653, accuracy: 0.662 [step = 60] loss: 0.624, accuracy: 0.673 EPOCH = 2, loss = 0.621,accuracy = 0.669, val_loss = 0.519, val_accuracy = 0.708 ================================================================================2020-06-17 20:53:49 [step = 30] loss: 0.582, accuracy: 0.688 [step = 60] loss: 0.555, accuracy: 0.723 EPOCH = 3, loss = 0.543,accuracy = 0.740, val_loss = 0.516, val_accuracy = 0.741 ================================================================================2020-06-17 20:53:49 [step = 30] loss: 0.563, accuracy: 0.721 [step = 60] loss: 0.528, accuracy: 0.752 EPOCH = 4, loss = 0.515,accuracy = 0.764, val_loss = 0.471, val_accuracy = 0.777 ================================================================================2020-06-17 20:53:50 [step = 30] loss: 0.433, accuracy: 0.783 [step = 60] loss: 0.477, accuracy: 0.785 EPOCH = 5, loss = 0.489,accuracy = 0.785, val_loss = 0.447, val_accuracy = 0.804 ================================================================================2020-06-17 20:53:50 [step = 30] loss: 0.460, accuracy: 0.812 [step = 60] loss: 0.477, accuracy: 0.798 EPOCH = 6, loss = 0.474,accuracy = 0.798, val_loss = 0.451, val_accuracy = 0.772 ================================================================================2020-06-17 20:53:50 [step = 30] loss: 0.516, accuracy: 0.792 [step = 60] loss: 0.496, accuracy: 0.779 EPOCH = 7, loss = 0.473,accuracy = 0.794, val_loss = 0.485, val_accuracy = 0.783 ================================================================================2020-06-17 20:53:50 [step = 30] loss: 0.472, accuracy: 0.779 [step = 60] loss: 0.487, accuracy: 0.794 EPOCH = 8, loss = 0.474,accuracy = 0.791, val_loss = 0.446, val_accuracy = 0.788 ================================================================================2020-06-17 20:53:50 [step = 30] loss: 0.492, accuracy: 0.771 [step = 60] loss: 0.445, accuracy: 0.800 EPOCH = 9, loss = 0.464,accuracy = 0.796, val_loss = 0.519, val_accuracy = 0.746 ================================================================================2020-06-17 20:53:50 [step = 30] loss: 0.436, accuracy: 0.796 [step = 60] loss: 0.460, accuracy: 0.794 EPOCH = 10, loss = 0.462,accuracy = 0.787, val_loss = 0.415, val_accuracy = 0.810 ================================================================================2020-06-17 20:53:51 Finished Training...","title":"\u4e09\uff0c\u8bad\u7ec3\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-1%2C%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u56db\u8bc4\u4f30\u6a21\u578b","text":"\u6211\u4eec\u9996\u5148\u8bc4\u4f30\u4e00\u4e0b\u6a21\u578b\u5728\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6548\u679c\u3002 dfhistory % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( dfhistory , metric ): train_metrics = dfhistory [ metric ] val_metrics = dfhistory [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( dfhistory , \"loss\" ) plot_metric ( dfhistory , \"accuracy\" )","title":"\u56db\uff0c\u8bc4\u4f30\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-1%2C%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e94\u4f7f\u7528\u6a21\u578b","text":"#\u9884\u6d4b\u6982\u7387 y_pred_probs = net ( torch . tensor ( x_test [ 0 : 10 ]) . float ()) . data y_pred_probs tensor([[0.0119], [0.6029], [0.2970], [0.5717], [0.5034], [0.8655], [0.0572], [0.9182], [0.5038], [0.1739]]) #\u9884\u6d4b\u7c7b\u522b y_pred = torch . where ( y_pred_probs > 0.5 , torch . ones_like ( y_pred_probs ), torch . zeros_like ( y_pred_probs )) y_pred tensor([[0.], [1.], [0.], [1.], [1.], [1.], [0.], [1.], [1.], [0.]])","title":"\u4e94\uff0c\u4f7f\u7528\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-1%2C%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u516d\u4fdd\u5b58\u6a21\u578b","text":"Pytorch \u6709\u4e24\u79cd\u4fdd\u5b58\u6a21\u578b\u7684\u65b9\u5f0f\uff0c\u90fd\u662f\u901a\u8fc7\u8c03\u7528pickle\u5e8f\u5217\u5316\u65b9\u6cd5\u5b9e\u73b0\u7684\u3002 \u7b2c\u4e00\u79cd\u65b9\u6cd5\u53ea\u4fdd\u5b58\u6a21\u578b\u53c2\u6570\u3002 \u7b2c\u4e8c\u79cd\u65b9\u6cd5\u4fdd\u5b58\u5b8c\u6574\u6a21\u578b\u3002 \u63a8\u8350\u4f7f\u7528\u7b2c\u4e00\u79cd\uff0c\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u53ef\u80fd\u5728\u5207\u6362\u8bbe\u5907\u548c\u76ee\u5f55\u7684\u65f6\u5019\u51fa\u73b0\u5404\u79cd\u95ee\u9898\u3002 1\uff0c\u4fdd\u5b58\u6a21\u578b\u53c2\u6570(\u63a8\u8350) print ( net . state_dict () . keys ()) odict_keys(['linear1.weight', 'linear1.bias', 'linear2.weight', 'linear2.bias', 'linear3.weight', 'linear3.bias']) # \u4fdd\u5b58\u6a21\u578b\u53c2\u6570 torch . save ( net . state_dict (), \"../data/net_parameter.pkl\" ) net_clone = create_net () net_clone . load_state_dict ( torch . load ( \"../data/net_parameter.pkl\" )) net_clone . forward ( torch . tensor ( x_test [ 0 : 10 ]) . float ()) . data tensor([[0.0119], [0.6029], [0.2970], [0.5717], [0.5034], [0.8655], [0.0572], [0.9182], [0.5038], [0.1739]]) 2\uff0c\u4fdd\u5b58\u5b8c\u6574\u6a21\u578b(\u4e0d\u63a8\u8350) torch . save ( net , '../data/net_model.pkl' ) net_loaded = torch . load ( '../data/net_model.pkl' ) net_loaded ( torch . tensor ( x_test [ 0 : 10 ]) . float ()) . data tensor([[0.0119], [0.6029], [0.2970], [0.5717], [0.5034], [0.8655], [0.0572], [0.9182], [0.5038], [0.1739]]) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u516d\uff0c\u4fdd\u5b58\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-2%2C%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/","text":"1-2,\u56fe\u7247\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b # import os import datetime #\u6253\u5370\u65f6\u95f4 def printbar (): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) #mac\u7cfb\u7edf\u4e0apytorch\u548cmatplotlib\u5728jupyter\u4e2d\u540c\u65f6\u8dd1\u9700\u8981\u66f4\u6539\u73af\u5883\u53d8\u91cf os . environ [ \"KMP_DUPLICATE_LIB_OK\" ] = \"TRUE\" \u4e00\uff0c\u51c6\u5907\u6570\u636e # cifar2\u6570\u636e\u96c6\u4e3acifar10\u6570\u636e\u96c6\u7684\u5b50\u96c6\uff0c\u53ea\u5305\u62ec\u524d\u4e24\u79cd\u7c7b\u522bairplane\u548cautomobile\u3002 \u8bad\u7ec3\u96c6\u6709airplane\u548cautomobile\u56fe\u7247\u54045000\u5f20\uff0c\u6d4b\u8bd5\u96c6\u6709airplane\u548cautomobile\u56fe\u7247\u54041000\u5f20\u3002 cifar2\u4efb\u52a1\u7684\u76ee\u6807\u662f\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\u6765\u5bf9\u98de\u673aairplane\u548c\u673a\u52a8\u8f66automobile\u4e24\u79cd\u56fe\u7247\u8fdb\u884c\u5206\u7c7b\u3002 \u6211\u4eec\u51c6\u5907\u7684Cifar2\u6570\u636e\u96c6\u7684\u6587\u4ef6\u7ed3\u6784\u5982\u4e0b\u6240\u793a\u3002 \u5728Pytorch\u4e2d\u6784\u5efa\u56fe\u7247\u6570\u636e\u7ba1\u9053\u901a\u5e38\u6709\u4e09\u79cd\u65b9\u6cd5\u3002 \u7b2c\u4e00\u79cd\u662f\u4f7f\u7528 torchvision\u4e2d\u7684datasets.ImageFolder\u6765\u8bfb\u53d6\u56fe\u7247\u7136\u540e\u7528 DataLoader\u6765\u5e76\u884c\u52a0\u8f7d\u3002 \u7b2c\u4e8c\u79cd\u662f\u901a\u8fc7\u7ee7\u627f torch.utils.data.Dataset \u5b9e\u73b0\u7528\u6237\u81ea\u5b9a\u4e49\u8bfb\u53d6\u903b\u8f91\u7136\u540e\u7528 DataLoader\u6765\u5e76\u884c\u52a0\u8f7d\u3002 \u7b2c\u4e09\u79cd\u65b9\u6cd5\u662f\u8bfb\u53d6\u7528\u6237\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u7684\u901a\u7528\u65b9\u6cd5\uff0c\u65e2\u53ef\u4ee5\u8bfb\u53d6\u56fe\u7247\u6570\u636e\u96c6\uff0c\u4e5f\u53ef\u4ee5\u8bfb\u53d6\u6587\u672c\u6570\u636e\u96c6\u3002 \u672c\u7bc7\u6211\u4eec\u4ecb\u7ecd\u7b2c\u4e00\u79cd\u65b9\u6cd5\u3002 import torch from torch import nn from torch.utils.data import Dataset , DataLoader from torchvision import transforms , datasets transform_train = transforms . Compose ( [ transforms . ToTensor ()]) transform_valid = transforms . Compose ( [ transforms . ToTensor ()]) ds_train = datasets . ImageFolder ( \"../data/cifar2/train/\" , transform = transform_train , target_transform = lambda t : torch . tensor ([ t ]) . float ()) ds_valid = datasets . ImageFolder ( \"../data/cifar2/test/\" , transform = transform_valid , target_transform = lambda t : torch . tensor ([ t ]) . float ()) print ( ds_train . class_to_idx ) {'0_airplane': 0, '1_automobile': 1} dl_train = DataLoader ( ds_train , batch_size = 50 , shuffle = True , num_workers = 3 ) dl_valid = DataLoader ( ds_valid , batch_size = 50 , shuffle = True , num_workers = 3 ) % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u67e5\u770b\u90e8\u5206\u6837\u672c from matplotlib import pyplot as plt plt . figure ( figsize = ( 8 , 8 )) for i in range ( 9 ): img , label = ds_train [ i ] img = img . permute ( 1 , 2 , 0 ) ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow ( img . numpy ()) ax . set_title ( \"label = %d \" % label . item ()) ax . set_xticks ([]) ax . set_yticks ([]) plt . show () # Pytorch\u7684\u56fe\u7247\u9ed8\u8ba4\u987a\u5e8f\u662f Batch,Channel,Width,Height for x , y in dl_train : print ( x . shape , y . shape ) break torch.Size([50, 3, 32, 32]) torch.Size([50, 1]) \u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b # \u4f7f\u7528Pytorch\u901a\u5e38\u6709\u4e09\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528nn.Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u6a21\u578b\u5e76\u8f85\u52a9\u5e94\u7528\u6a21\u578b\u5bb9\u5668(nn.Sequential,nn.ModuleList,nn.ModuleDict)\u8fdb\u884c\u5c01\u88c5\u3002 \u6b64\u5904\u9009\u62e9\u901a\u8fc7\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 #\u6d4b\u8bd5AdaptiveMaxPool2d\u7684\u6548\u679c pool = nn . AdaptiveMaxPool2d (( 1 , 1 )) t = torch . randn ( 10 , 8 , 32 , 32 ) pool ( t ) . shape torch.Size([10, 8, 1, 1]) class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 ) self . pool = nn . MaxPool2d ( kernel_size = 2 , stride = 2 ) self . conv2 = nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ) self . dropout = nn . Dropout2d ( p = 0.1 ) self . adaptive_pool = nn . AdaptiveMaxPool2d (( 1 , 1 )) self . flatten = nn . Flatten () self . linear1 = nn . Linear ( 64 , 32 ) self . relu = nn . ReLU () self . linear2 = nn . Linear ( 32 , 1 ) self . sigmoid = nn . Sigmoid () def forward ( self , x ): x = self . conv1 ( x ) x = self . pool ( x ) x = self . conv2 ( x ) x = self . pool ( x ) x = self . dropout ( x ) x = self . adaptive_pool ( x ) x = self . flatten ( x ) x = self . linear1 ( x ) x = self . relu ( x ) x = self . linear2 ( x ) y = self . sigmoid ( x ) return y net = Net () print ( net ) Net( (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (dropout): Dropout2d(p=0.1, inplace=False) (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1)) (flatten): Flatten() (linear1): Linear(in_features=64, out_features=32, bias=True) (relu): ReLU() (linear2): Linear(in_features=32, out_features=1, bias=True) (sigmoid): Sigmoid() ) import torchkeras torchkeras . summary ( net , input_shape = ( 3 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 896 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 1] 33 Sigmoid-11 [-1, 1] 0 ================================================================ Total params: 54,273 Trainable params: 54,273 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.011719 Forward/backward pass size (MB): 0.359634 Params size (MB): 0.207035 Estimated Total Size (MB): 0.578388 ---------------------------------------------------------------- \u4e09\uff0c\u8bad\u7ec3\u6a21\u578b # Pytorch\u901a\u5e38\u9700\u8981\u7528\u6237\u7f16\u5199\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\uff0c\u8bad\u7ec3\u5faa\u73af\u7684\u4ee3\u7801\u98ce\u683c\u56e0\u4eba\u800c\u5f02\u3002 \u67093\u7c7b\u5178\u578b\u7684\u8bad\u7ec3\u5faa\u73af\u4ee3\u7801\u98ce\u683c\uff1a\u811a\u672c\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u51fd\u6570\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u7c7b\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\u3002 \u6b64\u5904\u4ecb\u7ecd\u4e00\u79cd\u8f83\u901a\u7528\u7684\u51fd\u6570\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\u3002 import pandas as pd from sklearn.metrics import roc_auc_score model = net model . optimizer = torch . optim . SGD ( model . parameters (), lr = 0.01 ) model . loss_func = torch . nn . BCELoss () model . metric_func = lambda y_pred , y_true : roc_auc_score ( y_true . data . numpy (), y_pred . data . numpy ()) model . metric_name = \"auc\" def train_step ( model , features , labels ): # \u8bad\u7ec3\u6a21\u5f0f\uff0cdropout\u5c42\u53d1\u751f\u4f5c\u7528 model . train () # \u68af\u5ea6\u6e05\u96f6 model . optimizer . zero_grad () # \u6b63\u5411\u4f20\u64ad\u6c42\u635f\u5931 predictions = model ( features ) loss = model . loss_func ( predictions , labels ) metric = model . metric_func ( predictions , labels ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 loss . backward () model . optimizer . step () return loss . item (), metric . item () def valid_step ( model , features , labels ): # \u9884\u6d4b\u6a21\u5f0f\uff0cdropout\u5c42\u4e0d\u53d1\u751f\u4f5c\u7528 model . eval () # \u5173\u95ed\u68af\u5ea6\u8ba1\u7b97 with torch . no_grad (): predictions = model ( features ) loss = model . loss_func ( predictions , labels ) metric = model . metric_func ( predictions , labels ) return loss . item (), metric . item () # \u6d4b\u8bd5train_step\u6548\u679c features , labels = next ( iter ( dl_train )) train_step ( model , features , labels ) (0.6922046542167664, 0.5088566827697262) def train_model ( model , epochs , dl_train , dl_valid , log_step_freq ): metric_name = model . metric_name dfhistory = pd . DataFrame ( columns = [ \"epoch\" , \"loss\" , metric_name , \"val_loss\" , \"val_\" + metric_name ]) print ( \"Start Training...\" ) nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \"==========\" * 8 + \" %s \" % nowtime ) for epoch in range ( 1 , epochs + 1 ): # 1\uff0c\u8bad\u7ec3\u5faa\u73af------------------------------------------------- loss_sum = 0.0 metric_sum = 0.0 step = 1 for step , ( features , labels ) in enumerate ( dl_train , 1 ): loss , metric = train_step ( model , features , labels ) # \u6253\u5370batch\u7ea7\u522b\u65e5\u5fd7 loss_sum += loss metric_sum += metric if step % log_step_freq == 0 : print (( \"[step = %d ] loss: %.3f , \" + metric_name + \": %.3f \" ) % ( step , loss_sum / step , metric_sum / step )) # 2\uff0c\u9a8c\u8bc1\u5faa\u73af------------------------------------------------- val_loss_sum = 0.0 val_metric_sum = 0.0 val_step = 1 for val_step , ( features , labels ) in enumerate ( dl_valid , 1 ): val_loss , val_metric = valid_step ( model , features , labels ) val_loss_sum += val_loss val_metric_sum += val_metric # 3\uff0c\u8bb0\u5f55\u65e5\u5fd7------------------------------------------------- info = ( epoch , loss_sum / step , metric_sum / step , val_loss_sum / val_step , val_metric_sum / val_step ) dfhistory . loc [ epoch - 1 ] = info # \u6253\u5370epoch\u7ea7\u522b\u65e5\u5fd7 print (( \" \\n EPOCH = %d , loss = %.3f ,\" + metric_name + \\ \" = %.3f , val_loss = %.3f , \" + \"val_\" + metric_name + \" = %.3f \" ) % info ) nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) print ( 'Finished Training...' ) return dfhistory epochs = 20 dfhistory = train_model ( model , epochs , dl_train , dl_valid , log_step_freq = 50 ) Start Training... ================================================================================2020-06-28 20:47:56 [step = 50] loss: 0.691, auc: 0.627 [step = 100] loss: 0.690, auc: 0.673 [step = 150] loss: 0.688, auc: 0.699 [step = 200] loss: 0.686, auc: 0.716 EPOCH = 1, loss = 0.686,auc = 0.716, val_loss = 0.678, val_auc = 0.806 ================================================================================2020-06-28 20:48:18 [step = 50] loss: 0.677, auc: 0.780 [step = 100] loss: 0.675, auc: 0.775 [step = 150] loss: 0.672, auc: 0.782 [step = 200] loss: 0.669, auc: 0.779 EPOCH = 2, loss = 0.669,auc = 0.779, val_loss = 0.651, val_auc = 0.815 ...... ================================================================================2020-06-28 20:54:24 [step = 50] loss: 0.386, auc: 0.914 [step = 100] loss: 0.392, auc: 0.913 [step = 150] loss: 0.395, auc: 0.911 [step = 200] loss: 0.398, auc: 0.911 EPOCH = 19, loss = 0.398,auc = 0.911, val_loss = 0.449, val_auc = 0.924 ================================================================================2020-06-28 20:54:43 [step = 50] loss: 0.416, auc: 0.917 [step = 100] loss: 0.417, auc: 0.916 [step = 150] loss: 0.404, auc: 0.918 [step = 200] loss: 0.402, auc: 0.918 EPOCH = 20, loss = 0.402,auc = 0.918, val_loss = 0.535, val_auc = 0.925 ================================================================================2020-06-28 20:55:03 Finished Training... \u56db\uff0c\u8bc4\u4f30\u6a21\u578b # dfhistory % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( dfhistory , metric ): train_metrics = dfhistory [ metric ] val_metrics = dfhistory [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( dfhistory , \"loss\" ) plot_metric ( dfhistory , \"auc\" ) \u4e94\uff0c\u4f7f\u7528\u6a21\u578b # def predict ( model , dl ): model . eval () with torch . no_grad (): result = torch . cat ([ model . forward ( t [ 0 ]) for t in dl ]) return ( result . data ) #\u9884\u6d4b\u6982\u7387 y_pred_probs = predict ( model , dl_valid ) y_pred_probs tensor([[8.4032e-01], [1.0407e-02], [5.4146e-04], ..., [1.4471e-02], [1.7673e-02], [4.5081e-01]]) #\u9884\u6d4b\u7c7b\u522b y_pred = torch . where ( y_pred_probs > 0.5 , torch . ones_like ( y_pred_probs ), torch . zeros_like ( y_pred_probs )) y_pred tensor([[1.], [0.], [0.], ..., [0.], [0.], [0.]]) \u516d\uff0c\u4fdd\u5b58\u6a21\u578b # \u63a8\u8350\u4f7f\u7528\u4fdd\u5b58\u53c2\u6570\u65b9\u5f0f\u4fdd\u5b58Pytorch\u6a21\u578b\u3002 print ( model . state_dict () . keys ()) odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'linear1.weight', 'linear1.bias', 'linear2.weight', 'linear2.bias']) # \u4fdd\u5b58\u6a21\u578b\u53c2\u6570 torch . save ( model . state_dict (), \"../data/model_parameter.pkl\" ) net_clone = Net () net_clone . load_state_dict ( torch . load ( \"../data/model_parameter.pkl\" )) predict ( net_clone , dl_valid ) tensor([[0.0204], [0.7692], [0.4967], ..., [0.6078], [0.7182], [0.8251]]) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"1-2,\u56fe\u7247\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-2%2C%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#1-2\u56fe\u7247\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b","text":"import os import datetime #\u6253\u5370\u65f6\u95f4 def printbar (): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) #mac\u7cfb\u7edf\u4e0apytorch\u548cmatplotlib\u5728jupyter\u4e2d\u540c\u65f6\u8dd1\u9700\u8981\u66f4\u6539\u73af\u5883\u53d8\u91cf os . environ [ \"KMP_DUPLICATE_LIB_OK\" ] = \"TRUE\"","title":"1-2,\u56fe\u7247\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-2%2C%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e00\u51c6\u5907\u6570\u636e","text":"cifar2\u6570\u636e\u96c6\u4e3acifar10\u6570\u636e\u96c6\u7684\u5b50\u96c6\uff0c\u53ea\u5305\u62ec\u524d\u4e24\u79cd\u7c7b\u522bairplane\u548cautomobile\u3002 \u8bad\u7ec3\u96c6\u6709airplane\u548cautomobile\u56fe\u7247\u54045000\u5f20\uff0c\u6d4b\u8bd5\u96c6\u6709airplane\u548cautomobile\u56fe\u7247\u54041000\u5f20\u3002 cifar2\u4efb\u52a1\u7684\u76ee\u6807\u662f\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\u6765\u5bf9\u98de\u673aairplane\u548c\u673a\u52a8\u8f66automobile\u4e24\u79cd\u56fe\u7247\u8fdb\u884c\u5206\u7c7b\u3002 \u6211\u4eec\u51c6\u5907\u7684Cifar2\u6570\u636e\u96c6\u7684\u6587\u4ef6\u7ed3\u6784\u5982\u4e0b\u6240\u793a\u3002 \u5728Pytorch\u4e2d\u6784\u5efa\u56fe\u7247\u6570\u636e\u7ba1\u9053\u901a\u5e38\u6709\u4e09\u79cd\u65b9\u6cd5\u3002 \u7b2c\u4e00\u79cd\u662f\u4f7f\u7528 torchvision\u4e2d\u7684datasets.ImageFolder\u6765\u8bfb\u53d6\u56fe\u7247\u7136\u540e\u7528 DataLoader\u6765\u5e76\u884c\u52a0\u8f7d\u3002 \u7b2c\u4e8c\u79cd\u662f\u901a\u8fc7\u7ee7\u627f torch.utils.data.Dataset \u5b9e\u73b0\u7528\u6237\u81ea\u5b9a\u4e49\u8bfb\u53d6\u903b\u8f91\u7136\u540e\u7528 DataLoader\u6765\u5e76\u884c\u52a0\u8f7d\u3002 \u7b2c\u4e09\u79cd\u65b9\u6cd5\u662f\u8bfb\u53d6\u7528\u6237\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u7684\u901a\u7528\u65b9\u6cd5\uff0c\u65e2\u53ef\u4ee5\u8bfb\u53d6\u56fe\u7247\u6570\u636e\u96c6\uff0c\u4e5f\u53ef\u4ee5\u8bfb\u53d6\u6587\u672c\u6570\u636e\u96c6\u3002 \u672c\u7bc7\u6211\u4eec\u4ecb\u7ecd\u7b2c\u4e00\u79cd\u65b9\u6cd5\u3002 import torch from torch import nn from torch.utils.data import Dataset , DataLoader from torchvision import transforms , datasets transform_train = transforms . Compose ( [ transforms . ToTensor ()]) transform_valid = transforms . Compose ( [ transforms . ToTensor ()]) ds_train = datasets . ImageFolder ( \"../data/cifar2/train/\" , transform = transform_train , target_transform = lambda t : torch . tensor ([ t ]) . float ()) ds_valid = datasets . ImageFolder ( \"../data/cifar2/test/\" , transform = transform_valid , target_transform = lambda t : torch . tensor ([ t ]) . float ()) print ( ds_train . class_to_idx ) {'0_airplane': 0, '1_automobile': 1} dl_train = DataLoader ( ds_train , batch_size = 50 , shuffle = True , num_workers = 3 ) dl_valid = DataLoader ( ds_valid , batch_size = 50 , shuffle = True , num_workers = 3 ) % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u67e5\u770b\u90e8\u5206\u6837\u672c from matplotlib import pyplot as plt plt . figure ( figsize = ( 8 , 8 )) for i in range ( 9 ): img , label = ds_train [ i ] img = img . permute ( 1 , 2 , 0 ) ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow ( img . numpy ()) ax . set_title ( \"label = %d \" % label . item ()) ax . set_xticks ([]) ax . set_yticks ([]) plt . show () # Pytorch\u7684\u56fe\u7247\u9ed8\u8ba4\u987a\u5e8f\u662f Batch,Channel,Width,Height for x , y in dl_train : print ( x . shape , y . shape ) break torch.Size([50, 3, 32, 32]) torch.Size([50, 1])","title":"\u4e00\uff0c\u51c6\u5907\u6570\u636e"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-2%2C%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e8c\u5b9a\u4e49\u6a21\u578b","text":"\u4f7f\u7528Pytorch\u901a\u5e38\u6709\u4e09\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528nn.Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u6a21\u578b\u5e76\u8f85\u52a9\u5e94\u7528\u6a21\u578b\u5bb9\u5668(nn.Sequential,nn.ModuleList,nn.ModuleDict)\u8fdb\u884c\u5c01\u88c5\u3002 \u6b64\u5904\u9009\u62e9\u901a\u8fc7\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 #\u6d4b\u8bd5AdaptiveMaxPool2d\u7684\u6548\u679c pool = nn . AdaptiveMaxPool2d (( 1 , 1 )) t = torch . randn ( 10 , 8 , 32 , 32 ) pool ( t ) . shape torch.Size([10, 8, 1, 1]) class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 ) self . pool = nn . MaxPool2d ( kernel_size = 2 , stride = 2 ) self . conv2 = nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ) self . dropout = nn . Dropout2d ( p = 0.1 ) self . adaptive_pool = nn . AdaptiveMaxPool2d (( 1 , 1 )) self . flatten = nn . Flatten () self . linear1 = nn . Linear ( 64 , 32 ) self . relu = nn . ReLU () self . linear2 = nn . Linear ( 32 , 1 ) self . sigmoid = nn . Sigmoid () def forward ( self , x ): x = self . conv1 ( x ) x = self . pool ( x ) x = self . conv2 ( x ) x = self . pool ( x ) x = self . dropout ( x ) x = self . adaptive_pool ( x ) x = self . flatten ( x ) x = self . linear1 ( x ) x = self . relu ( x ) x = self . linear2 ( x ) y = self . sigmoid ( x ) return y net = Net () print ( net ) Net( (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (dropout): Dropout2d(p=0.1, inplace=False) (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1)) (flatten): Flatten() (linear1): Linear(in_features=64, out_features=32, bias=True) (relu): ReLU() (linear2): Linear(in_features=32, out_features=1, bias=True) (sigmoid): Sigmoid() ) import torchkeras torchkeras . summary ( net , input_shape = ( 3 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 896 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 1] 33 Sigmoid-11 [-1, 1] 0 ================================================================ Total params: 54,273 Trainable params: 54,273 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.011719 Forward/backward pass size (MB): 0.359634 Params size (MB): 0.207035 Estimated Total Size (MB): 0.578388 ----------------------------------------------------------------","title":"\u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-2%2C%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e09\u8bad\u7ec3\u6a21\u578b","text":"Pytorch\u901a\u5e38\u9700\u8981\u7528\u6237\u7f16\u5199\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\uff0c\u8bad\u7ec3\u5faa\u73af\u7684\u4ee3\u7801\u98ce\u683c\u56e0\u4eba\u800c\u5f02\u3002 \u67093\u7c7b\u5178\u578b\u7684\u8bad\u7ec3\u5faa\u73af\u4ee3\u7801\u98ce\u683c\uff1a\u811a\u672c\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u51fd\u6570\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u7c7b\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\u3002 \u6b64\u5904\u4ecb\u7ecd\u4e00\u79cd\u8f83\u901a\u7528\u7684\u51fd\u6570\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\u3002 import pandas as pd from sklearn.metrics import roc_auc_score model = net model . optimizer = torch . optim . SGD ( model . parameters (), lr = 0.01 ) model . loss_func = torch . nn . BCELoss () model . metric_func = lambda y_pred , y_true : roc_auc_score ( y_true . data . numpy (), y_pred . data . numpy ()) model . metric_name = \"auc\" def train_step ( model , features , labels ): # \u8bad\u7ec3\u6a21\u5f0f\uff0cdropout\u5c42\u53d1\u751f\u4f5c\u7528 model . train () # \u68af\u5ea6\u6e05\u96f6 model . optimizer . zero_grad () # \u6b63\u5411\u4f20\u64ad\u6c42\u635f\u5931 predictions = model ( features ) loss = model . loss_func ( predictions , labels ) metric = model . metric_func ( predictions , labels ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 loss . backward () model . optimizer . step () return loss . item (), metric . item () def valid_step ( model , features , labels ): # \u9884\u6d4b\u6a21\u5f0f\uff0cdropout\u5c42\u4e0d\u53d1\u751f\u4f5c\u7528 model . eval () # \u5173\u95ed\u68af\u5ea6\u8ba1\u7b97 with torch . no_grad (): predictions = model ( features ) loss = model . loss_func ( predictions , labels ) metric = model . metric_func ( predictions , labels ) return loss . item (), metric . item () # \u6d4b\u8bd5train_step\u6548\u679c features , labels = next ( iter ( dl_train )) train_step ( model , features , labels ) (0.6922046542167664, 0.5088566827697262) def train_model ( model , epochs , dl_train , dl_valid , log_step_freq ): metric_name = model . metric_name dfhistory = pd . DataFrame ( columns = [ \"epoch\" , \"loss\" , metric_name , \"val_loss\" , \"val_\" + metric_name ]) print ( \"Start Training...\" ) nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \"==========\" * 8 + \" %s \" % nowtime ) for epoch in range ( 1 , epochs + 1 ): # 1\uff0c\u8bad\u7ec3\u5faa\u73af------------------------------------------------- loss_sum = 0.0 metric_sum = 0.0 step = 1 for step , ( features , labels ) in enumerate ( dl_train , 1 ): loss , metric = train_step ( model , features , labels ) # \u6253\u5370batch\u7ea7\u522b\u65e5\u5fd7 loss_sum += loss metric_sum += metric if step % log_step_freq == 0 : print (( \"[step = %d ] loss: %.3f , \" + metric_name + \": %.3f \" ) % ( step , loss_sum / step , metric_sum / step )) # 2\uff0c\u9a8c\u8bc1\u5faa\u73af------------------------------------------------- val_loss_sum = 0.0 val_metric_sum = 0.0 val_step = 1 for val_step , ( features , labels ) in enumerate ( dl_valid , 1 ): val_loss , val_metric = valid_step ( model , features , labels ) val_loss_sum += val_loss val_metric_sum += val_metric # 3\uff0c\u8bb0\u5f55\u65e5\u5fd7------------------------------------------------- info = ( epoch , loss_sum / step , metric_sum / step , val_loss_sum / val_step , val_metric_sum / val_step ) dfhistory . loc [ epoch - 1 ] = info # \u6253\u5370epoch\u7ea7\u522b\u65e5\u5fd7 print (( \" \\n EPOCH = %d , loss = %.3f ,\" + metric_name + \\ \" = %.3f , val_loss = %.3f , \" + \"val_\" + metric_name + \" = %.3f \" ) % info ) nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) print ( 'Finished Training...' ) return dfhistory epochs = 20 dfhistory = train_model ( model , epochs , dl_train , dl_valid , log_step_freq = 50 ) Start Training... ================================================================================2020-06-28 20:47:56 [step = 50] loss: 0.691, auc: 0.627 [step = 100] loss: 0.690, auc: 0.673 [step = 150] loss: 0.688, auc: 0.699 [step = 200] loss: 0.686, auc: 0.716 EPOCH = 1, loss = 0.686,auc = 0.716, val_loss = 0.678, val_auc = 0.806 ================================================================================2020-06-28 20:48:18 [step = 50] loss: 0.677, auc: 0.780 [step = 100] loss: 0.675, auc: 0.775 [step = 150] loss: 0.672, auc: 0.782 [step = 200] loss: 0.669, auc: 0.779 EPOCH = 2, loss = 0.669,auc = 0.779, val_loss = 0.651, val_auc = 0.815 ...... ================================================================================2020-06-28 20:54:24 [step = 50] loss: 0.386, auc: 0.914 [step = 100] loss: 0.392, auc: 0.913 [step = 150] loss: 0.395, auc: 0.911 [step = 200] loss: 0.398, auc: 0.911 EPOCH = 19, loss = 0.398,auc = 0.911, val_loss = 0.449, val_auc = 0.924 ================================================================================2020-06-28 20:54:43 [step = 50] loss: 0.416, auc: 0.917 [step = 100] loss: 0.417, auc: 0.916 [step = 150] loss: 0.404, auc: 0.918 [step = 200] loss: 0.402, auc: 0.918 EPOCH = 20, loss = 0.402,auc = 0.918, val_loss = 0.535, val_auc = 0.925 ================================================================================2020-06-28 20:55:03 Finished Training...","title":"\u4e09\uff0c\u8bad\u7ec3\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-2%2C%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u56db\u8bc4\u4f30\u6a21\u578b","text":"dfhistory % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( dfhistory , metric ): train_metrics = dfhistory [ metric ] val_metrics = dfhistory [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( dfhistory , \"loss\" ) plot_metric ( dfhistory , \"auc\" )","title":"\u56db\uff0c\u8bc4\u4f30\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-2%2C%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e94\u4f7f\u7528\u6a21\u578b","text":"def predict ( model , dl ): model . eval () with torch . no_grad (): result = torch . cat ([ model . forward ( t [ 0 ]) for t in dl ]) return ( result . data ) #\u9884\u6d4b\u6982\u7387 y_pred_probs = predict ( model , dl_valid ) y_pred_probs tensor([[8.4032e-01], [1.0407e-02], [5.4146e-04], ..., [1.4471e-02], [1.7673e-02], [4.5081e-01]]) #\u9884\u6d4b\u7c7b\u522b y_pred = torch . where ( y_pred_probs > 0.5 , torch . ones_like ( y_pred_probs ), torch . zeros_like ( y_pred_probs )) y_pred tensor([[1.], [0.], [0.], ..., [0.], [0.], [0.]])","title":"\u4e94\uff0c\u4f7f\u7528\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-2%2C%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u516d\u4fdd\u5b58\u6a21\u578b","text":"\u63a8\u8350\u4f7f\u7528\u4fdd\u5b58\u53c2\u6570\u65b9\u5f0f\u4fdd\u5b58Pytorch\u6a21\u578b\u3002 print ( model . state_dict () . keys ()) odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'linear1.weight', 'linear1.bias', 'linear2.weight', 'linear2.bias']) # \u4fdd\u5b58\u6a21\u578b\u53c2\u6570 torch . save ( model . state_dict (), \"../data/model_parameter.pkl\" ) net_clone = Net () net_clone . load_state_dict ( torch . load ( \"../data/model_parameter.pkl\" )) predict ( net_clone , dl_valid ) tensor([[0.0204], [0.7692], [0.4967], ..., [0.6078], [0.7182], [0.8251]]) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u516d\uff0c\u4fdd\u5b58\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-3%2C%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/","text":"1-3,\u6587\u672c\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b # \u4e00\uff0c\u51c6\u5907\u6570\u636e # imdb\u6570\u636e\u96c6\u7684\u76ee\u6807\u662f\u6839\u636e\u7535\u5f71\u8bc4\u8bba\u7684\u6587\u672c\u5185\u5bb9\u9884\u6d4b\u8bc4\u8bba\u7684\u60c5\u611f\u6807\u7b7e\u3002 \u8bad\u7ec3\u96c6\u670920000\u6761\u7535\u5f71\u8bc4\u8bba\u6587\u672c\uff0c\u6d4b\u8bd5\u96c6\u67095000\u6761\u7535\u5f71\u8bc4\u8bba\u6587\u672c\uff0c\u5176\u4e2d\u6b63\u9762\u8bc4\u8bba\u548c\u8d1f\u9762\u8bc4\u8bba\u90fd\u5404\u5360\u4e00\u534a\u3002 \u6587\u672c\u6570\u636e\u9884\u5904\u7406\u8f83\u4e3a\u7e41\u7410\uff0c\u5305\u62ec\u4e2d\u6587\u5207\u8bcd\uff08\u672c\u793a\u4f8b\u4e0d\u6d89\u53ca\uff09\uff0c\u6784\u5efa\u8bcd\u5178\uff0c\u7f16\u7801\u8f6c\u6362\uff0c\u5e8f\u5217\u586b\u5145\uff0c\u6784\u5efa\u6570\u636e\u7ba1\u9053\u7b49\u7b49\u3002 \u5728torch\u4e2d\u9884\u5904\u7406\u6587\u672c\u6570\u636e\u4e00\u822c\u4f7f\u7528torchtext\u6216\u8005\u81ea\u5b9a\u4e49Dataset\uff0ctorchtext\u529f\u80fd\u975e\u5e38\u5f3a\u5927\uff0c\u53ef\u4ee5\u6784\u5efa\u6587\u672c\u5206\u7c7b\uff0c\u5e8f\u5217\u6807\u6ce8\uff0c\u95ee\u7b54\u6a21\u578b\uff0c\u673a\u5668\u7ffb\u8bd1\u7b49NLP\u4efb\u52a1\u7684\u6570\u636e\u96c6\u3002 \u4e0b\u9762\u4ec5\u6f14\u793a\u4f7f\u7528\u5b83\u6765\u6784\u5efa\u6587\u672c\u5206\u7c7b\u6570\u636e\u96c6\u7684\u65b9\u6cd5\u3002 \u8f83\u5b8c\u6574\u7684\u6559\u7a0b\u53ef\u4ee5\u53c2\u8003\u4ee5\u4e0b\u77e5\u4e4e\u6587\u7ae0\uff1a\u300apytorch\u5b66\u4e60\u7b14\u8bb0\u2014Torchtext\u300b https://zhuanlan.zhihu.com/p/65833208 torchtext\u5e38\u89c1API\u4e00\u89c8 torchtext.data.Example : \u7528\u6765\u8868\u793a\u4e00\u4e2a\u6837\u672c\uff0c\u6570\u636e\u548c\u6807\u7b7e torchtext.vocab.Vocab: \u8bcd\u6c47\u8868\uff0c\u53ef\u4ee5\u5bfc\u5165\u4e00\u4e9b\u9884\u8bad\u7ec3\u8bcd\u5411\u91cf torchtext.data.Datasets: \u6570\u636e\u96c6\u7c7b\uff0c __getitem__ \u8fd4\u56de Example\u5b9e\u4f8b, torchtext.data.TabularDataset\u662f\u5176\u5b50\u7c7b\u3002 torchtext.data.Field : \u7528\u6765\u5b9a\u4e49\u5b57\u6bb5\u7684\u5904\u7406\u65b9\u6cd5\uff08\u6587\u672c\u5b57\u6bb5\uff0c\u6807\u7b7e\u5b57\u6bb5\uff09\u521b\u5efa Example\u65f6\u7684 \u9884\u5904\u7406\uff0cbatch \u65f6\u7684\u4e00\u4e9b\u5904\u7406\u64cd\u4f5c\u3002 torchtext.data.Iterator: \u8fed\u4ee3\u5668\uff0c\u7528\u6765\u751f\u6210 batch torchtext.datasets: \u5305\u542b\u4e86\u5e38\u89c1\u7684\u6570\u636e\u96c6. import torch import string , re import torchtext MAX_WORDS = 10000 # \u4ec5\u8003\u8651\u6700\u9ad8\u9891\u768410000\u4e2a\u8bcd MAX_LEN = 200 # \u6bcf\u4e2a\u6837\u672c\u4fdd\u7559200\u4e2a\u8bcd\u7684\u957f\u5ea6 BATCH_SIZE = 20 #\u5206\u8bcd\u65b9\u6cd5 tokenizer = lambda x : re . sub ( '[ %s ]' % string . punctuation , \"\" , x ) . split ( \" \" ) #\u8fc7\u6ee4\u6389\u4f4e\u9891\u8bcd def filterLowFreqWords ( arr , vocab ): arr = [[ x if x < MAX_WORDS else 0 for x in example ] for example in arr ] return arr #1,\u5b9a\u4e49\u5404\u4e2a\u5b57\u6bb5\u7684\u9884\u5904\u7406\u65b9\u6cd5 TEXT = torchtext . data . Field ( sequential = True , tokenize = tokenizer , lower = True , fix_length = MAX_LEN , postprocessing = filterLowFreqWords ) LABEL = torchtext . data . Field ( sequential = False , use_vocab = False ) #2,\u6784\u5efa\u8868\u683c\u578bdataset #torchtext.data.TabularDataset\u53ef\u8bfb\u53d6csv,tsv,json\u7b49\u683c\u5f0f ds_train , ds_test = torchtext . data . TabularDataset . splits ( path = '../data/imdb' , train = 'train.tsv' , test = 'test.tsv' , format = 'tsv' , fields = [( 'label' , LABEL ), ( 'text' , TEXT )], skip_header = False ) #3,\u6784\u5efa\u8bcd\u5178 TEXT . build_vocab ( ds_train ) #4,\u6784\u5efa\u6570\u636e\u7ba1\u9053\u8fed\u4ee3\u5668 train_iter , test_iter = torchtext . data . Iterator . splits ( ( ds_train , ds_test ), sort_within_batch = True , sort_key = lambda x : len ( x . text ), batch_sizes = ( BATCH_SIZE , BATCH_SIZE )) #\u67e5\u770bexample\u4fe1\u606f print ( ds_train [ 0 ] . text ) print ( ds_train [ 0 ] . label ) ['it', 'really', 'boggles', 'my', 'mind', 'when', 'someone', 'comes', 'across', 'a', 'movie', 'like', 'this', 'and', 'claims', 'it', 'to', 'be', 'one', 'of', 'the', 'worst', 'slasher', 'films', 'out', 'there', 'this', 'is', 'by', 'far', 'not', 'one', 'of', 'the', 'worst', 'out', 'there', 'still', 'not', 'a', 'good', 'movie', 'but', 'not', 'the', 'worst', 'nonetheless', 'go', 'see', 'something', 'like', 'death', 'nurse', 'or', 'blood', 'lake', 'and', 'then', 'come', 'back', 'to', 'me', 'and', 'tell', 'me', 'if', 'you', 'think', 'the', 'night', 'brings', 'charlie', 'is', 'the', 'worst', 'the', 'film', 'has', 'decent', 'camera', 'work', 'and', 'editing', 'which', 'is', 'way', 'more', 'than', 'i', 'can', 'say', 'for', 'many', 'more', 'extremely', 'obscure', 'slasher', 'filmsbr', 'br', 'the', 'film', 'doesnt', 'deliver', 'on', 'the', 'onscreen', 'deaths', 'theres', 'one', 'death', 'where', 'you', 'see', 'his', 'pruning', 'saw', 'rip', 'into', 'a', 'neck', 'but', 'all', 'other', 'deaths', 'are', 'hardly', 'interesting', 'but', 'the', 'lack', 'of', 'onscreen', 'graphic', 'violence', 'doesnt', 'mean', 'this', 'isnt', 'a', 'slasher', 'film', 'just', 'a', 'bad', 'onebr', 'br', 'the', 'film', 'was', 'obviously', 'intended', 'not', 'to', 'be', 'taken', 'too', 'seriously', 'the', 'film', 'came', 'in', 'at', 'the', 'end', 'of', 'the', 'second', 'slasher', 'cycle', 'so', 'it', 'certainly', 'was', 'a', 'reflection', 'on', 'traditional', 'slasher', 'elements', 'done', 'in', 'a', 'tongue', 'in', 'cheek', 'way', 'for', 'example', 'after', 'a', 'kill', 'charlie', 'goes', 'to', 'the', 'towns', 'welcome', 'sign', 'and', 'marks', 'the', 'population', 'down', 'one', 'less', 'this', 'is', 'something', 'that', 'can', 'only', 'get', 'a', 'laughbr', 'br', 'if', 'youre', 'into', 'slasher', 'films', 'definitely', 'give', 'this', 'film', 'a', 'watch', 'it', 'is', 'slightly', 'different', 'than', 'your', 'usual', 'slasher', 'film', 'with', 'possibility', 'of', 'two', 'killers', 'but', 'not', 'by', 'much', 'the', 'comedy', 'of', 'the', 'movie', 'is', 'pretty', 'much', 'telling', 'the', 'audience', 'to', 'relax', 'and', 'not', 'take', 'the', 'movie', 'so', 'god', 'darn', 'serious', 'you', 'may', 'forget', 'the', 'movie', 'you', 'may', 'remember', 'it', 'ill', 'remember', 'it', 'because', 'i', 'love', 'the', 'name'] 0 # \u67e5\u770b\u8bcd\u5178\u4fe1\u606f print ( len ( TEXT . vocab )) #itos: index to string print ( TEXT . vocab . itos [ 0 ]) print ( TEXT . vocab . itos [ 1 ]) #stoi: string to index print ( TEXT . vocab . stoi [ '<unk>' ]) #unknown \u672a\u77e5\u8bcd print ( TEXT . vocab . stoi [ '<pad>' ]) #padding \u586b\u5145 #freqs: \u8bcd\u9891 print ( TEXT . vocab . freqs [ '<unk>' ]) print ( TEXT . vocab . freqs [ 'a' ]) print ( TEXT . vocab . freqs [ 'good' ]) 108197 <unk> <pad> 0 1 0 129453 11457 # \u67e5\u770b\u6570\u636e\u7ba1\u9053\u4fe1\u606f # \u6ce8\u610f\u6709\u5751\uff1atext\u7b2c0\u7ef4\u662f\u53e5\u5b50\u957f\u5ea6 for batch in train_iter : features = batch . text labels = batch . label print ( features ) print ( features . shape ) print ( labels ) break tensor([[ 17, 31, 148, ..., 54, 11, 201], [ 2, 2, 904, ..., 335, 7, 109], [1371, 1737, 44, ..., 806, 2, 11], ..., [ 6, 5, 62, ..., 1, 1, 1], [ 170, 0, 27, ..., 1, 1, 1], [ 15, 0, 45, ..., 1, 1, 1]]) torch.Size([200, 20]) tensor([0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0]) # \u5c06\u6570\u636e\u7ba1\u9053\u7ec4\u7ec7\u6210torch.utils.data.DataLoader\u76f8\u4f3c\u7684features,label\u8f93\u51fa\u5f62\u5f0f class DataLoader : def __init__ ( self , data_iter ): self . data_iter = data_iter self . length = len ( data_iter ) def __len__ ( self ): return self . length def __iter__ ( self ): # \u6ce8\u610f\uff1a\u6b64\u5904\u8c03\u6574features\u4e3a batch first\uff0c\u5e76\u8c03\u6574label\u7684shape\u548cdtype for batch in self . data_iter : yield ( torch . transpose ( batch . text , 0 , 1 ), torch . unsqueeze ( batch . label . float (), dim = 1 )) dl_train = DataLoader ( train_iter ) dl_test = DataLoader ( test_iter ) \u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b # \u4f7f\u7528Pytorch\u901a\u5e38\u6709\u4e09\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528nn.Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u6a21\u578b\u5e76\u8f85\u52a9\u5e94\u7528\u6a21\u578b\u5bb9\u5668(nn.Sequential,nn.ModuleList,nn.ModuleDict)\u8fdb\u884c\u5c01\u88c5\u3002 \u6b64\u5904\u9009\u62e9\u4f7f\u7528\u7b2c\u4e09\u79cd\u65b9\u5f0f\u8fdb\u884c\u6784\u5efa\u3002 \u7531\u4e8e\u63a5\u4e0b\u6765\u4f7f\u7528\u7c7b\u5f62\u5f0f\u7684\u8bad\u7ec3\u5faa\u73af\uff0c\u6211\u4eec\u5c06\u6a21\u578b\u5c01\u88c5\u6210torchkeras.Model\u7c7b\u6765\u83b7\u5f97\u7c7b\u4f3cKeras\u4e2d\u9ad8\u9636\u6a21\u578b\u63a5\u53e3\u7684\u529f\u80fd\u3002 Model\u7c7b\u5b9e\u9645\u4e0a\u7ee7\u627f\u81eann.Module\u7c7b\u3002 import torch from torch import nn import torchkeras torch . random . seed () import torch from torch import nn class Net ( torchkeras . Model ): def __init__ ( self ): super ( Net , self ) . __init__ () #\u8bbe\u7f6epadding_idx\u53c2\u6570\u540e\u5c06\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5c06\u586b\u5145\u7684token\u59cb\u7ec8\u8d4b\u503c\u4e3a0\u5411\u91cf self . embedding = nn . Embedding ( num_embeddings = MAX_WORDS , embedding_dim = 3 , padding_idx = 1 ) self . conv = nn . Sequential () self . conv . add_module ( \"conv_1\" , nn . Conv1d ( in_channels = 3 , out_channels = 16 , kernel_size = 5 )) self . conv . add_module ( \"pool_1\" , nn . MaxPool1d ( kernel_size = 2 )) self . conv . add_module ( \"relu_1\" , nn . ReLU ()) self . conv . add_module ( \"conv_2\" , nn . Conv1d ( in_channels = 16 , out_channels = 128 , kernel_size = 2 )) self . conv . add_module ( \"pool_2\" , nn . MaxPool1d ( kernel_size = 2 )) self . conv . add_module ( \"relu_2\" , nn . ReLU ()) self . dense = nn . Sequential () self . dense . add_module ( \"flatten\" , nn . Flatten ()) self . dense . add_module ( \"linear\" , nn . Linear ( 6144 , 1 )) self . dense . add_module ( \"sigmoid\" , nn . Sigmoid ()) def forward ( self , x ): x = self . embedding ( x ) . transpose ( 1 , 2 ) x = self . conv ( x ) y = self . dense ( x ) return y model = Net () print ( model ) model . summary ( input_shape = ( 200 ,), input_dtype = torch . LongTensor ) Net( (embedding): Embedding(10000, 3, padding_idx=1) (conv): Sequential( (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,)) (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_1): ReLU() (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,)) (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_2): ReLU() ) (dense): Sequential( (flatten): Flatten() (linear): Linear(in_features=6144, out_features=1, bias=True) (sigmoid): Sigmoid() ) ) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Embedding-1 [-1, 200, 3] 30,000 Conv1d-2 [-1, 16, 196] 256 MaxPool1d-3 [-1, 16, 98] 0 ReLU-4 [-1, 16, 98] 0 Conv1d-5 [-1, 128, 97] 4,224 MaxPool1d-6 [-1, 128, 48] 0 ReLU-7 [-1, 128, 48] 0 Flatten-8 [-1, 6144] 0 Linear-9 [-1, 1] 6,145 Sigmoid-10 [-1, 1] 0 ================================================================ Total params: 40,625 Trainable params: 40,625 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.000763 Forward/backward pass size (MB): 0.287796 Params size (MB): 0.154972 Estimated Total Size (MB): 0.443531 ---------------------------------------------------------------- \u4e09\uff0c\u8bad\u7ec3\u6a21\u578b # \u8bad\u7ec3Pytorch\u901a\u5e38\u9700\u8981\u7528\u6237\u7f16\u5199\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\uff0c\u8bad\u7ec3\u5faa\u73af\u7684\u4ee3\u7801\u98ce\u683c\u56e0\u4eba\u800c\u5f02\u3002 \u67093\u7c7b\u5178\u578b\u7684\u8bad\u7ec3\u5faa\u73af\u4ee3\u7801\u98ce\u683c\uff1a\u811a\u672c\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u51fd\u6570\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u7c7b\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\u3002 \u6b64\u5904\u4ecb\u7ecd\u4e00\u79cd\u7c7b\u5f62\u5f0f\u7684\u8bad\u7ec3\u5faa\u73af\u3002 \u6211\u4eec\u4eff\u7167Keras\u5b9a\u4e49\u4e86\u4e00\u4e2a\u9ad8\u9636\u7684\u6a21\u578b\u63a5\u53e3Model,\u5b9e\u73b0 fit, validate\uff0cpredict, summary \u65b9\u6cd5\uff0c\u76f8\u5f53\u4e8e\u7528\u6237\u81ea\u5b9a\u4e49\u9ad8\u9636API\u3002 # \u51c6\u786e\u7387 def accuracy ( y_pred , y_true ): y_pred = torch . where ( y_pred > 0.5 , torch . ones_like ( y_pred , dtype = torch . float32 ), torch . zeros_like ( y_pred , dtype = torch . float32 )) acc = torch . mean ( 1 - torch . abs ( y_true - y_pred )) return acc model . compile ( loss_func = nn . BCELoss (), optimizer = torch . optim . Adagrad ( model . parameters (), lr = 0.02 ), metrics_dict = { \"accuracy\" : accuracy }) # \u6709\u65f6\u5019\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4e0d\u6536\u655b\uff0c\u9700\u8981\u591a\u8bd5\u51e0\u6b21 dfhistory = model . fit ( 20 , dl_train , dl_val = dl_test , log_step_freq = 200 ) Start Training ... ================================================================================2020-05-09 17:53:56 {'step': 200, 'loss': 1.127, 'accuracy': 0.504} {'step': 400, 'loss': 0.908, 'accuracy': 0.517} {'step': 600, 'loss': 0.833, 'accuracy': 0.531} {'step': 800, 'loss': 0.793, 'accuracy': 0.545} {'step': 1000, 'loss': 0.765, 'accuracy': 0.56} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 1 | 0.765 | 0.56 | 0.64 | 0.64 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:54:23 {'step': 200, 'loss': 0.626, 'accuracy': 0.659} {'step': 400, 'loss': 0.621, 'accuracy': 0.662} {'step': 600, 'loss': 0.616, 'accuracy': 0.664} {'step': 800, 'loss': 0.61, 'accuracy': 0.671} {'step': 1000, 'loss': 0.603, 'accuracy': 0.677} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 2 | 0.603 | 0.677 | 0.577 | 0.705 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:54:50 {'step': 200, 'loss': 0.545, 'accuracy': 0.726} {'step': 400, 'loss': 0.538, 'accuracy': 0.735} {'step': 600, 'loss': 0.532, 'accuracy': 0.737} {'step': 800, 'loss': 0.531, 'accuracy': 0.737} {'step': 1000, 'loss': 0.528, 'accuracy': 0.739} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 3 | 0.528 | 0.739 | 0.536 | 0.739 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:55:18 {'step': 200, 'loss': 0.488, 'accuracy': 0.773} {'step': 400, 'loss': 0.482, 'accuracy': 0.774} {'step': 600, 'loss': 0.482, 'accuracy': 0.773} {'step': 800, 'loss': 0.479, 'accuracy': 0.773} {'step': 1000, 'loss': 0.473, 'accuracy': 0.776} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 4 | 0.473 | 0.776 | 0.504 | 0.766 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:55:45 {'step': 200, 'loss': 0.446, 'accuracy': 0.789} {'step': 400, 'loss': 0.437, 'accuracy': 0.796} {'step': 600, 'loss': 0.436, 'accuracy': 0.799} {'step': 800, 'loss': 0.436, 'accuracy': 0.798} {'step': 1000, 'loss': 0.434, 'accuracy': 0.8} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 5 | 0.434 | 0.8 | 0.481 | 0.774 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:56:12 {'step': 200, 'loss': 0.404, 'accuracy': 0.817} {'step': 400, 'loss': 0.4, 'accuracy': 0.819} {'step': 600, 'loss': 0.398, 'accuracy': 0.821} {'step': 800, 'loss': 0.402, 'accuracy': 0.818} {'step': 1000, 'loss': 0.402, 'accuracy': 0.817} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 6 | 0.402 | 0.817 | 0.47 | 0.781 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:56:39 {'step': 200, 'loss': 0.369, 'accuracy': 0.834} {'step': 400, 'loss': 0.374, 'accuracy': 0.833} {'step': 600, 'loss': 0.373, 'accuracy': 0.834} {'step': 800, 'loss': 0.374, 'accuracy': 0.834} {'step': 1000, 'loss': 0.375, 'accuracy': 0.833} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 7 | 0.375 | 0.833 | 0.468 | 0.787 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:57:06 {'step': 200, 'loss': 0.36, 'accuracy': 0.839} {'step': 400, 'loss': 0.355, 'accuracy': 0.846} {'step': 600, 'loss': 0.35, 'accuracy': 0.849} {'step': 800, 'loss': 0.353, 'accuracy': 0.846} {'step': 1000, 'loss': 0.352, 'accuracy': 0.847} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 8 | 0.352 | 0.847 | 0.461 | 0.791 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:57:33 {'step': 200, 'loss': 0.313, 'accuracy': 0.867} {'step': 400, 'loss': 0.326, 'accuracy': 0.862} {'step': 600, 'loss': 0.331, 'accuracy': 0.86} {'step': 800, 'loss': 0.333, 'accuracy': 0.859} {'step': 1000, 'loss': 0.332, 'accuracy': 0.859} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 9 | 0.332 | 0.859 | 0.462 | 0.789 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:58:00 {'step': 200, 'loss': 0.309, 'accuracy': 0.869} {'step': 400, 'loss': 0.31, 'accuracy': 0.872} {'step': 600, 'loss': 0.31, 'accuracy': 0.871} {'step': 800, 'loss': 0.311, 'accuracy': 0.869} {'step': 1000, 'loss': 0.314, 'accuracy': 0.869} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 10 | 0.314 | 0.869 | 0.46 | 0.793 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:58:26 {'step': 200, 'loss': 0.3, 'accuracy': 0.88} {'step': 400, 'loss': 0.293, 'accuracy': 0.881} {'step': 600, 'loss': 0.297, 'accuracy': 0.878} {'step': 800, 'loss': 0.299, 'accuracy': 0.877} {'step': 1000, 'loss': 0.297, 'accuracy': 0.878} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 11 | 0.297 | 0.878 | 0.471 | 0.789 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:58:54 {'step': 200, 'loss': 0.275, 'accuracy': 0.891} {'step': 400, 'loss': 0.282, 'accuracy': 0.887} {'step': 600, 'loss': 0.283, 'accuracy': 0.888} {'step': 800, 'loss': 0.283, 'accuracy': 0.887} {'step': 1000, 'loss': 0.282, 'accuracy': 0.886} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 12 | 0.282 | 0.886 | 0.465 | 0.795 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:59:22 {'step': 200, 'loss': 0.26, 'accuracy': 0.903} {'step': 400, 'loss': 0.268, 'accuracy': 0.894} {'step': 600, 'loss': 0.271, 'accuracy': 0.893} {'step': 800, 'loss': 0.267, 'accuracy': 0.893} {'step': 1000, 'loss': 0.268, 'accuracy': 0.892} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 13 | 0.268 | 0.892 | 0.472 | 0.794 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:59:49 {'step': 200, 'loss': 0.252, 'accuracy': 0.903} {'step': 400, 'loss': 0.25, 'accuracy': 0.905} {'step': 600, 'loss': 0.251, 'accuracy': 0.903} {'step': 800, 'loss': 0.253, 'accuracy': 0.9} {'step': 1000, 'loss': 0.255, 'accuracy': 0.9} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 14 | 0.255 | 0.9 | 0.469 | 0.796 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 18:00:16 {'step': 200, 'loss': 0.242, 'accuracy': 0.912} {'step': 400, 'loss': 0.237, 'accuracy': 0.911} {'step': 600, 'loss': 0.24, 'accuracy': 0.91} {'step': 800, 'loss': 0.241, 'accuracy': 0.908} {'step': 1000, 'loss': 0.242, 'accuracy': 0.906} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 15 | 0.242 | 0.906 | 0.475 | 0.797 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 18:00:44 {'step': 200, 'loss': 0.218, 'accuracy': 0.921} {'step': 400, 'loss': 0.223, 'accuracy': 0.916} {'step': 600, 'loss': 0.229, 'accuracy': 0.912} {'step': 800, 'loss': 0.229, 'accuracy': 0.913} {'step': 1000, 'loss': 0.231, 'accuracy': 0.911} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 16 | 0.231 | 0.911 | 0.486 | 0.794 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 18:01:12 {'step': 200, 'loss': 0.21, 'accuracy': 0.919} {'step': 400, 'loss': 0.22, 'accuracy': 0.915} {'step': 600, 'loss': 0.22, 'accuracy': 0.915} {'step': 800, 'loss': 0.22, 'accuracy': 0.916} {'step': 1000, 'loss': 0.22, 'accuracy': 0.916} +-------+------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+------+----------+----------+--------------+ | 17 | 0.22 | 0.916 | 0.486 | 0.796 | +-------+------+----------+----------+--------------+ ================================================================================2020-05-09 18:02:24 {'step': 200, 'loss': 0.206, 'accuracy': 0.927} {'step': 400, 'loss': 0.21, 'accuracy': 0.923} {'step': 600, 'loss': 0.21, 'accuracy': 0.924} {'step': 800, 'loss': 0.213, 'accuracy': 0.922} {'step': 1000, 'loss': 0.21, 'accuracy': 0.923} +-------+------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+------+----------+----------+--------------+ | 18 | 0.21 | 0.923 | 0.493 | 0.796 | +-------+------+----------+----------+--------------+ ================================================================================2020-05-09 18:02:53 {'step': 200, 'loss': 0.191, 'accuracy': 0.932} {'step': 400, 'loss': 0.197, 'accuracy': 0.926} {'step': 600, 'loss': 0.199, 'accuracy': 0.928} {'step': 800, 'loss': 0.199, 'accuracy': 0.927} {'step': 1000, 'loss': 0.2, 'accuracy': 0.927} +-------+------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+------+----------+----------+--------------+ | 19 | 0.2 | 0.927 | 0.5 | 0.794 | +-------+------+----------+----------+--------------+ ================================================================================2020-05-09 18:03:22 {'step': 200, 'loss': 0.19, 'accuracy': 0.934} {'step': 400, 'loss': 0.192, 'accuracy': 0.931} {'step': 600, 'loss': 0.195, 'accuracy': 0.929} {'step': 800, 'loss': 0.194, 'accuracy': 0.93} {'step': 1000, 'loss': 0.191, 'accuracy': 0.931} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 20 | 0.191 | 0.931 | 0.506 | 0.795 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 18:03:58 Finished Training... \u56db\uff0c\u8bc4\u4f30\u6a21\u578b # % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( dfhistory , metric ): train_metrics = dfhistory [ metric ] val_metrics = dfhistory [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( dfhistory , \"loss\" ) plot_metric ( dfhistory , \"accuracy\" ) # \u8bc4\u4f30 model . evaluate ( dl_test ) {'val_loss': 0.5056138457655907, 'val_accuracy': 0.7948000040054322} \u4e94\uff0c\u4f7f\u7528\u6a21\u578b # model . predict ( dl_test ) tensor([[3.9803e-02], [9.9295e-01], [6.0493e-01], ..., [1.2023e-01], [9.3701e-01], [2.5752e-04]]) \u516d\uff0c\u4fdd\u5b58\u6a21\u578b # \u63a8\u8350\u4f7f\u7528\u4fdd\u5b58\u53c2\u6570\u65b9\u5f0f\u4fdd\u5b58Pytorch\u6a21\u578b\u3002 print ( model . state_dict () . keys ()) odict_keys(['embedding.weight', 'conv.conv_1.weight', 'conv.conv_1.bias', 'conv.conv_2.weight', 'conv.conv_2.bias', 'dense.linear.weight', 'dense.linear.bias']) # \u4fdd\u5b58\u6a21\u578b\u53c2\u6570 torch . save ( model . state_dict (), \"../data/model_parameter.pkl\" ) model_clone = Net () model_clone . load_state_dict ( torch . load ( \"../data/model_parameter.pkl\" )) model_clone . compile ( loss_func = nn . BCELoss (), optimizer = torch . optim . Adagrad ( model . parameters (), lr = 0.02 ), metrics_dict = { \"accuracy\" : accuracy }) # \u8bc4\u4f30\u6a21\u578b model_clone . evaluate ( dl_test ) {'val_loss': 0.5056138457655907, 'val_accuracy': 0.7948000040054322} \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"1-3,\u6587\u672c\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-3%2C%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#1-3\u6587\u672c\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b","text":"","title":"1-3,\u6587\u672c\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-3%2C%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e00\u51c6\u5907\u6570\u636e","text":"imdb\u6570\u636e\u96c6\u7684\u76ee\u6807\u662f\u6839\u636e\u7535\u5f71\u8bc4\u8bba\u7684\u6587\u672c\u5185\u5bb9\u9884\u6d4b\u8bc4\u8bba\u7684\u60c5\u611f\u6807\u7b7e\u3002 \u8bad\u7ec3\u96c6\u670920000\u6761\u7535\u5f71\u8bc4\u8bba\u6587\u672c\uff0c\u6d4b\u8bd5\u96c6\u67095000\u6761\u7535\u5f71\u8bc4\u8bba\u6587\u672c\uff0c\u5176\u4e2d\u6b63\u9762\u8bc4\u8bba\u548c\u8d1f\u9762\u8bc4\u8bba\u90fd\u5404\u5360\u4e00\u534a\u3002 \u6587\u672c\u6570\u636e\u9884\u5904\u7406\u8f83\u4e3a\u7e41\u7410\uff0c\u5305\u62ec\u4e2d\u6587\u5207\u8bcd\uff08\u672c\u793a\u4f8b\u4e0d\u6d89\u53ca\uff09\uff0c\u6784\u5efa\u8bcd\u5178\uff0c\u7f16\u7801\u8f6c\u6362\uff0c\u5e8f\u5217\u586b\u5145\uff0c\u6784\u5efa\u6570\u636e\u7ba1\u9053\u7b49\u7b49\u3002 \u5728torch\u4e2d\u9884\u5904\u7406\u6587\u672c\u6570\u636e\u4e00\u822c\u4f7f\u7528torchtext\u6216\u8005\u81ea\u5b9a\u4e49Dataset\uff0ctorchtext\u529f\u80fd\u975e\u5e38\u5f3a\u5927\uff0c\u53ef\u4ee5\u6784\u5efa\u6587\u672c\u5206\u7c7b\uff0c\u5e8f\u5217\u6807\u6ce8\uff0c\u95ee\u7b54\u6a21\u578b\uff0c\u673a\u5668\u7ffb\u8bd1\u7b49NLP\u4efb\u52a1\u7684\u6570\u636e\u96c6\u3002 \u4e0b\u9762\u4ec5\u6f14\u793a\u4f7f\u7528\u5b83\u6765\u6784\u5efa\u6587\u672c\u5206\u7c7b\u6570\u636e\u96c6\u7684\u65b9\u6cd5\u3002 \u8f83\u5b8c\u6574\u7684\u6559\u7a0b\u53ef\u4ee5\u53c2\u8003\u4ee5\u4e0b\u77e5\u4e4e\u6587\u7ae0\uff1a\u300apytorch\u5b66\u4e60\u7b14\u8bb0\u2014Torchtext\u300b https://zhuanlan.zhihu.com/p/65833208 torchtext\u5e38\u89c1API\u4e00\u89c8 torchtext.data.Example : \u7528\u6765\u8868\u793a\u4e00\u4e2a\u6837\u672c\uff0c\u6570\u636e\u548c\u6807\u7b7e torchtext.vocab.Vocab: \u8bcd\u6c47\u8868\uff0c\u53ef\u4ee5\u5bfc\u5165\u4e00\u4e9b\u9884\u8bad\u7ec3\u8bcd\u5411\u91cf torchtext.data.Datasets: \u6570\u636e\u96c6\u7c7b\uff0c __getitem__ \u8fd4\u56de Example\u5b9e\u4f8b, torchtext.data.TabularDataset\u662f\u5176\u5b50\u7c7b\u3002 torchtext.data.Field : \u7528\u6765\u5b9a\u4e49\u5b57\u6bb5\u7684\u5904\u7406\u65b9\u6cd5\uff08\u6587\u672c\u5b57\u6bb5\uff0c\u6807\u7b7e\u5b57\u6bb5\uff09\u521b\u5efa Example\u65f6\u7684 \u9884\u5904\u7406\uff0cbatch \u65f6\u7684\u4e00\u4e9b\u5904\u7406\u64cd\u4f5c\u3002 torchtext.data.Iterator: \u8fed\u4ee3\u5668\uff0c\u7528\u6765\u751f\u6210 batch torchtext.datasets: \u5305\u542b\u4e86\u5e38\u89c1\u7684\u6570\u636e\u96c6. import torch import string , re import torchtext MAX_WORDS = 10000 # \u4ec5\u8003\u8651\u6700\u9ad8\u9891\u768410000\u4e2a\u8bcd MAX_LEN = 200 # \u6bcf\u4e2a\u6837\u672c\u4fdd\u7559200\u4e2a\u8bcd\u7684\u957f\u5ea6 BATCH_SIZE = 20 #\u5206\u8bcd\u65b9\u6cd5 tokenizer = lambda x : re . sub ( '[ %s ]' % string . punctuation , \"\" , x ) . split ( \" \" ) #\u8fc7\u6ee4\u6389\u4f4e\u9891\u8bcd def filterLowFreqWords ( arr , vocab ): arr = [[ x if x < MAX_WORDS else 0 for x in example ] for example in arr ] return arr #1,\u5b9a\u4e49\u5404\u4e2a\u5b57\u6bb5\u7684\u9884\u5904\u7406\u65b9\u6cd5 TEXT = torchtext . data . Field ( sequential = True , tokenize = tokenizer , lower = True , fix_length = MAX_LEN , postprocessing = filterLowFreqWords ) LABEL = torchtext . data . Field ( sequential = False , use_vocab = False ) #2,\u6784\u5efa\u8868\u683c\u578bdataset #torchtext.data.TabularDataset\u53ef\u8bfb\u53d6csv,tsv,json\u7b49\u683c\u5f0f ds_train , ds_test = torchtext . data . TabularDataset . splits ( path = '../data/imdb' , train = 'train.tsv' , test = 'test.tsv' , format = 'tsv' , fields = [( 'label' , LABEL ), ( 'text' , TEXT )], skip_header = False ) #3,\u6784\u5efa\u8bcd\u5178 TEXT . build_vocab ( ds_train ) #4,\u6784\u5efa\u6570\u636e\u7ba1\u9053\u8fed\u4ee3\u5668 train_iter , test_iter = torchtext . data . Iterator . splits ( ( ds_train , ds_test ), sort_within_batch = True , sort_key = lambda x : len ( x . text ), batch_sizes = ( BATCH_SIZE , BATCH_SIZE )) #\u67e5\u770bexample\u4fe1\u606f print ( ds_train [ 0 ] . text ) print ( ds_train [ 0 ] . label ) ['it', 'really', 'boggles', 'my', 'mind', 'when', 'someone', 'comes', 'across', 'a', 'movie', 'like', 'this', 'and', 'claims', 'it', 'to', 'be', 'one', 'of', 'the', 'worst', 'slasher', 'films', 'out', 'there', 'this', 'is', 'by', 'far', 'not', 'one', 'of', 'the', 'worst', 'out', 'there', 'still', 'not', 'a', 'good', 'movie', 'but', 'not', 'the', 'worst', 'nonetheless', 'go', 'see', 'something', 'like', 'death', 'nurse', 'or', 'blood', 'lake', 'and', 'then', 'come', 'back', 'to', 'me', 'and', 'tell', 'me', 'if', 'you', 'think', 'the', 'night', 'brings', 'charlie', 'is', 'the', 'worst', 'the', 'film', 'has', 'decent', 'camera', 'work', 'and', 'editing', 'which', 'is', 'way', 'more', 'than', 'i', 'can', 'say', 'for', 'many', 'more', 'extremely', 'obscure', 'slasher', 'filmsbr', 'br', 'the', 'film', 'doesnt', 'deliver', 'on', 'the', 'onscreen', 'deaths', 'theres', 'one', 'death', 'where', 'you', 'see', 'his', 'pruning', 'saw', 'rip', 'into', 'a', 'neck', 'but', 'all', 'other', 'deaths', 'are', 'hardly', 'interesting', 'but', 'the', 'lack', 'of', 'onscreen', 'graphic', 'violence', 'doesnt', 'mean', 'this', 'isnt', 'a', 'slasher', 'film', 'just', 'a', 'bad', 'onebr', 'br', 'the', 'film', 'was', 'obviously', 'intended', 'not', 'to', 'be', 'taken', 'too', 'seriously', 'the', 'film', 'came', 'in', 'at', 'the', 'end', 'of', 'the', 'second', 'slasher', 'cycle', 'so', 'it', 'certainly', 'was', 'a', 'reflection', 'on', 'traditional', 'slasher', 'elements', 'done', 'in', 'a', 'tongue', 'in', 'cheek', 'way', 'for', 'example', 'after', 'a', 'kill', 'charlie', 'goes', 'to', 'the', 'towns', 'welcome', 'sign', 'and', 'marks', 'the', 'population', 'down', 'one', 'less', 'this', 'is', 'something', 'that', 'can', 'only', 'get', 'a', 'laughbr', 'br', 'if', 'youre', 'into', 'slasher', 'films', 'definitely', 'give', 'this', 'film', 'a', 'watch', 'it', 'is', 'slightly', 'different', 'than', 'your', 'usual', 'slasher', 'film', 'with', 'possibility', 'of', 'two', 'killers', 'but', 'not', 'by', 'much', 'the', 'comedy', 'of', 'the', 'movie', 'is', 'pretty', 'much', 'telling', 'the', 'audience', 'to', 'relax', 'and', 'not', 'take', 'the', 'movie', 'so', 'god', 'darn', 'serious', 'you', 'may', 'forget', 'the', 'movie', 'you', 'may', 'remember', 'it', 'ill', 'remember', 'it', 'because', 'i', 'love', 'the', 'name'] 0 # \u67e5\u770b\u8bcd\u5178\u4fe1\u606f print ( len ( TEXT . vocab )) #itos: index to string print ( TEXT . vocab . itos [ 0 ]) print ( TEXT . vocab . itos [ 1 ]) #stoi: string to index print ( TEXT . vocab . stoi [ '<unk>' ]) #unknown \u672a\u77e5\u8bcd print ( TEXT . vocab . stoi [ '<pad>' ]) #padding \u586b\u5145 #freqs: \u8bcd\u9891 print ( TEXT . vocab . freqs [ '<unk>' ]) print ( TEXT . vocab . freqs [ 'a' ]) print ( TEXT . vocab . freqs [ 'good' ]) 108197 <unk> <pad> 0 1 0 129453 11457 # \u67e5\u770b\u6570\u636e\u7ba1\u9053\u4fe1\u606f # \u6ce8\u610f\u6709\u5751\uff1atext\u7b2c0\u7ef4\u662f\u53e5\u5b50\u957f\u5ea6 for batch in train_iter : features = batch . text labels = batch . label print ( features ) print ( features . shape ) print ( labels ) break tensor([[ 17, 31, 148, ..., 54, 11, 201], [ 2, 2, 904, ..., 335, 7, 109], [1371, 1737, 44, ..., 806, 2, 11], ..., [ 6, 5, 62, ..., 1, 1, 1], [ 170, 0, 27, ..., 1, 1, 1], [ 15, 0, 45, ..., 1, 1, 1]]) torch.Size([200, 20]) tensor([0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0]) # \u5c06\u6570\u636e\u7ba1\u9053\u7ec4\u7ec7\u6210torch.utils.data.DataLoader\u76f8\u4f3c\u7684features,label\u8f93\u51fa\u5f62\u5f0f class DataLoader : def __init__ ( self , data_iter ): self . data_iter = data_iter self . length = len ( data_iter ) def __len__ ( self ): return self . length def __iter__ ( self ): # \u6ce8\u610f\uff1a\u6b64\u5904\u8c03\u6574features\u4e3a batch first\uff0c\u5e76\u8c03\u6574label\u7684shape\u548cdtype for batch in self . data_iter : yield ( torch . transpose ( batch . text , 0 , 1 ), torch . unsqueeze ( batch . label . float (), dim = 1 )) dl_train = DataLoader ( train_iter ) dl_test = DataLoader ( test_iter )","title":"\u4e00\uff0c\u51c6\u5907\u6570\u636e"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-3%2C%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e8c\u5b9a\u4e49\u6a21\u578b","text":"\u4f7f\u7528Pytorch\u901a\u5e38\u6709\u4e09\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528nn.Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u6a21\u578b\u5e76\u8f85\u52a9\u5e94\u7528\u6a21\u578b\u5bb9\u5668(nn.Sequential,nn.ModuleList,nn.ModuleDict)\u8fdb\u884c\u5c01\u88c5\u3002 \u6b64\u5904\u9009\u62e9\u4f7f\u7528\u7b2c\u4e09\u79cd\u65b9\u5f0f\u8fdb\u884c\u6784\u5efa\u3002 \u7531\u4e8e\u63a5\u4e0b\u6765\u4f7f\u7528\u7c7b\u5f62\u5f0f\u7684\u8bad\u7ec3\u5faa\u73af\uff0c\u6211\u4eec\u5c06\u6a21\u578b\u5c01\u88c5\u6210torchkeras.Model\u7c7b\u6765\u83b7\u5f97\u7c7b\u4f3cKeras\u4e2d\u9ad8\u9636\u6a21\u578b\u63a5\u53e3\u7684\u529f\u80fd\u3002 Model\u7c7b\u5b9e\u9645\u4e0a\u7ee7\u627f\u81eann.Module\u7c7b\u3002 import torch from torch import nn import torchkeras torch . random . seed () import torch from torch import nn class Net ( torchkeras . Model ): def __init__ ( self ): super ( Net , self ) . __init__ () #\u8bbe\u7f6epadding_idx\u53c2\u6570\u540e\u5c06\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5c06\u586b\u5145\u7684token\u59cb\u7ec8\u8d4b\u503c\u4e3a0\u5411\u91cf self . embedding = nn . Embedding ( num_embeddings = MAX_WORDS , embedding_dim = 3 , padding_idx = 1 ) self . conv = nn . Sequential () self . conv . add_module ( \"conv_1\" , nn . Conv1d ( in_channels = 3 , out_channels = 16 , kernel_size = 5 )) self . conv . add_module ( \"pool_1\" , nn . MaxPool1d ( kernel_size = 2 )) self . conv . add_module ( \"relu_1\" , nn . ReLU ()) self . conv . add_module ( \"conv_2\" , nn . Conv1d ( in_channels = 16 , out_channels = 128 , kernel_size = 2 )) self . conv . add_module ( \"pool_2\" , nn . MaxPool1d ( kernel_size = 2 )) self . conv . add_module ( \"relu_2\" , nn . ReLU ()) self . dense = nn . Sequential () self . dense . add_module ( \"flatten\" , nn . Flatten ()) self . dense . add_module ( \"linear\" , nn . Linear ( 6144 , 1 )) self . dense . add_module ( \"sigmoid\" , nn . Sigmoid ()) def forward ( self , x ): x = self . embedding ( x ) . transpose ( 1 , 2 ) x = self . conv ( x ) y = self . dense ( x ) return y model = Net () print ( model ) model . summary ( input_shape = ( 200 ,), input_dtype = torch . LongTensor ) Net( (embedding): Embedding(10000, 3, padding_idx=1) (conv): Sequential( (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,)) (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_1): ReLU() (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,)) (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_2): ReLU() ) (dense): Sequential( (flatten): Flatten() (linear): Linear(in_features=6144, out_features=1, bias=True) (sigmoid): Sigmoid() ) ) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Embedding-1 [-1, 200, 3] 30,000 Conv1d-2 [-1, 16, 196] 256 MaxPool1d-3 [-1, 16, 98] 0 ReLU-4 [-1, 16, 98] 0 Conv1d-5 [-1, 128, 97] 4,224 MaxPool1d-6 [-1, 128, 48] 0 ReLU-7 [-1, 128, 48] 0 Flatten-8 [-1, 6144] 0 Linear-9 [-1, 1] 6,145 Sigmoid-10 [-1, 1] 0 ================================================================ Total params: 40,625 Trainable params: 40,625 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.000763 Forward/backward pass size (MB): 0.287796 Params size (MB): 0.154972 Estimated Total Size (MB): 0.443531 ----------------------------------------------------------------","title":"\u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-3%2C%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e09\u8bad\u7ec3\u6a21\u578b","text":"\u8bad\u7ec3Pytorch\u901a\u5e38\u9700\u8981\u7528\u6237\u7f16\u5199\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\uff0c\u8bad\u7ec3\u5faa\u73af\u7684\u4ee3\u7801\u98ce\u683c\u56e0\u4eba\u800c\u5f02\u3002 \u67093\u7c7b\u5178\u578b\u7684\u8bad\u7ec3\u5faa\u73af\u4ee3\u7801\u98ce\u683c\uff1a\u811a\u672c\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u51fd\u6570\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u7c7b\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\u3002 \u6b64\u5904\u4ecb\u7ecd\u4e00\u79cd\u7c7b\u5f62\u5f0f\u7684\u8bad\u7ec3\u5faa\u73af\u3002 \u6211\u4eec\u4eff\u7167Keras\u5b9a\u4e49\u4e86\u4e00\u4e2a\u9ad8\u9636\u7684\u6a21\u578b\u63a5\u53e3Model,\u5b9e\u73b0 fit, validate\uff0cpredict, summary \u65b9\u6cd5\uff0c\u76f8\u5f53\u4e8e\u7528\u6237\u81ea\u5b9a\u4e49\u9ad8\u9636API\u3002 # \u51c6\u786e\u7387 def accuracy ( y_pred , y_true ): y_pred = torch . where ( y_pred > 0.5 , torch . ones_like ( y_pred , dtype = torch . float32 ), torch . zeros_like ( y_pred , dtype = torch . float32 )) acc = torch . mean ( 1 - torch . abs ( y_true - y_pred )) return acc model . compile ( loss_func = nn . BCELoss (), optimizer = torch . optim . Adagrad ( model . parameters (), lr = 0.02 ), metrics_dict = { \"accuracy\" : accuracy }) # \u6709\u65f6\u5019\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4e0d\u6536\u655b\uff0c\u9700\u8981\u591a\u8bd5\u51e0\u6b21 dfhistory = model . fit ( 20 , dl_train , dl_val = dl_test , log_step_freq = 200 ) Start Training ... ================================================================================2020-05-09 17:53:56 {'step': 200, 'loss': 1.127, 'accuracy': 0.504} {'step': 400, 'loss': 0.908, 'accuracy': 0.517} {'step': 600, 'loss': 0.833, 'accuracy': 0.531} {'step': 800, 'loss': 0.793, 'accuracy': 0.545} {'step': 1000, 'loss': 0.765, 'accuracy': 0.56} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 1 | 0.765 | 0.56 | 0.64 | 0.64 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:54:23 {'step': 200, 'loss': 0.626, 'accuracy': 0.659} {'step': 400, 'loss': 0.621, 'accuracy': 0.662} {'step': 600, 'loss': 0.616, 'accuracy': 0.664} {'step': 800, 'loss': 0.61, 'accuracy': 0.671} {'step': 1000, 'loss': 0.603, 'accuracy': 0.677} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 2 | 0.603 | 0.677 | 0.577 | 0.705 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:54:50 {'step': 200, 'loss': 0.545, 'accuracy': 0.726} {'step': 400, 'loss': 0.538, 'accuracy': 0.735} {'step': 600, 'loss': 0.532, 'accuracy': 0.737} {'step': 800, 'loss': 0.531, 'accuracy': 0.737} {'step': 1000, 'loss': 0.528, 'accuracy': 0.739} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 3 | 0.528 | 0.739 | 0.536 | 0.739 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:55:18 {'step': 200, 'loss': 0.488, 'accuracy': 0.773} {'step': 400, 'loss': 0.482, 'accuracy': 0.774} {'step': 600, 'loss': 0.482, 'accuracy': 0.773} {'step': 800, 'loss': 0.479, 'accuracy': 0.773} {'step': 1000, 'loss': 0.473, 'accuracy': 0.776} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 4 | 0.473 | 0.776 | 0.504 | 0.766 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:55:45 {'step': 200, 'loss': 0.446, 'accuracy': 0.789} {'step': 400, 'loss': 0.437, 'accuracy': 0.796} {'step': 600, 'loss': 0.436, 'accuracy': 0.799} {'step': 800, 'loss': 0.436, 'accuracy': 0.798} {'step': 1000, 'loss': 0.434, 'accuracy': 0.8} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 5 | 0.434 | 0.8 | 0.481 | 0.774 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:56:12 {'step': 200, 'loss': 0.404, 'accuracy': 0.817} {'step': 400, 'loss': 0.4, 'accuracy': 0.819} {'step': 600, 'loss': 0.398, 'accuracy': 0.821} {'step': 800, 'loss': 0.402, 'accuracy': 0.818} {'step': 1000, 'loss': 0.402, 'accuracy': 0.817} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 6 | 0.402 | 0.817 | 0.47 | 0.781 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:56:39 {'step': 200, 'loss': 0.369, 'accuracy': 0.834} {'step': 400, 'loss': 0.374, 'accuracy': 0.833} {'step': 600, 'loss': 0.373, 'accuracy': 0.834} {'step': 800, 'loss': 0.374, 'accuracy': 0.834} {'step': 1000, 'loss': 0.375, 'accuracy': 0.833} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 7 | 0.375 | 0.833 | 0.468 | 0.787 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:57:06 {'step': 200, 'loss': 0.36, 'accuracy': 0.839} {'step': 400, 'loss': 0.355, 'accuracy': 0.846} {'step': 600, 'loss': 0.35, 'accuracy': 0.849} {'step': 800, 'loss': 0.353, 'accuracy': 0.846} {'step': 1000, 'loss': 0.352, 'accuracy': 0.847} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 8 | 0.352 | 0.847 | 0.461 | 0.791 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:57:33 {'step': 200, 'loss': 0.313, 'accuracy': 0.867} {'step': 400, 'loss': 0.326, 'accuracy': 0.862} {'step': 600, 'loss': 0.331, 'accuracy': 0.86} {'step': 800, 'loss': 0.333, 'accuracy': 0.859} {'step': 1000, 'loss': 0.332, 'accuracy': 0.859} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 9 | 0.332 | 0.859 | 0.462 | 0.789 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:58:00 {'step': 200, 'loss': 0.309, 'accuracy': 0.869} {'step': 400, 'loss': 0.31, 'accuracy': 0.872} {'step': 600, 'loss': 0.31, 'accuracy': 0.871} {'step': 800, 'loss': 0.311, 'accuracy': 0.869} {'step': 1000, 'loss': 0.314, 'accuracy': 0.869} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 10 | 0.314 | 0.869 | 0.46 | 0.793 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:58:26 {'step': 200, 'loss': 0.3, 'accuracy': 0.88} {'step': 400, 'loss': 0.293, 'accuracy': 0.881} {'step': 600, 'loss': 0.297, 'accuracy': 0.878} {'step': 800, 'loss': 0.299, 'accuracy': 0.877} {'step': 1000, 'loss': 0.297, 'accuracy': 0.878} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 11 | 0.297 | 0.878 | 0.471 | 0.789 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:58:54 {'step': 200, 'loss': 0.275, 'accuracy': 0.891} {'step': 400, 'loss': 0.282, 'accuracy': 0.887} {'step': 600, 'loss': 0.283, 'accuracy': 0.888} {'step': 800, 'loss': 0.283, 'accuracy': 0.887} {'step': 1000, 'loss': 0.282, 'accuracy': 0.886} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 12 | 0.282 | 0.886 | 0.465 | 0.795 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:59:22 {'step': 200, 'loss': 0.26, 'accuracy': 0.903} {'step': 400, 'loss': 0.268, 'accuracy': 0.894} {'step': 600, 'loss': 0.271, 'accuracy': 0.893} {'step': 800, 'loss': 0.267, 'accuracy': 0.893} {'step': 1000, 'loss': 0.268, 'accuracy': 0.892} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 13 | 0.268 | 0.892 | 0.472 | 0.794 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 17:59:49 {'step': 200, 'loss': 0.252, 'accuracy': 0.903} {'step': 400, 'loss': 0.25, 'accuracy': 0.905} {'step': 600, 'loss': 0.251, 'accuracy': 0.903} {'step': 800, 'loss': 0.253, 'accuracy': 0.9} {'step': 1000, 'loss': 0.255, 'accuracy': 0.9} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 14 | 0.255 | 0.9 | 0.469 | 0.796 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 18:00:16 {'step': 200, 'loss': 0.242, 'accuracy': 0.912} {'step': 400, 'loss': 0.237, 'accuracy': 0.911} {'step': 600, 'loss': 0.24, 'accuracy': 0.91} {'step': 800, 'loss': 0.241, 'accuracy': 0.908} {'step': 1000, 'loss': 0.242, 'accuracy': 0.906} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 15 | 0.242 | 0.906 | 0.475 | 0.797 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 18:00:44 {'step': 200, 'loss': 0.218, 'accuracy': 0.921} {'step': 400, 'loss': 0.223, 'accuracy': 0.916} {'step': 600, 'loss': 0.229, 'accuracy': 0.912} {'step': 800, 'loss': 0.229, 'accuracy': 0.913} {'step': 1000, 'loss': 0.231, 'accuracy': 0.911} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 16 | 0.231 | 0.911 | 0.486 | 0.794 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 18:01:12 {'step': 200, 'loss': 0.21, 'accuracy': 0.919} {'step': 400, 'loss': 0.22, 'accuracy': 0.915} {'step': 600, 'loss': 0.22, 'accuracy': 0.915} {'step': 800, 'loss': 0.22, 'accuracy': 0.916} {'step': 1000, 'loss': 0.22, 'accuracy': 0.916} +-------+------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+------+----------+----------+--------------+ | 17 | 0.22 | 0.916 | 0.486 | 0.796 | +-------+------+----------+----------+--------------+ ================================================================================2020-05-09 18:02:24 {'step': 200, 'loss': 0.206, 'accuracy': 0.927} {'step': 400, 'loss': 0.21, 'accuracy': 0.923} {'step': 600, 'loss': 0.21, 'accuracy': 0.924} {'step': 800, 'loss': 0.213, 'accuracy': 0.922} {'step': 1000, 'loss': 0.21, 'accuracy': 0.923} +-------+------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+------+----------+----------+--------------+ | 18 | 0.21 | 0.923 | 0.493 | 0.796 | +-------+------+----------+----------+--------------+ ================================================================================2020-05-09 18:02:53 {'step': 200, 'loss': 0.191, 'accuracy': 0.932} {'step': 400, 'loss': 0.197, 'accuracy': 0.926} {'step': 600, 'loss': 0.199, 'accuracy': 0.928} {'step': 800, 'loss': 0.199, 'accuracy': 0.927} {'step': 1000, 'loss': 0.2, 'accuracy': 0.927} +-------+------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+------+----------+----------+--------------+ | 19 | 0.2 | 0.927 | 0.5 | 0.794 | +-------+------+----------+----------+--------------+ ================================================================================2020-05-09 18:03:22 {'step': 200, 'loss': 0.19, 'accuracy': 0.934} {'step': 400, 'loss': 0.192, 'accuracy': 0.931} {'step': 600, 'loss': 0.195, 'accuracy': 0.929} {'step': 800, 'loss': 0.194, 'accuracy': 0.93} {'step': 1000, 'loss': 0.191, 'accuracy': 0.931} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 20 | 0.191 | 0.931 | 0.506 | 0.795 | +-------+-------+----------+----------+--------------+ ================================================================================2020-05-09 18:03:58 Finished Training...","title":"\u4e09\uff0c\u8bad\u7ec3\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-3%2C%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u56db\u8bc4\u4f30\u6a21\u578b","text":"% matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( dfhistory , metric ): train_metrics = dfhistory [ metric ] val_metrics = dfhistory [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( dfhistory , \"loss\" ) plot_metric ( dfhistory , \"accuracy\" ) # \u8bc4\u4f30 model . evaluate ( dl_test ) {'val_loss': 0.5056138457655907, 'val_accuracy': 0.7948000040054322}","title":"\u56db\uff0c\u8bc4\u4f30\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-3%2C%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e94\u4f7f\u7528\u6a21\u578b","text":"model . predict ( dl_test ) tensor([[3.9803e-02], [9.9295e-01], [6.0493e-01], ..., [1.2023e-01], [9.3701e-01], [2.5752e-04]])","title":"\u4e94\uff0c\u4f7f\u7528\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-3%2C%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u516d\u4fdd\u5b58\u6a21\u578b","text":"\u63a8\u8350\u4f7f\u7528\u4fdd\u5b58\u53c2\u6570\u65b9\u5f0f\u4fdd\u5b58Pytorch\u6a21\u578b\u3002 print ( model . state_dict () . keys ()) odict_keys(['embedding.weight', 'conv.conv_1.weight', 'conv.conv_1.bias', 'conv.conv_2.weight', 'conv.conv_2.bias', 'dense.linear.weight', 'dense.linear.bias']) # \u4fdd\u5b58\u6a21\u578b\u53c2\u6570 torch . save ( model . state_dict (), \"../data/model_parameter.pkl\" ) model_clone = Net () model_clone . load_state_dict ( torch . load ( \"../data/model_parameter.pkl\" )) model_clone . compile ( loss_func = nn . BCELoss (), optimizer = torch . optim . Adagrad ( model . parameters (), lr = 0.02 ), metrics_dict = { \"accuracy\" : accuracy }) # \u8bc4\u4f30\u6a21\u578b model_clone . evaluate ( dl_test ) {'val_loss': 0.5056138457655907, 'val_accuracy': 0.7948000040054322} \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u516d\uff0c\u4fdd\u5b58\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-4%2C%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/","text":"1-4,\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b # 2020\u5e74\u53d1\u751f\u7684\u65b0\u51a0\u80ba\u708e\u75ab\u60c5\u707e\u96be\u7ed9\u5404\u56fd\u4eba\u6c11\u7684\u751f\u6d3b\u9020\u6210\u4e86\u8bf8\u591a\u65b9\u9762\u7684\u5f71\u54cd\u3002 \u6709\u7684\u540c\u5b66\u662f\u6536\u5165\u4e0a\u7684\uff0c\u6709\u7684\u540c\u5b66\u662f\u611f\u60c5\u4e0a\u7684\uff0c\u6709\u7684\u540c\u5b66\u662f\u5fc3\u7406\u4e0a\u7684\uff0c\u8fd8\u6709\u7684\u540c\u5b66\u662f\u4f53\u91cd\u4e0a\u7684\u3002 \u672c\u6587\u57fa\u4e8e\u4e2d\u56fd2020\u5e743\u6708\u4e4b\u524d\u7684\u75ab\u60c5\u6570\u636e\uff0c\u5efa\u7acb\u65f6\u95f4\u5e8f\u5217RNN\u6a21\u578b\uff0c\u5bf9\u4e2d\u56fd\u7684\u65b0\u51a0\u80ba\u708e\u75ab\u60c5\u7ed3\u675f\u65f6\u95f4\u8fdb\u884c\u9884\u6d4b\u3002 import os import datetime import importlib import torchkeras #\u6253\u5370\u65f6\u95f4 def printbar (): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) #mac\u7cfb\u7edf\u4e0apytorch\u548cmatplotlib\u5728jupyter\u4e2d\u540c\u65f6\u8dd1\u9700\u8981\u66f4\u6539\u73af\u5883\u53d8\u91cf os . environ [ \"KMP_DUPLICATE_LIB_OK\" ] = \"TRUE\" \u4e00\uff0c\u51c6\u5907\u6570\u636e # \u672c\u6587\u7684\u6570\u636e\u96c6\u53d6\u81eatushare\uff0c\u83b7\u53d6\u8be5\u6570\u636e\u96c6\u7684\u65b9\u6cd5\u53c2\u8003\u4e86\u4ee5\u4e0b\u6587\u7ae0\u3002 \u300a https://zhuanlan.zhihu.com/p/109556102 \u300b import numpy as np import pandas as pd import matplotlib.pyplot as plt % matplotlib inline % config InlineBackend . figure_format = 'svg' df = pd . read_csv ( \"../data/covid-19.csv\" , sep = \" \\t \" ) df . plot ( x = \"date\" , y = [ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ], figsize = ( 10 , 6 )) plt . xticks ( rotation = 60 ); dfdata = df . set_index ( \"date\" ) dfdiff = dfdata . diff ( periods = 1 ) . dropna () dfdiff = dfdiff . reset_index ( \"date\" ) dfdiff . plot ( x = \"date\" , y = [ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ], figsize = ( 10 , 6 )) plt . xticks ( rotation = 60 ) dfdiff = dfdiff . drop ( \"date\" , axis = 1 ) . astype ( \"float32\" ) dfdiff . head () \u4e0b\u9762\u6211\u4eec\u901a\u8fc7\u7ee7\u627ftorch.utils.data.Dataset\u5b9e\u73b0\u81ea\u5b9a\u4e49\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u3002 torch.utils.data.Dataset\u662f\u4e00\u4e2a\u62bd\u8c61\u7c7b\uff0c\u7528\u6237\u60f3\u8981\u52a0\u8f7d\u81ea\u5b9a\u4e49\u7684\u6570\u636e\u53ea\u9700\u8981\u7ee7\u627f\u8fd9\u4e2a\u7c7b\uff0c\u5e76\u4e14\u8986\u5199\u5176\u4e2d\u7684\u4e24\u4e2a\u65b9\u6cd5\u5373\u53ef\uff1a __len__ :\u5b9e\u73b0len(dataset)\u8fd4\u56de\u6574\u4e2a\u6570\u636e\u96c6\u7684\u5927\u5c0f\u3002 __getitem__ :\u7528\u6765\u83b7\u53d6\u4e00\u4e9b\u7d22\u5f15\u7684\u6570\u636e\uff0c\u4f7f dataset[i] \u8fd4\u56de\u6570\u636e\u96c6\u4e2d\u7b2ci\u4e2a\u6837\u672c\u3002 \u4e0d\u8986\u5199\u8fd9\u4e24\u4e2a\u65b9\u6cd5\u4f1a\u76f4\u63a5\u8fd4\u56de\u9519\u8bef\u3002 import torch from torch import nn from torch.utils.data import Dataset , DataLoader , TensorDataset #\u7528\u67d0\u65e5\u524d8\u5929\u7a97\u53e3\u6570\u636e\u4f5c\u4e3a\u8f93\u5165\u9884\u6d4b\u8be5\u65e5\u6570\u636e WINDOW_SIZE = 8 class Covid19Dataset ( Dataset ): def __len__ ( self ): return len ( dfdiff ) - WINDOW_SIZE def __getitem__ ( self , i ): x = dfdiff . loc [ i : i + WINDOW_SIZE - 1 ,:] feature = torch . tensor ( x . values ) y = dfdiff . loc [ i + WINDOW_SIZE ,:] label = torch . tensor ( y . values ) return ( feature , label ) ds_train = Covid19Dataset () #\u6570\u636e\u8f83\u5c0f\uff0c\u53ef\u4ee5\u5c06\u5168\u90e8\u8bad\u7ec3\u6570\u636e\u653e\u5165\u5230\u4e00\u4e2abatch\u4e2d\uff0c\u63d0\u5347\u6027\u80fd dl_train = DataLoader ( ds_train , batch_size = 38 ) \u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b # \u4f7f\u7528Pytorch\u901a\u5e38\u6709\u4e09\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528nn.Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u6a21\u578b\u5e76\u8f85\u52a9\u5e94\u7528\u6a21\u578b\u5bb9\u5668\u8fdb\u884c\u5c01\u88c5\u3002 \u6b64\u5904\u9009\u62e9\u7b2c\u4e8c\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\u3002 \u7531\u4e8e\u63a5\u4e0b\u6765\u4f7f\u7528\u7c7b\u5f62\u5f0f\u7684\u8bad\u7ec3\u5faa\u73af\uff0c\u6211\u4eec\u8fdb\u4e00\u6b65\u5c06\u6a21\u578b\u5c01\u88c5\u6210torchkeras\u4e2d\u7684Model\u7c7b\u6765\u83b7\u5f97\u7c7b\u4f3cKeras\u4e2d\u9ad8\u9636\u6a21\u578b\u63a5\u53e3\u7684\u529f\u80fd\u3002 Model\u7c7b\u5b9e\u9645\u4e0a\u7ee7\u627f\u81eann.Module\u7c7b\u3002 import torch from torch import nn import importlib import torchkeras torch . random . seed () class Block ( nn . Module ): def __init__ ( self ): super ( Block , self ) . __init__ () def forward ( self , x , x_input ): x_out = torch . max (( 1 + x ) * x_input [:, - 1 ,:], torch . tensor ( 0.0 )) return x_out class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () # 3\u5c42lstm self . lstm = nn . LSTM ( input_size = 3 , hidden_size = 3 , num_layers = 5 , batch_first = True ) self . linear = nn . Linear ( 3 , 3 ) self . block = Block () def forward ( self , x_input ): x = self . lstm ( x_input )[ 0 ][:, - 1 ,:] x = self . linear ( x ) y = self . block ( x , x_input ) return y net = Net () model = torchkeras . Model ( net ) print ( model ) model . summary ( input_shape = ( 8 , 3 ), input_dtype = torch . FloatTensor ) Net( (lstm): LSTM(3, 3, num_layers=5, batch_first=True) (linear): Linear(in_features=3, out_features=3, bias=True) (block): Block() ) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ LSTM-1 [-1, 8, 3] 480 Linear-2 [-1, 3] 12 Block-3 [-1, 3] 0 ================================================================ Total params: 492 Trainable params: 492 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.000092 Forward/backward pass size (MB): 0.000229 Params size (MB): 0.001877 Estimated Total Size (MB): 0.002197 ---------------------------------------------------------------- \u4e09\uff0c\u8bad\u7ec3\u6a21\u578b # \u8bad\u7ec3Pytorch\u901a\u5e38\u9700\u8981\u7528\u6237\u7f16\u5199\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\uff0c\u8bad\u7ec3\u5faa\u73af\u7684\u4ee3\u7801\u98ce\u683c\u56e0\u4eba\u800c\u5f02\u3002 \u67093\u7c7b\u5178\u578b\u7684\u8bad\u7ec3\u5faa\u73af\u4ee3\u7801\u98ce\u683c\uff1a\u811a\u672c\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u51fd\u6570\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u7c7b\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\u3002 \u6b64\u5904\u4ecb\u7ecd\u4e00\u79cd\u7c7b\u5f62\u5f0f\u7684\u8bad\u7ec3\u5faa\u73af\u3002 \u6211\u4eec\u4eff\u7167Keras\u5b9a\u4e49\u4e86\u4e00\u4e2a\u9ad8\u9636\u7684\u6a21\u578b\u63a5\u53e3Model,\u5b9e\u73b0 fit, validate\uff0cpredict, summary \u65b9\u6cd5\uff0c\u76f8\u5f53\u4e8e\u7528\u6237\u81ea\u5b9a\u4e49\u9ad8\u9636API\u3002 \u6ce8\uff1a\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u8c03\u8bd5\u8f83\u4e3a\u56f0\u96be\uff0c\u9700\u8981\u8bbe\u7f6e\u591a\u4e2a\u4e0d\u540c\u7684\u5b66\u4e60\u7387\u591a\u6b21\u5c1d\u8bd5\uff0c\u4ee5\u53d6\u5f97\u8f83\u597d\u7684\u6548\u679c\u3002 def mspe ( y_pred , y_true ): err_percent = ( y_true - y_pred ) ** 2 / ( torch . max ( y_true ** 2 , torch . tensor ( 1e-7 ))) return torch . mean ( err_percent ) model . compile ( loss_func = mspe , optimizer = torch . optim . Adagrad ( model . parameters (), lr = 0.1 )) dfhistory = model . fit ( 100 , dl_train , log_step_freq = 10 ) \u56db\uff0c\u8bc4\u4f30\u6a21\u578b # \u8bc4\u4f30\u6a21\u578b\u4e00\u822c\u8981\u8bbe\u7f6e\u9a8c\u8bc1\u96c6\u6216\u8005\u6d4b\u8bd5\u96c6\uff0c\u7531\u4e8e\u6b64\u4f8b\u6570\u636e\u8f83\u5c11\uff0c\u6211\u4eec\u4ec5\u4ec5\u53ef\u89c6\u5316\u635f\u5931\u51fd\u6570\u5728\u8bad\u7ec3\u96c6\u4e0a\u7684\u8fed\u4ee3\u60c5\u51b5\u3002 % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( dfhistory , metric ): train_metrics = dfhistory [ metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . title ( 'Training ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric ]) plt . show () plot_metric ( dfhistory , \"loss\" ) \u4e94\uff0c\u4f7f\u7528\u6a21\u578b # \u6b64\u5904\u6211\u4eec\u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u75ab\u60c5\u7ed3\u675f\u65f6\u95f4\uff0c\u5373 \u65b0\u589e\u786e\u8bca\u75c5\u4f8b\u4e3a0 \u7684\u65f6\u95f4\u3002 #\u4f7f\u7528dfresult\u8bb0\u5f55\u73b0\u6709\u6570\u636e\u4ee5\u53ca\u6b64\u540e\u9884\u6d4b\u7684\u75ab\u60c5\u6570\u636e dfresult = dfdiff [[ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ]] . copy () dfresult . tail () #\u9884\u6d4b\u6b64\u540e200\u5929\u7684\u65b0\u589e\u8d70\u52bf,\u5c06\u5176\u7ed3\u679c\u6dfb\u52a0\u5230dfresult\u4e2d for i in range ( 200 ): arr_input = torch . unsqueeze ( torch . from_numpy ( dfresult . values [ - 38 :,:]), axis = 0 ) arr_predict = model . forward ( arr_input ) dfpredict = pd . DataFrame ( torch . floor ( arr_predict ) . data . numpy (), columns = dfresult . columns ) dfresult = dfresult . append ( dfpredict , ignore_index = True ) dfresult . query ( \"confirmed_num==0\" ) . head () # \u7b2c50\u5929\u5f00\u59cb\u65b0\u589e\u786e\u8bca\u964d\u4e3a0\uff0c\u7b2c45\u5929\u5bf9\u5e943\u670810\u65e5\uff0c\u4e5f\u5c31\u662f5\u5929\u540e\uff0c\u5373\u9884\u8ba13\u670815\u65e5\u65b0\u589e\u786e\u8bca\u964d\u4e3a0 # \u6ce8\uff1a\u8be5\u9884\u6d4b\u504f\u4e50\u89c2 dfresult . query ( \"cured_num==0\" ) . head () # \u7b2c132\u5929\u5f00\u59cb\u65b0\u589e\u6cbb\u6108\u964d\u4e3a0\uff0c\u7b2c45\u5929\u5bf9\u5e943\u670810\u65e5\uff0c\u4e5f\u5c31\u662f\u5927\u69823\u4e2a\u6708\u540e\uff0c\u53736\u670810\u65e5\u5de6\u53f3\u5168\u90e8\u6cbb\u6108\u3002 # \u6ce8: \u8be5\u9884\u6d4b\u504f\u60b2\u89c2\uff0c\u5e76\u4e14\u5b58\u5728\u95ee\u9898\uff0c\u5982\u679c\u5c06\u6bcf\u5929\u65b0\u589e\u6cbb\u6108\u4eba\u6570\u52a0\u8d77\u6765\uff0c\u5c06\u8d85\u8fc7\u7d2f\u8ba1\u786e\u8bca\u4eba\u6570\u3002 dfresult . query ( \"dead_num==0\" ) . head () # \u7b2c50\u5929\u5f00\u59cb\u65b0\u589e\u786e\u8bca\u964d\u4e3a0\uff0c\u7b2c45\u5929\u5bf9\u5e943\u670810\u65e5\uff0c\u4e5f\u5c31\u662f5\u5929\u540e\uff0c\u5373\u9884\u8ba13\u670815\u65e5\u65b0\u589e\u786e\u8bca\u964d\u4e3a0 # \u6ce8\uff1a\u8be5\u9884\u6d4b\u504f\u4e50\u89c2 \u516d\uff0c\u4fdd\u5b58\u6a21\u578b # \u63a8\u8350\u4f7f\u7528\u4fdd\u5b58\u53c2\u6570\u65b9\u5f0f\u4fdd\u5b58Pytorch\u6a21\u578b\u3002 print ( model . net . state_dict () . keys ()) # \u4fdd\u5b58\u6a21\u578b\u53c2\u6570 torch . save ( model . net . state_dict (), \"../data/model_parameter.pkl\" ) net_clone = Net () net_clone . load_state_dict ( torch . load ( \"../data/model_parameter.pkl\" )) model_clone = torchkeras . Model ( net_clone ) model_clone . compile ( loss_func = mspe ) # \u8bc4\u4f30\u6a21\u578b model_clone . evaluate ( dl_train ) {'val_loss': 4.254558563232422} \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"1-4,\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-4%2C%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#1-4\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b","text":"2020\u5e74\u53d1\u751f\u7684\u65b0\u51a0\u80ba\u708e\u75ab\u60c5\u707e\u96be\u7ed9\u5404\u56fd\u4eba\u6c11\u7684\u751f\u6d3b\u9020\u6210\u4e86\u8bf8\u591a\u65b9\u9762\u7684\u5f71\u54cd\u3002 \u6709\u7684\u540c\u5b66\u662f\u6536\u5165\u4e0a\u7684\uff0c\u6709\u7684\u540c\u5b66\u662f\u611f\u60c5\u4e0a\u7684\uff0c\u6709\u7684\u540c\u5b66\u662f\u5fc3\u7406\u4e0a\u7684\uff0c\u8fd8\u6709\u7684\u540c\u5b66\u662f\u4f53\u91cd\u4e0a\u7684\u3002 \u672c\u6587\u57fa\u4e8e\u4e2d\u56fd2020\u5e743\u6708\u4e4b\u524d\u7684\u75ab\u60c5\u6570\u636e\uff0c\u5efa\u7acb\u65f6\u95f4\u5e8f\u5217RNN\u6a21\u578b\uff0c\u5bf9\u4e2d\u56fd\u7684\u65b0\u51a0\u80ba\u708e\u75ab\u60c5\u7ed3\u675f\u65f6\u95f4\u8fdb\u884c\u9884\u6d4b\u3002 import os import datetime import importlib import torchkeras #\u6253\u5370\u65f6\u95f4 def printbar (): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) #mac\u7cfb\u7edf\u4e0apytorch\u548cmatplotlib\u5728jupyter\u4e2d\u540c\u65f6\u8dd1\u9700\u8981\u66f4\u6539\u73af\u5883\u53d8\u91cf os . environ [ \"KMP_DUPLICATE_LIB_OK\" ] = \"TRUE\"","title":"1-4,\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5efa\u6a21\u6d41\u7a0b\u8303\u4f8b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-4%2C%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e00\u51c6\u5907\u6570\u636e","text":"\u672c\u6587\u7684\u6570\u636e\u96c6\u53d6\u81eatushare\uff0c\u83b7\u53d6\u8be5\u6570\u636e\u96c6\u7684\u65b9\u6cd5\u53c2\u8003\u4e86\u4ee5\u4e0b\u6587\u7ae0\u3002 \u300a https://zhuanlan.zhihu.com/p/109556102 \u300b import numpy as np import pandas as pd import matplotlib.pyplot as plt % matplotlib inline % config InlineBackend . figure_format = 'svg' df = pd . read_csv ( \"../data/covid-19.csv\" , sep = \" \\t \" ) df . plot ( x = \"date\" , y = [ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ], figsize = ( 10 , 6 )) plt . xticks ( rotation = 60 ); dfdata = df . set_index ( \"date\" ) dfdiff = dfdata . diff ( periods = 1 ) . dropna () dfdiff = dfdiff . reset_index ( \"date\" ) dfdiff . plot ( x = \"date\" , y = [ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ], figsize = ( 10 , 6 )) plt . xticks ( rotation = 60 ) dfdiff = dfdiff . drop ( \"date\" , axis = 1 ) . astype ( \"float32\" ) dfdiff . head () \u4e0b\u9762\u6211\u4eec\u901a\u8fc7\u7ee7\u627ftorch.utils.data.Dataset\u5b9e\u73b0\u81ea\u5b9a\u4e49\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u3002 torch.utils.data.Dataset\u662f\u4e00\u4e2a\u62bd\u8c61\u7c7b\uff0c\u7528\u6237\u60f3\u8981\u52a0\u8f7d\u81ea\u5b9a\u4e49\u7684\u6570\u636e\u53ea\u9700\u8981\u7ee7\u627f\u8fd9\u4e2a\u7c7b\uff0c\u5e76\u4e14\u8986\u5199\u5176\u4e2d\u7684\u4e24\u4e2a\u65b9\u6cd5\u5373\u53ef\uff1a __len__ :\u5b9e\u73b0len(dataset)\u8fd4\u56de\u6574\u4e2a\u6570\u636e\u96c6\u7684\u5927\u5c0f\u3002 __getitem__ :\u7528\u6765\u83b7\u53d6\u4e00\u4e9b\u7d22\u5f15\u7684\u6570\u636e\uff0c\u4f7f dataset[i] \u8fd4\u56de\u6570\u636e\u96c6\u4e2d\u7b2ci\u4e2a\u6837\u672c\u3002 \u4e0d\u8986\u5199\u8fd9\u4e24\u4e2a\u65b9\u6cd5\u4f1a\u76f4\u63a5\u8fd4\u56de\u9519\u8bef\u3002 import torch from torch import nn from torch.utils.data import Dataset , DataLoader , TensorDataset #\u7528\u67d0\u65e5\u524d8\u5929\u7a97\u53e3\u6570\u636e\u4f5c\u4e3a\u8f93\u5165\u9884\u6d4b\u8be5\u65e5\u6570\u636e WINDOW_SIZE = 8 class Covid19Dataset ( Dataset ): def __len__ ( self ): return len ( dfdiff ) - WINDOW_SIZE def __getitem__ ( self , i ): x = dfdiff . loc [ i : i + WINDOW_SIZE - 1 ,:] feature = torch . tensor ( x . values ) y = dfdiff . loc [ i + WINDOW_SIZE ,:] label = torch . tensor ( y . values ) return ( feature , label ) ds_train = Covid19Dataset () #\u6570\u636e\u8f83\u5c0f\uff0c\u53ef\u4ee5\u5c06\u5168\u90e8\u8bad\u7ec3\u6570\u636e\u653e\u5165\u5230\u4e00\u4e2abatch\u4e2d\uff0c\u63d0\u5347\u6027\u80fd dl_train = DataLoader ( ds_train , batch_size = 38 )","title":"\u4e00\uff0c\u51c6\u5907\u6570\u636e"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-4%2C%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e8c\u5b9a\u4e49\u6a21\u578b","text":"\u4f7f\u7528Pytorch\u901a\u5e38\u6709\u4e09\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a\u4f7f\u7528nn.Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u6a21\u578b\u5e76\u8f85\u52a9\u5e94\u7528\u6a21\u578b\u5bb9\u5668\u8fdb\u884c\u5c01\u88c5\u3002 \u6b64\u5904\u9009\u62e9\u7b2c\u4e8c\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\u3002 \u7531\u4e8e\u63a5\u4e0b\u6765\u4f7f\u7528\u7c7b\u5f62\u5f0f\u7684\u8bad\u7ec3\u5faa\u73af\uff0c\u6211\u4eec\u8fdb\u4e00\u6b65\u5c06\u6a21\u578b\u5c01\u88c5\u6210torchkeras\u4e2d\u7684Model\u7c7b\u6765\u83b7\u5f97\u7c7b\u4f3cKeras\u4e2d\u9ad8\u9636\u6a21\u578b\u63a5\u53e3\u7684\u529f\u80fd\u3002 Model\u7c7b\u5b9e\u9645\u4e0a\u7ee7\u627f\u81eann.Module\u7c7b\u3002 import torch from torch import nn import importlib import torchkeras torch . random . seed () class Block ( nn . Module ): def __init__ ( self ): super ( Block , self ) . __init__ () def forward ( self , x , x_input ): x_out = torch . max (( 1 + x ) * x_input [:, - 1 ,:], torch . tensor ( 0.0 )) return x_out class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () # 3\u5c42lstm self . lstm = nn . LSTM ( input_size = 3 , hidden_size = 3 , num_layers = 5 , batch_first = True ) self . linear = nn . Linear ( 3 , 3 ) self . block = Block () def forward ( self , x_input ): x = self . lstm ( x_input )[ 0 ][:, - 1 ,:] x = self . linear ( x ) y = self . block ( x , x_input ) return y net = Net () model = torchkeras . Model ( net ) print ( model ) model . summary ( input_shape = ( 8 , 3 ), input_dtype = torch . FloatTensor ) Net( (lstm): LSTM(3, 3, num_layers=5, batch_first=True) (linear): Linear(in_features=3, out_features=3, bias=True) (block): Block() ) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ LSTM-1 [-1, 8, 3] 480 Linear-2 [-1, 3] 12 Block-3 [-1, 3] 0 ================================================================ Total params: 492 Trainable params: 492 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.000092 Forward/backward pass size (MB): 0.000229 Params size (MB): 0.001877 Estimated Total Size (MB): 0.002197 ----------------------------------------------------------------","title":"\u4e8c\uff0c\u5b9a\u4e49\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-4%2C%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e09\u8bad\u7ec3\u6a21\u578b","text":"\u8bad\u7ec3Pytorch\u901a\u5e38\u9700\u8981\u7528\u6237\u7f16\u5199\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\uff0c\u8bad\u7ec3\u5faa\u73af\u7684\u4ee3\u7801\u98ce\u683c\u56e0\u4eba\u800c\u5f02\u3002 \u67093\u7c7b\u5178\u578b\u7684\u8bad\u7ec3\u5faa\u73af\u4ee3\u7801\u98ce\u683c\uff1a\u811a\u672c\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u51fd\u6570\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u7c7b\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\u3002 \u6b64\u5904\u4ecb\u7ecd\u4e00\u79cd\u7c7b\u5f62\u5f0f\u7684\u8bad\u7ec3\u5faa\u73af\u3002 \u6211\u4eec\u4eff\u7167Keras\u5b9a\u4e49\u4e86\u4e00\u4e2a\u9ad8\u9636\u7684\u6a21\u578b\u63a5\u53e3Model,\u5b9e\u73b0 fit, validate\uff0cpredict, summary \u65b9\u6cd5\uff0c\u76f8\u5f53\u4e8e\u7528\u6237\u81ea\u5b9a\u4e49\u9ad8\u9636API\u3002 \u6ce8\uff1a\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u8c03\u8bd5\u8f83\u4e3a\u56f0\u96be\uff0c\u9700\u8981\u8bbe\u7f6e\u591a\u4e2a\u4e0d\u540c\u7684\u5b66\u4e60\u7387\u591a\u6b21\u5c1d\u8bd5\uff0c\u4ee5\u53d6\u5f97\u8f83\u597d\u7684\u6548\u679c\u3002 def mspe ( y_pred , y_true ): err_percent = ( y_true - y_pred ) ** 2 / ( torch . max ( y_true ** 2 , torch . tensor ( 1e-7 ))) return torch . mean ( err_percent ) model . compile ( loss_func = mspe , optimizer = torch . optim . Adagrad ( model . parameters (), lr = 0.1 )) dfhistory = model . fit ( 100 , dl_train , log_step_freq = 10 )","title":"\u4e09\uff0c\u8bad\u7ec3\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-4%2C%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u56db\u8bc4\u4f30\u6a21\u578b","text":"\u8bc4\u4f30\u6a21\u578b\u4e00\u822c\u8981\u8bbe\u7f6e\u9a8c\u8bc1\u96c6\u6216\u8005\u6d4b\u8bd5\u96c6\uff0c\u7531\u4e8e\u6b64\u4f8b\u6570\u636e\u8f83\u5c11\uff0c\u6211\u4eec\u4ec5\u4ec5\u53ef\u89c6\u5316\u635f\u5931\u51fd\u6570\u5728\u8bad\u7ec3\u96c6\u4e0a\u7684\u8fed\u4ee3\u60c5\u51b5\u3002 % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( dfhistory , metric ): train_metrics = dfhistory [ metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . title ( 'Training ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric ]) plt . show () plot_metric ( dfhistory , \"loss\" )","title":"\u56db\uff0c\u8bc4\u4f30\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-4%2C%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u4e94\u4f7f\u7528\u6a21\u578b","text":"\u6b64\u5904\u6211\u4eec\u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u75ab\u60c5\u7ed3\u675f\u65f6\u95f4\uff0c\u5373 \u65b0\u589e\u786e\u8bca\u75c5\u4f8b\u4e3a0 \u7684\u65f6\u95f4\u3002 #\u4f7f\u7528dfresult\u8bb0\u5f55\u73b0\u6709\u6570\u636e\u4ee5\u53ca\u6b64\u540e\u9884\u6d4b\u7684\u75ab\u60c5\u6570\u636e dfresult = dfdiff [[ \"confirmed_num\" , \"cured_num\" , \"dead_num\" ]] . copy () dfresult . tail () #\u9884\u6d4b\u6b64\u540e200\u5929\u7684\u65b0\u589e\u8d70\u52bf,\u5c06\u5176\u7ed3\u679c\u6dfb\u52a0\u5230dfresult\u4e2d for i in range ( 200 ): arr_input = torch . unsqueeze ( torch . from_numpy ( dfresult . values [ - 38 :,:]), axis = 0 ) arr_predict = model . forward ( arr_input ) dfpredict = pd . DataFrame ( torch . floor ( arr_predict ) . data . numpy (), columns = dfresult . columns ) dfresult = dfresult . append ( dfpredict , ignore_index = True ) dfresult . query ( \"confirmed_num==0\" ) . head () # \u7b2c50\u5929\u5f00\u59cb\u65b0\u589e\u786e\u8bca\u964d\u4e3a0\uff0c\u7b2c45\u5929\u5bf9\u5e943\u670810\u65e5\uff0c\u4e5f\u5c31\u662f5\u5929\u540e\uff0c\u5373\u9884\u8ba13\u670815\u65e5\u65b0\u589e\u786e\u8bca\u964d\u4e3a0 # \u6ce8\uff1a\u8be5\u9884\u6d4b\u504f\u4e50\u89c2 dfresult . query ( \"cured_num==0\" ) . head () # \u7b2c132\u5929\u5f00\u59cb\u65b0\u589e\u6cbb\u6108\u964d\u4e3a0\uff0c\u7b2c45\u5929\u5bf9\u5e943\u670810\u65e5\uff0c\u4e5f\u5c31\u662f\u5927\u69823\u4e2a\u6708\u540e\uff0c\u53736\u670810\u65e5\u5de6\u53f3\u5168\u90e8\u6cbb\u6108\u3002 # \u6ce8: \u8be5\u9884\u6d4b\u504f\u60b2\u89c2\uff0c\u5e76\u4e14\u5b58\u5728\u95ee\u9898\uff0c\u5982\u679c\u5c06\u6bcf\u5929\u65b0\u589e\u6cbb\u6108\u4eba\u6570\u52a0\u8d77\u6765\uff0c\u5c06\u8d85\u8fc7\u7d2f\u8ba1\u786e\u8bca\u4eba\u6570\u3002 dfresult . query ( \"dead_num==0\" ) . head () # \u7b2c50\u5929\u5f00\u59cb\u65b0\u589e\u786e\u8bca\u964d\u4e3a0\uff0c\u7b2c45\u5929\u5bf9\u5e943\u670810\u65e5\uff0c\u4e5f\u5c31\u662f5\u5929\u540e\uff0c\u5373\u9884\u8ba13\u670815\u65e5\u65b0\u589e\u786e\u8bca\u964d\u4e3a0 # \u6ce8\uff1a\u8be5\u9884\u6d4b\u504f\u4e50\u89c2","title":"\u4e94\uff0c\u4f7f\u7528\u6a21\u578b"},{"location":"1.%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B/1-4%2C%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B/#\u516d\u4fdd\u5b58\u6a21\u578b","text":"\u63a8\u8350\u4f7f\u7528\u4fdd\u5b58\u53c2\u6570\u65b9\u5f0f\u4fdd\u5b58Pytorch\u6a21\u578b\u3002 print ( model . net . state_dict () . keys ()) # \u4fdd\u5b58\u6a21\u578b\u53c2\u6570 torch . save ( model . net . state_dict (), \"../data/model_parameter.pkl\" ) net_clone = Net () net_clone . load_state_dict ( torch . load ( \"../data/model_parameter.pkl\" )) model_clone = torchkeras . Model ( net_clone ) model_clone . compile ( loss_func = mspe ) # \u8bc4\u4f30\u6a21\u578b model_clone . evaluate ( dl_train ) {'val_loss': 4.254558563232422} \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u516d\uff0c\u4fdd\u5b58\u6a21\u578b"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/","text":"\u4e8c\u3001Pytorch\u7684\u6838\u5fc3\u6982\u5ff5 # Pytorch\u662f\u4e00\u4e2a\u57fa\u4e8ePython\u7684\u673a\u5668\u5b66\u4e60\u5e93\u3002\u5b83\u5e7f\u6cdb\u5e94\u7528\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\uff0c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u3002\u662f\u76ee\u524d\u548cTensorFlow\u5206\u5ead\u6297\u793c\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u5b66\u672f\u5708\u9887\u53d7\u6b22\u8fce\u3002 \u5b83\u4e3b\u8981\u63d0\u4f9b\u4e86\u4ee5\u4e0b\u4e24\u79cd\u6838\u5fc3\u529f\u80fd\uff1a 1\uff0c\u652f\u6301GPU\u52a0\u901f\u7684\u5f20\u91cf\u8ba1\u7b97\u3002 2\uff0c\u65b9\u4fbf\u4f18\u5316\u6a21\u578b\u7684\u81ea\u52a8\u5fae\u5206\u673a\u5236\u3002 Pytorch\u7684\u4e3b\u8981\u4f18\u70b9\uff1a \u7b80\u6d01\u6613\u61c2\uff1aPytorch\u7684API\u8bbe\u8ba1\u7684\u76f8\u5f53\u7b80\u6d01\u4e00\u81f4\u3002\u57fa\u672c\u4e0a\u5c31\u662ftensor, autograd, nn\u4e09\u7ea7\u5c01\u88c5\u3002\u5b66\u4e60\u8d77\u6765\u975e\u5e38\u5bb9\u6613\u3002\u6709\u4e00\u4e2a\u8fd9\u6837\u7684\u6bb5\u5b50\uff0c\u8bf4TensorFlow\u7684\u8bbe\u8ba1\u54f2\u5b66\u662f Make it complicated, Keras \u7684\u8bbe\u8ba1\u54f2\u5b66\u662f Make it complicated and hide it, \u800cPytorch\u7684\u8bbe\u8ba1\u54f2\u5b66\u662f Keep it simple and stupid. \u4fbf\u4e8e\u8c03\u8bd5\uff1aPytorch\u91c7\u7528\u52a8\u6001\u56fe\uff0c\u53ef\u4ee5\u50cf\u666e\u901aPython\u4ee3\u7801\u4e00\u6837\u8fdb\u884c\u8c03\u8bd5\u3002\u4e0d\u540c\u4e8eTensorFlow, Pytorch\u7684\u62a5\u9519\u8bf4\u660e\u901a\u5e38\u5f88\u5bb9\u6613\u770b\u61c2\u3002\u6709\u4e00\u4e2a\u8fd9\u6837\u7684\u6bb5\u5b50\uff0c\u8bf4\u4f60\u6c38\u8fdc\u4e0d\u53ef\u80fd\u4eceTensorFlow\u7684\u62a5\u9519\u8bf4\u660e\u4e2d\u627e\u5230\u5b83\u51fa\u9519\u7684\u539f\u56e0\u3002 \u5f3a\u5927\u9ad8\u6548\uff1aPytorch\u63d0\u4f9b\u4e86\u975e\u5e38\u4e30\u5bcc\u7684\u6a21\u578b\u7ec4\u4ef6\uff0c\u53ef\u4ee5\u5feb\u901f\u5b9e\u73b0\u60f3\u6cd5\u3002\u5e76\u4e14\u8fd0\u884c\u901f\u5ea6\u5f88\u5feb\u3002\u76ee\u524d\u5927\u90e8\u5206\u6df1\u5ea6\u5b66\u4e60\u76f8\u5173\u7684Paper\u90fd\u662f\u7528Pytorch\u5b9e\u73b0\u7684\u3002\u6709\u4e9b\u7814\u7a76\u4eba\u5458\u8868\u793a\uff0c\u4ece\u4f7f\u7528TensorFlow\u8f6c\u6362\u4e3a\u4f7f\u7528Pytorch\u4e4b\u540e\uff0c\u4ed6\u4eec\u7684\u7761\u7720\u597d\u591a\u4e86\uff0c\u5934\u53d1\u6bd4\u4ee5\u524d\u6d53\u5bc6\u4e86\uff0c\u76ae\u80a4\u4e5f\u6bd4\u4ee5\u524d\u5149\u6ed1\u4e86\u3002 \u4fd7\u8bdd\u8bf4\uff0c\u4e07\u4e08\u9ad8\u697c\u5e73\u5730\u8d77\uff0cPytorch\u8fd9\u5ea7\u5927\u53a6\u4e5f\u6709\u5b83\u7684\u5730\u57fa\u3002 Pytorch\u5e95\u5c42\u6700\u6838\u5fc3\u7684\u6982\u5ff5\u662f\u5f20\u91cf\uff0c\u52a8\u6001\u8ba1\u7b97\u56fe\u4ee5\u53ca\u81ea\u52a8\u5fae\u5206\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\u3001Pytorch\u7684\u6838\u5fc3\u6982\u5ff5"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/#\u4e8cpytorch\u7684\u6838\u5fc3\u6982\u5ff5","text":"Pytorch\u662f\u4e00\u4e2a\u57fa\u4e8ePython\u7684\u673a\u5668\u5b66\u4e60\u5e93\u3002\u5b83\u5e7f\u6cdb\u5e94\u7528\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\uff0c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u3002\u662f\u76ee\u524d\u548cTensorFlow\u5206\u5ead\u6297\u793c\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u5b66\u672f\u5708\u9887\u53d7\u6b22\u8fce\u3002 \u5b83\u4e3b\u8981\u63d0\u4f9b\u4e86\u4ee5\u4e0b\u4e24\u79cd\u6838\u5fc3\u529f\u80fd\uff1a 1\uff0c\u652f\u6301GPU\u52a0\u901f\u7684\u5f20\u91cf\u8ba1\u7b97\u3002 2\uff0c\u65b9\u4fbf\u4f18\u5316\u6a21\u578b\u7684\u81ea\u52a8\u5fae\u5206\u673a\u5236\u3002 Pytorch\u7684\u4e3b\u8981\u4f18\u70b9\uff1a \u7b80\u6d01\u6613\u61c2\uff1aPytorch\u7684API\u8bbe\u8ba1\u7684\u76f8\u5f53\u7b80\u6d01\u4e00\u81f4\u3002\u57fa\u672c\u4e0a\u5c31\u662ftensor, autograd, nn\u4e09\u7ea7\u5c01\u88c5\u3002\u5b66\u4e60\u8d77\u6765\u975e\u5e38\u5bb9\u6613\u3002\u6709\u4e00\u4e2a\u8fd9\u6837\u7684\u6bb5\u5b50\uff0c\u8bf4TensorFlow\u7684\u8bbe\u8ba1\u54f2\u5b66\u662f Make it complicated, Keras \u7684\u8bbe\u8ba1\u54f2\u5b66\u662f Make it complicated and hide it, \u800cPytorch\u7684\u8bbe\u8ba1\u54f2\u5b66\u662f Keep it simple and stupid. \u4fbf\u4e8e\u8c03\u8bd5\uff1aPytorch\u91c7\u7528\u52a8\u6001\u56fe\uff0c\u53ef\u4ee5\u50cf\u666e\u901aPython\u4ee3\u7801\u4e00\u6837\u8fdb\u884c\u8c03\u8bd5\u3002\u4e0d\u540c\u4e8eTensorFlow, Pytorch\u7684\u62a5\u9519\u8bf4\u660e\u901a\u5e38\u5f88\u5bb9\u6613\u770b\u61c2\u3002\u6709\u4e00\u4e2a\u8fd9\u6837\u7684\u6bb5\u5b50\uff0c\u8bf4\u4f60\u6c38\u8fdc\u4e0d\u53ef\u80fd\u4eceTensorFlow\u7684\u62a5\u9519\u8bf4\u660e\u4e2d\u627e\u5230\u5b83\u51fa\u9519\u7684\u539f\u56e0\u3002 \u5f3a\u5927\u9ad8\u6548\uff1aPytorch\u63d0\u4f9b\u4e86\u975e\u5e38\u4e30\u5bcc\u7684\u6a21\u578b\u7ec4\u4ef6\uff0c\u53ef\u4ee5\u5feb\u901f\u5b9e\u73b0\u60f3\u6cd5\u3002\u5e76\u4e14\u8fd0\u884c\u901f\u5ea6\u5f88\u5feb\u3002\u76ee\u524d\u5927\u90e8\u5206\u6df1\u5ea6\u5b66\u4e60\u76f8\u5173\u7684Paper\u90fd\u662f\u7528Pytorch\u5b9e\u73b0\u7684\u3002\u6709\u4e9b\u7814\u7a76\u4eba\u5458\u8868\u793a\uff0c\u4ece\u4f7f\u7528TensorFlow\u8f6c\u6362\u4e3a\u4f7f\u7528Pytorch\u4e4b\u540e\uff0c\u4ed6\u4eec\u7684\u7761\u7720\u597d\u591a\u4e86\uff0c\u5934\u53d1\u6bd4\u4ee5\u524d\u6d53\u5bc6\u4e86\uff0c\u76ae\u80a4\u4e5f\u6bd4\u4ee5\u524d\u5149\u6ed1\u4e86\u3002 \u4fd7\u8bdd\u8bf4\uff0c\u4e07\u4e08\u9ad8\u697c\u5e73\u5730\u8d77\uff0cPytorch\u8fd9\u5ea7\u5927\u53a6\u4e5f\u6709\u5b83\u7684\u5730\u57fa\u3002 Pytorch\u5e95\u5c42\u6700\u6838\u5fc3\u7684\u6982\u5ff5\u662f\u5f20\u91cf\uff0c\u52a8\u6001\u8ba1\u7b97\u56fe\u4ee5\u53ca\u81ea\u52a8\u5fae\u5206\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\u3001Pytorch\u7684\u6838\u5fc3\u6982\u5ff5"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-1%2C%E5%BC%A0%E9%87%8F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","text":"2-1,\u5f20\u91cf\u6570\u636e\u7ed3\u6784 # Pytorch\u7684\u57fa\u672c\u6570\u636e\u7ed3\u6784\u662f\u5f20\u91cfTensor\u3002\u5f20\u91cf\u5373\u591a\u7ef4\u6570\u7ec4\u3002Pytorch\u7684\u5f20\u91cf\u548cnumpy\u4e2d\u7684array\u5f88\u7c7b\u4f3c\u3002 \u672c\u8282\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecd\u5f20\u91cf\u7684\u6570\u636e\u7c7b\u578b\u3001\u5f20\u91cf\u7684\u7ef4\u5ea6\u3001\u5f20\u91cf\u7684\u5c3a\u5bf8\u3001\u5f20\u91cf\u548cnumpy\u6570\u7ec4\u7b49\u57fa\u672c\u6982\u5ff5\u3002 \u4e00\uff0c\u5f20\u91cf\u7684\u6570\u636e\u7c7b\u578b # \u5f20\u91cf\u7684\u6570\u636e\u7c7b\u578b\u548cnumpy.array\u57fa\u672c\u4e00\u4e00\u5bf9\u5e94\uff0c\u4f46\u662f\u4e0d\u652f\u6301str\u7c7b\u578b\u3002 \u5305\u62ec: torch.float64(torch.double), torch.float32(torch.float) , torch.float16, torch.int64(torch.long), torch.int32(torch.int), torch.int16, torch.int8, torch.uint8, torch.bool \u4e00\u822c\u795e\u7ecf\u7f51\u7edc\u5efa\u6a21\u4f7f\u7528\u7684\u90fd\u662ftorch.float32\u7c7b\u578b\u3002 import numpy as np import torch # \u81ea\u52a8\u63a8\u65ad\u6570\u636e\u7c7b\u578b i = torch . tensor ( 1 ); print ( i , i . dtype ) x = torch . tensor ( 2.0 ); print ( x , x . dtype ) b = torch . tensor ( True ); print ( b , b . dtype ) tensor(1) torch.int64 tensor(2.) torch.float32 tensor(True) torch.bool # \u6307\u5b9a\u6570\u636e\u7c7b\u578b i = torch . tensor ( 1 , dtype = torch . int32 ); print ( i , i . dtype ) x = torch . tensor ( 2.0 , dtype = torch . double ); print ( x , x . dtype ) tensor(1, dtype=torch.int32) torch.int32 tensor(2., dtype=torch.float64) torch.float64 # \u4f7f\u7528\u7279\u5b9a\u7c7b\u578b\u6784\u9020\u51fd\u6570 i = torch . IntTensor ( 1 ); print ( i , i . dtype ) x = torch . Tensor ( np . array ( 2.0 )); print ( x , x . dtype ) #\u7b49\u4ef7\u4e8etorch.FloatTensor b = torch . BoolTensor ( np . array ([ 1 , 0 , 2 , 0 ])); print ( b , b . dtype ) tensor([5], dtype=torch.int32) torch.int32 tensor(2.) torch.float32 tensor([ True, False, True, False]) torch.bool # \u4e0d\u540c\u7c7b\u578b\u8fdb\u884c\u8f6c\u6362 i = torch . tensor ( 1 ); print ( i , i . dtype ) x = i . float (); print ( x , x . dtype ) #\u8c03\u7528 float\u65b9\u6cd5\u8f6c\u6362\u6210\u6d6e\u70b9\u7c7b\u578b y = i . type ( torch . float ); print ( y , y . dtype ) #\u4f7f\u7528type\u51fd\u6570\u8f6c\u6362\u6210\u6d6e\u70b9\u7c7b\u578b z = i . type_as ( x ); print ( z , z . dtype ) #\u4f7f\u7528type_as\u65b9\u6cd5\u8f6c\u6362\u6210\u67d0\u4e2aTensor\u76f8\u540c\u7c7b\u578b tensor(1) torch.int64 tensor(1.) torch.float32 tensor(1.) torch.float32 tensor(1.) torch.float32 \u4e8c\uff0c\u5f20\u91cf\u7684\u7ef4\u5ea6 # \u4e0d\u540c\u7c7b\u578b\u7684\u6570\u636e\u53ef\u4ee5\u7528\u4e0d\u540c\u7ef4\u5ea6(dimension)\u7684\u5f20\u91cf\u6765\u8868\u793a\u3002 \u6807\u91cf\u4e3a0\u7ef4\u5f20\u91cf\uff0c\u5411\u91cf\u4e3a1\u7ef4\u5f20\u91cf\uff0c\u77e9\u9635\u4e3a2\u7ef4\u5f20\u91cf\u3002 \u5f69\u8272\u56fe\u50cf\u6709rgb\u4e09\u4e2a\u901a\u9053\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a3\u7ef4\u5f20\u91cf\u3002 \u89c6\u9891\u8fd8\u6709\u65f6\u95f4\u7ef4\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a4\u7ef4\u5f20\u91cf\u3002 \u53ef\u4ee5\u7b80\u5355\u5730\u603b\u7ed3\u4e3a\uff1a\u6709\u51e0\u5c42\u4e2d\u62ec\u53f7\uff0c\u5c31\u662f\u591a\u5c11\u7ef4\u7684\u5f20\u91cf\u3002 scalar = torch . tensor ( True ) print ( scalar ) print ( scalar . dim ()) # \u6807\u91cf\uff0c0\u7ef4\u5f20\u91cf tensor(True) 0 vector = torch . tensor ([ 1.0 , 2.0 , 3.0 , 4.0 ]) #\u5411\u91cf\uff0c1\u7ef4\u5f20\u91cf print ( vector ) print ( vector . dim ()) tensor([1., 2., 3., 4.]) 1 matrix = torch . tensor ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) #\u77e9\u9635, 2\u7ef4\u5f20\u91cf print ( matrix ) print ( matrix . dim ()) matrix = torch.tensor([[1.0,2.0],[3.0,4.0]]) #\u77e9\u9635, 2\u7ef4\u5f20\u91cf print(matrix) print(matrix.dim()) tensor3 = torch . tensor ([[[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]],[[ 5.0 , 6.0 ],[ 7.0 , 8.0 ]]]) # 3\u7ef4\u5f20\u91cf print ( tensor3 ) print ( tensor3 . dim ()) tensor([[[1., 2.], [3., 4.]], [[5., 6.], [7., 8.]]]) 3 tensor4 = torch . tensor ([[[[ 1.0 , 1.0 ],[ 2.0 , 2.0 ]],[[ 3.0 , 3.0 ],[ 4.0 , 4.0 ]]], [[[ 5.0 , 5.0 ],[ 6.0 , 6.0 ]],[[ 7.0 , 7.0 ],[ 8.0 , 8.0 ]]]]) # 4\u7ef4\u5f20\u91cf print ( tensor4 ) print ( tensor4 . dim ()) tensor([[[[1., 1.], [2., 2.]], [[3., 3.], [4., 4.]]], [[[5., 5.], [6., 6.]], [[7., 7.], [8., 8.]]]]) 4 \u4e09\uff0c\u5f20\u91cf\u7684\u5c3a\u5bf8 # \u53ef\u4ee5\u4f7f\u7528 shape\u5c5e\u6027\u6216\u8005 size()\u65b9\u6cd5\u67e5\u770b\u5f20\u91cf\u5728\u6bcf\u4e00\u7ef4\u7684\u957f\u5ea6. \u53ef\u4ee5\u4f7f\u7528view\u65b9\u6cd5\u6539\u53d8\u5f20\u91cf\u7684\u5c3a\u5bf8\u3002 \u5982\u679cview\u65b9\u6cd5\u6539\u53d8\u5c3a\u5bf8\u5931\u8d25\uff0c\u53ef\u4ee5\u4f7f\u7528reshape\u65b9\u6cd5. scalar = torch . tensor ( True ) print ( scalar . size ()) print ( scalar . shape ) torch.Size([]) torch.Size([4]) vector = torch . tensor ([ 1.0 , 2.0 , 3.0 , 4.0 ]) print ( vector . size ()) print ( vector . shape ) torch.Size([4]) torch.Size([4]) matrix = torch . tensor ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) print ( matrix . size ()) torch.Size([2, 2]) # \u4f7f\u7528view\u53ef\u4ee5\u6539\u53d8\u5f20\u91cf\u5c3a\u5bf8 vector = torch . arange ( 0 , 12 ) print ( vector ) print ( vector . shape ) matrix34 = vector . view ( 3 , 4 ) print ( matrix34 ) print ( matrix34 . shape ) matrix43 = vector . view ( 4 , - 1 ) #-1\u8868\u793a\u8be5\u4f4d\u7f6e\u957f\u5ea6\u7531\u7a0b\u5e8f\u81ea\u52a8\u63a8\u65ad print ( matrix43 ) print ( matrix43 . shape ) tensor([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) torch.Size([12]) tensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) torch.Size([3, 4]) tensor([[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8], [ 9, 10, 11]]) torch.Size([4, 3]) # \u6709\u4e9b\u64cd\u4f5c\u4f1a\u8ba9\u5f20\u91cf\u5b58\u50a8\u7ed3\u6784\u626d\u66f2\uff0c\u76f4\u63a5\u4f7f\u7528view\u4f1a\u5931\u8d25\uff0c\u53ef\u4ee5\u7528reshape\u65b9\u6cd5 matrix26 = torch . arange ( 0 , 12 ) . view ( 2 , 6 ) print ( matrix26 ) print ( matrix26 . shape ) # \u8f6c\u7f6e\u64cd\u4f5c\u8ba9\u5f20\u91cf\u5b58\u50a8\u7ed3\u6784\u626d\u66f2 matrix62 = matrix26 . t () print ( matrix62 . is_contiguous ()) # \u76f4\u63a5\u4f7f\u7528view\u65b9\u6cd5\u4f1a\u5931\u8d25\uff0c\u53ef\u4ee5\u4f7f\u7528reshape\u65b9\u6cd5 #matrix34 = matrix62.view(3,4) #error! matrix34 = matrix62 . reshape ( 3 , 4 ) #\u7b49\u4ef7\u4e8ematrix34 = matrix62.contiguous().view(3,4) print ( matrix34 ) tensor([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11]]) torch.Size([2, 6]) False tensor([[ 0, 6, 1, 7], [ 2, 8, 3, 9], [ 4, 10, 5, 11]]) \u56db\uff0c\u5f20\u91cf\u548cnumpy\u6570\u7ec4 # \u53ef\u4ee5\u7528numpy\u65b9\u6cd5\u4eceTensor\u5f97\u5230numpy\u6570\u7ec4\uff0c\u4e5f\u53ef\u4ee5\u7528torch.from_numpy\u4ecenumpy\u6570\u7ec4\u5f97\u5230Tensor\u3002 \u8fd9\u4e24\u79cd\u65b9\u6cd5\u5173\u8054\u7684Tensor\u548cnumpy\u6570\u7ec4\u662f\u5171\u4eab\u6570\u636e\u5185\u5b58\u7684\u3002 \u5982\u679c\u6539\u53d8\u5176\u4e2d\u4e00\u4e2a\uff0c\u53e6\u5916\u4e00\u4e2a\u7684\u503c\u4e5f\u4f1a\u53d1\u751f\u6539\u53d8\u3002 \u5982\u679c\u6709\u9700\u8981\uff0c\u53ef\u4ee5\u7528\u5f20\u91cf\u7684clone\u65b9\u6cd5\u62f7\u8d1d\u5f20\u91cf\uff0c\u4e2d\u65ad\u8fd9\u79cd\u5173\u8054\u3002 \u6b64\u5916\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528item\u65b9\u6cd5\u4ece\u6807\u91cf\u5f20\u91cf\u5f97\u5230\u5bf9\u5e94\u7684Python\u6570\u503c\u3002 \u4f7f\u7528tolist\u65b9\u6cd5\u4ece\u5f20\u91cf\u5f97\u5230\u5bf9\u5e94\u7684Python\u6570\u503c\u5217\u8868\u3002 import numpy as np import torch #torch.from_numpy\u51fd\u6570\u4ecenumpy\u6570\u7ec4\u5f97\u5230Tensor arr = np . zeros ( 3 ) tensor = torch . from_numpy ( arr ) print ( \"before add 1:\" ) print ( arr ) print ( tensor ) print ( \" \\n after add 1:\" ) np . add ( arr , 1 , out = arr ) #\u7ed9 arr\u589e\u52a01\uff0ctensor\u4e5f\u968f\u4e4b\u6539\u53d8 print ( arr ) print ( tensor ) before add 1: [0. 0. 0.] tensor([0., 0., 0.], dtype=torch.float64) after add 1: [1. 1. 1.] tensor([1., 1., 1.], dtype=torch.float64) # numpy\u65b9\u6cd5\u4eceTensor\u5f97\u5230numpy\u6570\u7ec4 tensor = torch . zeros ( 3 ) arr = tensor . numpy () print ( \"before add 1:\" ) print ( tensor ) print ( arr ) print ( \" \\n after add 1:\" ) #\u4f7f\u7528\u5e26\u4e0b\u5212\u7ebf\u7684\u65b9\u6cd5\u8868\u793a\u8ba1\u7b97\u7ed3\u679c\u4f1a\u8fd4\u56de\u7ed9\u8c03\u7528 \u5f20\u91cf tensor . add_ ( 1 ) #\u7ed9 tensor\u589e\u52a01\uff0carr\u4e5f\u968f\u4e4b\u6539\u53d8 #\u6216\uff1a torch.add(tensor,1,out = tensor) print ( tensor ) print ( arr ) before add 1: tensor([0., 0., 0.]) [0. 0. 0.] after add 1: tensor([1., 1., 1.]) [1. 1. 1.] # \u53ef\u4ee5\u7528clone() \u65b9\u6cd5\u62f7\u8d1d\u5f20\u91cf\uff0c\u4e2d\u65ad\u8fd9\u79cd\u5173\u8054 tensor = torch . zeros ( 3 ) #\u4f7f\u7528clone\u65b9\u6cd5\u62f7\u8d1d\u5f20\u91cf, \u62f7\u8d1d\u540e\u7684\u5f20\u91cf\u548c\u539f\u59cb\u5f20\u91cf\u5185\u5b58\u72ec\u7acb arr = tensor . clone () . numpy () # \u4e5f\u53ef\u4ee5\u4f7f\u7528tensor.data.numpy() print ( \"before add 1:\" ) print ( tensor ) print ( arr ) print ( \" \\n after add 1:\" ) #\u4f7f\u7528 \u5e26\u4e0b\u5212\u7ebf\u7684\u65b9\u6cd5\u8868\u793a\u8ba1\u7b97\u7ed3\u679c\u4f1a\u8fd4\u56de\u7ed9\u8c03\u7528 \u5f20\u91cf tensor . add_ ( 1 ) #\u7ed9 tensor\u589e\u52a01\uff0carr\u4e0d\u518d\u968f\u4e4b\u6539\u53d8 print ( tensor ) print ( arr ) before add 1: tensor([0., 0., 0.]) [0. 0. 0.] after add 1: tensor([1., 1., 1.]) [0. 0. 0.] # item\u65b9\u6cd5\u548ctolist\u65b9\u6cd5\u53ef\u4ee5\u5c06\u5f20\u91cf\u8f6c\u6362\u6210Python\u6570\u503c\u548c\u6570\u503c\u5217\u8868 scalar = torch . tensor ( 1.0 ) s = scalar . item () print ( s ) print ( type ( s )) tensor = torch . rand ( 2 , 2 ) t = tensor . tolist () print ( t ) print ( type ( t )) 1.0 <class 'float'> [[0.8211846351623535, 0.20020723342895508], [0.011571824550628662, 0.2906131148338318]] <class 'list'> \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"2-1,\u5f20\u91cf\u6570\u636e\u7ed3\u6784"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-1%2C%E5%BC%A0%E9%87%8F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#2-1\u5f20\u91cf\u6570\u636e\u7ed3\u6784","text":"Pytorch\u7684\u57fa\u672c\u6570\u636e\u7ed3\u6784\u662f\u5f20\u91cfTensor\u3002\u5f20\u91cf\u5373\u591a\u7ef4\u6570\u7ec4\u3002Pytorch\u7684\u5f20\u91cf\u548cnumpy\u4e2d\u7684array\u5f88\u7c7b\u4f3c\u3002 \u672c\u8282\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecd\u5f20\u91cf\u7684\u6570\u636e\u7c7b\u578b\u3001\u5f20\u91cf\u7684\u7ef4\u5ea6\u3001\u5f20\u91cf\u7684\u5c3a\u5bf8\u3001\u5f20\u91cf\u548cnumpy\u6570\u7ec4\u7b49\u57fa\u672c\u6982\u5ff5\u3002","title":"2-1,\u5f20\u91cf\u6570\u636e\u7ed3\u6784"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-1%2C%E5%BC%A0%E9%87%8F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#\u4e00\u5f20\u91cf\u7684\u6570\u636e\u7c7b\u578b","text":"\u5f20\u91cf\u7684\u6570\u636e\u7c7b\u578b\u548cnumpy.array\u57fa\u672c\u4e00\u4e00\u5bf9\u5e94\uff0c\u4f46\u662f\u4e0d\u652f\u6301str\u7c7b\u578b\u3002 \u5305\u62ec: torch.float64(torch.double), torch.float32(torch.float) , torch.float16, torch.int64(torch.long), torch.int32(torch.int), torch.int16, torch.int8, torch.uint8, torch.bool \u4e00\u822c\u795e\u7ecf\u7f51\u7edc\u5efa\u6a21\u4f7f\u7528\u7684\u90fd\u662ftorch.float32\u7c7b\u578b\u3002 import numpy as np import torch # \u81ea\u52a8\u63a8\u65ad\u6570\u636e\u7c7b\u578b i = torch . tensor ( 1 ); print ( i , i . dtype ) x = torch . tensor ( 2.0 ); print ( x , x . dtype ) b = torch . tensor ( True ); print ( b , b . dtype ) tensor(1) torch.int64 tensor(2.) torch.float32 tensor(True) torch.bool # \u6307\u5b9a\u6570\u636e\u7c7b\u578b i = torch . tensor ( 1 , dtype = torch . int32 ); print ( i , i . dtype ) x = torch . tensor ( 2.0 , dtype = torch . double ); print ( x , x . dtype ) tensor(1, dtype=torch.int32) torch.int32 tensor(2., dtype=torch.float64) torch.float64 # \u4f7f\u7528\u7279\u5b9a\u7c7b\u578b\u6784\u9020\u51fd\u6570 i = torch . IntTensor ( 1 ); print ( i , i . dtype ) x = torch . Tensor ( np . array ( 2.0 )); print ( x , x . dtype ) #\u7b49\u4ef7\u4e8etorch.FloatTensor b = torch . BoolTensor ( np . array ([ 1 , 0 , 2 , 0 ])); print ( b , b . dtype ) tensor([5], dtype=torch.int32) torch.int32 tensor(2.) torch.float32 tensor([ True, False, True, False]) torch.bool # \u4e0d\u540c\u7c7b\u578b\u8fdb\u884c\u8f6c\u6362 i = torch . tensor ( 1 ); print ( i , i . dtype ) x = i . float (); print ( x , x . dtype ) #\u8c03\u7528 float\u65b9\u6cd5\u8f6c\u6362\u6210\u6d6e\u70b9\u7c7b\u578b y = i . type ( torch . float ); print ( y , y . dtype ) #\u4f7f\u7528type\u51fd\u6570\u8f6c\u6362\u6210\u6d6e\u70b9\u7c7b\u578b z = i . type_as ( x ); print ( z , z . dtype ) #\u4f7f\u7528type_as\u65b9\u6cd5\u8f6c\u6362\u6210\u67d0\u4e2aTensor\u76f8\u540c\u7c7b\u578b tensor(1) torch.int64 tensor(1.) torch.float32 tensor(1.) torch.float32 tensor(1.) torch.float32","title":"\u4e00\uff0c\u5f20\u91cf\u7684\u6570\u636e\u7c7b\u578b"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-1%2C%E5%BC%A0%E9%87%8F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#\u4e8c\u5f20\u91cf\u7684\u7ef4\u5ea6","text":"\u4e0d\u540c\u7c7b\u578b\u7684\u6570\u636e\u53ef\u4ee5\u7528\u4e0d\u540c\u7ef4\u5ea6(dimension)\u7684\u5f20\u91cf\u6765\u8868\u793a\u3002 \u6807\u91cf\u4e3a0\u7ef4\u5f20\u91cf\uff0c\u5411\u91cf\u4e3a1\u7ef4\u5f20\u91cf\uff0c\u77e9\u9635\u4e3a2\u7ef4\u5f20\u91cf\u3002 \u5f69\u8272\u56fe\u50cf\u6709rgb\u4e09\u4e2a\u901a\u9053\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a3\u7ef4\u5f20\u91cf\u3002 \u89c6\u9891\u8fd8\u6709\u65f6\u95f4\u7ef4\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a4\u7ef4\u5f20\u91cf\u3002 \u53ef\u4ee5\u7b80\u5355\u5730\u603b\u7ed3\u4e3a\uff1a\u6709\u51e0\u5c42\u4e2d\u62ec\u53f7\uff0c\u5c31\u662f\u591a\u5c11\u7ef4\u7684\u5f20\u91cf\u3002 scalar = torch . tensor ( True ) print ( scalar ) print ( scalar . dim ()) # \u6807\u91cf\uff0c0\u7ef4\u5f20\u91cf tensor(True) 0 vector = torch . tensor ([ 1.0 , 2.0 , 3.0 , 4.0 ]) #\u5411\u91cf\uff0c1\u7ef4\u5f20\u91cf print ( vector ) print ( vector . dim ()) tensor([1., 2., 3., 4.]) 1 matrix = torch . tensor ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) #\u77e9\u9635, 2\u7ef4\u5f20\u91cf print ( matrix ) print ( matrix . dim ()) matrix = torch.tensor([[1.0,2.0],[3.0,4.0]]) #\u77e9\u9635, 2\u7ef4\u5f20\u91cf print(matrix) print(matrix.dim()) tensor3 = torch . tensor ([[[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]],[[ 5.0 , 6.0 ],[ 7.0 , 8.0 ]]]) # 3\u7ef4\u5f20\u91cf print ( tensor3 ) print ( tensor3 . dim ()) tensor([[[1., 2.], [3., 4.]], [[5., 6.], [7., 8.]]]) 3 tensor4 = torch . tensor ([[[[ 1.0 , 1.0 ],[ 2.0 , 2.0 ]],[[ 3.0 , 3.0 ],[ 4.0 , 4.0 ]]], [[[ 5.0 , 5.0 ],[ 6.0 , 6.0 ]],[[ 7.0 , 7.0 ],[ 8.0 , 8.0 ]]]]) # 4\u7ef4\u5f20\u91cf print ( tensor4 ) print ( tensor4 . dim ()) tensor([[[[1., 1.], [2., 2.]], [[3., 3.], [4., 4.]]], [[[5., 5.], [6., 6.]], [[7., 7.], [8., 8.]]]]) 4","title":"\u4e8c\uff0c\u5f20\u91cf\u7684\u7ef4\u5ea6"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-1%2C%E5%BC%A0%E9%87%8F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#\u4e09\u5f20\u91cf\u7684\u5c3a\u5bf8","text":"\u53ef\u4ee5\u4f7f\u7528 shape\u5c5e\u6027\u6216\u8005 size()\u65b9\u6cd5\u67e5\u770b\u5f20\u91cf\u5728\u6bcf\u4e00\u7ef4\u7684\u957f\u5ea6. \u53ef\u4ee5\u4f7f\u7528view\u65b9\u6cd5\u6539\u53d8\u5f20\u91cf\u7684\u5c3a\u5bf8\u3002 \u5982\u679cview\u65b9\u6cd5\u6539\u53d8\u5c3a\u5bf8\u5931\u8d25\uff0c\u53ef\u4ee5\u4f7f\u7528reshape\u65b9\u6cd5. scalar = torch . tensor ( True ) print ( scalar . size ()) print ( scalar . shape ) torch.Size([]) torch.Size([4]) vector = torch . tensor ([ 1.0 , 2.0 , 3.0 , 4.0 ]) print ( vector . size ()) print ( vector . shape ) torch.Size([4]) torch.Size([4]) matrix = torch . tensor ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) print ( matrix . size ()) torch.Size([2, 2]) # \u4f7f\u7528view\u53ef\u4ee5\u6539\u53d8\u5f20\u91cf\u5c3a\u5bf8 vector = torch . arange ( 0 , 12 ) print ( vector ) print ( vector . shape ) matrix34 = vector . view ( 3 , 4 ) print ( matrix34 ) print ( matrix34 . shape ) matrix43 = vector . view ( 4 , - 1 ) #-1\u8868\u793a\u8be5\u4f4d\u7f6e\u957f\u5ea6\u7531\u7a0b\u5e8f\u81ea\u52a8\u63a8\u65ad print ( matrix43 ) print ( matrix43 . shape ) tensor([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) torch.Size([12]) tensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) torch.Size([3, 4]) tensor([[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8], [ 9, 10, 11]]) torch.Size([4, 3]) # \u6709\u4e9b\u64cd\u4f5c\u4f1a\u8ba9\u5f20\u91cf\u5b58\u50a8\u7ed3\u6784\u626d\u66f2\uff0c\u76f4\u63a5\u4f7f\u7528view\u4f1a\u5931\u8d25\uff0c\u53ef\u4ee5\u7528reshape\u65b9\u6cd5 matrix26 = torch . arange ( 0 , 12 ) . view ( 2 , 6 ) print ( matrix26 ) print ( matrix26 . shape ) # \u8f6c\u7f6e\u64cd\u4f5c\u8ba9\u5f20\u91cf\u5b58\u50a8\u7ed3\u6784\u626d\u66f2 matrix62 = matrix26 . t () print ( matrix62 . is_contiguous ()) # \u76f4\u63a5\u4f7f\u7528view\u65b9\u6cd5\u4f1a\u5931\u8d25\uff0c\u53ef\u4ee5\u4f7f\u7528reshape\u65b9\u6cd5 #matrix34 = matrix62.view(3,4) #error! matrix34 = matrix62 . reshape ( 3 , 4 ) #\u7b49\u4ef7\u4e8ematrix34 = matrix62.contiguous().view(3,4) print ( matrix34 ) tensor([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11]]) torch.Size([2, 6]) False tensor([[ 0, 6, 1, 7], [ 2, 8, 3, 9], [ 4, 10, 5, 11]])","title":"\u4e09\uff0c\u5f20\u91cf\u7684\u5c3a\u5bf8"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-1%2C%E5%BC%A0%E9%87%8F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#\u56db\u5f20\u91cf\u548cnumpy\u6570\u7ec4","text":"\u53ef\u4ee5\u7528numpy\u65b9\u6cd5\u4eceTensor\u5f97\u5230numpy\u6570\u7ec4\uff0c\u4e5f\u53ef\u4ee5\u7528torch.from_numpy\u4ecenumpy\u6570\u7ec4\u5f97\u5230Tensor\u3002 \u8fd9\u4e24\u79cd\u65b9\u6cd5\u5173\u8054\u7684Tensor\u548cnumpy\u6570\u7ec4\u662f\u5171\u4eab\u6570\u636e\u5185\u5b58\u7684\u3002 \u5982\u679c\u6539\u53d8\u5176\u4e2d\u4e00\u4e2a\uff0c\u53e6\u5916\u4e00\u4e2a\u7684\u503c\u4e5f\u4f1a\u53d1\u751f\u6539\u53d8\u3002 \u5982\u679c\u6709\u9700\u8981\uff0c\u53ef\u4ee5\u7528\u5f20\u91cf\u7684clone\u65b9\u6cd5\u62f7\u8d1d\u5f20\u91cf\uff0c\u4e2d\u65ad\u8fd9\u79cd\u5173\u8054\u3002 \u6b64\u5916\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528item\u65b9\u6cd5\u4ece\u6807\u91cf\u5f20\u91cf\u5f97\u5230\u5bf9\u5e94\u7684Python\u6570\u503c\u3002 \u4f7f\u7528tolist\u65b9\u6cd5\u4ece\u5f20\u91cf\u5f97\u5230\u5bf9\u5e94\u7684Python\u6570\u503c\u5217\u8868\u3002 import numpy as np import torch #torch.from_numpy\u51fd\u6570\u4ecenumpy\u6570\u7ec4\u5f97\u5230Tensor arr = np . zeros ( 3 ) tensor = torch . from_numpy ( arr ) print ( \"before add 1:\" ) print ( arr ) print ( tensor ) print ( \" \\n after add 1:\" ) np . add ( arr , 1 , out = arr ) #\u7ed9 arr\u589e\u52a01\uff0ctensor\u4e5f\u968f\u4e4b\u6539\u53d8 print ( arr ) print ( tensor ) before add 1: [0. 0. 0.] tensor([0., 0., 0.], dtype=torch.float64) after add 1: [1. 1. 1.] tensor([1., 1., 1.], dtype=torch.float64) # numpy\u65b9\u6cd5\u4eceTensor\u5f97\u5230numpy\u6570\u7ec4 tensor = torch . zeros ( 3 ) arr = tensor . numpy () print ( \"before add 1:\" ) print ( tensor ) print ( arr ) print ( \" \\n after add 1:\" ) #\u4f7f\u7528\u5e26\u4e0b\u5212\u7ebf\u7684\u65b9\u6cd5\u8868\u793a\u8ba1\u7b97\u7ed3\u679c\u4f1a\u8fd4\u56de\u7ed9\u8c03\u7528 \u5f20\u91cf tensor . add_ ( 1 ) #\u7ed9 tensor\u589e\u52a01\uff0carr\u4e5f\u968f\u4e4b\u6539\u53d8 #\u6216\uff1a torch.add(tensor,1,out = tensor) print ( tensor ) print ( arr ) before add 1: tensor([0., 0., 0.]) [0. 0. 0.] after add 1: tensor([1., 1., 1.]) [1. 1. 1.] # \u53ef\u4ee5\u7528clone() \u65b9\u6cd5\u62f7\u8d1d\u5f20\u91cf\uff0c\u4e2d\u65ad\u8fd9\u79cd\u5173\u8054 tensor = torch . zeros ( 3 ) #\u4f7f\u7528clone\u65b9\u6cd5\u62f7\u8d1d\u5f20\u91cf, \u62f7\u8d1d\u540e\u7684\u5f20\u91cf\u548c\u539f\u59cb\u5f20\u91cf\u5185\u5b58\u72ec\u7acb arr = tensor . clone () . numpy () # \u4e5f\u53ef\u4ee5\u4f7f\u7528tensor.data.numpy() print ( \"before add 1:\" ) print ( tensor ) print ( arr ) print ( \" \\n after add 1:\" ) #\u4f7f\u7528 \u5e26\u4e0b\u5212\u7ebf\u7684\u65b9\u6cd5\u8868\u793a\u8ba1\u7b97\u7ed3\u679c\u4f1a\u8fd4\u56de\u7ed9\u8c03\u7528 \u5f20\u91cf tensor . add_ ( 1 ) #\u7ed9 tensor\u589e\u52a01\uff0carr\u4e0d\u518d\u968f\u4e4b\u6539\u53d8 print ( tensor ) print ( arr ) before add 1: tensor([0., 0., 0.]) [0. 0. 0.] after add 1: tensor([1., 1., 1.]) [0. 0. 0.] # item\u65b9\u6cd5\u548ctolist\u65b9\u6cd5\u53ef\u4ee5\u5c06\u5f20\u91cf\u8f6c\u6362\u6210Python\u6570\u503c\u548c\u6570\u503c\u5217\u8868 scalar = torch . tensor ( 1.0 ) s = scalar . item () print ( s ) print ( type ( s )) tensor = torch . rand ( 2 , 2 ) t = tensor . tolist () print ( t ) print ( type ( t )) 1.0 <class 'float'> [[0.8211846351623535, 0.20020723342895508], [0.011571824550628662, 0.2906131148338318]] <class 'list'> \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u56db\uff0c\u5f20\u91cf\u548cnumpy\u6570\u7ec4"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-2%2C%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86%E6%9C%BA%E5%88%B6/","text":"2-2,\u81ea\u52a8\u5fae\u5206\u673a\u5236 # \u795e\u7ecf\u7f51\u7edc\u901a\u5e38\u4f9d\u8d56\u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6\u6765\u66f4\u65b0\u7f51\u7edc\u53c2\u6570\uff0c\u6c42\u68af\u5ea6\u8fc7\u7a0b\u901a\u5e38\u662f\u4e00\u4ef6\u975e\u5e38\u590d\u6742\u800c\u5bb9\u6613\u51fa\u9519\u7684\u4e8b\u60c5\u3002 \u800c\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u81ea\u52a8\u5730\u5b8c\u6210\u8fd9\u79cd\u6c42\u68af\u5ea6\u8fd0\u7b97\u3002 Pytorch\u4e00\u822c\u901a\u8fc7\u53cd\u5411\u4f20\u64ad backward \u65b9\u6cd5 \u5b9e\u73b0\u8fd9\u79cd\u6c42\u68af\u5ea6\u8ba1\u7b97\u3002\u8be5\u65b9\u6cd5\u6c42\u5f97\u7684\u68af\u5ea6\u5c06\u5b58\u5728\u5bf9\u5e94\u81ea\u53d8\u91cf\u5f20\u91cf\u7684grad\u5c5e\u6027\u4e0b\u3002 \u9664\u6b64\u4e4b\u5916\uff0c\u4e5f\u80fd\u591f\u8c03\u7528torch.autograd.grad \u51fd\u6570\u6765\u5b9e\u73b0\u6c42\u68af\u5ea6\u8ba1\u7b97\u3002 \u8fd9\u5c31\u662fPytorch\u7684\u81ea\u52a8\u5fae\u5206\u673a\u5236\u3002 \u4e00\uff0c\u5229\u7528backward\u65b9\u6cd5\u6c42\u5bfc\u6570 # backward \u65b9\u6cd5\u901a\u5e38\u5728\u4e00\u4e2a\u6807\u91cf\u5f20\u91cf\u4e0a\u8c03\u7528\uff0c\u8be5\u65b9\u6cd5\u6c42\u5f97\u7684\u68af\u5ea6\u5c06\u5b58\u5728\u5bf9\u5e94\u81ea\u53d8\u91cf\u5f20\u91cf\u7684grad\u5c5e\u6027\u4e0b\u3002 \u5982\u679c\u8c03\u7528\u7684\u5f20\u91cf\u975e\u6807\u91cf\uff0c\u5219\u8981\u4f20\u5165\u4e00\u4e2a\u548c\u5b83\u540c\u5f62\u72b6 \u7684gradient\u53c2\u6570\u5f20\u91cf\u3002 \u76f8\u5f53\u4e8e\u7528\u8be5gradient\u53c2\u6570\u5f20\u91cf\u4e0e\u8c03\u7528\u5f20\u91cf\u4f5c\u5411\u91cf\u70b9\u4e58\uff0c\u5f97\u5230\u7684\u6807\u91cf\u7ed3\u679c\u518d\u53cd\u5411\u4f20\u64ad\u3002 1, \u6807\u91cf\u7684\u53cd\u5411\u4f20\u64ad import numpy as np import torch # f(x) = a*x**2 + b*x + c\u7684\u5bfc\u6570 x = torch . tensor ( 0.0 , requires_grad = True ) # x\u9700\u8981\u88ab\u6c42\u5bfc a = torch . tensor ( 1.0 ) b = torch . tensor ( - 2.0 ) c = torch . tensor ( 1.0 ) y = a * torch . pow ( x , 2 ) + b * x + c y . backward () dy_dx = x . grad print ( dy_dx ) tensor(-2.) 2, \u975e\u6807\u91cf\u7684\u53cd\u5411\u4f20\u64ad import numpy as np import torch # f(x) = a*x**2 + b*x + c x = torch . tensor ([[ 0.0 , 0.0 ],[ 1.0 , 2.0 ]], requires_grad = True ) # x\u9700\u8981\u88ab\u6c42\u5bfc a = torch . tensor ( 1.0 ) b = torch . tensor ( - 2.0 ) c = torch . tensor ( 1.0 ) y = a * torch . pow ( x , 2 ) + b * x + c gradient = torch . tensor ([[ 1.0 , 1.0 ],[ 1.0 , 1.0 ]]) print ( \"x: \\n \" , x ) print ( \"y: \\n \" , y ) y . backward ( gradient = gradient ) x_grad = x . grad print ( \"x_grad: \\n \" , x_grad ) x: tensor([[0., 0.], [1., 2.]], requires_grad=True) y: tensor([[1., 1.], [0., 1.]], grad_fn=<AddBackward0>) x_grad: tensor([[-2., -2.], [ 0., 2.]]) 3, \u975e\u6807\u91cf\u7684\u53cd\u5411\u4f20\u64ad\u53ef\u4ee5\u7528\u6807\u91cf\u7684\u53cd\u5411\u4f20\u64ad\u5b9e\u73b0 import numpy as np import torch # f(x) = a*x**2 + b*x + c x = torch . tensor ([[ 0.0 , 0.0 ],[ 1.0 , 2.0 ]], requires_grad = True ) # x\u9700\u8981\u88ab\u6c42\u5bfc a = torch . tensor ( 1.0 ) b = torch . tensor ( - 2.0 ) c = torch . tensor ( 1.0 ) y = a * torch . pow ( x , 2 ) + b * x + c gradient = torch . tensor ([[ 1.0 , 1.0 ],[ 1.0 , 1.0 ]]) z = torch . sum ( y * gradient ) print ( \"x:\" , x ) print ( \"y:\" , y ) z . backward () x_grad = x . grad print ( \"x_grad: \\n \" , x_grad ) x: tensor([[0., 0.], [1., 2.]], requires_grad=True) y: tensor([[1., 1.], [0., 1.]], grad_fn=<AddBackward0>) x_grad: tensor([[-2., -2.], [ 0., 2.]]) \u4e8c\uff0c\u5229\u7528autograd.grad\u65b9\u6cd5\u6c42\u5bfc\u6570 # import numpy as np import torch # f(x) = a*x**2 + b*x + c\u7684\u5bfc\u6570 x = torch . tensor ( 0.0 , requires_grad = True ) # x\u9700\u8981\u88ab\u6c42\u5bfc a = torch . tensor ( 1.0 ) b = torch . tensor ( - 2.0 ) c = torch . tensor ( 1.0 ) y = a * torch . pow ( x , 2 ) + b * x + c # create_graph \u8bbe\u7f6e\u4e3a True \u5c06\u5141\u8bb8\u521b\u5efa\u66f4\u9ad8\u9636\u7684\u5bfc\u6570 dy_dx = torch . autograd . grad ( y , x , create_graph = True )[ 0 ] print ( dy_dx . data ) # \u6c42\u4e8c\u9636\u5bfc\u6570 dy2_dx2 = torch . autograd . grad ( dy_dx , x )[ 0 ] print ( dy2_dx2 . data ) tensor(-2.) tensor(2.) import numpy as np import torch x1 = torch . tensor ( 1.0 , requires_grad = True ) # x\u9700\u8981\u88ab\u6c42\u5bfc x2 = torch . tensor ( 2.0 , requires_grad = True ) y1 = x1 * x2 y2 = x1 + x2 # \u5141\u8bb8\u540c\u65f6\u5bf9\u591a\u4e2a\u81ea\u53d8\u91cf\u6c42\u5bfc\u6570 ( dy1_dx1 , dy1_dx2 ) = torch . autograd . grad ( outputs = y1 , inputs = [ x1 , x2 ], retain_graph = True ) print ( dy1_dx1 , dy1_dx2 ) # \u5982\u679c\u6709\u591a\u4e2a\u56e0\u53d8\u91cf\uff0c\u76f8\u5f53\u4e8e\u628a\u591a\u4e2a\u56e0\u53d8\u91cf\u7684\u68af\u5ea6\u7ed3\u679c\u6c42\u548c ( dy12_dx1 , dy12_dx2 ) = torch . autograd . grad ( outputs = [ y1 , y2 ], inputs = [ x1 , x2 ]) print ( dy12_dx1 , dy12_dx2 ) tensor(2.) tensor(1.) tensor(3.) tensor(2.) \u4e09\uff0c\u5229\u7528\u81ea\u52a8\u5fae\u5206\u548c\u4f18\u5316\u5668\u6c42\u6700\u5c0f\u503c # import numpy as np import torch # f(x) = a*x**2 + b*x + c\u7684\u6700\u5c0f\u503c x = torch . tensor ( 0.0 , requires_grad = True ) # x\u9700\u8981\u88ab\u6c42\u5bfc a = torch . tensor ( 1.0 ) b = torch . tensor ( - 2.0 ) c = torch . tensor ( 1.0 ) optimizer = torch . optim . SGD ( params = [ x ], lr = 0.01 ) def f ( x ): result = a * torch . pow ( x , 2 ) + b * x + c return ( result ) for i in range ( 500 ): optimizer . zero_grad () y = f ( x ) y . backward () optimizer . step () print ( \"y=\" , f ( x ) . data , \";\" , \"x=\" , x . data ) y= tensor(0.) ; x= tensor(1.0000) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"2-2,\u81ea\u52a8\u5fae\u5206\u673a\u5236"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-2%2C%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86%E6%9C%BA%E5%88%B6/#2-2\u81ea\u52a8\u5fae\u5206\u673a\u5236","text":"\u795e\u7ecf\u7f51\u7edc\u901a\u5e38\u4f9d\u8d56\u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6\u6765\u66f4\u65b0\u7f51\u7edc\u53c2\u6570\uff0c\u6c42\u68af\u5ea6\u8fc7\u7a0b\u901a\u5e38\u662f\u4e00\u4ef6\u975e\u5e38\u590d\u6742\u800c\u5bb9\u6613\u51fa\u9519\u7684\u4e8b\u60c5\u3002 \u800c\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u81ea\u52a8\u5730\u5b8c\u6210\u8fd9\u79cd\u6c42\u68af\u5ea6\u8fd0\u7b97\u3002 Pytorch\u4e00\u822c\u901a\u8fc7\u53cd\u5411\u4f20\u64ad backward \u65b9\u6cd5 \u5b9e\u73b0\u8fd9\u79cd\u6c42\u68af\u5ea6\u8ba1\u7b97\u3002\u8be5\u65b9\u6cd5\u6c42\u5f97\u7684\u68af\u5ea6\u5c06\u5b58\u5728\u5bf9\u5e94\u81ea\u53d8\u91cf\u5f20\u91cf\u7684grad\u5c5e\u6027\u4e0b\u3002 \u9664\u6b64\u4e4b\u5916\uff0c\u4e5f\u80fd\u591f\u8c03\u7528torch.autograd.grad \u51fd\u6570\u6765\u5b9e\u73b0\u6c42\u68af\u5ea6\u8ba1\u7b97\u3002 \u8fd9\u5c31\u662fPytorch\u7684\u81ea\u52a8\u5fae\u5206\u673a\u5236\u3002","title":"2-2,\u81ea\u52a8\u5fae\u5206\u673a\u5236"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-2%2C%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86%E6%9C%BA%E5%88%B6/#\u4e00\u5229\u7528backward\u65b9\u6cd5\u6c42\u5bfc\u6570","text":"backward \u65b9\u6cd5\u901a\u5e38\u5728\u4e00\u4e2a\u6807\u91cf\u5f20\u91cf\u4e0a\u8c03\u7528\uff0c\u8be5\u65b9\u6cd5\u6c42\u5f97\u7684\u68af\u5ea6\u5c06\u5b58\u5728\u5bf9\u5e94\u81ea\u53d8\u91cf\u5f20\u91cf\u7684grad\u5c5e\u6027\u4e0b\u3002 \u5982\u679c\u8c03\u7528\u7684\u5f20\u91cf\u975e\u6807\u91cf\uff0c\u5219\u8981\u4f20\u5165\u4e00\u4e2a\u548c\u5b83\u540c\u5f62\u72b6 \u7684gradient\u53c2\u6570\u5f20\u91cf\u3002 \u76f8\u5f53\u4e8e\u7528\u8be5gradient\u53c2\u6570\u5f20\u91cf\u4e0e\u8c03\u7528\u5f20\u91cf\u4f5c\u5411\u91cf\u70b9\u4e58\uff0c\u5f97\u5230\u7684\u6807\u91cf\u7ed3\u679c\u518d\u53cd\u5411\u4f20\u64ad\u3002 1, \u6807\u91cf\u7684\u53cd\u5411\u4f20\u64ad import numpy as np import torch # f(x) = a*x**2 + b*x + c\u7684\u5bfc\u6570 x = torch . tensor ( 0.0 , requires_grad = True ) # x\u9700\u8981\u88ab\u6c42\u5bfc a = torch . tensor ( 1.0 ) b = torch . tensor ( - 2.0 ) c = torch . tensor ( 1.0 ) y = a * torch . pow ( x , 2 ) + b * x + c y . backward () dy_dx = x . grad print ( dy_dx ) tensor(-2.) 2, \u975e\u6807\u91cf\u7684\u53cd\u5411\u4f20\u64ad import numpy as np import torch # f(x) = a*x**2 + b*x + c x = torch . tensor ([[ 0.0 , 0.0 ],[ 1.0 , 2.0 ]], requires_grad = True ) # x\u9700\u8981\u88ab\u6c42\u5bfc a = torch . tensor ( 1.0 ) b = torch . tensor ( - 2.0 ) c = torch . tensor ( 1.0 ) y = a * torch . pow ( x , 2 ) + b * x + c gradient = torch . tensor ([[ 1.0 , 1.0 ],[ 1.0 , 1.0 ]]) print ( \"x: \\n \" , x ) print ( \"y: \\n \" , y ) y . backward ( gradient = gradient ) x_grad = x . grad print ( \"x_grad: \\n \" , x_grad ) x: tensor([[0., 0.], [1., 2.]], requires_grad=True) y: tensor([[1., 1.], [0., 1.]], grad_fn=<AddBackward0>) x_grad: tensor([[-2., -2.], [ 0., 2.]]) 3, \u975e\u6807\u91cf\u7684\u53cd\u5411\u4f20\u64ad\u53ef\u4ee5\u7528\u6807\u91cf\u7684\u53cd\u5411\u4f20\u64ad\u5b9e\u73b0 import numpy as np import torch # f(x) = a*x**2 + b*x + c x = torch . tensor ([[ 0.0 , 0.0 ],[ 1.0 , 2.0 ]], requires_grad = True ) # x\u9700\u8981\u88ab\u6c42\u5bfc a = torch . tensor ( 1.0 ) b = torch . tensor ( - 2.0 ) c = torch . tensor ( 1.0 ) y = a * torch . pow ( x , 2 ) + b * x + c gradient = torch . tensor ([[ 1.0 , 1.0 ],[ 1.0 , 1.0 ]]) z = torch . sum ( y * gradient ) print ( \"x:\" , x ) print ( \"y:\" , y ) z . backward () x_grad = x . grad print ( \"x_grad: \\n \" , x_grad ) x: tensor([[0., 0.], [1., 2.]], requires_grad=True) y: tensor([[1., 1.], [0., 1.]], grad_fn=<AddBackward0>) x_grad: tensor([[-2., -2.], [ 0., 2.]])","title":"\u4e00\uff0c\u5229\u7528backward\u65b9\u6cd5\u6c42\u5bfc\u6570"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-2%2C%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86%E6%9C%BA%E5%88%B6/#\u4e8c\u5229\u7528autogradgrad\u65b9\u6cd5\u6c42\u5bfc\u6570","text":"import numpy as np import torch # f(x) = a*x**2 + b*x + c\u7684\u5bfc\u6570 x = torch . tensor ( 0.0 , requires_grad = True ) # x\u9700\u8981\u88ab\u6c42\u5bfc a = torch . tensor ( 1.0 ) b = torch . tensor ( - 2.0 ) c = torch . tensor ( 1.0 ) y = a * torch . pow ( x , 2 ) + b * x + c # create_graph \u8bbe\u7f6e\u4e3a True \u5c06\u5141\u8bb8\u521b\u5efa\u66f4\u9ad8\u9636\u7684\u5bfc\u6570 dy_dx = torch . autograd . grad ( y , x , create_graph = True )[ 0 ] print ( dy_dx . data ) # \u6c42\u4e8c\u9636\u5bfc\u6570 dy2_dx2 = torch . autograd . grad ( dy_dx , x )[ 0 ] print ( dy2_dx2 . data ) tensor(-2.) tensor(2.) import numpy as np import torch x1 = torch . tensor ( 1.0 , requires_grad = True ) # x\u9700\u8981\u88ab\u6c42\u5bfc x2 = torch . tensor ( 2.0 , requires_grad = True ) y1 = x1 * x2 y2 = x1 + x2 # \u5141\u8bb8\u540c\u65f6\u5bf9\u591a\u4e2a\u81ea\u53d8\u91cf\u6c42\u5bfc\u6570 ( dy1_dx1 , dy1_dx2 ) = torch . autograd . grad ( outputs = y1 , inputs = [ x1 , x2 ], retain_graph = True ) print ( dy1_dx1 , dy1_dx2 ) # \u5982\u679c\u6709\u591a\u4e2a\u56e0\u53d8\u91cf\uff0c\u76f8\u5f53\u4e8e\u628a\u591a\u4e2a\u56e0\u53d8\u91cf\u7684\u68af\u5ea6\u7ed3\u679c\u6c42\u548c ( dy12_dx1 , dy12_dx2 ) = torch . autograd . grad ( outputs = [ y1 , y2 ], inputs = [ x1 , x2 ]) print ( dy12_dx1 , dy12_dx2 ) tensor(2.) tensor(1.) tensor(3.) tensor(2.)","title":"\u4e8c\uff0c\u5229\u7528autograd.grad\u65b9\u6cd5\u6c42\u5bfc\u6570"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-2%2C%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86%E6%9C%BA%E5%88%B6/#\u4e09\u5229\u7528\u81ea\u52a8\u5fae\u5206\u548c\u4f18\u5316\u5668\u6c42\u6700\u5c0f\u503c","text":"import numpy as np import torch # f(x) = a*x**2 + b*x + c\u7684\u6700\u5c0f\u503c x = torch . tensor ( 0.0 , requires_grad = True ) # x\u9700\u8981\u88ab\u6c42\u5bfc a = torch . tensor ( 1.0 ) b = torch . tensor ( - 2.0 ) c = torch . tensor ( 1.0 ) optimizer = torch . optim . SGD ( params = [ x ], lr = 0.01 ) def f ( x ): result = a * torch . pow ( x , 2 ) + b * x + c return ( result ) for i in range ( 500 ): optimizer . zero_grad () y = f ( x ) y . backward () optimizer . step () print ( \"y=\" , f ( x ) . data , \";\" , \"x=\" , x . data ) y= tensor(0.) ; x= tensor(1.0000) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e09\uff0c\u5229\u7528\u81ea\u52a8\u5fae\u5206\u548c\u4f18\u5316\u5668\u6c42\u6700\u5c0f\u503c"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-3%2C%E5%8A%A8%E6%80%81%E8%AE%A1%E7%AE%97%E5%9B%BE/","text":"2-3,\u52a8\u6001\u8ba1\u7b97\u56fe # \u672c\u8282\u6211\u4eec\u5c06\u4ecb\u7ecd Pytorch\u7684\u52a8\u6001\u8ba1\u7b97\u56fe\u3002 \u5305\u62ec\uff1a \u52a8\u6001\u8ba1\u7b97\u56fe\u7b80\u4ecb \u8ba1\u7b97\u56fe\u4e2d\u7684Function \u8ba1\u7b97\u56fe\u548c\u53cd\u5411\u4f20\u64ad \u53f6\u5b50\u8282\u70b9\u548c\u975e\u53f6\u5b50\u8282\u70b9 \u8ba1\u7b97\u56fe\u5728TensorBoard\u4e2d\u7684\u53ef\u89c6\u5316 \u4e00\uff0c\u52a8\u6001\u8ba1\u7b97\u56fe\u7b80\u4ecb # Pytorch\u7684\u8ba1\u7b97\u56fe\u7531\u8282\u70b9\u548c\u8fb9\u7ec4\u6210\uff0c\u8282\u70b9\u8868\u793a\u5f20\u91cf\u6216\u8005Function\uff0c\u8fb9\u8868\u793a\u5f20\u91cf\u548cFunction\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u3002 Pytorch\u4e2d\u7684\u8ba1\u7b97\u56fe\u662f\u52a8\u6001\u56fe\u3002\u8fd9\u91cc\u7684\u52a8\u6001\u4e3b\u8981\u6709\u4e24\u91cd\u542b\u4e49\u3002 \u7b2c\u4e00\u5c42\u542b\u4e49\u662f\uff1a\u8ba1\u7b97\u56fe\u7684\u6b63\u5411\u4f20\u64ad\u662f\u7acb\u5373\u6267\u884c\u7684\u3002\u65e0\u9700\u7b49\u5f85\u5b8c\u6574\u7684\u8ba1\u7b97\u56fe\u521b\u5efa\u5b8c\u6bd5\uff0c\u6bcf\u6761\u8bed\u53e5\u90fd\u4f1a\u5728\u8ba1\u7b97\u56fe\u4e2d\u52a8\u6001\u6dfb\u52a0\u8282\u70b9\u548c\u8fb9\uff0c\u5e76\u7acb\u5373\u6267\u884c\u6b63\u5411\u4f20\u64ad\u5f97\u5230\u8ba1\u7b97\u7ed3\u679c\u3002 \u7b2c\u4e8c\u5c42\u542b\u4e49\u662f\uff1a\u8ba1\u7b97\u56fe\u5728\u53cd\u5411\u4f20\u64ad\u540e\u7acb\u5373\u9500\u6bc1\u3002\u4e0b\u6b21\u8c03\u7528\u9700\u8981\u91cd\u65b0\u6784\u5efa\u8ba1\u7b97\u56fe\u3002\u5982\u679c\u5728\u7a0b\u5e8f\u4e2d\u4f7f\u7528\u4e86backward\u65b9\u6cd5\u6267\u884c\u4e86\u53cd\u5411\u4f20\u64ad\uff0c\u6216\u8005\u5229\u7528torch.autograd.grad\u65b9\u6cd5\u8ba1\u7b97\u4e86\u68af\u5ea6\uff0c\u90a3\u4e48\u521b\u5efa\u7684\u8ba1\u7b97\u56fe\u4f1a\u88ab\u7acb\u5373\u9500\u6bc1\uff0c\u91ca\u653e\u5b58\u50a8\u7a7a\u95f4\uff0c\u4e0b\u6b21\u8c03\u7528\u9700\u8981\u91cd\u65b0\u521b\u5efa\u3002 1\uff0c\u8ba1\u7b97\u56fe\u7684\u6b63\u5411\u4f20\u64ad\u662f\u7acb\u5373\u6267\u884c\u7684\u3002 import torch w = torch . tensor ([[ 3.0 , 1.0 ]], requires_grad = True ) b = torch . tensor ([[ 3.0 ]], requires_grad = True ) X = torch . randn ( 10 , 2 ) Y = torch . randn ( 10 , 1 ) Y_hat = X @w . t () + b # Y_hat\u5b9a\u4e49\u540e\u5176\u6b63\u5411\u4f20\u64ad\u88ab\u7acb\u5373\u6267\u884c\uff0c\u4e0e\u5176\u540e\u9762\u7684loss\u521b\u5efa\u8bed\u53e5\u65e0\u5173 loss = torch . mean ( torch . pow ( Y_hat - Y , 2 )) print ( loss . data ) print ( Y_hat . data ) tensor(17.8969) tensor([[3.2613], [4.7322], [4.5037], [7.5899], [7.0973], [1.3287], [6.1473], [1.3492], [1.3911], [1.2150]]) 2\uff0c\u8ba1\u7b97\u56fe\u5728\u53cd\u5411\u4f20\u64ad\u540e\u7acb\u5373\u9500\u6bc1\u3002 import torch w = torch . tensor ([[ 3.0 , 1.0 ]], requires_grad = True ) b = torch . tensor ([[ 3.0 ]], requires_grad = True ) X = torch . randn ( 10 , 2 ) Y = torch . randn ( 10 , 1 ) Y_hat = X @w . t () + b # Y_hat\u5b9a\u4e49\u540e\u5176\u6b63\u5411\u4f20\u64ad\u88ab\u7acb\u5373\u6267\u884c\uff0c\u4e0e\u5176\u540e\u9762\u7684loss\u521b\u5efa\u8bed\u53e5\u65e0\u5173 loss = torch . mean ( torch . pow ( Y_hat - Y , 2 )) #\u8ba1\u7b97\u56fe\u5728\u53cd\u5411\u4f20\u64ad\u540e\u7acb\u5373\u9500\u6bc1\uff0c\u5982\u679c\u9700\u8981\u4fdd\u7559\u8ba1\u7b97\u56fe, \u9700\u8981\u8bbe\u7f6eretain_graph = True loss . backward () #loss.backward(retain_graph = True) #loss.backward() #\u5982\u679c\u518d\u6b21\u6267\u884c\u53cd\u5411\u4f20\u64ad\u5c06\u62a5\u9519 \u4e8c\uff0c\u8ba1\u7b97\u56fe\u4e2d\u7684Function # \u8ba1\u7b97\u56fe\u4e2d\u7684 \u5f20\u91cf\u6211\u4eec\u5df2\u7ecf\u6bd4\u8f83\u719f\u6089\u4e86, \u8ba1\u7b97\u56fe\u4e2d\u7684\u53e6\u5916\u4e00\u79cd\u8282\u70b9\u662fFunction, \u5b9e\u9645\u4e0a\u5c31\u662f Pytorch\u4e2d\u5404\u79cd\u5bf9\u5f20\u91cf\u64cd\u4f5c\u7684\u51fd\u6570\u3002 \u8fd9\u4e9bFunction\u548c\u6211\u4eecPython\u4e2d\u7684\u51fd\u6570\u6709\u4e00\u4e2a\u8f83\u5927\u7684\u533a\u522b\uff0c\u90a3\u5c31\u662f\u5b83\u540c\u65f6\u5305\u62ec\u6b63\u5411\u8ba1\u7b97\u903b\u8f91\u548c\u53cd\u5411\u4f20\u64ad\u7684\u903b\u8f91\u3002 \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u7ee7\u627ftorch.autograd.Function\u6765\u521b\u5efa\u8fd9\u79cd\u652f\u6301\u53cd\u5411\u4f20\u64ad\u7684Function class MyReLU ( torch . autograd . Function ): #\u6b63\u5411\u4f20\u64ad\u903b\u8f91\uff0c\u53ef\u4ee5\u7528ctx\u5b58\u50a8\u4e00\u4e9b\u503c\uff0c\u4f9b\u53cd\u5411\u4f20\u64ad\u4f7f\u7528\u3002 @staticmethod def forward ( ctx , input ): ctx . save_for_backward ( input ) return input . clamp ( min = 0 ) #\u53cd\u5411\u4f20\u64ad\u903b\u8f91 @staticmethod def backward ( ctx , grad_output ): input , = ctx . saved_tensors grad_input = grad_output . clone () grad_input [ input < 0 ] = 0 return grad_input import torch w = torch . tensor ([[ 3.0 , 1.0 ]], requires_grad = True ) b = torch . tensor ([[ 3.0 ]], requires_grad = True ) X = torch . tensor ([[ - 1.0 , - 1.0 ],[ 1.0 , 1.0 ]]) Y = torch . tensor ([[ 2.0 , 3.0 ]]) relu = MyReLU . apply # relu\u73b0\u5728\u4e5f\u53ef\u4ee5\u5177\u6709\u6b63\u5411\u4f20\u64ad\u548c\u53cd\u5411\u4f20\u64ad\u529f\u80fd Y_hat = relu ( X @w . t () + b ) loss = torch . mean ( torch . pow ( Y_hat - Y , 2 )) loss . backward () print ( w . grad ) print ( b . grad ) tensor([[4.5000, 4.5000]]) tensor([[4.5000]]) # Y_hat\u7684\u68af\u5ea6\u51fd\u6570\u5373\u662f\u6211\u4eec\u81ea\u5df1\u6240\u5b9a\u4e49\u7684 MyReLU.backward print ( Y_hat . grad_fn ) <torch.autograd.function.MyReLUBackward object at 0x1205a46c8> \u4e09\uff0c\u8ba1\u7b97\u56fe\u4e0e\u53cd\u5411\u4f20\u64ad # \u4e86\u89e3\u4e86Function\u7684\u529f\u80fd\uff0c\u6211\u4eec\u53ef\u4ee5\u7b80\u5355\u5730\u7406\u89e3\u4e00\u4e0b\u53cd\u5411\u4f20\u64ad\u7684\u539f\u7406\u548c\u8fc7\u7a0b\u3002\u7406\u89e3\u8be5\u90e8\u5206\u539f\u7406\u9700\u8981\u4e00\u4e9b\u9ad8\u7b49\u6570\u5b66\u4e2d\u6c42\u5bfc\u94fe\u5f0f\u6cd5\u5219\u7684\u57fa\u7840\u77e5\u8bc6\u3002 import torch x = torch . tensor ( 3.0 , requires_grad = True ) y1 = x + 1 y2 = 2 * x loss = ( y1 - y2 ) ** 2 loss . backward () loss.backward()\u8bed\u53e5\u8c03\u7528\u540e\uff0c\u4f9d\u6b21\u53d1\u751f\u4ee5\u4e0b\u8ba1\u7b97\u8fc7\u7a0b\u3002 1\uff0closs\u81ea\u5df1\u7684grad\u68af\u5ea6\u8d4b\u503c\u4e3a1\uff0c\u5373\u5bf9\u81ea\u8eab\u7684\u68af\u5ea6\u4e3a1\u3002 2\uff0closs\u6839\u636e\u5176\u81ea\u8eab\u68af\u5ea6\u4ee5\u53ca\u5173\u8054\u7684backward\u65b9\u6cd5\uff0c\u8ba1\u7b97\u51fa\u5176\u5bf9\u5e94\u7684\u81ea\u53d8\u91cf\u5373y1\u548cy2\u7684\u68af\u5ea6\uff0c\u5c06\u8be5\u503c\u8d4b\u503c\u5230y1.grad\u548cy2.grad\u3002 3\uff0cy2\u548cy1\u6839\u636e\u5176\u81ea\u8eab\u68af\u5ea6\u4ee5\u53ca\u5173\u8054\u7684backward\u65b9\u6cd5, \u5206\u522b\u8ba1\u7b97\u51fa\u5176\u5bf9\u5e94\u7684\u81ea\u53d8\u91cfx\u7684\u68af\u5ea6\uff0cx.grad\u5c06\u5176\u6536\u5230\u7684\u591a\u4e2a\u68af\u5ea6\u503c\u7d2f\u52a0\u3002 \uff08\u6ce8\u610f\uff0c1,2,3\u6b65\u9aa4\u7684\u6c42\u68af\u5ea6\u987a\u5e8f\u548c\u5bf9\u591a\u4e2a\u68af\u5ea6\u503c\u7684\u7d2f\u52a0\u89c4\u5219\u6070\u597d\u662f\u6c42\u5bfc\u94fe\u5f0f\u6cd5\u5219\u7684\u7a0b\u5e8f\u8868\u8ff0\uff09 \u6b63\u56e0\u4e3a\u6c42\u5bfc\u94fe\u5f0f\u6cd5\u5219\u884d\u751f\u7684\u68af\u5ea6\u7d2f\u52a0\u89c4\u5219\uff0c\u5f20\u91cf\u7684grad\u68af\u5ea6\u4e0d\u4f1a\u81ea\u52a8\u6e05\u96f6\uff0c\u5728\u9700\u8981\u7684\u65f6\u5019\u9700\u8981\u624b\u52a8\u7f6e\u96f6\u3002 \u56db\uff0c\u53f6\u5b50\u8282\u70b9\u548c\u975e\u53f6\u5b50\u8282\u70b9 # \u6267\u884c\u4e0b\u9762\u4ee3\u7801\uff0c\u6211\u4eec\u4f1a\u53d1\u73b0 loss.grad\u5e76\u4e0d\u662f\u6211\u4eec\u671f\u671b\u76841,\u800c\u662f None\u3002 \u7c7b\u4f3c\u5730 y1.grad \u4ee5\u53ca y2.grad\u4e5f\u662f None. \u8fd9\u662f\u4e3a\u4ec0\u4e48\u5462\uff1f\u8fd9\u662f\u7531\u4e8e\u5b83\u4eec\u4e0d\u662f\u53f6\u5b50\u8282\u70b9\u5f20\u91cf\u3002 \u5728\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\uff0c\u53ea\u6709 is_leaf=True \u7684\u53f6\u5b50\u8282\u70b9\uff0c\u9700\u8981\u6c42\u5bfc\u7684\u5f20\u91cf\u7684\u5bfc\u6570\u7ed3\u679c\u624d\u4f1a\u88ab\u6700\u540e\u4fdd\u7559\u4e0b\u6765\u3002 \u90a3\u4e48\u4ec0\u4e48\u662f\u53f6\u5b50\u8282\u70b9\u5f20\u91cf\u5462\uff1f\u53f6\u5b50\u8282\u70b9\u5f20\u91cf\u9700\u8981\u6ee1\u8db3\u4e24\u4e2a\u6761\u4ef6\u3002 1\uff0c\u53f6\u5b50\u8282\u70b9\u5f20\u91cf\u662f\u7531\u7528\u6237\u76f4\u63a5\u521b\u5efa\u7684\u5f20\u91cf\uff0c\u800c\u975e\u7531\u67d0\u4e2aFunction\u901a\u8fc7\u8ba1\u7b97\u5f97\u5230\u7684\u5f20\u91cf\u3002 2\uff0c\u53f6\u5b50\u8282\u70b9\u5f20\u91cf\u7684 requires_grad\u5c5e\u6027\u5fc5\u987b\u4e3aTrue. Pytorch\u8bbe\u8ba1\u8fd9\u6837\u7684\u89c4\u5219\u4e3b\u8981\u662f\u4e3a\u4e86\u8282\u7ea6\u5185\u5b58\u6216\u8005\u663e\u5b58\u7a7a\u95f4\uff0c\u56e0\u4e3a\u51e0\u4e4e\u6240\u6709\u7684\u65f6\u5019\uff0c\u7528\u6237\u53ea\u4f1a\u5173\u5fc3\u4ed6\u81ea\u5df1\u76f4\u63a5\u521b\u5efa\u7684\u5f20\u91cf\u7684\u68af\u5ea6\u3002 \u6240\u6709\u4f9d\u8d56\u4e8e\u53f6\u5b50\u8282\u70b9\u5f20\u91cf\u7684\u5f20\u91cf, \u5176requires_grad \u5c5e\u6027\u5fc5\u5b9a\u662fTrue\u7684\uff0c\u4f46\u5176\u68af\u5ea6\u503c\u53ea\u5728\u8ba1\u7b97\u8fc7\u7a0b\u4e2d\u88ab\u7528\u5230\uff0c\u4e0d\u4f1a\u6700\u7ec8\u5b58\u50a8\u5230grad\u5c5e\u6027\u4e2d\u3002 \u5982\u679c\u9700\u8981\u4fdd\u7559\u4e2d\u95f4\u8ba1\u7b97\u7ed3\u679c\u7684\u68af\u5ea6\u5230grad\u5c5e\u6027\u4e2d\uff0c\u53ef\u4ee5\u4f7f\u7528 retain_grad\u65b9\u6cd5\u3002 \u5982\u679c\u4ec5\u4ec5\u662f\u4e3a\u4e86\u8c03\u8bd5\u4ee3\u7801\u67e5\u770b\u68af\u5ea6\u503c\uff0c\u53ef\u4ee5\u5229\u7528register_hook\u6253\u5370\u65e5\u5fd7\u3002 import torch x = torch . tensor ( 3.0 , requires_grad = True ) y1 = x + 1 y2 = 2 * x loss = ( y1 - y2 ) ** 2 loss . backward () print ( \"loss.grad:\" , loss . grad ) print ( \"y1.grad:\" , y1 . grad ) print ( \"y2.grad:\" , y2 . grad ) print ( x . grad ) loss.grad: None y1.grad: None y2.grad: None tensor(4.) print ( x . is_leaf ) print ( y1 . is_leaf ) print ( y2 . is_leaf ) print ( loss . is_leaf ) True False False False \u5229\u7528retain_grad\u53ef\u4ee5\u4fdd\u7559\u975e\u53f6\u5b50\u8282\u70b9\u7684\u68af\u5ea6\u503c\uff0c\u5229\u7528register_hook\u53ef\u4ee5\u67e5\u770b\u975e\u53f6\u5b50\u8282\u70b9\u7684\u68af\u5ea6\u503c\u3002 import torch #\u6b63\u5411\u4f20\u64ad x = torch . tensor ( 3.0 , requires_grad = True ) y1 = x + 1 y2 = 2 * x loss = ( y1 - y2 ) ** 2 #\u975e\u53f6\u5b50\u8282\u70b9\u68af\u5ea6\u663e\u793a\u63a7\u5236 y1 . register_hook ( lambda grad : print ( 'y1 grad: ' , grad )) y2 . register_hook ( lambda grad : print ( 'y2 grad: ' , grad )) loss . retain_grad () #\u53cd\u5411\u4f20\u64ad loss . backward () print ( \"loss.grad:\" , loss . grad ) print ( \"x.grad:\" , x . grad ) y2 grad: tensor(4.) y1 grad: tensor(-4.) loss.grad: tensor(1.) x.grad: tensor(4.) \u4e94\uff0c\u8ba1\u7b97\u56fe\u5728TensorBoard\u4e2d\u7684\u53ef\u89c6\u5316 # \u53ef\u4ee5\u5229\u7528 torch.utils.tensorboard \u5c06\u8ba1\u7b97\u56fe\u5bfc\u51fa\u5230 TensorBoard\u8fdb\u884c\u53ef\u89c6\u5316\u3002 from torch import nn class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . w = nn . Parameter ( torch . randn ( 2 , 1 )) self . b = nn . Parameter ( torch . zeros ( 1 , 1 )) def forward ( self , x ): y = x @self . w + self . b return y net = Net () from torch.utils.tensorboard import SummaryWriter writer = SummaryWriter ( '../data/tensorboard' ) writer . add_graph ( net , input_to_model = torch . rand ( 10 , 2 )) writer . close () % load_ext tensorboard #%tensorboard --logdir ../data/tensorboard from tensorboard import notebook notebook . list () #\u5728tensorboard\u4e2d\u67e5\u770b\u6a21\u578b notebook . start ( \"--logdir ../data/tensorboard\" ) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"2-3,\u52a8\u6001\u8ba1\u7b97\u56fe"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-3%2C%E5%8A%A8%E6%80%81%E8%AE%A1%E7%AE%97%E5%9B%BE/#2-3\u52a8\u6001\u8ba1\u7b97\u56fe","text":"\u672c\u8282\u6211\u4eec\u5c06\u4ecb\u7ecd Pytorch\u7684\u52a8\u6001\u8ba1\u7b97\u56fe\u3002 \u5305\u62ec\uff1a \u52a8\u6001\u8ba1\u7b97\u56fe\u7b80\u4ecb \u8ba1\u7b97\u56fe\u4e2d\u7684Function \u8ba1\u7b97\u56fe\u548c\u53cd\u5411\u4f20\u64ad \u53f6\u5b50\u8282\u70b9\u548c\u975e\u53f6\u5b50\u8282\u70b9 \u8ba1\u7b97\u56fe\u5728TensorBoard\u4e2d\u7684\u53ef\u89c6\u5316","title":"2-3,\u52a8\u6001\u8ba1\u7b97\u56fe"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-3%2C%E5%8A%A8%E6%80%81%E8%AE%A1%E7%AE%97%E5%9B%BE/#\u4e00\u52a8\u6001\u8ba1\u7b97\u56fe\u7b80\u4ecb","text":"Pytorch\u7684\u8ba1\u7b97\u56fe\u7531\u8282\u70b9\u548c\u8fb9\u7ec4\u6210\uff0c\u8282\u70b9\u8868\u793a\u5f20\u91cf\u6216\u8005Function\uff0c\u8fb9\u8868\u793a\u5f20\u91cf\u548cFunction\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u3002 Pytorch\u4e2d\u7684\u8ba1\u7b97\u56fe\u662f\u52a8\u6001\u56fe\u3002\u8fd9\u91cc\u7684\u52a8\u6001\u4e3b\u8981\u6709\u4e24\u91cd\u542b\u4e49\u3002 \u7b2c\u4e00\u5c42\u542b\u4e49\u662f\uff1a\u8ba1\u7b97\u56fe\u7684\u6b63\u5411\u4f20\u64ad\u662f\u7acb\u5373\u6267\u884c\u7684\u3002\u65e0\u9700\u7b49\u5f85\u5b8c\u6574\u7684\u8ba1\u7b97\u56fe\u521b\u5efa\u5b8c\u6bd5\uff0c\u6bcf\u6761\u8bed\u53e5\u90fd\u4f1a\u5728\u8ba1\u7b97\u56fe\u4e2d\u52a8\u6001\u6dfb\u52a0\u8282\u70b9\u548c\u8fb9\uff0c\u5e76\u7acb\u5373\u6267\u884c\u6b63\u5411\u4f20\u64ad\u5f97\u5230\u8ba1\u7b97\u7ed3\u679c\u3002 \u7b2c\u4e8c\u5c42\u542b\u4e49\u662f\uff1a\u8ba1\u7b97\u56fe\u5728\u53cd\u5411\u4f20\u64ad\u540e\u7acb\u5373\u9500\u6bc1\u3002\u4e0b\u6b21\u8c03\u7528\u9700\u8981\u91cd\u65b0\u6784\u5efa\u8ba1\u7b97\u56fe\u3002\u5982\u679c\u5728\u7a0b\u5e8f\u4e2d\u4f7f\u7528\u4e86backward\u65b9\u6cd5\u6267\u884c\u4e86\u53cd\u5411\u4f20\u64ad\uff0c\u6216\u8005\u5229\u7528torch.autograd.grad\u65b9\u6cd5\u8ba1\u7b97\u4e86\u68af\u5ea6\uff0c\u90a3\u4e48\u521b\u5efa\u7684\u8ba1\u7b97\u56fe\u4f1a\u88ab\u7acb\u5373\u9500\u6bc1\uff0c\u91ca\u653e\u5b58\u50a8\u7a7a\u95f4\uff0c\u4e0b\u6b21\u8c03\u7528\u9700\u8981\u91cd\u65b0\u521b\u5efa\u3002 1\uff0c\u8ba1\u7b97\u56fe\u7684\u6b63\u5411\u4f20\u64ad\u662f\u7acb\u5373\u6267\u884c\u7684\u3002 import torch w = torch . tensor ([[ 3.0 , 1.0 ]], requires_grad = True ) b = torch . tensor ([[ 3.0 ]], requires_grad = True ) X = torch . randn ( 10 , 2 ) Y = torch . randn ( 10 , 1 ) Y_hat = X @w . t () + b # Y_hat\u5b9a\u4e49\u540e\u5176\u6b63\u5411\u4f20\u64ad\u88ab\u7acb\u5373\u6267\u884c\uff0c\u4e0e\u5176\u540e\u9762\u7684loss\u521b\u5efa\u8bed\u53e5\u65e0\u5173 loss = torch . mean ( torch . pow ( Y_hat - Y , 2 )) print ( loss . data ) print ( Y_hat . data ) tensor(17.8969) tensor([[3.2613], [4.7322], [4.5037], [7.5899], [7.0973], [1.3287], [6.1473], [1.3492], [1.3911], [1.2150]]) 2\uff0c\u8ba1\u7b97\u56fe\u5728\u53cd\u5411\u4f20\u64ad\u540e\u7acb\u5373\u9500\u6bc1\u3002 import torch w = torch . tensor ([[ 3.0 , 1.0 ]], requires_grad = True ) b = torch . tensor ([[ 3.0 ]], requires_grad = True ) X = torch . randn ( 10 , 2 ) Y = torch . randn ( 10 , 1 ) Y_hat = X @w . t () + b # Y_hat\u5b9a\u4e49\u540e\u5176\u6b63\u5411\u4f20\u64ad\u88ab\u7acb\u5373\u6267\u884c\uff0c\u4e0e\u5176\u540e\u9762\u7684loss\u521b\u5efa\u8bed\u53e5\u65e0\u5173 loss = torch . mean ( torch . pow ( Y_hat - Y , 2 )) #\u8ba1\u7b97\u56fe\u5728\u53cd\u5411\u4f20\u64ad\u540e\u7acb\u5373\u9500\u6bc1\uff0c\u5982\u679c\u9700\u8981\u4fdd\u7559\u8ba1\u7b97\u56fe, \u9700\u8981\u8bbe\u7f6eretain_graph = True loss . backward () #loss.backward(retain_graph = True) #loss.backward() #\u5982\u679c\u518d\u6b21\u6267\u884c\u53cd\u5411\u4f20\u64ad\u5c06\u62a5\u9519","title":"\u4e00\uff0c\u52a8\u6001\u8ba1\u7b97\u56fe\u7b80\u4ecb"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-3%2C%E5%8A%A8%E6%80%81%E8%AE%A1%E7%AE%97%E5%9B%BE/#\u4e8c\u8ba1\u7b97\u56fe\u4e2d\u7684function","text":"\u8ba1\u7b97\u56fe\u4e2d\u7684 \u5f20\u91cf\u6211\u4eec\u5df2\u7ecf\u6bd4\u8f83\u719f\u6089\u4e86, \u8ba1\u7b97\u56fe\u4e2d\u7684\u53e6\u5916\u4e00\u79cd\u8282\u70b9\u662fFunction, \u5b9e\u9645\u4e0a\u5c31\u662f Pytorch\u4e2d\u5404\u79cd\u5bf9\u5f20\u91cf\u64cd\u4f5c\u7684\u51fd\u6570\u3002 \u8fd9\u4e9bFunction\u548c\u6211\u4eecPython\u4e2d\u7684\u51fd\u6570\u6709\u4e00\u4e2a\u8f83\u5927\u7684\u533a\u522b\uff0c\u90a3\u5c31\u662f\u5b83\u540c\u65f6\u5305\u62ec\u6b63\u5411\u8ba1\u7b97\u903b\u8f91\u548c\u53cd\u5411\u4f20\u64ad\u7684\u903b\u8f91\u3002 \u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u7ee7\u627ftorch.autograd.Function\u6765\u521b\u5efa\u8fd9\u79cd\u652f\u6301\u53cd\u5411\u4f20\u64ad\u7684Function class MyReLU ( torch . autograd . Function ): #\u6b63\u5411\u4f20\u64ad\u903b\u8f91\uff0c\u53ef\u4ee5\u7528ctx\u5b58\u50a8\u4e00\u4e9b\u503c\uff0c\u4f9b\u53cd\u5411\u4f20\u64ad\u4f7f\u7528\u3002 @staticmethod def forward ( ctx , input ): ctx . save_for_backward ( input ) return input . clamp ( min = 0 ) #\u53cd\u5411\u4f20\u64ad\u903b\u8f91 @staticmethod def backward ( ctx , grad_output ): input , = ctx . saved_tensors grad_input = grad_output . clone () grad_input [ input < 0 ] = 0 return grad_input import torch w = torch . tensor ([[ 3.0 , 1.0 ]], requires_grad = True ) b = torch . tensor ([[ 3.0 ]], requires_grad = True ) X = torch . tensor ([[ - 1.0 , - 1.0 ],[ 1.0 , 1.0 ]]) Y = torch . tensor ([[ 2.0 , 3.0 ]]) relu = MyReLU . apply # relu\u73b0\u5728\u4e5f\u53ef\u4ee5\u5177\u6709\u6b63\u5411\u4f20\u64ad\u548c\u53cd\u5411\u4f20\u64ad\u529f\u80fd Y_hat = relu ( X @w . t () + b ) loss = torch . mean ( torch . pow ( Y_hat - Y , 2 )) loss . backward () print ( w . grad ) print ( b . grad ) tensor([[4.5000, 4.5000]]) tensor([[4.5000]]) # Y_hat\u7684\u68af\u5ea6\u51fd\u6570\u5373\u662f\u6211\u4eec\u81ea\u5df1\u6240\u5b9a\u4e49\u7684 MyReLU.backward print ( Y_hat . grad_fn ) <torch.autograd.function.MyReLUBackward object at 0x1205a46c8>","title":"\u4e8c\uff0c\u8ba1\u7b97\u56fe\u4e2d\u7684Function"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-3%2C%E5%8A%A8%E6%80%81%E8%AE%A1%E7%AE%97%E5%9B%BE/#\u4e09\u8ba1\u7b97\u56fe\u4e0e\u53cd\u5411\u4f20\u64ad","text":"\u4e86\u89e3\u4e86Function\u7684\u529f\u80fd\uff0c\u6211\u4eec\u53ef\u4ee5\u7b80\u5355\u5730\u7406\u89e3\u4e00\u4e0b\u53cd\u5411\u4f20\u64ad\u7684\u539f\u7406\u548c\u8fc7\u7a0b\u3002\u7406\u89e3\u8be5\u90e8\u5206\u539f\u7406\u9700\u8981\u4e00\u4e9b\u9ad8\u7b49\u6570\u5b66\u4e2d\u6c42\u5bfc\u94fe\u5f0f\u6cd5\u5219\u7684\u57fa\u7840\u77e5\u8bc6\u3002 import torch x = torch . tensor ( 3.0 , requires_grad = True ) y1 = x + 1 y2 = 2 * x loss = ( y1 - y2 ) ** 2 loss . backward () loss.backward()\u8bed\u53e5\u8c03\u7528\u540e\uff0c\u4f9d\u6b21\u53d1\u751f\u4ee5\u4e0b\u8ba1\u7b97\u8fc7\u7a0b\u3002 1\uff0closs\u81ea\u5df1\u7684grad\u68af\u5ea6\u8d4b\u503c\u4e3a1\uff0c\u5373\u5bf9\u81ea\u8eab\u7684\u68af\u5ea6\u4e3a1\u3002 2\uff0closs\u6839\u636e\u5176\u81ea\u8eab\u68af\u5ea6\u4ee5\u53ca\u5173\u8054\u7684backward\u65b9\u6cd5\uff0c\u8ba1\u7b97\u51fa\u5176\u5bf9\u5e94\u7684\u81ea\u53d8\u91cf\u5373y1\u548cy2\u7684\u68af\u5ea6\uff0c\u5c06\u8be5\u503c\u8d4b\u503c\u5230y1.grad\u548cy2.grad\u3002 3\uff0cy2\u548cy1\u6839\u636e\u5176\u81ea\u8eab\u68af\u5ea6\u4ee5\u53ca\u5173\u8054\u7684backward\u65b9\u6cd5, \u5206\u522b\u8ba1\u7b97\u51fa\u5176\u5bf9\u5e94\u7684\u81ea\u53d8\u91cfx\u7684\u68af\u5ea6\uff0cx.grad\u5c06\u5176\u6536\u5230\u7684\u591a\u4e2a\u68af\u5ea6\u503c\u7d2f\u52a0\u3002 \uff08\u6ce8\u610f\uff0c1,2,3\u6b65\u9aa4\u7684\u6c42\u68af\u5ea6\u987a\u5e8f\u548c\u5bf9\u591a\u4e2a\u68af\u5ea6\u503c\u7684\u7d2f\u52a0\u89c4\u5219\u6070\u597d\u662f\u6c42\u5bfc\u94fe\u5f0f\u6cd5\u5219\u7684\u7a0b\u5e8f\u8868\u8ff0\uff09 \u6b63\u56e0\u4e3a\u6c42\u5bfc\u94fe\u5f0f\u6cd5\u5219\u884d\u751f\u7684\u68af\u5ea6\u7d2f\u52a0\u89c4\u5219\uff0c\u5f20\u91cf\u7684grad\u68af\u5ea6\u4e0d\u4f1a\u81ea\u52a8\u6e05\u96f6\uff0c\u5728\u9700\u8981\u7684\u65f6\u5019\u9700\u8981\u624b\u52a8\u7f6e\u96f6\u3002","title":"\u4e09\uff0c\u8ba1\u7b97\u56fe\u4e0e\u53cd\u5411\u4f20\u64ad"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-3%2C%E5%8A%A8%E6%80%81%E8%AE%A1%E7%AE%97%E5%9B%BE/#\u56db\u53f6\u5b50\u8282\u70b9\u548c\u975e\u53f6\u5b50\u8282\u70b9","text":"\u6267\u884c\u4e0b\u9762\u4ee3\u7801\uff0c\u6211\u4eec\u4f1a\u53d1\u73b0 loss.grad\u5e76\u4e0d\u662f\u6211\u4eec\u671f\u671b\u76841,\u800c\u662f None\u3002 \u7c7b\u4f3c\u5730 y1.grad \u4ee5\u53ca y2.grad\u4e5f\u662f None. \u8fd9\u662f\u4e3a\u4ec0\u4e48\u5462\uff1f\u8fd9\u662f\u7531\u4e8e\u5b83\u4eec\u4e0d\u662f\u53f6\u5b50\u8282\u70b9\u5f20\u91cf\u3002 \u5728\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\uff0c\u53ea\u6709 is_leaf=True \u7684\u53f6\u5b50\u8282\u70b9\uff0c\u9700\u8981\u6c42\u5bfc\u7684\u5f20\u91cf\u7684\u5bfc\u6570\u7ed3\u679c\u624d\u4f1a\u88ab\u6700\u540e\u4fdd\u7559\u4e0b\u6765\u3002 \u90a3\u4e48\u4ec0\u4e48\u662f\u53f6\u5b50\u8282\u70b9\u5f20\u91cf\u5462\uff1f\u53f6\u5b50\u8282\u70b9\u5f20\u91cf\u9700\u8981\u6ee1\u8db3\u4e24\u4e2a\u6761\u4ef6\u3002 1\uff0c\u53f6\u5b50\u8282\u70b9\u5f20\u91cf\u662f\u7531\u7528\u6237\u76f4\u63a5\u521b\u5efa\u7684\u5f20\u91cf\uff0c\u800c\u975e\u7531\u67d0\u4e2aFunction\u901a\u8fc7\u8ba1\u7b97\u5f97\u5230\u7684\u5f20\u91cf\u3002 2\uff0c\u53f6\u5b50\u8282\u70b9\u5f20\u91cf\u7684 requires_grad\u5c5e\u6027\u5fc5\u987b\u4e3aTrue. Pytorch\u8bbe\u8ba1\u8fd9\u6837\u7684\u89c4\u5219\u4e3b\u8981\u662f\u4e3a\u4e86\u8282\u7ea6\u5185\u5b58\u6216\u8005\u663e\u5b58\u7a7a\u95f4\uff0c\u56e0\u4e3a\u51e0\u4e4e\u6240\u6709\u7684\u65f6\u5019\uff0c\u7528\u6237\u53ea\u4f1a\u5173\u5fc3\u4ed6\u81ea\u5df1\u76f4\u63a5\u521b\u5efa\u7684\u5f20\u91cf\u7684\u68af\u5ea6\u3002 \u6240\u6709\u4f9d\u8d56\u4e8e\u53f6\u5b50\u8282\u70b9\u5f20\u91cf\u7684\u5f20\u91cf, \u5176requires_grad \u5c5e\u6027\u5fc5\u5b9a\u662fTrue\u7684\uff0c\u4f46\u5176\u68af\u5ea6\u503c\u53ea\u5728\u8ba1\u7b97\u8fc7\u7a0b\u4e2d\u88ab\u7528\u5230\uff0c\u4e0d\u4f1a\u6700\u7ec8\u5b58\u50a8\u5230grad\u5c5e\u6027\u4e2d\u3002 \u5982\u679c\u9700\u8981\u4fdd\u7559\u4e2d\u95f4\u8ba1\u7b97\u7ed3\u679c\u7684\u68af\u5ea6\u5230grad\u5c5e\u6027\u4e2d\uff0c\u53ef\u4ee5\u4f7f\u7528 retain_grad\u65b9\u6cd5\u3002 \u5982\u679c\u4ec5\u4ec5\u662f\u4e3a\u4e86\u8c03\u8bd5\u4ee3\u7801\u67e5\u770b\u68af\u5ea6\u503c\uff0c\u53ef\u4ee5\u5229\u7528register_hook\u6253\u5370\u65e5\u5fd7\u3002 import torch x = torch . tensor ( 3.0 , requires_grad = True ) y1 = x + 1 y2 = 2 * x loss = ( y1 - y2 ) ** 2 loss . backward () print ( \"loss.grad:\" , loss . grad ) print ( \"y1.grad:\" , y1 . grad ) print ( \"y2.grad:\" , y2 . grad ) print ( x . grad ) loss.grad: None y1.grad: None y2.grad: None tensor(4.) print ( x . is_leaf ) print ( y1 . is_leaf ) print ( y2 . is_leaf ) print ( loss . is_leaf ) True False False False \u5229\u7528retain_grad\u53ef\u4ee5\u4fdd\u7559\u975e\u53f6\u5b50\u8282\u70b9\u7684\u68af\u5ea6\u503c\uff0c\u5229\u7528register_hook\u53ef\u4ee5\u67e5\u770b\u975e\u53f6\u5b50\u8282\u70b9\u7684\u68af\u5ea6\u503c\u3002 import torch #\u6b63\u5411\u4f20\u64ad x = torch . tensor ( 3.0 , requires_grad = True ) y1 = x + 1 y2 = 2 * x loss = ( y1 - y2 ) ** 2 #\u975e\u53f6\u5b50\u8282\u70b9\u68af\u5ea6\u663e\u793a\u63a7\u5236 y1 . register_hook ( lambda grad : print ( 'y1 grad: ' , grad )) y2 . register_hook ( lambda grad : print ( 'y2 grad: ' , grad )) loss . retain_grad () #\u53cd\u5411\u4f20\u64ad loss . backward () print ( \"loss.grad:\" , loss . grad ) print ( \"x.grad:\" , x . grad ) y2 grad: tensor(4.) y1 grad: tensor(-4.) loss.grad: tensor(1.) x.grad: tensor(4.)","title":"\u56db\uff0c\u53f6\u5b50\u8282\u70b9\u548c\u975e\u53f6\u5b50\u8282\u70b9"},{"location":"2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-3%2C%E5%8A%A8%E6%80%81%E8%AE%A1%E7%AE%97%E5%9B%BE/#\u4e94\u8ba1\u7b97\u56fe\u5728tensorboard\u4e2d\u7684\u53ef\u89c6\u5316","text":"\u53ef\u4ee5\u5229\u7528 torch.utils.tensorboard \u5c06\u8ba1\u7b97\u56fe\u5bfc\u51fa\u5230 TensorBoard\u8fdb\u884c\u53ef\u89c6\u5316\u3002 from torch import nn class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . w = nn . Parameter ( torch . randn ( 2 , 1 )) self . b = nn . Parameter ( torch . zeros ( 1 , 1 )) def forward ( self , x ): y = x @self . w + self . b return y net = Net () from torch.utils.tensorboard import SummaryWriter writer = SummaryWriter ( '../data/tensorboard' ) writer . add_graph ( net , input_to_model = torch . rand ( 10 , 2 )) writer . close () % load_ext tensorboard #%tensorboard --logdir ../data/tensorboard from tensorboard import notebook notebook . list () #\u5728tensorboard\u4e2d\u67e5\u770b\u6a21\u578b notebook . start ( \"--logdir ../data/tensorboard\" ) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e94\uff0c\u8ba1\u7b97\u56fe\u5728TensorBoard\u4e2d\u7684\u53ef\u89c6\u5316"},{"location":"3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/","text":"\u4e09\u3001Pytorch\u7684\u5c42\u6b21\u7ed3\u6784 # \u672c\u7ae0\u6211\u4eec\u4ecb\u7ecdPytorch\u4e2d5\u4e2a\u4e0d\u540c\u7684\u5c42\u6b21\u7ed3\u6784\uff1a\u5373\u786c\u4ef6\u5c42\uff0c\u5185\u6838\u5c42\uff0c\u4f4e\u9636API\uff0c\u4e2d\u9636API\uff0c\u9ad8\u9636API\u3010torchkeras\u3011\u3002\u5e76\u4ee5\u7ebf\u6027\u56de\u5f52\u548cDNN\u4e8c\u5206\u7c7b\u6a21\u578b\u4e3a\u4f8b\uff0c\u76f4\u89c2\u5bf9\u6bd4\u5c55\u793a\u5728\u4e0d\u540c\u5c42\u7ea7\u5b9e\u73b0\u6a21\u578b\u7684\u7279\u70b9\u3002 Pytorch\u7684\u5c42\u6b21\u7ed3\u6784\u4ece\u4f4e\u5230\u9ad8\u53ef\u4ee5\u5206\u6210\u5982\u4e0b\u4e94\u5c42\u3002 \u6700\u5e95\u5c42\u4e3a\u786c\u4ef6\u5c42\uff0cPytorch\u652f\u6301CPU\u3001GPU\u52a0\u5165\u8ba1\u7b97\u8d44\u6e90\u6c60\u3002 \u7b2c\u4e8c\u5c42\u4e3aC++\u5b9e\u73b0\u7684\u5185\u6838\u3002 \u7b2c\u4e09\u5c42\u4e3aPython\u5b9e\u73b0\u7684\u64cd\u4f5c\u7b26\uff0c\u63d0\u4f9b\u4e86\u5c01\u88c5C++\u5185\u6838\u7684\u4f4e\u7ea7API\u6307\u4ee4\uff0c\u4e3b\u8981\u5305\u62ec\u5404\u79cd\u5f20\u91cf\u64cd\u4f5c\u7b97\u5b50\u3001\u81ea\u52a8\u5fae\u5206\u3001\u53d8\u91cf\u7ba1\u7406. \u5982torch.tensor,torch.cat,torch.autograd.grad,nn.Module. \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u7b2c\u4e09\u5c42API\u5c31\u662f\u3010\u6a21\u578b\u4e4b\u7816\u3011\u3002 \u7b2c\u56db\u5c42\u4e3aPython\u5b9e\u73b0\u7684\u6a21\u578b\u7ec4\u4ef6\uff0c\u5bf9\u4f4e\u7ea7API\u8fdb\u884c\u4e86\u51fd\u6570\u5c01\u88c5\uff0c\u4e3b\u8981\u5305\u62ec\u5404\u79cd\u6a21\u578b\u5c42\uff0c\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u5668\uff0c\u6570\u636e\u7ba1\u9053\u7b49\u7b49\u3002 \u5982torch.nn.Linear,torch.nn.BCE,torch.optim.Adam,torch.utils.data.DataLoader. \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u7b2c\u56db\u5c42API\u5c31\u662f\u3010\u6a21\u578b\u4e4b\u5899\u3011\u3002 \u7b2c\u4e94\u5c42\u4e3aPython\u5b9e\u73b0\u7684\u6a21\u578b\u63a5\u53e3\u3002Pytorch\u6ca1\u6709\u5b98\u65b9\u7684\u9ad8\u9636API\u3002\u4e3a\u4e86\u4fbf\u4e8e\u8bad\u7ec3\u6a21\u578b\uff0c\u4f5c\u8005\u4eff\u7167keras\u4e2d\u7684\u6a21\u578b\u63a5\u53e3\uff0c\u4f7f\u7528\u4e86\u4e0d\u5230300\u884c\u4ee3\u7801\uff0c\u5c01\u88c5\u4e86Pytorch\u7684\u9ad8\u9636\u6a21\u578b\u63a5\u53e3torchkeras.Model\u3002\u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u7b2c\u4e94\u5c42API\u5c31\u662f\u6a21\u578b\u672c\u8eab\uff0c\u5373\u3010\u6a21\u578b\u4e4b\u5c4b\u3011\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e09\u3001Pytorch\u7684\u5c42\u6b21\u7ed3\u6784"},{"location":"3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/#\u4e09pytorch\u7684\u5c42\u6b21\u7ed3\u6784","text":"\u672c\u7ae0\u6211\u4eec\u4ecb\u7ecdPytorch\u4e2d5\u4e2a\u4e0d\u540c\u7684\u5c42\u6b21\u7ed3\u6784\uff1a\u5373\u786c\u4ef6\u5c42\uff0c\u5185\u6838\u5c42\uff0c\u4f4e\u9636API\uff0c\u4e2d\u9636API\uff0c\u9ad8\u9636API\u3010torchkeras\u3011\u3002\u5e76\u4ee5\u7ebf\u6027\u56de\u5f52\u548cDNN\u4e8c\u5206\u7c7b\u6a21\u578b\u4e3a\u4f8b\uff0c\u76f4\u89c2\u5bf9\u6bd4\u5c55\u793a\u5728\u4e0d\u540c\u5c42\u7ea7\u5b9e\u73b0\u6a21\u578b\u7684\u7279\u70b9\u3002 Pytorch\u7684\u5c42\u6b21\u7ed3\u6784\u4ece\u4f4e\u5230\u9ad8\u53ef\u4ee5\u5206\u6210\u5982\u4e0b\u4e94\u5c42\u3002 \u6700\u5e95\u5c42\u4e3a\u786c\u4ef6\u5c42\uff0cPytorch\u652f\u6301CPU\u3001GPU\u52a0\u5165\u8ba1\u7b97\u8d44\u6e90\u6c60\u3002 \u7b2c\u4e8c\u5c42\u4e3aC++\u5b9e\u73b0\u7684\u5185\u6838\u3002 \u7b2c\u4e09\u5c42\u4e3aPython\u5b9e\u73b0\u7684\u64cd\u4f5c\u7b26\uff0c\u63d0\u4f9b\u4e86\u5c01\u88c5C++\u5185\u6838\u7684\u4f4e\u7ea7API\u6307\u4ee4\uff0c\u4e3b\u8981\u5305\u62ec\u5404\u79cd\u5f20\u91cf\u64cd\u4f5c\u7b97\u5b50\u3001\u81ea\u52a8\u5fae\u5206\u3001\u53d8\u91cf\u7ba1\u7406. \u5982torch.tensor,torch.cat,torch.autograd.grad,nn.Module. \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u7b2c\u4e09\u5c42API\u5c31\u662f\u3010\u6a21\u578b\u4e4b\u7816\u3011\u3002 \u7b2c\u56db\u5c42\u4e3aPython\u5b9e\u73b0\u7684\u6a21\u578b\u7ec4\u4ef6\uff0c\u5bf9\u4f4e\u7ea7API\u8fdb\u884c\u4e86\u51fd\u6570\u5c01\u88c5\uff0c\u4e3b\u8981\u5305\u62ec\u5404\u79cd\u6a21\u578b\u5c42\uff0c\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u5668\uff0c\u6570\u636e\u7ba1\u9053\u7b49\u7b49\u3002 \u5982torch.nn.Linear,torch.nn.BCE,torch.optim.Adam,torch.utils.data.DataLoader. \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u7b2c\u56db\u5c42API\u5c31\u662f\u3010\u6a21\u578b\u4e4b\u5899\u3011\u3002 \u7b2c\u4e94\u5c42\u4e3aPython\u5b9e\u73b0\u7684\u6a21\u578b\u63a5\u53e3\u3002Pytorch\u6ca1\u6709\u5b98\u65b9\u7684\u9ad8\u9636API\u3002\u4e3a\u4e86\u4fbf\u4e8e\u8bad\u7ec3\u6a21\u578b\uff0c\u4f5c\u8005\u4eff\u7167keras\u4e2d\u7684\u6a21\u578b\u63a5\u53e3\uff0c\u4f7f\u7528\u4e86\u4e0d\u5230300\u884c\u4ee3\u7801\uff0c\u5c01\u88c5\u4e86Pytorch\u7684\u9ad8\u9636\u6a21\u578b\u63a5\u53e3torchkeras.Model\u3002\u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u7b2c\u4e94\u5c42API\u5c31\u662f\u6a21\u578b\u672c\u8eab\uff0c\u5373\u3010\u6a21\u578b\u4e4b\u5c4b\u3011\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e09\u3001Pytorch\u7684\u5c42\u6b21\u7ed3\u6784"},{"location":"3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-1%2C%E4%BD%8E%E9%98%B6API%E7%A4%BA%E8%8C%83/","text":"3-1,\u4f4e\u9636API\u793a\u8303 # \u4e0b\u9762\u7684\u8303\u4f8b\u4f7f\u7528Pytorch\u7684\u4f4e\u9636API\u5b9e\u73b0\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u548cDNN\u4e8c\u5206\u7c7b\u6a21\u578b\u3002 \u4f4e\u9636API\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u64cd\u4f5c\uff0c\u8ba1\u7b97\u56fe\u548c\u81ea\u52a8\u5fae\u5206\u3002 import os import datetime #\u6253\u5370\u65f6\u95f4 def printbar (): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) #mac\u7cfb\u7edf\u4e0apytorch\u548cmatplotlib\u5728jupyter\u4e2d\u540c\u65f6\u8dd1\u9700\u8981\u66f4\u6539\u73af\u5883\u53d8\u91cf os . environ [ \"KMP_DUPLICATE_LIB_OK\" ] = \"TRUE\" \u4e00\uff0c\u7ebf\u6027\u56de\u5f52\u6a21\u578b # 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import torch from torch import nn #\u6837\u672c\u6570\u91cf n = 400 # \u751f\u6210\u6d4b\u8bd5\u7528\u6570\u636e\u96c6 X = 10 * torch . rand ([ n , 2 ]) - 5.0 #torch.rand\u662f\u5747\u5300\u5206\u5e03 w0 = torch . tensor ([[ 2.0 ],[ - 3.0 ]]) b0 = torch . tensor ([[ 10.0 ]]) Y = X @w0 + b0 + torch . normal ( 0.0 , 2.0 , size = [ n , 1 ]) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 # \u6570\u636e\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ] . numpy (), Y [:, 0 ] . numpy (), c = \"b\" , label = \"samples\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ] . numpy (), Y [:, 0 ] . numpy (), c = \"g\" , label = \"samples\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () # \u6784\u5efa\u6570\u636e\u7ba1\u9053\u8fed\u4ee3\u5668 def data_iter ( features , labels , batch_size = 8 ): num_examples = len ( features ) indices = list ( range ( num_examples )) np . random . shuffle ( indices ) #\u6837\u672c\u7684\u8bfb\u53d6\u987a\u5e8f\u662f\u968f\u673a\u7684 for i in range ( 0 , num_examples , batch_size ): indexs = torch . LongTensor ( indices [ i : min ( i + batch_size , num_examples )]) yield features . index_select ( 0 , indexs ), labels . index_select ( 0 , indexs ) # \u6d4b\u8bd5\u6570\u636e\u7ba1\u9053\u6548\u679c batch_size = 8 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) print ( features ) print ( labels ) tensor([[-4.3880, 1.3655], [-0.1082, 3.9533], [-2.6286, 2.7058], [ 1.0604, -1.8646], [-1.5805, 1.5406], [-2.6217, -3.2342], [ 2.3748, -0.6449], [-1.2478, -2.0509]]) tensor([[-0.2069], [-3.2494], [-6.9620], [17.0528], [ 1.1076], [17.2117], [16.1081], [14.7092]]) 2\uff0c\u5b9a\u4e49\u6a21\u578b # \u5b9a\u4e49\u6a21\u578b class LinearRegression : def __init__ ( self ): self . w = torch . randn_like ( w0 , requires_grad = True ) self . b = torch . zeros_like ( b0 , requires_grad = True ) #\u6b63\u5411\u4f20\u64ad def forward ( self , x ): return x @self . w + self . b # \u635f\u5931\u51fd\u6570 def loss_func ( self , y_pred , y_true ): return torch . mean (( y_pred - y_true ) ** 2 / 2 ) model = LinearRegression () 3\uff0c\u8bad\u7ec3\u6a21\u578b def train_step ( model , features , labels ): predictions = model . forward ( features ) loss = model . loss_func ( predictions , labels ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 loss . backward () # \u4f7f\u7528torch.no_grad()\u907f\u514d\u68af\u5ea6\u8bb0\u5f55\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u64cd\u4f5c model.w.data \u5b9e\u73b0\u907f\u514d\u68af\u5ea6\u8bb0\u5f55 with torch . no_grad (): # \u68af\u5ea6\u4e0b\u964d\u6cd5\u66f4\u65b0\u53c2\u6570 model . w -= 0.001 * model . w . grad model . b -= 0.001 * model . b . grad # \u68af\u5ea6\u6e05\u96f6 model . w . grad . zero_ () model . b . grad . zero_ () return loss # \u6d4b\u8bd5train_step\u6548\u679c batch_size = 10 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) train_step ( model , features , labels ) tensor(92.8199, grad_fn=<MeanBackward0>) def train_model ( model , epochs ): for epoch in range ( 1 , epochs + 1 ): for features , labels in data_iter ( X , Y , 10 ): loss = train_step ( model , features , labels ) if epoch % 200 == 0 : printbar () print ( \"epoch =\" , epoch , \"loss = \" , loss . item ()) print ( \"model.w =\" , model . w . data ) print ( \"model.b =\" , model . b . data ) train_model ( model , epochs = 1000 ) ================================================================================2020-07-05 08:27:57 epoch = 200 loss = 2.6340413093566895 model.w = tensor([[ 2.0283], [-2.9632]]) model.b = tensor([[10.0748]]) ================================================================================2020-07-05 08:28:00 epoch = 400 loss = 2.24908709526062 model.w = tensor([[ 2.0300], [-2.9643]]) model.b = tensor([[10.0781]]) ================================================================================2020-07-05 08:28:04 epoch = 600 loss = 1.510349154472351 model.w = tensor([[ 2.0290], [-2.9630]]) model.b = tensor([[10.0781]]) ================================================================================2020-07-05 08:28:07 epoch = 800 loss = 1.038671851158142 model.w = tensor([[ 2.0314], [-2.9649]]) model.b = tensor([[10.0785]]) ================================================================================2020-07-05 08:28:10 epoch = 1000 loss = 1.9742190837860107 model.w = tensor([[ 2.0313], [-2.9648]]) model.b = tensor([[10.0781]]) # \u7ed3\u679c\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ] . numpy (), Y [:, 0 ] . numpy (), c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ] . numpy (),( model . w [ 0 ] . data * X [:, 0 ] + model . b [ 0 ] . data ) . numpy (), \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ] . numpy (), Y [:, 0 ] . numpy (), c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ] . numpy (),( model . w [ 1 ] . data * X [:, 1 ] + model . b [ 0 ] . data ) . numpy (), \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () \u4e8c\uff0cDNN\u4e8c\u5206\u7c7b\u6a21\u578b # 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import torch from torch import nn % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u6b63\u8d1f\u6837\u672c\u6570\u91cf n_positive , n_negative = 2000 , 2000 #\u751f\u6210\u6b63\u6837\u672c, \u5c0f\u5706\u73af\u5206\u5e03 r_p = 5.0 + torch . normal ( 0.0 , 1.0 , size = [ n_positive , 1 ]) theta_p = 2 * np . pi * torch . rand ([ n_positive , 1 ]) Xp = torch . cat ([ r_p * torch . cos ( theta_p ), r_p * torch . sin ( theta_p )], axis = 1 ) Yp = torch . ones_like ( r_p ) #\u751f\u6210\u8d1f\u6837\u672c, \u5927\u5706\u73af\u5206\u5e03 r_n = 8.0 + torch . normal ( 0.0 , 1.0 , size = [ n_negative , 1 ]) theta_n = 2 * np . pi * torch . rand ([ n_negative , 1 ]) Xn = torch . cat ([ r_n * torch . cos ( theta_n ), r_n * torch . sin ( theta_n )], axis = 1 ) Yn = torch . zeros_like ( r_n ) #\u6c47\u603b\u6837\u672c X = torch . cat ([ Xp , Xn ], axis = 0 ) Y = torch . cat ([ Yp , Yn ], axis = 0 ) #\u53ef\u89c6\u5316 plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) plt . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); # \u6784\u5efa\u6570\u636e\u7ba1\u9053\u8fed\u4ee3\u5668 def data_iter ( features , labels , batch_size = 8 ): num_examples = len ( features ) indices = list ( range ( num_examples )) np . random . shuffle ( indices ) #\u6837\u672c\u7684\u8bfb\u53d6\u987a\u5e8f\u662f\u968f\u673a\u7684 for i in range ( 0 , num_examples , batch_size ): indexs = torch . LongTensor ( indices [ i : min ( i + batch_size , num_examples )]) yield features . index_select ( 0 , indexs ), labels . index_select ( 0 , indexs ) # \u6d4b\u8bd5\u6570\u636e\u7ba1\u9053\u6548\u679c batch_size = 8 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) print ( features ) print ( labels ) tensor([[ 6.9914, -1.0820], [ 4.8156, 4.0532], [-1.0697, -7.4644], [ 2.6291, 3.8851], [-1.6780, -4.3390], [-6.1495, 1.2269], [-4.3422, 3.9552], [-6.2265, 2.6159]]) tensor([[0.], [1.], [0.], [1.], [1.], [1.], [1.], [1.]]) 2\uff0c\u5b9a\u4e49\u6a21\u578b \u6b64\u5904\u8303\u4f8b\u6211\u4eec\u5229\u7528nn.Module\u6765\u7ec4\u7ec7\u6a21\u578b\u53d8\u91cf\u3002 class DNNModel ( nn . Module ): def __init__ ( self ): super ( DNNModel , self ) . __init__ () self . w1 = nn . Parameter ( torch . randn ( 2 , 4 )) self . b1 = nn . Parameter ( torch . zeros ( 1 , 4 )) self . w2 = nn . Parameter ( torch . randn ( 4 , 8 )) self . b2 = nn . Parameter ( torch . zeros ( 1 , 8 )) self . w3 = nn . Parameter ( torch . randn ( 8 , 1 )) self . b3 = nn . Parameter ( torch . zeros ( 1 , 1 )) # \u6b63\u5411\u4f20\u64ad def forward ( self , x ): x = torch . relu ( x @self . w1 + self . b1 ) x = torch . relu ( x @self . w2 + self . b2 ) y = torch . sigmoid ( x @self . w3 + self . b3 ) return y # \u635f\u5931\u51fd\u6570(\u4e8c\u5143\u4ea4\u53c9\u71b5) def loss_func ( self , y_pred , y_true ): #\u5c06\u9884\u6d4b\u503c\u9650\u5236\u57281e-7\u4ee5\u4e0a, 1- (1e-7)\u4ee5\u4e0b\uff0c\u907f\u514dlog(0)\u9519\u8bef eps = 1e-7 y_pred = torch . clamp ( y_pred , eps , 1.0 - eps ) bce = - y_true * torch . log ( y_pred ) - ( 1 - y_true ) * torch . log ( 1 - y_pred ) return torch . mean ( bce ) # \u8bc4\u4f30\u6307\u6807(\u51c6\u786e\u7387) def metric_func ( self , y_pred , y_true ): y_pred = torch . where ( y_pred > 0.5 , torch . ones_like ( y_pred , dtype = torch . float32 ), torch . zeros_like ( y_pred , dtype = torch . float32 )) acc = torch . mean ( 1 - torch . abs ( y_true - y_pred )) return acc model = DNNModel () # \u6d4b\u8bd5\u6a21\u578b\u7ed3\u6784 batch_size = 10 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) predictions = model ( features ) loss = model . loss_func ( labels , predictions ) metric = model . metric_func ( labels , predictions ) print ( \"init loss:\" , loss . item ()) print ( \"init metric:\" , metric . item ()) init loss: 7.979694366455078 init metric: 0.50347900390625 len ( list ( model . parameters ())) 6 3\uff0c\u8bad\u7ec3\u6a21\u578b def train_step ( model , features , labels ): # \u6b63\u5411\u4f20\u64ad\u6c42\u635f\u5931 predictions = model . forward ( features ) loss = model . loss_func ( predictions , labels ) metric = model . metric_func ( predictions , labels ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 loss . backward () # \u68af\u5ea6\u4e0b\u964d\u6cd5\u66f4\u65b0\u53c2\u6570 for param in model . parameters (): #\u6ce8\u610f\u662f\u5bf9param.data\u8fdb\u884c\u91cd\u65b0\u8d4b\u503c,\u907f\u514d\u6b64\u5904\u64cd\u4f5c\u5f15\u8d77\u68af\u5ea6\u8bb0\u5f55 param . data = ( param . data - 0.01 * param . grad . data ) # \u68af\u5ea6\u6e05\u96f6 model . zero_grad () return loss . item (), metric . item () def train_model ( model , epochs ): for epoch in range ( 1 , epochs + 1 ): loss_list , metric_list = [],[] for features , labels in data_iter ( X , Y , 20 ): lossi , metrici = train_step ( model , features , labels ) loss_list . append ( lossi ) metric_list . append ( metrici ) loss = np . mean ( loss_list ) metric = np . mean ( metric_list ) if epoch % 100 == 0 : printbar () print ( \"epoch =\" , epoch , \"loss = \" , loss , \"metric = \" , metric ) train_model ( model , epochs = 1000 ) ================================================================================2020-07-05 08:32:16 epoch = 100 loss = 0.24841043589636683 metric = 0.8944999960064888 ================================================================================2020-07-05 08:32:34 epoch = 200 loss = 0.20398724960163236 metric = 0.920999992787838 ================================================================================2020-07-05 08:32:54 epoch = 300 loss = 0.19509393003769218 metric = 0.9239999914169311 ================================================================================2020-07-05 08:33:14 epoch = 400 loss = 0.19067603485658766 metric = 0.9272499939799309 ================================================================================2020-07-05 08:33:33 epoch = 500 loss = 0.1898010154720396 metric = 0.9237499925494194 ================================================================================2020-07-05 08:33:54 epoch = 600 loss = 0.19151576517149807 metric = 0.9254999926686287 ================================================================================2020-07-05 08:34:18 epoch = 700 loss = 0.18914461021777243 metric = 0.9274999949336052 ================================================================================2020-07-05 08:34:39 epoch = 800 loss = 0.18801998342387377 metric = 0.9264999932050705 ================================================================================2020-07-05 08:35:00 epoch = 900 loss = 0.1852504052128643 metric = 0.9249999937415123 ================================================================================2020-07-05 08:35:21 epoch = 1000 loss = 0.18695520935580134 metric = 0.9272499927878379 # \u7ed3\u679c\u53ef\u89c6\u5316 fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) ax1 . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = X [ torch . squeeze ( model . forward ( X ) >= 0.5 )] Xn_pred = X [ torch . squeeze ( model . forward ( X ) < 0.5 )] ax2 . scatter ( Xp_pred [:, 0 ], Xp_pred [:, 1 ], c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ], Xn_pred [:, 1 ], c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"3-1,\u4f4e\u9636API\u793a\u8303"},{"location":"3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-1%2C%E4%BD%8E%E9%98%B6API%E7%A4%BA%E8%8C%83/#3-1\u4f4e\u9636api\u793a\u8303","text":"\u4e0b\u9762\u7684\u8303\u4f8b\u4f7f\u7528Pytorch\u7684\u4f4e\u9636API\u5b9e\u73b0\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u548cDNN\u4e8c\u5206\u7c7b\u6a21\u578b\u3002 \u4f4e\u9636API\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u64cd\u4f5c\uff0c\u8ba1\u7b97\u56fe\u548c\u81ea\u52a8\u5fae\u5206\u3002 import os import datetime #\u6253\u5370\u65f6\u95f4 def printbar (): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) #mac\u7cfb\u7edf\u4e0apytorch\u548cmatplotlib\u5728jupyter\u4e2d\u540c\u65f6\u8dd1\u9700\u8981\u66f4\u6539\u73af\u5883\u53d8\u91cf os . environ [ \"KMP_DUPLICATE_LIB_OK\" ] = \"TRUE\"","title":"3-1,\u4f4e\u9636API\u793a\u8303"},{"location":"3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-1%2C%E4%BD%8E%E9%98%B6API%E7%A4%BA%E8%8C%83/#\u4e00\u7ebf\u6027\u56de\u5f52\u6a21\u578b","text":"1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import torch from torch import nn #\u6837\u672c\u6570\u91cf n = 400 # \u751f\u6210\u6d4b\u8bd5\u7528\u6570\u636e\u96c6 X = 10 * torch . rand ([ n , 2 ]) - 5.0 #torch.rand\u662f\u5747\u5300\u5206\u5e03 w0 = torch . tensor ([[ 2.0 ],[ - 3.0 ]]) b0 = torch . tensor ([[ 10.0 ]]) Y = X @w0 + b0 + torch . normal ( 0.0 , 2.0 , size = [ n , 1 ]) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 # \u6570\u636e\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ] . numpy (), Y [:, 0 ] . numpy (), c = \"b\" , label = \"samples\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ] . numpy (), Y [:, 0 ] . numpy (), c = \"g\" , label = \"samples\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () # \u6784\u5efa\u6570\u636e\u7ba1\u9053\u8fed\u4ee3\u5668 def data_iter ( features , labels , batch_size = 8 ): num_examples = len ( features ) indices = list ( range ( num_examples )) np . random . shuffle ( indices ) #\u6837\u672c\u7684\u8bfb\u53d6\u987a\u5e8f\u662f\u968f\u673a\u7684 for i in range ( 0 , num_examples , batch_size ): indexs = torch . LongTensor ( indices [ i : min ( i + batch_size , num_examples )]) yield features . index_select ( 0 , indexs ), labels . index_select ( 0 , indexs ) # \u6d4b\u8bd5\u6570\u636e\u7ba1\u9053\u6548\u679c batch_size = 8 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) print ( features ) print ( labels ) tensor([[-4.3880, 1.3655], [-0.1082, 3.9533], [-2.6286, 2.7058], [ 1.0604, -1.8646], [-1.5805, 1.5406], [-2.6217, -3.2342], [ 2.3748, -0.6449], [-1.2478, -2.0509]]) tensor([[-0.2069], [-3.2494], [-6.9620], [17.0528], [ 1.1076], [17.2117], [16.1081], [14.7092]]) 2\uff0c\u5b9a\u4e49\u6a21\u578b # \u5b9a\u4e49\u6a21\u578b class LinearRegression : def __init__ ( self ): self . w = torch . randn_like ( w0 , requires_grad = True ) self . b = torch . zeros_like ( b0 , requires_grad = True ) #\u6b63\u5411\u4f20\u64ad def forward ( self , x ): return x @self . w + self . b # \u635f\u5931\u51fd\u6570 def loss_func ( self , y_pred , y_true ): return torch . mean (( y_pred - y_true ) ** 2 / 2 ) model = LinearRegression () 3\uff0c\u8bad\u7ec3\u6a21\u578b def train_step ( model , features , labels ): predictions = model . forward ( features ) loss = model . loss_func ( predictions , labels ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 loss . backward () # \u4f7f\u7528torch.no_grad()\u907f\u514d\u68af\u5ea6\u8bb0\u5f55\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u64cd\u4f5c model.w.data \u5b9e\u73b0\u907f\u514d\u68af\u5ea6\u8bb0\u5f55 with torch . no_grad (): # \u68af\u5ea6\u4e0b\u964d\u6cd5\u66f4\u65b0\u53c2\u6570 model . w -= 0.001 * model . w . grad model . b -= 0.001 * model . b . grad # \u68af\u5ea6\u6e05\u96f6 model . w . grad . zero_ () model . b . grad . zero_ () return loss # \u6d4b\u8bd5train_step\u6548\u679c batch_size = 10 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) train_step ( model , features , labels ) tensor(92.8199, grad_fn=<MeanBackward0>) def train_model ( model , epochs ): for epoch in range ( 1 , epochs + 1 ): for features , labels in data_iter ( X , Y , 10 ): loss = train_step ( model , features , labels ) if epoch % 200 == 0 : printbar () print ( \"epoch =\" , epoch , \"loss = \" , loss . item ()) print ( \"model.w =\" , model . w . data ) print ( \"model.b =\" , model . b . data ) train_model ( model , epochs = 1000 ) ================================================================================2020-07-05 08:27:57 epoch = 200 loss = 2.6340413093566895 model.w = tensor([[ 2.0283], [-2.9632]]) model.b = tensor([[10.0748]]) ================================================================================2020-07-05 08:28:00 epoch = 400 loss = 2.24908709526062 model.w = tensor([[ 2.0300], [-2.9643]]) model.b = tensor([[10.0781]]) ================================================================================2020-07-05 08:28:04 epoch = 600 loss = 1.510349154472351 model.w = tensor([[ 2.0290], [-2.9630]]) model.b = tensor([[10.0781]]) ================================================================================2020-07-05 08:28:07 epoch = 800 loss = 1.038671851158142 model.w = tensor([[ 2.0314], [-2.9649]]) model.b = tensor([[10.0785]]) ================================================================================2020-07-05 08:28:10 epoch = 1000 loss = 1.9742190837860107 model.w = tensor([[ 2.0313], [-2.9648]]) model.b = tensor([[10.0781]]) # \u7ed3\u679c\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ] . numpy (), Y [:, 0 ] . numpy (), c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ] . numpy (),( model . w [ 0 ] . data * X [:, 0 ] + model . b [ 0 ] . data ) . numpy (), \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ] . numpy (), Y [:, 0 ] . numpy (), c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ] . numpy (),( model . w [ 1 ] . data * X [:, 1 ] + model . b [ 0 ] . data ) . numpy (), \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show ()","title":"\u4e00\uff0c\u7ebf\u6027\u56de\u5f52\u6a21\u578b"},{"location":"3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-1%2C%E4%BD%8E%E9%98%B6API%E7%A4%BA%E8%8C%83/#\u4e8cdnn\u4e8c\u5206\u7c7b\u6a21\u578b","text":"1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import torch from torch import nn % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u6b63\u8d1f\u6837\u672c\u6570\u91cf n_positive , n_negative = 2000 , 2000 #\u751f\u6210\u6b63\u6837\u672c, \u5c0f\u5706\u73af\u5206\u5e03 r_p = 5.0 + torch . normal ( 0.0 , 1.0 , size = [ n_positive , 1 ]) theta_p = 2 * np . pi * torch . rand ([ n_positive , 1 ]) Xp = torch . cat ([ r_p * torch . cos ( theta_p ), r_p * torch . sin ( theta_p )], axis = 1 ) Yp = torch . ones_like ( r_p ) #\u751f\u6210\u8d1f\u6837\u672c, \u5927\u5706\u73af\u5206\u5e03 r_n = 8.0 + torch . normal ( 0.0 , 1.0 , size = [ n_negative , 1 ]) theta_n = 2 * np . pi * torch . rand ([ n_negative , 1 ]) Xn = torch . cat ([ r_n * torch . cos ( theta_n ), r_n * torch . sin ( theta_n )], axis = 1 ) Yn = torch . zeros_like ( r_n ) #\u6c47\u603b\u6837\u672c X = torch . cat ([ Xp , Xn ], axis = 0 ) Y = torch . cat ([ Yp , Yn ], axis = 0 ) #\u53ef\u89c6\u5316 plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ] . numpy (), Xp [:, 1 ] . numpy (), c = \"r\" ) plt . scatter ( Xn [:, 0 ] . numpy (), Xn [:, 1 ] . numpy (), c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); # \u6784\u5efa\u6570\u636e\u7ba1\u9053\u8fed\u4ee3\u5668 def data_iter ( features , labels , batch_size = 8 ): num_examples = len ( features ) indices = list ( range ( num_examples )) np . random . shuffle ( indices ) #\u6837\u672c\u7684\u8bfb\u53d6\u987a\u5e8f\u662f\u968f\u673a\u7684 for i in range ( 0 , num_examples , batch_size ): indexs = torch . LongTensor ( indices [ i : min ( i + batch_size , num_examples )]) yield features . index_select ( 0 , indexs ), labels . index_select ( 0 , indexs ) # \u6d4b\u8bd5\u6570\u636e\u7ba1\u9053\u6548\u679c batch_size = 8 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) print ( features ) print ( labels ) tensor([[ 6.9914, -1.0820], [ 4.8156, 4.0532], [-1.0697, -7.4644], [ 2.6291, 3.8851], [-1.6780, -4.3390], [-6.1495, 1.2269], [-4.3422, 3.9552], [-6.2265, 2.6159]]) tensor([[0.], [1.], [0.], [1.], [1.], [1.], [1.], [1.]]) 2\uff0c\u5b9a\u4e49\u6a21\u578b \u6b64\u5904\u8303\u4f8b\u6211\u4eec\u5229\u7528nn.Module\u6765\u7ec4\u7ec7\u6a21\u578b\u53d8\u91cf\u3002 class DNNModel ( nn . Module ): def __init__ ( self ): super ( DNNModel , self ) . __init__ () self . w1 = nn . Parameter ( torch . randn ( 2 , 4 )) self . b1 = nn . Parameter ( torch . zeros ( 1 , 4 )) self . w2 = nn . Parameter ( torch . randn ( 4 , 8 )) self . b2 = nn . Parameter ( torch . zeros ( 1 , 8 )) self . w3 = nn . Parameter ( torch . randn ( 8 , 1 )) self . b3 = nn . Parameter ( torch . zeros ( 1 , 1 )) # \u6b63\u5411\u4f20\u64ad def forward ( self , x ): x = torch . relu ( x @self . w1 + self . b1 ) x = torch . relu ( x @self . w2 + self . b2 ) y = torch . sigmoid ( x @self . w3 + self . b3 ) return y # \u635f\u5931\u51fd\u6570(\u4e8c\u5143\u4ea4\u53c9\u71b5) def loss_func ( self , y_pred , y_true ): #\u5c06\u9884\u6d4b\u503c\u9650\u5236\u57281e-7\u4ee5\u4e0a, 1- (1e-7)\u4ee5\u4e0b\uff0c\u907f\u514dlog(0)\u9519\u8bef eps = 1e-7 y_pred = torch . clamp ( y_pred , eps , 1.0 - eps ) bce = - y_true * torch . log ( y_pred ) - ( 1 - y_true ) * torch . log ( 1 - y_pred ) return torch . mean ( bce ) # \u8bc4\u4f30\u6307\u6807(\u51c6\u786e\u7387) def metric_func ( self , y_pred , y_true ): y_pred = torch . where ( y_pred > 0.5 , torch . ones_like ( y_pred , dtype = torch . float32 ), torch . zeros_like ( y_pred , dtype = torch . float32 )) acc = torch . mean ( 1 - torch . abs ( y_true - y_pred )) return acc model = DNNModel () # \u6d4b\u8bd5\u6a21\u578b\u7ed3\u6784 batch_size = 10 ( features , labels ) = next ( data_iter ( X , Y , batch_size )) predictions = model ( features ) loss = model . loss_func ( labels , predictions ) metric = model . metric_func ( labels , predictions ) print ( \"init loss:\" , loss . item ()) print ( \"init metric:\" , metric . item ()) init loss: 7.979694366455078 init metric: 0.50347900390625 len ( list ( model . parameters ())) 6 3\uff0c\u8bad\u7ec3\u6a21\u578b def train_step ( model , features , labels ): # \u6b63\u5411\u4f20\u64ad\u6c42\u635f\u5931 predictions = model . forward ( features ) loss = model . loss_func ( predictions , labels ) metric = model . metric_func ( predictions , labels ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 loss . backward () # \u68af\u5ea6\u4e0b\u964d\u6cd5\u66f4\u65b0\u53c2\u6570 for param in model . parameters (): #\u6ce8\u610f\u662f\u5bf9param.data\u8fdb\u884c\u91cd\u65b0\u8d4b\u503c,\u907f\u514d\u6b64\u5904\u64cd\u4f5c\u5f15\u8d77\u68af\u5ea6\u8bb0\u5f55 param . data = ( param . data - 0.01 * param . grad . data ) # \u68af\u5ea6\u6e05\u96f6 model . zero_grad () return loss . item (), metric . item () def train_model ( model , epochs ): for epoch in range ( 1 , epochs + 1 ): loss_list , metric_list = [],[] for features , labels in data_iter ( X , Y , 20 ): lossi , metrici = train_step ( model , features , labels ) loss_list . append ( lossi ) metric_list . append ( metrici ) loss = np . mean ( loss_list ) metric = np . mean ( metric_list ) if epoch % 100 == 0 : printbar () print ( \"epoch =\" , epoch , \"loss = \" , loss , \"metric = \" , metric ) train_model ( model , epochs = 1000 ) ================================================================================2020-07-05 08:32:16 epoch = 100 loss = 0.24841043589636683 metric = 0.8944999960064888 ================================================================================2020-07-05 08:32:34 epoch = 200 loss = 0.20398724960163236 metric = 0.920999992787838 ================================================================================2020-07-05 08:32:54 epoch = 300 loss = 0.19509393003769218 metric = 0.9239999914169311 ================================================================================2020-07-05 08:33:14 epoch = 400 loss = 0.19067603485658766 metric = 0.9272499939799309 ================================================================================2020-07-05 08:33:33 epoch = 500 loss = 0.1898010154720396 metric = 0.9237499925494194 ================================================================================2020-07-05 08:33:54 epoch = 600 loss = 0.19151576517149807 metric = 0.9254999926686287 ================================================================================2020-07-05 08:34:18 epoch = 700 loss = 0.18914461021777243 metric = 0.9274999949336052 ================================================================================2020-07-05 08:34:39 epoch = 800 loss = 0.18801998342387377 metric = 0.9264999932050705 ================================================================================2020-07-05 08:35:00 epoch = 900 loss = 0.1852504052128643 metric = 0.9249999937415123 ================================================================================2020-07-05 08:35:21 epoch = 1000 loss = 0.18695520935580134 metric = 0.9272499927878379 # \u7ed3\u679c\u53ef\u89c6\u5316 fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) ax1 . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = X [ torch . squeeze ( model . forward ( X ) >= 0.5 )] Xn_pred = X [ torch . squeeze ( model . forward ( X ) < 0.5 )] ax2 . scatter ( Xp_pred [:, 0 ], Xp_pred [:, 1 ], c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ], Xn_pred [:, 1 ], c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\uff0cDNN\u4e8c\u5206\u7c7b\u6a21\u578b"},{"location":"3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-2%2C%E4%B8%AD%E9%98%B6API%E7%A4%BA%E8%8C%83/","text":"3-2,\u4e2d\u9636API\u793a\u8303 # \u4e0b\u9762\u7684\u8303\u4f8b\u4f7f\u7528Pytorch\u7684\u4e2d\u9636API\u5b9e\u73b0\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u548c\u548cDNN\u4e8c\u5206\u7c7b\u6a21\u578b\u3002 Pytorch\u7684\u4e2d\u9636API\u4e3b\u8981\u5305\u62ec\u5404\u79cd\u6a21\u578b\u5c42\uff0c\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u5668\uff0c\u6570\u636e\u7ba1\u9053\u7b49\u7b49\u3002 import os import datetime #\u6253\u5370\u65f6\u95f4 def printbar (): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) #mac\u7cfb\u7edf\u4e0apytorch\u548cmatplotlib\u5728jupyter\u4e2d\u540c\u65f6\u8dd1\u9700\u8981\u66f4\u6539\u73af\u5883\u53d8\u91cf os . environ [ \"KMP_DUPLICATE_LIB_OK\" ] = \"TRUE\" \u4e00\uff0c\u7ebf\u6027\u56de\u5f52\u6a21\u578b # 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import torch from torch import nn import torch.nn.functional as F from torch.utils.data import Dataset , DataLoader , TensorDataset #\u6837\u672c\u6570\u91cf n = 400 # \u751f\u6210\u6d4b\u8bd5\u7528\u6570\u636e\u96c6 X = 10 * torch . rand ([ n , 2 ]) - 5.0 #torch.rand\u662f\u5747\u5300\u5206\u5e03 w0 = torch . tensor ([[ 2.0 ],[ - 3.0 ]]) b0 = torch . tensor ([[ 10.0 ]]) Y = X @w0 + b0 + torch . normal ( 0.0 , 2.0 , size = [ n , 1 ]) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 # \u6570\u636e\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () #\u6784\u5efa\u8f93\u5165\u6570\u636e\u7ba1\u9053 ds = TensorDataset ( X , Y ) dl = DataLoader ( ds , batch_size = 10 , shuffle = True , num_workers = 2 ) 2\uff0c\u5b9a\u4e49\u6a21\u578b model = nn . Linear ( 2 , 1 ) #\u7ebf\u6027\u5c42 model . loss_func = nn . MSELoss () model . optimizer = torch . optim . SGD ( model . parameters (), lr = 0.01 ) 3\uff0c\u8bad\u7ec3\u6a21\u578b def train_step ( model , features , labels ): predictions = model ( features ) loss = model . loss_func ( predictions , labels ) loss . backward () model . optimizer . step () model . optimizer . zero_grad () return loss . item () # \u6d4b\u8bd5train_step\u6548\u679c features , labels = next ( iter ( dl )) train_step ( model , features , labels ) 269.98016357421875 def train_model ( model , epochs ): for epoch in range ( 1 , epochs + 1 ): for features , labels in dl : loss = train_step ( model , features , labels ) if epoch % 50 == 0 : printbar () w = model . state_dict ()[ \"weight\" ] b = model . state_dict ()[ \"bias\" ] print ( \"epoch =\" , epoch , \"loss = \" , loss ) print ( \"w =\" , w ) print ( \"b =\" , b ) train_model ( model , epochs = 200 ) ================================================================================2020-07-05 22:51:53 epoch = 50 loss = 3.0177409648895264 w = tensor([[ 1.9315, -2.9573]]) b = tensor([9.9625]) ================================================================================2020-07-05 22:51:57 epoch = 100 loss = 2.1144354343414307 w = tensor([[ 1.9760, -2.9398]]) b = tensor([9.9428]) ================================================================================2020-07-05 22:52:01 epoch = 150 loss = 3.290461778640747 w = tensor([[ 2.1075, -2.9509]]) b = tensor([9.9599]) ================================================================================2020-07-05 22:52:06 epoch = 200 loss = 3.047853469848633 w = tensor([[ 2.1134, -2.9306]]) b = tensor([9.9722]) # \u7ed3\u679c\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' w , b = model . state_dict ()[ \"weight\" ], model . state_dict ()[ \"bias\" ] plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ], w [ 0 , 0 ] * X [:, 0 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ], w [ 0 , 1 ] * X [:, 1 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () \u4e8c\uff0c DNN\u4e8c\u5206\u7c7b\u6a21\u578b # 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import torch from torch import nn import torch.nn.functional as F from torch.utils.data import Dataset , DataLoader , TensorDataset % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u6b63\u8d1f\u6837\u672c\u6570\u91cf n_positive , n_negative = 2000 , 2000 #\u751f\u6210\u6b63\u6837\u672c, \u5c0f\u5706\u73af\u5206\u5e03 r_p = 5.0 + torch . normal ( 0.0 , 1.0 , size = [ n_positive , 1 ]) theta_p = 2 * np . pi * torch . rand ([ n_positive , 1 ]) Xp = torch . cat ([ r_p * torch . cos ( theta_p ), r_p * torch . sin ( theta_p )], axis = 1 ) Yp = torch . ones_like ( r_p ) #\u751f\u6210\u8d1f\u6837\u672c, \u5927\u5706\u73af\u5206\u5e03 r_n = 8.0 + torch . normal ( 0.0 , 1.0 , size = [ n_negative , 1 ]) theta_n = 2 * np . pi * torch . rand ([ n_negative , 1 ]) Xn = torch . cat ([ r_n * torch . cos ( theta_n ), r_n * torch . sin ( theta_n )], axis = 1 ) Yn = torch . zeros_like ( r_n ) #\u6c47\u603b\u6837\u672c X = torch . cat ([ Xp , Xn ], axis = 0 ) Y = torch . cat ([ Yp , Yn ], axis = 0 ) #\u53ef\u89c6\u5316 plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) plt . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); #\u6784\u5efa\u8f93\u5165\u6570\u636e\u7ba1\u9053 ds = TensorDataset ( X , Y ) dl = DataLoader ( ds , batch_size = 10 , shuffle = True , num_workers = 2 ) 2, \u5b9a\u4e49\u6a21\u578b class DNNModel ( nn . Module ): def __init__ ( self ): super ( DNNModel , self ) . __init__ () self . fc1 = nn . Linear ( 2 , 4 ) self . fc2 = nn . Linear ( 4 , 8 ) self . fc3 = nn . Linear ( 8 , 1 ) # \u6b63\u5411\u4f20\u64ad def forward ( self , x ): x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) y = nn . Sigmoid ()( self . fc3 ( x )) return y # \u635f\u5931\u51fd\u6570 def loss_func ( self , y_pred , y_true ): return nn . BCELoss ()( y_pred , y_true ) # \u8bc4\u4f30\u51fd\u6570(\u51c6\u786e\u7387) def metric_func ( self , y_pred , y_true ): y_pred = torch . where ( y_pred > 0.5 , torch . ones_like ( y_pred , dtype = torch . float32 ), torch . zeros_like ( y_pred , dtype = torch . float32 )) acc = torch . mean ( 1 - torch . abs ( y_true - y_pred )) return acc # \u4f18\u5316\u5668 @property def optimizer ( self ): return torch . optim . Adam ( self . parameters (), lr = 0.001 ) model = DNNModel () # \u6d4b\u8bd5\u6a21\u578b\u7ed3\u6784 ( features , labels ) = next ( iter ( dl )) predictions = model ( features ) loss = model . loss_func ( predictions , labels ) metric = model . metric_func ( predictions , labels ) print ( \"init loss:\" , loss . item ()) print ( \"init metric:\" , metric . item ()) init loss: 0.7065666913986206 init metric: 0.6000000238418579 3\uff0c\u8bad\u7ec3\u6a21\u578b def train_step ( model , features , labels ): # \u6b63\u5411\u4f20\u64ad\u6c42\u635f\u5931 predictions = model ( features ) loss = model . loss_func ( predictions , labels ) metric = model . metric_func ( predictions , labels ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 loss . backward () # \u66f4\u65b0\u6a21\u578b\u53c2\u6570 model . optimizer . step () model . optimizer . zero_grad () return loss . item (), metric . item () # \u6d4b\u8bd5train_step\u6548\u679c features , labels = next ( iter ( dl )) train_step ( model , features , labels ) (0.6048880815505981, 0.699999988079071) def train_model ( model , epochs ): for epoch in range ( 1 , epochs + 1 ): loss_list , metric_list = [],[] for features , labels in dl : lossi , metrici = train_step ( model , features , labels ) loss_list . append ( lossi ) metric_list . append ( metrici ) loss = np . mean ( loss_list ) metric = np . mean ( metric_list ) if epoch % 100 == 0 : printbar () print ( \"epoch =\" , epoch , \"loss = \" , loss , \"metric = \" , metric ) train_model ( model , epochs = 300 ) ================================================================================2020-07-05 22:56:38 epoch = 100 loss = 0.23532892110607917 metric = 0.934749992787838 ================================================================================2020-07-05 22:58:18 epoch = 200 loss = 0.24743918558603128 metric = 0.934999993443489 ================================================================================2020-07-05 22:59:56 epoch = 300 loss = 0.2936080049697884 metric = 0.931499992609024 # \u7ed3\u679c\u53ef\u89c6\u5316 fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) ax1 . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = X [ torch . squeeze ( model . forward ( X ) >= 0.5 )] Xn_pred = X [ torch . squeeze ( model . forward ( X ) < 0.5 )] ax2 . scatter ( Xp_pred [:, 0 ], Xp_pred [:, 1 ], c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ], Xn_pred [:, 1 ], c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"3-2,\u4e2d\u9636API\u793a\u8303"},{"location":"3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-2%2C%E4%B8%AD%E9%98%B6API%E7%A4%BA%E8%8C%83/#3-2\u4e2d\u9636api\u793a\u8303","text":"\u4e0b\u9762\u7684\u8303\u4f8b\u4f7f\u7528Pytorch\u7684\u4e2d\u9636API\u5b9e\u73b0\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u548c\u548cDNN\u4e8c\u5206\u7c7b\u6a21\u578b\u3002 Pytorch\u7684\u4e2d\u9636API\u4e3b\u8981\u5305\u62ec\u5404\u79cd\u6a21\u578b\u5c42\uff0c\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u5668\uff0c\u6570\u636e\u7ba1\u9053\u7b49\u7b49\u3002 import os import datetime #\u6253\u5370\u65f6\u95f4 def printbar (): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) #mac\u7cfb\u7edf\u4e0apytorch\u548cmatplotlib\u5728jupyter\u4e2d\u540c\u65f6\u8dd1\u9700\u8981\u66f4\u6539\u73af\u5883\u53d8\u91cf os . environ [ \"KMP_DUPLICATE_LIB_OK\" ] = \"TRUE\"","title":"3-2,\u4e2d\u9636API\u793a\u8303"},{"location":"3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-2%2C%E4%B8%AD%E9%98%B6API%E7%A4%BA%E8%8C%83/#\u4e00\u7ebf\u6027\u56de\u5f52\u6a21\u578b","text":"1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import torch from torch import nn import torch.nn.functional as F from torch.utils.data import Dataset , DataLoader , TensorDataset #\u6837\u672c\u6570\u91cf n = 400 # \u751f\u6210\u6d4b\u8bd5\u7528\u6570\u636e\u96c6 X = 10 * torch . rand ([ n , 2 ]) - 5.0 #torch.rand\u662f\u5747\u5300\u5206\u5e03 w0 = torch . tensor ([[ 2.0 ],[ - 3.0 ]]) b0 = torch . tensor ([[ 10.0 ]]) Y = X @w0 + b0 + torch . normal ( 0.0 , 2.0 , size = [ n , 1 ]) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 # \u6570\u636e\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () #\u6784\u5efa\u8f93\u5165\u6570\u636e\u7ba1\u9053 ds = TensorDataset ( X , Y ) dl = DataLoader ( ds , batch_size = 10 , shuffle = True , num_workers = 2 ) 2\uff0c\u5b9a\u4e49\u6a21\u578b model = nn . Linear ( 2 , 1 ) #\u7ebf\u6027\u5c42 model . loss_func = nn . MSELoss () model . optimizer = torch . optim . SGD ( model . parameters (), lr = 0.01 ) 3\uff0c\u8bad\u7ec3\u6a21\u578b def train_step ( model , features , labels ): predictions = model ( features ) loss = model . loss_func ( predictions , labels ) loss . backward () model . optimizer . step () model . optimizer . zero_grad () return loss . item () # \u6d4b\u8bd5train_step\u6548\u679c features , labels = next ( iter ( dl )) train_step ( model , features , labels ) 269.98016357421875 def train_model ( model , epochs ): for epoch in range ( 1 , epochs + 1 ): for features , labels in dl : loss = train_step ( model , features , labels ) if epoch % 50 == 0 : printbar () w = model . state_dict ()[ \"weight\" ] b = model . state_dict ()[ \"bias\" ] print ( \"epoch =\" , epoch , \"loss = \" , loss ) print ( \"w =\" , w ) print ( \"b =\" , b ) train_model ( model , epochs = 200 ) ================================================================================2020-07-05 22:51:53 epoch = 50 loss = 3.0177409648895264 w = tensor([[ 1.9315, -2.9573]]) b = tensor([9.9625]) ================================================================================2020-07-05 22:51:57 epoch = 100 loss = 2.1144354343414307 w = tensor([[ 1.9760, -2.9398]]) b = tensor([9.9428]) ================================================================================2020-07-05 22:52:01 epoch = 150 loss = 3.290461778640747 w = tensor([[ 2.1075, -2.9509]]) b = tensor([9.9599]) ================================================================================2020-07-05 22:52:06 epoch = 200 loss = 3.047853469848633 w = tensor([[ 2.1134, -2.9306]]) b = tensor([9.9722]) # \u7ed3\u679c\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' w , b = model . state_dict ()[ \"weight\" ], model . state_dict ()[ \"bias\" ] plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ], w [ 0 , 0 ] * X [:, 0 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ], w [ 0 , 1 ] * X [:, 1 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show ()","title":"\u4e00\uff0c\u7ebf\u6027\u56de\u5f52\u6a21\u578b"},{"location":"3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-2%2C%E4%B8%AD%E9%98%B6API%E7%A4%BA%E8%8C%83/#\u4e8c-dnn\u4e8c\u5206\u7c7b\u6a21\u578b","text":"1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import torch from torch import nn import torch.nn.functional as F from torch.utils.data import Dataset , DataLoader , TensorDataset % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u6b63\u8d1f\u6837\u672c\u6570\u91cf n_positive , n_negative = 2000 , 2000 #\u751f\u6210\u6b63\u6837\u672c, \u5c0f\u5706\u73af\u5206\u5e03 r_p = 5.0 + torch . normal ( 0.0 , 1.0 , size = [ n_positive , 1 ]) theta_p = 2 * np . pi * torch . rand ([ n_positive , 1 ]) Xp = torch . cat ([ r_p * torch . cos ( theta_p ), r_p * torch . sin ( theta_p )], axis = 1 ) Yp = torch . ones_like ( r_p ) #\u751f\u6210\u8d1f\u6837\u672c, \u5927\u5706\u73af\u5206\u5e03 r_n = 8.0 + torch . normal ( 0.0 , 1.0 , size = [ n_negative , 1 ]) theta_n = 2 * np . pi * torch . rand ([ n_negative , 1 ]) Xn = torch . cat ([ r_n * torch . cos ( theta_n ), r_n * torch . sin ( theta_n )], axis = 1 ) Yn = torch . zeros_like ( r_n ) #\u6c47\u603b\u6837\u672c X = torch . cat ([ Xp , Xn ], axis = 0 ) Y = torch . cat ([ Yp , Yn ], axis = 0 ) #\u53ef\u89c6\u5316 plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) plt . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); #\u6784\u5efa\u8f93\u5165\u6570\u636e\u7ba1\u9053 ds = TensorDataset ( X , Y ) dl = DataLoader ( ds , batch_size = 10 , shuffle = True , num_workers = 2 ) 2, \u5b9a\u4e49\u6a21\u578b class DNNModel ( nn . Module ): def __init__ ( self ): super ( DNNModel , self ) . __init__ () self . fc1 = nn . Linear ( 2 , 4 ) self . fc2 = nn . Linear ( 4 , 8 ) self . fc3 = nn . Linear ( 8 , 1 ) # \u6b63\u5411\u4f20\u64ad def forward ( self , x ): x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) y = nn . Sigmoid ()( self . fc3 ( x )) return y # \u635f\u5931\u51fd\u6570 def loss_func ( self , y_pred , y_true ): return nn . BCELoss ()( y_pred , y_true ) # \u8bc4\u4f30\u51fd\u6570(\u51c6\u786e\u7387) def metric_func ( self , y_pred , y_true ): y_pred = torch . where ( y_pred > 0.5 , torch . ones_like ( y_pred , dtype = torch . float32 ), torch . zeros_like ( y_pred , dtype = torch . float32 )) acc = torch . mean ( 1 - torch . abs ( y_true - y_pred )) return acc # \u4f18\u5316\u5668 @property def optimizer ( self ): return torch . optim . Adam ( self . parameters (), lr = 0.001 ) model = DNNModel () # \u6d4b\u8bd5\u6a21\u578b\u7ed3\u6784 ( features , labels ) = next ( iter ( dl )) predictions = model ( features ) loss = model . loss_func ( predictions , labels ) metric = model . metric_func ( predictions , labels ) print ( \"init loss:\" , loss . item ()) print ( \"init metric:\" , metric . item ()) init loss: 0.7065666913986206 init metric: 0.6000000238418579 3\uff0c\u8bad\u7ec3\u6a21\u578b def train_step ( model , features , labels ): # \u6b63\u5411\u4f20\u64ad\u6c42\u635f\u5931 predictions = model ( features ) loss = model . loss_func ( predictions , labels ) metric = model . metric_func ( predictions , labels ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 loss . backward () # \u66f4\u65b0\u6a21\u578b\u53c2\u6570 model . optimizer . step () model . optimizer . zero_grad () return loss . item (), metric . item () # \u6d4b\u8bd5train_step\u6548\u679c features , labels = next ( iter ( dl )) train_step ( model , features , labels ) (0.6048880815505981, 0.699999988079071) def train_model ( model , epochs ): for epoch in range ( 1 , epochs + 1 ): loss_list , metric_list = [],[] for features , labels in dl : lossi , metrici = train_step ( model , features , labels ) loss_list . append ( lossi ) metric_list . append ( metrici ) loss = np . mean ( loss_list ) metric = np . mean ( metric_list ) if epoch % 100 == 0 : printbar () print ( \"epoch =\" , epoch , \"loss = \" , loss , \"metric = \" , metric ) train_model ( model , epochs = 300 ) ================================================================================2020-07-05 22:56:38 epoch = 100 loss = 0.23532892110607917 metric = 0.934749992787838 ================================================================================2020-07-05 22:58:18 epoch = 200 loss = 0.24743918558603128 metric = 0.934999993443489 ================================================================================2020-07-05 22:59:56 epoch = 300 loss = 0.2936080049697884 metric = 0.931499992609024 # \u7ed3\u679c\u53ef\u89c6\u5316 fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) ax1 . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = X [ torch . squeeze ( model . forward ( X ) >= 0.5 )] Xn_pred = X [ torch . squeeze ( model . forward ( X ) < 0.5 )] ax2 . scatter ( Xp_pred [:, 0 ], Xp_pred [:, 1 ], c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ], Xn_pred [:, 1 ], c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\uff0c DNN\u4e8c\u5206\u7c7b\u6a21\u578b"},{"location":"3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-3%2C%E9%AB%98%E9%98%B6API%E7%A4%BA%E8%8C%83/","text":"3-3,\u9ad8\u9636API\u793a\u8303 # Pytorch\u6ca1\u6709\u5b98\u65b9\u7684\u9ad8\u9636API\uff0c\u4e00\u822c\u9700\u8981\u7528\u6237\u81ea\u5df1\u5b9e\u73b0\u8bad\u7ec3\u5faa\u73af\u3001\u9a8c\u8bc1\u5faa\u73af\u3001\u548c\u9884\u6d4b\u5faa\u73af\u3002 \u4f5c\u8005\u901a\u8fc7\u4eff\u7167tf.keras.Model\u7684\u529f\u80fd\u5bf9Pytorch\u7684nn.Module\u8fdb\u884c\u4e86\u5c01\u88c5\uff0c \u5b9e\u73b0\u4e86 fit, validate\uff0cpredict, summary \u65b9\u6cd5\uff0c\u76f8\u5f53\u4e8e\u7528\u6237\u81ea\u5b9a\u4e49\u9ad8\u9636API\u3002 \u5e76\u5728\u5176\u57fa\u7840\u4e0a\u5b9e\u73b0\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u548cDNN\u4e8c\u5206\u7c7b\u6a21\u578b\u3002 import os import datetime from torchkeras import Model , summary #\u6253\u5370\u65f6\u95f4 def printbar (): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) #mac\u7cfb\u7edf\u4e0apytorch\u548cmatplotlib\u5728jupyter\u4e2d\u540c\u65f6\u8dd1\u9700\u8981\u66f4\u6539\u73af\u5883\u53d8\u91cf os . environ [ \"KMP_DUPLICATE_LIB_OK\" ] = \"TRUE\" \u4e00\uff0c\u7ebf\u6027\u56de\u5f52\u6a21\u578b # \u6b64\u8303\u4f8b\u6211\u4eec\u901a\u8fc7\u7ee7\u627f\u4e0a\u8ff0\u7528\u6237\u81ea\u5b9a\u4e49 Model\u6a21\u578b\u63a5\u53e3\uff0c\u5b9e\u73b0\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u3002 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import torch from torch import nn import torch.nn.functional as F from torch.utils.data import Dataset , DataLoader , TensorDataset #\u6837\u672c\u6570\u91cf n = 400 # \u751f\u6210\u6d4b\u8bd5\u7528\u6570\u636e\u96c6 X = 10 * torch . rand ([ n , 2 ]) - 5.0 #torch.rand\u662f\u5747\u5300\u5206\u5e03 w0 = torch . tensor ([[ 2.0 ],[ - 3.0 ]]) b0 = torch . tensor ([[ 10.0 ]]) Y = X @w0 + b0 + torch . normal ( 0.0 , 2.0 , size = [ n , 1 ]) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 # \u6570\u636e\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () #\u6784\u5efa\u8f93\u5165\u6570\u636e\u7ba1\u9053 ds = TensorDataset ( X , Y ) ds_train , ds_valid = torch . utils . data . random_split ( ds ,[ int ( 400 * 0.7 ), 400 - int ( 400 * 0.7 )]) dl_train = DataLoader ( ds_train , batch_size = 10 , shuffle = True , num_workers = 2 ) dl_valid = DataLoader ( ds_valid , batch_size = 10 , num_workers = 2 ) 2\uff0c\u5b9a\u4e49\u6a21\u578b # \u7ee7\u627f\u7528\u6237\u81ea\u5b9a\u4e49\u6a21\u578b from torchkeras import Model class LinearRegression ( Model ): def __init__ ( self ): super ( LinearRegression , self ) . __init__ () self . fc = nn . Linear ( 2 , 1 ) def forward ( self , x ): return self . fc ( x ) model = LinearRegression () model . summary ( input_shape = ( 2 ,)) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Linear-1 [-1, 1] 3 ================================================================ Total params: 3 Trainable params: 3 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.000008 Forward/backward pass size (MB): 0.000008 Params size (MB): 0.000011 Estimated Total Size (MB): 0.000027 ---------------------------------------------------------------- 3\uff0c\u8bad\u7ec3\u6a21\u578b ### \u4f7f\u7528fit\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3 def mean_absolute_error ( y_pred , y_true ): return torch . mean ( torch . abs ( y_pred - y_true )) def mean_absolute_percent_error ( y_pred , y_true ): absolute_percent_error = ( torch . abs ( y_pred - y_true ) + 1e-7 ) / ( torch . abs ( y_true ) + 1e-7 ) return torch . mean ( absolute_percent_error ) model . compile ( loss_func = nn . MSELoss (), optimizer = torch . optim . Adam ( model . parameters (), lr = 0.01 ), metrics_dict = { \"mae\" : mean_absolute_error , \"mape\" : mean_absolute_percent_error }) dfhistory = model . fit ( 200 , dl_train = dl_train , dl_val = dl_valid , log_step_freq = 20 ) Start Training ... ================================================================================2020-07-05 23:07:25 {'step': 20, 'loss': 226.768, 'mae': 12.198, 'mape': 1.212} +-------+---------+-------+-------+----------+---------+----------+ | epoch | loss | mae | mape | val_loss | val_mae | val_mape | +-------+---------+-------+-------+----------+---------+----------+ | 1 | 230.773 | 12.41 | 1.394 | 223.262 | 12.582 | 1.095 | +-------+---------+-------+-------+----------+---------+----------+ ================================================================================2020-07-05 23:07:26 {'step': 20, 'loss': 200.964, 'mae': 11.584, 'mape': 1.382} +-------+---------+--------+------+----------+---------+----------+ | epoch | loss | mae | mape | val_loss | val_mae | val_mape | +-------+---------+--------+------+----------+---------+----------+ | 2 | 206.238 | 11.759 | 1.26 | 199.669 | 11.895 | 1.012 | +-------+---------+--------+------+----------+---------+----------+ ================================================================================2020-07-05 23:07:26 {'step': 20, 'loss': 188.247, 'mae': 11.387, 'mape': 1.172} +-------+---------+--------+-------+----------+---------+----------+ | epoch | loss | mae | mape | val_loss | val_mae | val_mape | +-------+---------+--------+-------+----------+---------+----------+ | 3 | 185.185 | 11.177 | 1.189 | 178.112 | 11.24 | 0.952 | +-------+---------+--------+-------+----------+---------+----------+ ================================================================================2020-07-05 23:07:59 {'step': 20, 'loss': 4.14, 'mae': 1.677, 'mape': 1.845} +-------+-------+-------+-------+----------+---------+----------+ | epoch | loss | mae | mape | val_loss | val_mae | val_mape | +-------+-------+-------+-------+----------+---------+----------+ | 199 | 4.335 | 1.707 | 1.441 | 3.741 | 1.533 | 0.359 | +-------+-------+-------+-------+----------+---------+----------+ ================================================================================2020-07-05 23:07:59 {'step': 20, 'loss': 4.653, 'mae': 1.775, 'mape': 0.679} +-------+------+-------+-------+----------+---------+----------+ | epoch | loss | mae | mape | val_loss | val_mae | val_mape | +-------+------+-------+-------+----------+---------+----------+ | 200 | 4.37 | 1.718 | 1.394 | 3.749 | 1.534 | 0.363 | +-------+------+-------+-------+----------+---------+----------+ ================================================================================2020-07-05 23:07:59 Finished Training... # \u7ed3\u679c\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' w , b = model . state_dict ()[ \"fc.weight\" ], model . state_dict ()[ \"fc.bias\" ] plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ], w [ 0 , 0 ] * X [:, 0 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ], w [ 0 , 1 ] * X [:, 1 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () 4\uff0c\u8bc4\u4f30\u6a21\u578b dfhistory . tail () % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( dfhistory , metric ): train_metrics = dfhistory [ metric ] val_metrics = dfhistory [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( dfhistory , \"loss\" ) plot_metric ( dfhistory , \"mape\" ) # \u8bc4\u4f30 model . evaluate ( dl_valid ) {'val_loss': 3.749117374420166, 'val_mae': 1.5336137612660725, 'val_mape': 0.36319838215907413} 5\uff0c\u4f7f\u7528\u6a21\u578b # \u9884\u6d4b dl = DataLoader ( TensorDataset ( X )) model . predict ( dl )[ 0 : 10 ] tensor([[ 3.9212], [ 8.6336], [ 6.1982], [ 6.1212], [-5.0974], [-6.3183], [ 4.6588], [ 5.5349], [11.9106], [24.6937]]) # \u9884\u6d4b model . predict ( dl_valid )[ 0 : 10 ] tensor([[ 2.8368], [16.2797], [ 2.3135], [ 9.5395], [16.4363], [10.0742], [15.0864], [12.9775], [21.8568], [21.8226]]) \u4e8c\uff0cDNN\u4e8c\u5206\u7c7b\u6a21\u578b # \u6b64\u8303\u4f8b\u6211\u4eec\u901a\u8fc7\u7ee7\u627f\u4e0a\u8ff0\u7528\u6237\u81ea\u5b9a\u4e49 Model\u6a21\u578b\u63a5\u53e3\uff0c\u5b9e\u73b0DNN\u4e8c\u5206\u7c7b\u6a21\u578b\u3002 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import torch from torch import nn import torch.nn.functional as F from torch.utils.data import Dataset , DataLoader , TensorDataset import torchkeras % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u6b63\u8d1f\u6837\u672c\u6570\u91cf n_positive , n_negative = 2000 , 2000 #\u751f\u6210\u6b63\u6837\u672c, \u5c0f\u5706\u73af\u5206\u5e03 r_p = 5.0 + torch . normal ( 0.0 , 1.0 , size = [ n_positive , 1 ]) theta_p = 2 * np . pi * torch . rand ([ n_positive , 1 ]) Xp = torch . cat ([ r_p * torch . cos ( theta_p ), r_p * torch . sin ( theta_p )], axis = 1 ) Yp = torch . ones_like ( r_p ) #\u751f\u6210\u8d1f\u6837\u672c, \u5927\u5706\u73af\u5206\u5e03 r_n = 8.0 + torch . normal ( 0.0 , 1.0 , size = [ n_negative , 1 ]) theta_n = 2 * np . pi * torch . rand ([ n_negative , 1 ]) Xn = torch . cat ([ r_n * torch . cos ( theta_n ), r_n * torch . sin ( theta_n )], axis = 1 ) Yn = torch . zeros_like ( r_n ) #\u6c47\u603b\u6837\u672c X = torch . cat ([ Xp , Xn ], axis = 0 ) Y = torch . cat ([ Yp , Yn ], axis = 0 ) #\u53ef\u89c6\u5316 plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) plt . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); ds = TensorDataset ( X , Y ) ds_train , ds_valid = torch . utils . data . random_split ( ds ,[ int ( len ( ds ) * 0.7 ), len ( ds ) - int ( len ( ds ) * 0.7 )]) dl_train = DataLoader ( ds_train , batch_size = 100 , shuffle = True , num_workers = 2 ) dl_valid = DataLoader ( ds_valid , batch_size = 100 , num_workers = 2 ) 2\uff0c\u5b9a\u4e49\u6a21\u578b class Net ( nn . Module ): def __init__ ( self ): super () . __init__ () self . fc1 = nn . Linear ( 2 , 4 ) self . fc2 = nn . Linear ( 4 , 8 ) self . fc3 = nn . Linear ( 8 , 1 ) def forward ( self , x ): x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) y = nn . Sigmoid ()( self . fc3 ( x )) return y model = torchkeras . Model ( Net ()) model . summary ( input_shape = ( 2 ,)) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Linear-1 [-1, 4] 12 Linear-2 [-1, 8] 40 Linear-3 [-1, 1] 9 ================================================================ Total params: 61 Trainable params: 61 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.000008 Forward/backward pass size (MB): 0.000099 Params size (MB): 0.000233 Estimated Total Size (MB): 0.000340 ---------------------------------------------------------------- 3\uff0c\u8bad\u7ec3\u6a21\u578b # \u51c6\u786e\u7387 def accuracy ( y_pred , y_true ): y_pred = torch . where ( y_pred > 0.5 , torch . ones_like ( y_pred , dtype = torch . float32 ), torch . zeros_like ( y_pred , dtype = torch . float32 )) acc = torch . mean ( 1 - torch . abs ( y_true - y_pred )) return acc model . compile ( loss_func = nn . BCELoss (), optimizer = torch . optim . Adam ( model . parameters (), lr = 0.01 ), metrics_dict = { \"accuracy\" : accuracy }) dfhistory = model . fit ( 100 , dl_train = dl_train , dl_val = dl_valid , log_step_freq = 10 ) Start Training ... ================================================================================2020-07-05 23:12:51 {'step': 10, 'loss': 0.733, 'accuracy': 0.487} {'step': 20, 'loss': 0.713, 'accuracy': 0.515} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 1 | 0.704 | 0.539 | 0.676 | 0.666 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-05 23:12:51 {'step': 10, 'loss': 0.67, 'accuracy': 0.703} {'step': 20, 'loss': 0.66, 'accuracy': 0.697} +-------+------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+------+----------+----------+--------------+ | 2 | 0.65 | 0.702 | 0.625 | 0.651 | +-------+------+----------+----------+--------------+ ================================================================================2020-07-05 23:13:10 {'step': 10, 'loss': 0.17, 'accuracy': 0.929} {'step': 20, 'loss': 0.173, 'accuracy': 0.929} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 98 | 0.175 | 0.929 | 0.169 | 0.933 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-05 23:13:10 {'step': 10, 'loss': 0.165, 'accuracy': 0.942} {'step': 20, 'loss': 0.171, 'accuracy': 0.932} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 99 | 0.173 | 0.931 | 0.166 | 0.935 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-05 23:13:10 {'step': 10, 'loss': 0.156, 'accuracy': 0.945} {'step': 20, 'loss': 0.17, 'accuracy': 0.935} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 100 | 0.168 | 0.937 | 0.173 | 0.926 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-05 23:13:11 Finished Training... # \u7ed3\u679c\u53ef\u89c6\u5316 fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) ax1 . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = X [ torch . squeeze ( model . forward ( X ) >= 0.5 )] Xn_pred = X [ torch . squeeze ( model . forward ( X ) < 0.5 )] ax2 . scatter ( Xp_pred [:, 0 ], Xp_pred [:, 1 ], c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ], Xn_pred [:, 1 ], c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); 4\uff0c\u8bc4\u4f30\u6a21\u578b % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( dfhistory , metric ): train_metrics = dfhistory [ metric ] val_metrics = dfhistory [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( dfhistory , \"loss\" ) plot_metric ( dfhistory , \"accuracy\" ) model . evaluate ( dl_valid ) {'val_loss': 0.17309962399303913, 'val_accuracy': 0.9258333394924799} 5\uff0c\u4f7f\u7528\u6a21\u578b model . predict ( dl_valid )[ 0 : 10 ] tensor([[0.9998], [0.0459], [0.0349], [0.0147], [0.9990], [0.9995], [0.8535], [0.0373], [0.2134], [0.9356]]) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"3-3,\u9ad8\u9636API\u793a\u8303"},{"location":"3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-3%2C%E9%AB%98%E9%98%B6API%E7%A4%BA%E8%8C%83/#3-3\u9ad8\u9636api\u793a\u8303","text":"Pytorch\u6ca1\u6709\u5b98\u65b9\u7684\u9ad8\u9636API\uff0c\u4e00\u822c\u9700\u8981\u7528\u6237\u81ea\u5df1\u5b9e\u73b0\u8bad\u7ec3\u5faa\u73af\u3001\u9a8c\u8bc1\u5faa\u73af\u3001\u548c\u9884\u6d4b\u5faa\u73af\u3002 \u4f5c\u8005\u901a\u8fc7\u4eff\u7167tf.keras.Model\u7684\u529f\u80fd\u5bf9Pytorch\u7684nn.Module\u8fdb\u884c\u4e86\u5c01\u88c5\uff0c \u5b9e\u73b0\u4e86 fit, validate\uff0cpredict, summary \u65b9\u6cd5\uff0c\u76f8\u5f53\u4e8e\u7528\u6237\u81ea\u5b9a\u4e49\u9ad8\u9636API\u3002 \u5e76\u5728\u5176\u57fa\u7840\u4e0a\u5b9e\u73b0\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u548cDNN\u4e8c\u5206\u7c7b\u6a21\u578b\u3002 import os import datetime from torchkeras import Model , summary #\u6253\u5370\u65f6\u95f4 def printbar (): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) #mac\u7cfb\u7edf\u4e0apytorch\u548cmatplotlib\u5728jupyter\u4e2d\u540c\u65f6\u8dd1\u9700\u8981\u66f4\u6539\u73af\u5883\u53d8\u91cf os . environ [ \"KMP_DUPLICATE_LIB_OK\" ] = \"TRUE\"","title":"3-3,\u9ad8\u9636API\u793a\u8303"},{"location":"3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-3%2C%E9%AB%98%E9%98%B6API%E7%A4%BA%E8%8C%83/#\u4e00\u7ebf\u6027\u56de\u5f52\u6a21\u578b","text":"\u6b64\u8303\u4f8b\u6211\u4eec\u901a\u8fc7\u7ee7\u627f\u4e0a\u8ff0\u7528\u6237\u81ea\u5b9a\u4e49 Model\u6a21\u578b\u63a5\u53e3\uff0c\u5b9e\u73b0\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u3002 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import torch from torch import nn import torch.nn.functional as F from torch.utils.data import Dataset , DataLoader , TensorDataset #\u6837\u672c\u6570\u91cf n = 400 # \u751f\u6210\u6d4b\u8bd5\u7528\u6570\u636e\u96c6 X = 10 * torch . rand ([ n , 2 ]) - 5.0 #torch.rand\u662f\u5747\u5300\u5206\u5e03 w0 = torch . tensor ([[ 2.0 ],[ - 3.0 ]]) b0 = torch . tensor ([[ 10.0 ]]) Y = X @w0 + b0 + torch . normal ( 0.0 , 2.0 , size = [ n , 1 ]) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 # \u6570\u636e\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () #\u6784\u5efa\u8f93\u5165\u6570\u636e\u7ba1\u9053 ds = TensorDataset ( X , Y ) ds_train , ds_valid = torch . utils . data . random_split ( ds ,[ int ( 400 * 0.7 ), 400 - int ( 400 * 0.7 )]) dl_train = DataLoader ( ds_train , batch_size = 10 , shuffle = True , num_workers = 2 ) dl_valid = DataLoader ( ds_valid , batch_size = 10 , num_workers = 2 ) 2\uff0c\u5b9a\u4e49\u6a21\u578b # \u7ee7\u627f\u7528\u6237\u81ea\u5b9a\u4e49\u6a21\u578b from torchkeras import Model class LinearRegression ( Model ): def __init__ ( self ): super ( LinearRegression , self ) . __init__ () self . fc = nn . Linear ( 2 , 1 ) def forward ( self , x ): return self . fc ( x ) model = LinearRegression () model . summary ( input_shape = ( 2 ,)) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Linear-1 [-1, 1] 3 ================================================================ Total params: 3 Trainable params: 3 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.000008 Forward/backward pass size (MB): 0.000008 Params size (MB): 0.000011 Estimated Total Size (MB): 0.000027 ---------------------------------------------------------------- 3\uff0c\u8bad\u7ec3\u6a21\u578b ### \u4f7f\u7528fit\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3 def mean_absolute_error ( y_pred , y_true ): return torch . mean ( torch . abs ( y_pred - y_true )) def mean_absolute_percent_error ( y_pred , y_true ): absolute_percent_error = ( torch . abs ( y_pred - y_true ) + 1e-7 ) / ( torch . abs ( y_true ) + 1e-7 ) return torch . mean ( absolute_percent_error ) model . compile ( loss_func = nn . MSELoss (), optimizer = torch . optim . Adam ( model . parameters (), lr = 0.01 ), metrics_dict = { \"mae\" : mean_absolute_error , \"mape\" : mean_absolute_percent_error }) dfhistory = model . fit ( 200 , dl_train = dl_train , dl_val = dl_valid , log_step_freq = 20 ) Start Training ... ================================================================================2020-07-05 23:07:25 {'step': 20, 'loss': 226.768, 'mae': 12.198, 'mape': 1.212} +-------+---------+-------+-------+----------+---------+----------+ | epoch | loss | mae | mape | val_loss | val_mae | val_mape | +-------+---------+-------+-------+----------+---------+----------+ | 1 | 230.773 | 12.41 | 1.394 | 223.262 | 12.582 | 1.095 | +-------+---------+-------+-------+----------+---------+----------+ ================================================================================2020-07-05 23:07:26 {'step': 20, 'loss': 200.964, 'mae': 11.584, 'mape': 1.382} +-------+---------+--------+------+----------+---------+----------+ | epoch | loss | mae | mape | val_loss | val_mae | val_mape | +-------+---------+--------+------+----------+---------+----------+ | 2 | 206.238 | 11.759 | 1.26 | 199.669 | 11.895 | 1.012 | +-------+---------+--------+------+----------+---------+----------+ ================================================================================2020-07-05 23:07:26 {'step': 20, 'loss': 188.247, 'mae': 11.387, 'mape': 1.172} +-------+---------+--------+-------+----------+---------+----------+ | epoch | loss | mae | mape | val_loss | val_mae | val_mape | +-------+---------+--------+-------+----------+---------+----------+ | 3 | 185.185 | 11.177 | 1.189 | 178.112 | 11.24 | 0.952 | +-------+---------+--------+-------+----------+---------+----------+ ================================================================================2020-07-05 23:07:59 {'step': 20, 'loss': 4.14, 'mae': 1.677, 'mape': 1.845} +-------+-------+-------+-------+----------+---------+----------+ | epoch | loss | mae | mape | val_loss | val_mae | val_mape | +-------+-------+-------+-------+----------+---------+----------+ | 199 | 4.335 | 1.707 | 1.441 | 3.741 | 1.533 | 0.359 | +-------+-------+-------+-------+----------+---------+----------+ ================================================================================2020-07-05 23:07:59 {'step': 20, 'loss': 4.653, 'mae': 1.775, 'mape': 0.679} +-------+------+-------+-------+----------+---------+----------+ | epoch | loss | mae | mape | val_loss | val_mae | val_mape | +-------+------+-------+-------+----------+---------+----------+ | 200 | 4.37 | 1.718 | 1.394 | 3.749 | 1.534 | 0.363 | +-------+------+-------+-------+----------+---------+----------+ ================================================================================2020-07-05 23:07:59 Finished Training... # \u7ed3\u679c\u53ef\u89c6\u5316 % matplotlib inline % config InlineBackend . figure_format = 'svg' w , b = model . state_dict ()[ \"fc.weight\" ], model . state_dict ()[ \"fc.bias\" ] plt . figure ( figsize = ( 12 , 5 )) ax1 = plt . subplot ( 121 ) ax1 . scatter ( X [:, 0 ], Y [:, 0 ], c = \"b\" , label = \"samples\" ) ax1 . plot ( X [:, 0 ], w [ 0 , 0 ] * X [:, 0 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax1 . legend () plt . xlabel ( \"x1\" ) plt . ylabel ( \"y\" , rotation = 0 ) ax2 = plt . subplot ( 122 ) ax2 . scatter ( X [:, 1 ], Y [:, 0 ], c = \"g\" , label = \"samples\" ) ax2 . plot ( X [:, 1 ], w [ 0 , 1 ] * X [:, 1 ] + b [ 0 ], \"-r\" , linewidth = 5.0 , label = \"model\" ) ax2 . legend () plt . xlabel ( \"x2\" ) plt . ylabel ( \"y\" , rotation = 0 ) plt . show () 4\uff0c\u8bc4\u4f30\u6a21\u578b dfhistory . tail () % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( dfhistory , metric ): train_metrics = dfhistory [ metric ] val_metrics = dfhistory [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( dfhistory , \"loss\" ) plot_metric ( dfhistory , \"mape\" ) # \u8bc4\u4f30 model . evaluate ( dl_valid ) {'val_loss': 3.749117374420166, 'val_mae': 1.5336137612660725, 'val_mape': 0.36319838215907413} 5\uff0c\u4f7f\u7528\u6a21\u578b # \u9884\u6d4b dl = DataLoader ( TensorDataset ( X )) model . predict ( dl )[ 0 : 10 ] tensor([[ 3.9212], [ 8.6336], [ 6.1982], [ 6.1212], [-5.0974], [-6.3183], [ 4.6588], [ 5.5349], [11.9106], [24.6937]]) # \u9884\u6d4b model . predict ( dl_valid )[ 0 : 10 ] tensor([[ 2.8368], [16.2797], [ 2.3135], [ 9.5395], [16.4363], [10.0742], [15.0864], [12.9775], [21.8568], [21.8226]])","title":"\u4e00\uff0c\u7ebf\u6027\u56de\u5f52\u6a21\u578b"},{"location":"3.%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/3-3%2C%E9%AB%98%E9%98%B6API%E7%A4%BA%E8%8C%83/#\u4e8cdnn\u4e8c\u5206\u7c7b\u6a21\u578b","text":"\u6b64\u8303\u4f8b\u6211\u4eec\u901a\u8fc7\u7ee7\u627f\u4e0a\u8ff0\u7528\u6237\u81ea\u5b9a\u4e49 Model\u6a21\u578b\u63a5\u53e3\uff0c\u5b9e\u73b0DNN\u4e8c\u5206\u7c7b\u6a21\u578b\u3002 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import torch from torch import nn import torch.nn.functional as F from torch.utils.data import Dataset , DataLoader , TensorDataset import torchkeras % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u6b63\u8d1f\u6837\u672c\u6570\u91cf n_positive , n_negative = 2000 , 2000 #\u751f\u6210\u6b63\u6837\u672c, \u5c0f\u5706\u73af\u5206\u5e03 r_p = 5.0 + torch . normal ( 0.0 , 1.0 , size = [ n_positive , 1 ]) theta_p = 2 * np . pi * torch . rand ([ n_positive , 1 ]) Xp = torch . cat ([ r_p * torch . cos ( theta_p ), r_p * torch . sin ( theta_p )], axis = 1 ) Yp = torch . ones_like ( r_p ) #\u751f\u6210\u8d1f\u6837\u672c, \u5927\u5706\u73af\u5206\u5e03 r_n = 8.0 + torch . normal ( 0.0 , 1.0 , size = [ n_negative , 1 ]) theta_n = 2 * np . pi * torch . rand ([ n_negative , 1 ]) Xn = torch . cat ([ r_n * torch . cos ( theta_n ), r_n * torch . sin ( theta_n )], axis = 1 ) Yn = torch . zeros_like ( r_n ) #\u6c47\u603b\u6837\u672c X = torch . cat ([ Xp , Xn ], axis = 0 ) Y = torch . cat ([ Yp , Yn ], axis = 0 ) #\u53ef\u89c6\u5316 plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) plt . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); ds = TensorDataset ( X , Y ) ds_train , ds_valid = torch . utils . data . random_split ( ds ,[ int ( len ( ds ) * 0.7 ), len ( ds ) - int ( len ( ds ) * 0.7 )]) dl_train = DataLoader ( ds_train , batch_size = 100 , shuffle = True , num_workers = 2 ) dl_valid = DataLoader ( ds_valid , batch_size = 100 , num_workers = 2 ) 2\uff0c\u5b9a\u4e49\u6a21\u578b class Net ( nn . Module ): def __init__ ( self ): super () . __init__ () self . fc1 = nn . Linear ( 2 , 4 ) self . fc2 = nn . Linear ( 4 , 8 ) self . fc3 = nn . Linear ( 8 , 1 ) def forward ( self , x ): x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) y = nn . Sigmoid ()( self . fc3 ( x )) return y model = torchkeras . Model ( Net ()) model . summary ( input_shape = ( 2 ,)) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Linear-1 [-1, 4] 12 Linear-2 [-1, 8] 40 Linear-3 [-1, 1] 9 ================================================================ Total params: 61 Trainable params: 61 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.000008 Forward/backward pass size (MB): 0.000099 Params size (MB): 0.000233 Estimated Total Size (MB): 0.000340 ---------------------------------------------------------------- 3\uff0c\u8bad\u7ec3\u6a21\u578b # \u51c6\u786e\u7387 def accuracy ( y_pred , y_true ): y_pred = torch . where ( y_pred > 0.5 , torch . ones_like ( y_pred , dtype = torch . float32 ), torch . zeros_like ( y_pred , dtype = torch . float32 )) acc = torch . mean ( 1 - torch . abs ( y_true - y_pred )) return acc model . compile ( loss_func = nn . BCELoss (), optimizer = torch . optim . Adam ( model . parameters (), lr = 0.01 ), metrics_dict = { \"accuracy\" : accuracy }) dfhistory = model . fit ( 100 , dl_train = dl_train , dl_val = dl_valid , log_step_freq = 10 ) Start Training ... ================================================================================2020-07-05 23:12:51 {'step': 10, 'loss': 0.733, 'accuracy': 0.487} {'step': 20, 'loss': 0.713, 'accuracy': 0.515} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 1 | 0.704 | 0.539 | 0.676 | 0.666 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-05 23:12:51 {'step': 10, 'loss': 0.67, 'accuracy': 0.703} {'step': 20, 'loss': 0.66, 'accuracy': 0.697} +-------+------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+------+----------+----------+--------------+ | 2 | 0.65 | 0.702 | 0.625 | 0.651 | +-------+------+----------+----------+--------------+ ================================================================================2020-07-05 23:13:10 {'step': 10, 'loss': 0.17, 'accuracy': 0.929} {'step': 20, 'loss': 0.173, 'accuracy': 0.929} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 98 | 0.175 | 0.929 | 0.169 | 0.933 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-05 23:13:10 {'step': 10, 'loss': 0.165, 'accuracy': 0.942} {'step': 20, 'loss': 0.171, 'accuracy': 0.932} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 99 | 0.173 | 0.931 | 0.166 | 0.935 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-05 23:13:10 {'step': 10, 'loss': 0.156, 'accuracy': 0.945} {'step': 20, 'loss': 0.17, 'accuracy': 0.935} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 100 | 0.168 | 0.937 | 0.173 | 0.926 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-05 23:13:11 Finished Training... # \u7ed3\u679c\u53ef\u89c6\u5316 fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) ax1 . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = X [ torch . squeeze ( model . forward ( X ) >= 0.5 )] Xn_pred = X [ torch . squeeze ( model . forward ( X ) < 0.5 )] ax2 . scatter ( Xp_pred [:, 0 ], Xp_pred [:, 1 ], c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ], Xn_pred [:, 1 ], c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); 4\uff0c\u8bc4\u4f30\u6a21\u578b % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( dfhistory , metric ): train_metrics = dfhistory [ metric ] val_metrics = dfhistory [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( dfhistory , \"loss\" ) plot_metric ( dfhistory , \"accuracy\" ) model . evaluate ( dl_valid ) {'val_loss': 0.17309962399303913, 'val_accuracy': 0.9258333394924799} 5\uff0c\u4f7f\u7528\u6a21\u578b model . predict ( dl_valid )[ 0 : 10 ] tensor([[0.9998], [0.0459], [0.0349], [0.0147], [0.9990], [0.9995], [0.8535], [0.0373], [0.2134], [0.9356]]) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\uff0cDNN\u4e8c\u5206\u7c7b\u6a21\u578b"},{"location":"4.%E4%BD%8E%E9%98%B6API/","text":"\u56db\u3001Pytorch\u7684\u4f4e\u9636API # Pytorch\u7684\u4f4e\u9636API\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u64cd\u4f5c\uff0c\u52a8\u6001\u8ba1\u7b97\u56fe\u548c\u81ea\u52a8\u5fae\u5206\u3002 \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u4f4e\u9636API\u5c31\u662f\u3010\u6a21\u578b\u4e4b\u7816\u3011\u3002 \u5728\u4f4e\u9636API\u5c42\u6b21\u4e0a\uff0c\u53ef\u4ee5\u628aPytorch\u5f53\u505a\u4e00\u4e2a\u589e\u5f3a\u7248\u7684numpy\u6765\u4f7f\u7528\u3002 Pytorch\u63d0\u4f9b\u7684\u65b9\u6cd5\u6bd4numpy\u66f4\u5168\u9762\uff0c\u8fd0\u7b97\u901f\u5ea6\u66f4\u5feb\uff0c\u5982\u679c\u9700\u8981\u7684\u8bdd\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528GPU\u8fdb\u884c\u52a0\u901f\u3002 \u524d\u9762\u51e0\u7ae0\u6211\u4eec\u5bf9\u4f4e\u9636API\u5df2\u7ecf\u6709\u4e86\u4e00\u4e2a\u6574\u4f53\u7684\u8ba4\u8bc6\uff0c\u672c\u7ae0\u6211\u4eec\u5c06\u91cd\u70b9\u8be6\u7ec6\u4ecb\u7ecd\u5f20\u91cf\u64cd\u4f5c\u548c\u52a8\u6001\u8ba1\u7b97\u56fe\u3002 \u5f20\u91cf\u7684\u64cd\u4f5c\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u548c\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u3002 \u5f20\u91cf\u7ed3\u6784\u64cd\u4f5c\u8bf8\u5982\uff1a\u5f20\u91cf\u521b\u5efa\uff0c\u7d22\u5f15\u5207\u7247\uff0c\u7ef4\u5ea6\u53d8\u6362\uff0c\u5408\u5e76\u5206\u5272\u3002 \u5f20\u91cf\u6570\u5b66\u8fd0\u7b97\u4e3b\u8981\u6709\uff1a\u6807\u91cf\u8fd0\u7b97\uff0c\u5411\u91cf\u8fd0\u7b97\uff0c\u77e9\u9635\u8fd0\u7b97\u3002\u53e6\u5916\u6211\u4eec\u4f1a\u4ecb\u7ecd\u5f20\u91cf\u8fd0\u7b97\u7684\u5e7f\u64ad\u673a\u5236\u3002 \u52a8\u6001\u8ba1\u7b97\u56fe\u6211\u4eec\u5c06\u4e3b\u8981\u4ecb\u7ecd\u52a8\u6001\u8ba1\u7b97\u56fe\u7684\u7279\u6027\uff0c\u8ba1\u7b97\u56fe\u4e2d\u7684Function\uff0c\u8ba1\u7b97\u56fe\u4e0e\u53cd\u5411\u4f20\u64ad\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u56db\u3001Pytorch\u7684\u4f4e\u9636API"},{"location":"4.%E4%BD%8E%E9%98%B6API/#\u56dbpytorch\u7684\u4f4e\u9636api","text":"Pytorch\u7684\u4f4e\u9636API\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u64cd\u4f5c\uff0c\u52a8\u6001\u8ba1\u7b97\u56fe\u548c\u81ea\u52a8\u5fae\u5206\u3002 \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u4f4e\u9636API\u5c31\u662f\u3010\u6a21\u578b\u4e4b\u7816\u3011\u3002 \u5728\u4f4e\u9636API\u5c42\u6b21\u4e0a\uff0c\u53ef\u4ee5\u628aPytorch\u5f53\u505a\u4e00\u4e2a\u589e\u5f3a\u7248\u7684numpy\u6765\u4f7f\u7528\u3002 Pytorch\u63d0\u4f9b\u7684\u65b9\u6cd5\u6bd4numpy\u66f4\u5168\u9762\uff0c\u8fd0\u7b97\u901f\u5ea6\u66f4\u5feb\uff0c\u5982\u679c\u9700\u8981\u7684\u8bdd\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528GPU\u8fdb\u884c\u52a0\u901f\u3002 \u524d\u9762\u51e0\u7ae0\u6211\u4eec\u5bf9\u4f4e\u9636API\u5df2\u7ecf\u6709\u4e86\u4e00\u4e2a\u6574\u4f53\u7684\u8ba4\u8bc6\uff0c\u672c\u7ae0\u6211\u4eec\u5c06\u91cd\u70b9\u8be6\u7ec6\u4ecb\u7ecd\u5f20\u91cf\u64cd\u4f5c\u548c\u52a8\u6001\u8ba1\u7b97\u56fe\u3002 \u5f20\u91cf\u7684\u64cd\u4f5c\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u548c\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u3002 \u5f20\u91cf\u7ed3\u6784\u64cd\u4f5c\u8bf8\u5982\uff1a\u5f20\u91cf\u521b\u5efa\uff0c\u7d22\u5f15\u5207\u7247\uff0c\u7ef4\u5ea6\u53d8\u6362\uff0c\u5408\u5e76\u5206\u5272\u3002 \u5f20\u91cf\u6570\u5b66\u8fd0\u7b97\u4e3b\u8981\u6709\uff1a\u6807\u91cf\u8fd0\u7b97\uff0c\u5411\u91cf\u8fd0\u7b97\uff0c\u77e9\u9635\u8fd0\u7b97\u3002\u53e6\u5916\u6211\u4eec\u4f1a\u4ecb\u7ecd\u5f20\u91cf\u8fd0\u7b97\u7684\u5e7f\u64ad\u673a\u5236\u3002 \u52a8\u6001\u8ba1\u7b97\u56fe\u6211\u4eec\u5c06\u4e3b\u8981\u4ecb\u7ecd\u52a8\u6001\u8ba1\u7b97\u56fe\u7684\u7279\u6027\uff0c\u8ba1\u7b97\u56fe\u4e2d\u7684Function\uff0c\u8ba1\u7b97\u56fe\u4e0e\u53cd\u5411\u4f20\u64ad\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u56db\u3001Pytorch\u7684\u4f4e\u9636API"},{"location":"4.%E4%BD%8E%E9%98%B6API/4-1%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%93%E6%9E%84%E6%93%8D%E4%BD%9C/","text":"4-1,\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c # \u5f20\u91cf\u7684\u64cd\u4f5c\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u548c\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u3002 \u5f20\u91cf\u7ed3\u6784\u64cd\u4f5c\u8bf8\u5982\uff1a\u5f20\u91cf\u521b\u5efa\uff0c\u7d22\u5f15\u5207\u7247\uff0c\u7ef4\u5ea6\u53d8\u6362\uff0c\u5408\u5e76\u5206\u5272\u3002 \u5f20\u91cf\u6570\u5b66\u8fd0\u7b97\u4e3b\u8981\u6709\uff1a\u6807\u91cf\u8fd0\u7b97\uff0c\u5411\u91cf\u8fd0\u7b97\uff0c\u77e9\u9635\u8fd0\u7b97\u3002\u53e6\u5916\u6211\u4eec\u4f1a\u4ecb\u7ecd\u5f20\u91cf\u8fd0\u7b97\u7684\u5e7f\u64ad\u673a\u5236\u3002 \u672c\u7bc7\u6211\u4eec\u4ecb\u7ecd\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u3002 \u4e00\uff0c\u521b\u5efa\u5f20\u91cf # \u5f20\u91cf\u521b\u5efa\u7684\u8bb8\u591a\u65b9\u6cd5\u548cnumpy\u4e2d\u521b\u5efaarray\u7684\u65b9\u6cd5\u5f88\u50cf\u3002 import numpy as np import torch a = torch . tensor ([ 1 , 2 , 3 ], dtype = torch . float ) print ( a ) tensor([1., 2., 3.]) b = torch . arange ( 1 , 10 , step = 2 ) print ( b ) tensor([1, 3, 5, 7, 9]) c = torch . linspace ( 0.0 , 2 * 3.14 , 10 ) print ( c ) tensor([0.0000, 0.6978, 1.3956, 2.0933, 2.7911, 3.4889, 4.1867, 4.8844, 5.5822, 6.2800]) d = torch . zeros (( 3 , 3 )) print ( d ) tensor([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]) a = torch . ones (( 3 , 3 ), dtype = torch . int ) b = torch . zeros_like ( a , dtype = torch . float ) print ( a ) print ( b ) tensor([[1, 1, 1], [1, 1, 1], [1, 1, 1]], dtype=torch.int32) tensor([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]) torch . fill_ ( b , 5 ) print ( b ) tensor([[5., 5., 5.], [5., 5., 5.], [5., 5., 5.]]) #\u5747\u5300\u968f\u673a\u5206\u5e03 torch . manual_seed ( 0 ) minval , maxval = 0 , 10 a = minval + ( maxval - minval ) * torch . rand ([ 5 ]) print ( a ) tensor([4.9626, 7.6822, 0.8848, 1.3203, 3.0742]) #\u6b63\u6001\u5206\u5e03\u968f\u673a b = torch . normal ( mean = torch . zeros ( 3 , 3 ), std = torch . ones ( 3 , 3 )) print ( b ) tensor([[-1.3836, 0.2459, -0.1312], [-0.1785, -0.5959, 0.2739], [ 0.5679, -0.6731, -1.2095]]) #\u6b63\u6001\u5206\u5e03\u968f\u673a mean , std = 2 , 5 c = std * torch . randn (( 3 , 3 )) + mean print ( c ) tensor([[ 8.7204, 13.9161, -0.8323], [ -3.7681, -10.5115, 6.3778], [-11.3628, 1.8433, 4.4939]]) #\u6574\u6570\u968f\u673a\u6392\u5217 d = torch . randperm ( 20 ) print ( d ) tensor([ 5, 15, 19, 10, 7, 17, 0, 4, 12, 16, 14, 13, 1, 3, 9, 6, 18, 2, 8, 11]) #\u7279\u6b8a\u77e9\u9635 I = torch . eye ( 3 , 3 ) #\u5355\u4f4d\u77e9\u9635 print ( I ) t = torch . diag ( torch . tensor ([ 1 , 2 , 3 ])) #\u5bf9\u89d2\u77e9\u9635 print ( t ) tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) tensor([[1, 0, 0], [0, 2, 0], [0, 0, 3]]) \u4e8c \uff0c\u7d22\u5f15\u5207\u7247 # \u5f20\u91cf\u7684\u7d22\u5f15\u5207\u7247\u65b9\u5f0f\u548cnumpy\u51e0\u4e4e\u662f\u4e00\u6837\u7684\u3002\u5207\u7247\u65f6\u652f\u6301\u7f3a\u7701\u53c2\u6570\u548c\u7701\u7565\u53f7\u3002 \u53ef\u4ee5\u901a\u8fc7\u7d22\u5f15\u548c\u5207\u7247\u5bf9\u90e8\u5206\u5143\u7d20\u8fdb\u884c\u4fee\u6539\u3002 \u6b64\u5916\uff0c\u5bf9\u4e8e\u4e0d\u89c4\u5219\u7684\u5207\u7247\u63d0\u53d6,\u53ef\u4ee5\u4f7f\u7528torch.index_select, torch.masked_select, torch.take \u5982\u679c\u8981\u901a\u8fc7\u4fee\u6539\u5f20\u91cf\u7684\u67d0\u4e9b\u5143\u7d20\u5f97\u5230\u65b0\u7684\u5f20\u91cf\uff0c\u53ef\u4ee5\u4f7f\u7528torch.where,torch.masked_fill,torch.index_fill #\u5747\u5300\u968f\u673a\u5206\u5e03 torch . manual_seed ( 0 ) minval , maxval = 0 , 10 t = torch . floor ( minval + ( maxval - minval ) * torch . rand ([ 5 , 5 ])) . int () print ( t ) tensor([[4, 7, 0, 1, 3], [6, 4, 8, 4, 6], [3, 4, 0, 1, 2], [5, 6, 8, 1, 2], [6, 9, 3, 8, 4]], dtype=torch.int32) #\u7b2c0\u884c print ( t [ 0 ]) tensor([4, 7, 0, 1, 3], dtype=torch.int32) #\u5012\u6570\u7b2c\u4e00\u884c print ( t [ - 1 ]) tensor([6, 9, 3, 8, 4], dtype=torch.int32) #\u7b2c1\u884c\u7b2c3\u5217 print ( t [ 1 , 3 ]) print ( t [ 1 ][ 3 ]) tensor(4, dtype=torch.int32) tensor(4, dtype=torch.int32) #\u7b2c1\u884c\u81f3\u7b2c3\u884c print ( t [ 1 : 4 ,:]) tensor([[6, 4, 8, 4, 6], [3, 4, 0, 1, 2], [5, 6, 8, 1, 2]], dtype=torch.int32) #\u7b2c1\u884c\u81f3\u6700\u540e\u4e00\u884c\uff0c\u7b2c0\u5217\u5230\u6700\u540e\u4e00\u5217\u6bcf\u9694\u4e24\u5217\u53d6\u4e00\u5217 print ( t [ 1 : 4 ,: 4 : 2 ]) tensor([[6, 8], [3, 0], [5, 8]], dtype=torch.int32) #\u53ef\u4ee5\u4f7f\u7528\u7d22\u5f15\u548c\u5207\u7247\u4fee\u6539\u90e8\u5206\u5143\u7d20 x = torch . tensor ([[ 1 , 2 ],[ 3 , 4 ]], dtype = torch . float32 , requires_grad = True ) x . data [ 1 ,:] = torch . tensor ([ 0.0 , 0.0 ]) x tensor([[1., 2.], [0., 0.]], requires_grad=True) a = torch . arange ( 27 ) . view ( 3 , 3 , 3 ) print ( a ) tensor([[[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8]], [[ 9, 10, 11], [12, 13, 14], [15, 16, 17]], [[18, 19, 20], [21, 22, 23], [24, 25, 26]]]) #\u7701\u7565\u53f7\u53ef\u4ee5\u8868\u793a\u591a\u4e2a\u5192\u53f7 print ( a [ ... , 1 ]) tensor([[ 1, 4, 7], [10, 13, 16], [19, 22, 25]]) \u4ee5\u4e0a\u5207\u7247\u65b9\u5f0f\u76f8\u5bf9\u89c4\u5219\uff0c\u5bf9\u4e8e\u4e0d\u89c4\u5219\u7684\u5207\u7247\u63d0\u53d6,\u53ef\u4ee5\u4f7f\u7528torch.index_select, torch.take, torch.gather, torch.masked_select. \u8003\u8651\u73ed\u7ea7\u6210\u7ee9\u518c\u7684\u4f8b\u5b50\uff0c\u67094\u4e2a\u73ed\u7ea7\uff0c\u6bcf\u4e2a\u73ed\u7ea710\u4e2a\u5b66\u751f\uff0c\u6bcf\u4e2a\u5b66\u751f7\u95e8\u79d1\u76ee\u6210\u7ee9\u3002\u53ef\u4ee5\u7528\u4e00\u4e2a4\u00d710\u00d77\u7684\u5f20\u91cf\u6765\u8868\u793a\u3002 minval = 0 maxval = 100 scores = torch . floor ( minval + ( maxval - minval ) * torch . rand ([ 4 , 10 , 7 ])) . int () print ( scores ) tensor([[[55, 95, 3, 18, 37, 30, 93], [17, 26, 15, 3, 20, 92, 72], [74, 52, 24, 58, 3, 13, 24], [81, 79, 27, 48, 81, 99, 69], [56, 83, 20, 59, 11, 15, 24], [72, 70, 20, 65, 77, 43, 51], [61, 81, 98, 11, 31, 69, 91], [93, 94, 59, 6, 54, 18, 3], [94, 88, 0, 59, 41, 41, 27], [69, 20, 68, 75, 85, 68, 0]], [[17, 74, 60, 10, 21, 97, 83], [28, 37, 2, 49, 12, 11, 47], [57, 29, 79, 19, 95, 84, 7], [37, 52, 57, 61, 69, 52, 25], [73, 2, 20, 37, 25, 32, 9], [39, 60, 17, 47, 85, 44, 51], [45, 60, 81, 97, 81, 97, 46], [ 5, 26, 84, 49, 25, 11, 3], [ 7, 39, 77, 77, 1, 81, 10], [39, 29, 40, 40, 5, 6, 42]], [[50, 27, 68, 4, 46, 93, 29], [95, 68, 4, 81, 44, 27, 89], [ 9, 55, 39, 85, 63, 74, 67], [37, 39, 8, 77, 89, 84, 14], [52, 14, 22, 20, 67, 20, 48], [52, 82, 12, 15, 20, 84, 32], [92, 68, 56, 49, 40, 56, 38], [49, 56, 10, 23, 90, 9, 46], [99, 68, 51, 6, 74, 14, 35], [33, 42, 50, 91, 56, 94, 80]], [[18, 72, 14, 28, 64, 66, 87], [33, 50, 75, 1, 86, 8, 50], [41, 23, 56, 91, 35, 20, 31], [ 0, 72, 25, 16, 21, 78, 76], [88, 68, 33, 36, 64, 91, 63], [26, 26, 2, 60, 21, 5, 93], [17, 44, 64, 51, 16, 9, 89], [58, 91, 33, 64, 38, 47, 19], [66, 65, 48, 38, 19, 84, 12], [70, 33, 25, 58, 24, 61, 59]]], dtype=torch.int32) #\u62bd\u53d6\u6bcf\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\uff0c\u7b2c5\u4e2a\u5b66\u751f\uff0c\u7b2c9\u4e2a\u5b66\u751f\u7684\u5168\u90e8\u6210\u7ee9 torch . index_select ( scores , dim = 1 , index = torch . tensor ([ 0 , 5 , 9 ])) tensor([[[55, 95, 3, 18, 37, 30, 93], [72, 70, 20, 65, 77, 43, 51], [69, 20, 68, 75, 85, 68, 0]], [[17, 74, 60, 10, 21, 97, 83], [39, 60, 17, 47, 85, 44, 51], [39, 29, 40, 40, 5, 6, 42]], [[50, 27, 68, 4, 46, 93, 29], [52, 82, 12, 15, 20, 84, 32], [33, 42, 50, 91, 56, 94, 80]], [[18, 72, 14, 28, 64, 66, 87], [26, 26, 2, 60, 21, 5, 93], [70, 33, 25, 58, 24, 61, 59]]], dtype=torch.int32) #\u62bd\u53d6\u6bcf\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\uff0c\u7b2c5\u4e2a\u5b66\u751f\uff0c\u7b2c9\u4e2a\u5b66\u751f\u7684\u7b2c1\u95e8\u8bfe\u7a0b\uff0c\u7b2c3\u95e8\u8bfe\u7a0b\uff0c\u7b2c6\u95e8\u8bfe\u7a0b\u6210\u7ee9 q = torch . index_select ( torch . index_select ( scores , dim = 1 , index = torch . tensor ([ 0 , 5 , 9 ])) , dim = 2 , index = torch . tensor ([ 1 , 3 , 6 ])) print ( q ) tensor([[[95, 18, 93], [70, 65, 51], [20, 75, 0]], [[74, 10, 83], [60, 47, 51], [29, 40, 42]], [[27, 4, 29], [82, 15, 32], [42, 91, 80]], [[72, 28, 87], [26, 60, 93], [33, 58, 59]]], dtype=torch.int32) #\u62bd\u53d6\u7b2c0\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\u7684\u7b2c0\u95e8\u8bfe\u7a0b\uff0c\u7b2c2\u4e2a\u73ed\u7ea7\u7684\u7b2c4\u4e2a\u5b66\u751f\u7684\u7b2c1\u95e8\u8bfe\u7a0b\uff0c\u7b2c3\u4e2a\u73ed\u7ea7\u7684\u7b2c9\u4e2a\u5b66\u751f\u7b2c6\u95e8\u8bfe\u7a0b\u6210\u7ee9 #take\u5c06\u8f93\u5165\u770b\u6210\u4e00\u7ef4\u6570\u7ec4\uff0c\u8f93\u51fa\u548cindex\u540c\u5f62\u72b6 s = torch . take ( scores , torch . tensor ([ 0 * 10 * 7 + 0 , 2 * 10 * 7 + 4 * 7 + 1 , 3 * 10 * 7 + 9 * 7 + 6 ])) s <tf.Tensor: shape=(3, 7), dtype=int32, numpy= array([[52, 82, 66, 55, 17, 86, 14], [99, 94, 46, 70, 1, 63, 41], [46, 83, 70, 80, 90, 85, 17]], dtype=int32)> #\u62bd\u53d6\u5206\u6570\u5927\u4e8e\u7b49\u4e8e80\u5206\u7684\u5206\u6570\uff08\u5e03\u5c14\u7d22\u5f15\uff09 #\u7ed3\u679c\u662f1\u7ef4\u5f20\u91cf g = torch . masked_select ( scores , scores >= 80 ) print ( g ) \u4ee5\u4e0a\u8fd9\u4e9b\u65b9\u6cd5\u4ec5\u80fd\u63d0\u53d6\u5f20\u91cf\u7684\u90e8\u5206\u5143\u7d20\u503c\uff0c\u4f46\u4e0d\u80fd\u66f4\u6539\u5f20\u91cf\u7684\u90e8\u5206\u5143\u7d20\u503c\u5f97\u5230\u65b0\u7684\u5f20\u91cf\u3002 \u5982\u679c\u8981\u901a\u8fc7\u4fee\u6539\u5f20\u91cf\u7684\u90e8\u5206\u5143\u7d20\u503c\u5f97\u5230\u65b0\u7684\u5f20\u91cf\uff0c\u53ef\u4ee5\u4f7f\u7528torch.where,torch.index_fill \u548c torch.masked_fill torch.where\u53ef\u4ee5\u7406\u89e3\u4e3aif\u7684\u5f20\u91cf\u7248\u672c\u3002 torch.index_fill\u7684\u9009\u53d6\u5143\u7d20\u903b\u8f91\u548ctorch.index_select\u76f8\u540c\u3002 torch.masked_fill\u7684\u9009\u53d6\u5143\u7d20\u903b\u8f91\u548ctorch.masked_select\u76f8\u540c\u3002 #\u5982\u679c\u5206\u6570\u5927\u4e8e60\u5206\uff0c\u8d4b\u503c\u62101\uff0c\u5426\u5219\u8d4b\u503c\u62100 ifpass = torch . where ( scores > 60 , torch . tensor ( 1 ), torch . tensor ( 0 )) print ( ifpass ) #\u5c06\u6bcf\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\uff0c\u7b2c5\u4e2a\u5b66\u751f\uff0c\u7b2c9\u4e2a\u5b66\u751f\u7684\u5168\u90e8\u6210\u7ee9\u8d4b\u503c\u6210\u6ee1\u5206 torch . index_fill ( scores , dim = 1 , index = torch . tensor ([ 0 , 5 , 9 ]), value = 100 ) #\u7b49\u4ef7\u4e8e scores.index_fill(dim = 1,index = torch.tensor([0,5,9]),value = 100) #\u5c06\u5206\u6570\u5c0f\u4e8e60\u5206\u7684\u5206\u6570\u8d4b\u503c\u621060\u5206 b = torch . masked_fill ( scores , scores < 60 , 60 ) #\u7b49\u4ef7\u4e8eb = scores.masked_fill(scores<60,60) b \u4e09\uff0c\u7ef4\u5ea6\u53d8\u6362 # \u7ef4\u5ea6\u53d8\u6362\u76f8\u5173\u51fd\u6570\u4e3b\u8981\u6709 torch.reshape(\u6216\u8005\u8c03\u7528\u5f20\u91cf\u7684view\u65b9\u6cd5), torch.squeeze, torch.unsqueeze, torch.transpose torch.reshape \u53ef\u4ee5\u6539\u53d8\u5f20\u91cf\u7684\u5f62\u72b6\u3002 torch.squeeze \u53ef\u4ee5\u51cf\u5c11\u7ef4\u5ea6\u3002 torch.unsqueeze \u53ef\u4ee5\u589e\u52a0\u7ef4\u5ea6\u3002 torch.transpose \u53ef\u4ee5\u4ea4\u6362\u7ef4\u5ea6\u3002 # \u5f20\u91cf\u7684view\u65b9\u6cd5\u6709\u65f6\u5019\u4f1a\u8c03\u7528\u5931\u8d25\uff0c\u53ef\u4ee5\u4f7f\u7528reshape\u65b9\u6cd5\u3002 torch . manual_seed ( 0 ) minval , maxval = 0 , 255 a = ( minval + ( maxval - minval ) * torch . rand ([ 1 , 3 , 3 , 2 ])) . int () print ( a . shape ) print ( a ) torch.Size([1, 3, 3, 2]) tensor([[[[126, 195], [ 22, 33], [ 78, 161]], [[124, 228], [116, 161], [ 88, 102]], [[ 5, 43], [ 74, 132], [177, 204]]]], dtype=torch.int32) # \u6539\u6210 \uff083,6\uff09\u5f62\u72b6\u7684\u5f20\u91cf b = a . view ([ 3 , 6 ]) #torch.reshape(a,[3,6]) print ( b . shape ) print ( b ) torch.Size([3, 6]) tensor([[126, 195, 22, 33, 78, 161], [124, 228, 116, 161, 88, 102], [ 5, 43, 74, 132, 177, 204]], dtype=torch.int32) # \u6539\u56de\u6210 [1,3,3,2] \u5f62\u72b6\u7684\u5f20\u91cf c = torch . reshape ( b ,[ 1 , 3 , 3 , 2 ]) # b.view([1,3,3,2]) print ( c ) tensor([[[[126, 195], [ 22, 33], [ 78, 161]], [[124, 228], [116, 161], [ 88, 102]], [[ 5, 43], [ 74, 132], [177, 204]]]], dtype=torch.int32) \u5982\u679c\u5f20\u91cf\u5728\u67d0\u4e2a\u7ef4\u5ea6\u4e0a\u53ea\u6709\u4e00\u4e2a\u5143\u7d20\uff0c\u5229\u7528torch.squeeze\u53ef\u4ee5\u6d88\u9664\u8fd9\u4e2a\u7ef4\u5ea6\u3002 torch.unsqueeze\u7684\u4f5c\u7528\u548ctorch.squeeze\u7684\u4f5c\u7528\u76f8\u53cd\u3002 a = torch . tensor ([[ 1.0 , 2.0 ]]) s = torch . squeeze ( a ) print ( a ) print ( s ) print ( a . shape ) print ( s . shape ) tensor([[1., 2.]]) tensor([1., 2.]) torch.Size([1, 2]) torch.Size([2]) #\u5728\u7b2c0\u7ef4\u63d2\u5165\u957f\u5ea6\u4e3a1\u7684\u4e00\u4e2a\u7ef4\u5ea6 d = torch . unsqueeze ( s , axis = 0 ) print ( s ) print ( d ) print ( s . shape ) print ( d . shape ) tensor([1., 2.]) tensor([[1., 2.]]) torch.Size([2]) torch.Size([1, 2]) torch.transpose\u53ef\u4ee5\u4ea4\u6362\u5f20\u91cf\u7684\u7ef4\u5ea6\uff0ctorch.transpose\u5e38\u7528\u4e8e\u56fe\u7247\u5b58\u50a8\u683c\u5f0f\u7684\u53d8\u6362\u4e0a\u3002 \u5982\u679c\u662f\u4e8c\u7ef4\u7684\u77e9\u9635\uff0c\u901a\u5e38\u4f1a\u8c03\u7528\u77e9\u9635\u7684\u8f6c\u7f6e\u65b9\u6cd5 matrix.t()\uff0c\u7b49\u4ef7\u4e8e torch.transpose(matrix,0,1)\u3002 minval = 0 maxval = 255 # Batch,Height,Width,Channel data = torch . floor ( minval + ( maxval - minval ) * torch . rand ([ 100 , 256 , 256 , 4 ])) . int () print ( data . shape ) # \u8f6c\u6362\u6210 Pytorch\u9ed8\u8ba4\u7684\u56fe\u7247\u683c\u5f0f Batch,Channel,Height,Width # \u9700\u8981\u4ea4\u6362\u4e24\u6b21 data_t = torch . transpose ( torch . transpose ( data , 1 , 2 ), 1 , 3 ) print ( data_t . shape ) torch.Size([100, 256, 256, 4]) torch.Size([100, 4, 256, 256]) matrix = torch . tensor ([[ 1 , 2 , 3 ],[ 4 , 5 , 6 ]]) print ( matrix ) print ( matrix . t ()) #\u7b49\u4ef7\u4e8etorch.transpose(matrix,0,1) tensor([[1, 2, 3], [4, 5, 6]]) tensor([[1, 4], [2, 5], [3, 6]]) \u56db\uff0c\u5408\u5e76\u5206\u5272 # \u53ef\u4ee5\u7528torch.cat\u65b9\u6cd5\u548ctorch.stack\u65b9\u6cd5\u5c06\u591a\u4e2a\u5f20\u91cf\u5408\u5e76\uff0c\u53ef\u4ee5\u7528torch.split\u65b9\u6cd5\u628a\u4e00\u4e2a\u5f20\u91cf\u5206\u5272\u6210\u591a\u4e2a\u5f20\u91cf\u3002 torch.cat\u548ctorch.stack\u6709\u7565\u5fae\u7684\u533a\u522b\uff0ctorch.cat\u662f\u8fde\u63a5\uff0c\u4e0d\u4f1a\u589e\u52a0\u7ef4\u5ea6\uff0c\u800ctorch.stack\u662f\u5806\u53e0\uff0c\u4f1a\u589e\u52a0\u7ef4\u5ea6\u3002 a = torch . tensor ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) b = torch . tensor ([[ 5.0 , 6.0 ],[ 7.0 , 8.0 ]]) c = torch . tensor ([[ 9.0 , 10.0 ],[ 11.0 , 12.0 ]]) abc_cat = torch . cat ([ a , b , c ], dim = 0 ) print ( abc_cat . shape ) print ( abc_cat ) torch.Size([6, 2]) tensor([[ 1., 2.], [ 3., 4.], [ 5., 6.], [ 7., 8.], [ 9., 10.], [11., 12.]]) abc_stack = torch . stack ([ a , b , c ], axis = 0 ) #torch\u4e2ddim\u548caxis\u53c2\u6570\u540d\u53ef\u4ee5\u6df7\u7528 print ( abc_stack . shape ) print ( abc_stack ) torch.Size([3, 2, 2]) tensor([[[ 1., 2.], [ 3., 4.]], [[ 5., 6.], [ 7., 8.]], [[ 9., 10.], [11., 12.]]]) torch . cat ([ a , b , c ], axis = 1 ) tensor([[ 1., 2., 5., 6., 9., 10.], [ 3., 4., 7., 8., 11., 12.]]) torch . stack ([ a , b , c ], axis = 1 ) tensor([[[ 1., 2.], [ 5., 6.], [ 9., 10.]], [[ 3., 4.], [ 7., 8.], [11., 12.]]]) torch.split\u662ftorch.cat\u7684\u9006\u8fd0\u7b97\uff0c\u53ef\u4ee5\u6307\u5b9a\u5206\u5272\u4efd\u6570\u5e73\u5747\u5206\u5272\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u6307\u5b9a\u6bcf\u4efd\u7684\u8bb0\u5f55\u6570\u91cf\u8fdb\u884c\u5206\u5272\u3002 print ( abc_cat ) a , b , c = torch . split ( abc_cat , split_size_or_sections = 2 , dim = 0 ) #\u6bcf\u4efd2\u4e2a\u8fdb\u884c\u5206\u5272 print ( a ) print ( b ) print ( c ) print ( abc_cat ) p , q , r = torch . split ( abc_cat , split_size_or_sections = [ 4 , 1 , 1 ], dim = 0 ) #\u6bcf\u4efd\u5206\u522b\u4e3a[4,1,1] print ( p ) print ( q ) print ( r ) tensor([[ 1., 2.], [ 3., 4.], [ 5., 6.], [ 7., 8.], [ 9., 10.], [11., 12.]]) tensor([[1., 2.], [3., 4.], [5., 6.], [7., 8.]]) tensor([[ 9., 10.]]) tensor([[11., 12.]]) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"4-1,\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c"},{"location":"4.%E4%BD%8E%E9%98%B6API/4-1%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%93%E6%9E%84%E6%93%8D%E4%BD%9C/#4-1\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c","text":"\u5f20\u91cf\u7684\u64cd\u4f5c\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u548c\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u3002 \u5f20\u91cf\u7ed3\u6784\u64cd\u4f5c\u8bf8\u5982\uff1a\u5f20\u91cf\u521b\u5efa\uff0c\u7d22\u5f15\u5207\u7247\uff0c\u7ef4\u5ea6\u53d8\u6362\uff0c\u5408\u5e76\u5206\u5272\u3002 \u5f20\u91cf\u6570\u5b66\u8fd0\u7b97\u4e3b\u8981\u6709\uff1a\u6807\u91cf\u8fd0\u7b97\uff0c\u5411\u91cf\u8fd0\u7b97\uff0c\u77e9\u9635\u8fd0\u7b97\u3002\u53e6\u5916\u6211\u4eec\u4f1a\u4ecb\u7ecd\u5f20\u91cf\u8fd0\u7b97\u7684\u5e7f\u64ad\u673a\u5236\u3002 \u672c\u7bc7\u6211\u4eec\u4ecb\u7ecd\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u3002","title":"4-1,\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c"},{"location":"4.%E4%BD%8E%E9%98%B6API/4-1%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%93%E6%9E%84%E6%93%8D%E4%BD%9C/#\u4e00\u521b\u5efa\u5f20\u91cf","text":"\u5f20\u91cf\u521b\u5efa\u7684\u8bb8\u591a\u65b9\u6cd5\u548cnumpy\u4e2d\u521b\u5efaarray\u7684\u65b9\u6cd5\u5f88\u50cf\u3002 import numpy as np import torch a = torch . tensor ([ 1 , 2 , 3 ], dtype = torch . float ) print ( a ) tensor([1., 2., 3.]) b = torch . arange ( 1 , 10 , step = 2 ) print ( b ) tensor([1, 3, 5, 7, 9]) c = torch . linspace ( 0.0 , 2 * 3.14 , 10 ) print ( c ) tensor([0.0000, 0.6978, 1.3956, 2.0933, 2.7911, 3.4889, 4.1867, 4.8844, 5.5822, 6.2800]) d = torch . zeros (( 3 , 3 )) print ( d ) tensor([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]) a = torch . ones (( 3 , 3 ), dtype = torch . int ) b = torch . zeros_like ( a , dtype = torch . float ) print ( a ) print ( b ) tensor([[1, 1, 1], [1, 1, 1], [1, 1, 1]], dtype=torch.int32) tensor([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]) torch . fill_ ( b , 5 ) print ( b ) tensor([[5., 5., 5.], [5., 5., 5.], [5., 5., 5.]]) #\u5747\u5300\u968f\u673a\u5206\u5e03 torch . manual_seed ( 0 ) minval , maxval = 0 , 10 a = minval + ( maxval - minval ) * torch . rand ([ 5 ]) print ( a ) tensor([4.9626, 7.6822, 0.8848, 1.3203, 3.0742]) #\u6b63\u6001\u5206\u5e03\u968f\u673a b = torch . normal ( mean = torch . zeros ( 3 , 3 ), std = torch . ones ( 3 , 3 )) print ( b ) tensor([[-1.3836, 0.2459, -0.1312], [-0.1785, -0.5959, 0.2739], [ 0.5679, -0.6731, -1.2095]]) #\u6b63\u6001\u5206\u5e03\u968f\u673a mean , std = 2 , 5 c = std * torch . randn (( 3 , 3 )) + mean print ( c ) tensor([[ 8.7204, 13.9161, -0.8323], [ -3.7681, -10.5115, 6.3778], [-11.3628, 1.8433, 4.4939]]) #\u6574\u6570\u968f\u673a\u6392\u5217 d = torch . randperm ( 20 ) print ( d ) tensor([ 5, 15, 19, 10, 7, 17, 0, 4, 12, 16, 14, 13, 1, 3, 9, 6, 18, 2, 8, 11]) #\u7279\u6b8a\u77e9\u9635 I = torch . eye ( 3 , 3 ) #\u5355\u4f4d\u77e9\u9635 print ( I ) t = torch . diag ( torch . tensor ([ 1 , 2 , 3 ])) #\u5bf9\u89d2\u77e9\u9635 print ( t ) tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) tensor([[1, 0, 0], [0, 2, 0], [0, 0, 3]])","title":"\u4e00\uff0c\u521b\u5efa\u5f20\u91cf"},{"location":"4.%E4%BD%8E%E9%98%B6API/4-1%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%93%E6%9E%84%E6%93%8D%E4%BD%9C/#\u4e8c-\u7d22\u5f15\u5207\u7247","text":"\u5f20\u91cf\u7684\u7d22\u5f15\u5207\u7247\u65b9\u5f0f\u548cnumpy\u51e0\u4e4e\u662f\u4e00\u6837\u7684\u3002\u5207\u7247\u65f6\u652f\u6301\u7f3a\u7701\u53c2\u6570\u548c\u7701\u7565\u53f7\u3002 \u53ef\u4ee5\u901a\u8fc7\u7d22\u5f15\u548c\u5207\u7247\u5bf9\u90e8\u5206\u5143\u7d20\u8fdb\u884c\u4fee\u6539\u3002 \u6b64\u5916\uff0c\u5bf9\u4e8e\u4e0d\u89c4\u5219\u7684\u5207\u7247\u63d0\u53d6,\u53ef\u4ee5\u4f7f\u7528torch.index_select, torch.masked_select, torch.take \u5982\u679c\u8981\u901a\u8fc7\u4fee\u6539\u5f20\u91cf\u7684\u67d0\u4e9b\u5143\u7d20\u5f97\u5230\u65b0\u7684\u5f20\u91cf\uff0c\u53ef\u4ee5\u4f7f\u7528torch.where,torch.masked_fill,torch.index_fill #\u5747\u5300\u968f\u673a\u5206\u5e03 torch . manual_seed ( 0 ) minval , maxval = 0 , 10 t = torch . floor ( minval + ( maxval - minval ) * torch . rand ([ 5 , 5 ])) . int () print ( t ) tensor([[4, 7, 0, 1, 3], [6, 4, 8, 4, 6], [3, 4, 0, 1, 2], [5, 6, 8, 1, 2], [6, 9, 3, 8, 4]], dtype=torch.int32) #\u7b2c0\u884c print ( t [ 0 ]) tensor([4, 7, 0, 1, 3], dtype=torch.int32) #\u5012\u6570\u7b2c\u4e00\u884c print ( t [ - 1 ]) tensor([6, 9, 3, 8, 4], dtype=torch.int32) #\u7b2c1\u884c\u7b2c3\u5217 print ( t [ 1 , 3 ]) print ( t [ 1 ][ 3 ]) tensor(4, dtype=torch.int32) tensor(4, dtype=torch.int32) #\u7b2c1\u884c\u81f3\u7b2c3\u884c print ( t [ 1 : 4 ,:]) tensor([[6, 4, 8, 4, 6], [3, 4, 0, 1, 2], [5, 6, 8, 1, 2]], dtype=torch.int32) #\u7b2c1\u884c\u81f3\u6700\u540e\u4e00\u884c\uff0c\u7b2c0\u5217\u5230\u6700\u540e\u4e00\u5217\u6bcf\u9694\u4e24\u5217\u53d6\u4e00\u5217 print ( t [ 1 : 4 ,: 4 : 2 ]) tensor([[6, 8], [3, 0], [5, 8]], dtype=torch.int32) #\u53ef\u4ee5\u4f7f\u7528\u7d22\u5f15\u548c\u5207\u7247\u4fee\u6539\u90e8\u5206\u5143\u7d20 x = torch . tensor ([[ 1 , 2 ],[ 3 , 4 ]], dtype = torch . float32 , requires_grad = True ) x . data [ 1 ,:] = torch . tensor ([ 0.0 , 0.0 ]) x tensor([[1., 2.], [0., 0.]], requires_grad=True) a = torch . arange ( 27 ) . view ( 3 , 3 , 3 ) print ( a ) tensor([[[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8]], [[ 9, 10, 11], [12, 13, 14], [15, 16, 17]], [[18, 19, 20], [21, 22, 23], [24, 25, 26]]]) #\u7701\u7565\u53f7\u53ef\u4ee5\u8868\u793a\u591a\u4e2a\u5192\u53f7 print ( a [ ... , 1 ]) tensor([[ 1, 4, 7], [10, 13, 16], [19, 22, 25]]) \u4ee5\u4e0a\u5207\u7247\u65b9\u5f0f\u76f8\u5bf9\u89c4\u5219\uff0c\u5bf9\u4e8e\u4e0d\u89c4\u5219\u7684\u5207\u7247\u63d0\u53d6,\u53ef\u4ee5\u4f7f\u7528torch.index_select, torch.take, torch.gather, torch.masked_select. \u8003\u8651\u73ed\u7ea7\u6210\u7ee9\u518c\u7684\u4f8b\u5b50\uff0c\u67094\u4e2a\u73ed\u7ea7\uff0c\u6bcf\u4e2a\u73ed\u7ea710\u4e2a\u5b66\u751f\uff0c\u6bcf\u4e2a\u5b66\u751f7\u95e8\u79d1\u76ee\u6210\u7ee9\u3002\u53ef\u4ee5\u7528\u4e00\u4e2a4\u00d710\u00d77\u7684\u5f20\u91cf\u6765\u8868\u793a\u3002 minval = 0 maxval = 100 scores = torch . floor ( minval + ( maxval - minval ) * torch . rand ([ 4 , 10 , 7 ])) . int () print ( scores ) tensor([[[55, 95, 3, 18, 37, 30, 93], [17, 26, 15, 3, 20, 92, 72], [74, 52, 24, 58, 3, 13, 24], [81, 79, 27, 48, 81, 99, 69], [56, 83, 20, 59, 11, 15, 24], [72, 70, 20, 65, 77, 43, 51], [61, 81, 98, 11, 31, 69, 91], [93, 94, 59, 6, 54, 18, 3], [94, 88, 0, 59, 41, 41, 27], [69, 20, 68, 75, 85, 68, 0]], [[17, 74, 60, 10, 21, 97, 83], [28, 37, 2, 49, 12, 11, 47], [57, 29, 79, 19, 95, 84, 7], [37, 52, 57, 61, 69, 52, 25], [73, 2, 20, 37, 25, 32, 9], [39, 60, 17, 47, 85, 44, 51], [45, 60, 81, 97, 81, 97, 46], [ 5, 26, 84, 49, 25, 11, 3], [ 7, 39, 77, 77, 1, 81, 10], [39, 29, 40, 40, 5, 6, 42]], [[50, 27, 68, 4, 46, 93, 29], [95, 68, 4, 81, 44, 27, 89], [ 9, 55, 39, 85, 63, 74, 67], [37, 39, 8, 77, 89, 84, 14], [52, 14, 22, 20, 67, 20, 48], [52, 82, 12, 15, 20, 84, 32], [92, 68, 56, 49, 40, 56, 38], [49, 56, 10, 23, 90, 9, 46], [99, 68, 51, 6, 74, 14, 35], [33, 42, 50, 91, 56, 94, 80]], [[18, 72, 14, 28, 64, 66, 87], [33, 50, 75, 1, 86, 8, 50], [41, 23, 56, 91, 35, 20, 31], [ 0, 72, 25, 16, 21, 78, 76], [88, 68, 33, 36, 64, 91, 63], [26, 26, 2, 60, 21, 5, 93], [17, 44, 64, 51, 16, 9, 89], [58, 91, 33, 64, 38, 47, 19], [66, 65, 48, 38, 19, 84, 12], [70, 33, 25, 58, 24, 61, 59]]], dtype=torch.int32) #\u62bd\u53d6\u6bcf\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\uff0c\u7b2c5\u4e2a\u5b66\u751f\uff0c\u7b2c9\u4e2a\u5b66\u751f\u7684\u5168\u90e8\u6210\u7ee9 torch . index_select ( scores , dim = 1 , index = torch . tensor ([ 0 , 5 , 9 ])) tensor([[[55, 95, 3, 18, 37, 30, 93], [72, 70, 20, 65, 77, 43, 51], [69, 20, 68, 75, 85, 68, 0]], [[17, 74, 60, 10, 21, 97, 83], [39, 60, 17, 47, 85, 44, 51], [39, 29, 40, 40, 5, 6, 42]], [[50, 27, 68, 4, 46, 93, 29], [52, 82, 12, 15, 20, 84, 32], [33, 42, 50, 91, 56, 94, 80]], [[18, 72, 14, 28, 64, 66, 87], [26, 26, 2, 60, 21, 5, 93], [70, 33, 25, 58, 24, 61, 59]]], dtype=torch.int32) #\u62bd\u53d6\u6bcf\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\uff0c\u7b2c5\u4e2a\u5b66\u751f\uff0c\u7b2c9\u4e2a\u5b66\u751f\u7684\u7b2c1\u95e8\u8bfe\u7a0b\uff0c\u7b2c3\u95e8\u8bfe\u7a0b\uff0c\u7b2c6\u95e8\u8bfe\u7a0b\u6210\u7ee9 q = torch . index_select ( torch . index_select ( scores , dim = 1 , index = torch . tensor ([ 0 , 5 , 9 ])) , dim = 2 , index = torch . tensor ([ 1 , 3 , 6 ])) print ( q ) tensor([[[95, 18, 93], [70, 65, 51], [20, 75, 0]], [[74, 10, 83], [60, 47, 51], [29, 40, 42]], [[27, 4, 29], [82, 15, 32], [42, 91, 80]], [[72, 28, 87], [26, 60, 93], [33, 58, 59]]], dtype=torch.int32) #\u62bd\u53d6\u7b2c0\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\u7684\u7b2c0\u95e8\u8bfe\u7a0b\uff0c\u7b2c2\u4e2a\u73ed\u7ea7\u7684\u7b2c4\u4e2a\u5b66\u751f\u7684\u7b2c1\u95e8\u8bfe\u7a0b\uff0c\u7b2c3\u4e2a\u73ed\u7ea7\u7684\u7b2c9\u4e2a\u5b66\u751f\u7b2c6\u95e8\u8bfe\u7a0b\u6210\u7ee9 #take\u5c06\u8f93\u5165\u770b\u6210\u4e00\u7ef4\u6570\u7ec4\uff0c\u8f93\u51fa\u548cindex\u540c\u5f62\u72b6 s = torch . take ( scores , torch . tensor ([ 0 * 10 * 7 + 0 , 2 * 10 * 7 + 4 * 7 + 1 , 3 * 10 * 7 + 9 * 7 + 6 ])) s <tf.Tensor: shape=(3, 7), dtype=int32, numpy= array([[52, 82, 66, 55, 17, 86, 14], [99, 94, 46, 70, 1, 63, 41], [46, 83, 70, 80, 90, 85, 17]], dtype=int32)> #\u62bd\u53d6\u5206\u6570\u5927\u4e8e\u7b49\u4e8e80\u5206\u7684\u5206\u6570\uff08\u5e03\u5c14\u7d22\u5f15\uff09 #\u7ed3\u679c\u662f1\u7ef4\u5f20\u91cf g = torch . masked_select ( scores , scores >= 80 ) print ( g ) \u4ee5\u4e0a\u8fd9\u4e9b\u65b9\u6cd5\u4ec5\u80fd\u63d0\u53d6\u5f20\u91cf\u7684\u90e8\u5206\u5143\u7d20\u503c\uff0c\u4f46\u4e0d\u80fd\u66f4\u6539\u5f20\u91cf\u7684\u90e8\u5206\u5143\u7d20\u503c\u5f97\u5230\u65b0\u7684\u5f20\u91cf\u3002 \u5982\u679c\u8981\u901a\u8fc7\u4fee\u6539\u5f20\u91cf\u7684\u90e8\u5206\u5143\u7d20\u503c\u5f97\u5230\u65b0\u7684\u5f20\u91cf\uff0c\u53ef\u4ee5\u4f7f\u7528torch.where,torch.index_fill \u548c torch.masked_fill torch.where\u53ef\u4ee5\u7406\u89e3\u4e3aif\u7684\u5f20\u91cf\u7248\u672c\u3002 torch.index_fill\u7684\u9009\u53d6\u5143\u7d20\u903b\u8f91\u548ctorch.index_select\u76f8\u540c\u3002 torch.masked_fill\u7684\u9009\u53d6\u5143\u7d20\u903b\u8f91\u548ctorch.masked_select\u76f8\u540c\u3002 #\u5982\u679c\u5206\u6570\u5927\u4e8e60\u5206\uff0c\u8d4b\u503c\u62101\uff0c\u5426\u5219\u8d4b\u503c\u62100 ifpass = torch . where ( scores > 60 , torch . tensor ( 1 ), torch . tensor ( 0 )) print ( ifpass ) #\u5c06\u6bcf\u4e2a\u73ed\u7ea7\u7b2c0\u4e2a\u5b66\u751f\uff0c\u7b2c5\u4e2a\u5b66\u751f\uff0c\u7b2c9\u4e2a\u5b66\u751f\u7684\u5168\u90e8\u6210\u7ee9\u8d4b\u503c\u6210\u6ee1\u5206 torch . index_fill ( scores , dim = 1 , index = torch . tensor ([ 0 , 5 , 9 ]), value = 100 ) #\u7b49\u4ef7\u4e8e scores.index_fill(dim = 1,index = torch.tensor([0,5,9]),value = 100) #\u5c06\u5206\u6570\u5c0f\u4e8e60\u5206\u7684\u5206\u6570\u8d4b\u503c\u621060\u5206 b = torch . masked_fill ( scores , scores < 60 , 60 ) #\u7b49\u4ef7\u4e8eb = scores.masked_fill(scores<60,60) b","title":"\u4e8c \uff0c\u7d22\u5f15\u5207\u7247"},{"location":"4.%E4%BD%8E%E9%98%B6API/4-1%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%93%E6%9E%84%E6%93%8D%E4%BD%9C/#\u4e09\u7ef4\u5ea6\u53d8\u6362","text":"\u7ef4\u5ea6\u53d8\u6362\u76f8\u5173\u51fd\u6570\u4e3b\u8981\u6709 torch.reshape(\u6216\u8005\u8c03\u7528\u5f20\u91cf\u7684view\u65b9\u6cd5), torch.squeeze, torch.unsqueeze, torch.transpose torch.reshape \u53ef\u4ee5\u6539\u53d8\u5f20\u91cf\u7684\u5f62\u72b6\u3002 torch.squeeze \u53ef\u4ee5\u51cf\u5c11\u7ef4\u5ea6\u3002 torch.unsqueeze \u53ef\u4ee5\u589e\u52a0\u7ef4\u5ea6\u3002 torch.transpose \u53ef\u4ee5\u4ea4\u6362\u7ef4\u5ea6\u3002 # \u5f20\u91cf\u7684view\u65b9\u6cd5\u6709\u65f6\u5019\u4f1a\u8c03\u7528\u5931\u8d25\uff0c\u53ef\u4ee5\u4f7f\u7528reshape\u65b9\u6cd5\u3002 torch . manual_seed ( 0 ) minval , maxval = 0 , 255 a = ( minval + ( maxval - minval ) * torch . rand ([ 1 , 3 , 3 , 2 ])) . int () print ( a . shape ) print ( a ) torch.Size([1, 3, 3, 2]) tensor([[[[126, 195], [ 22, 33], [ 78, 161]], [[124, 228], [116, 161], [ 88, 102]], [[ 5, 43], [ 74, 132], [177, 204]]]], dtype=torch.int32) # \u6539\u6210 \uff083,6\uff09\u5f62\u72b6\u7684\u5f20\u91cf b = a . view ([ 3 , 6 ]) #torch.reshape(a,[3,6]) print ( b . shape ) print ( b ) torch.Size([3, 6]) tensor([[126, 195, 22, 33, 78, 161], [124, 228, 116, 161, 88, 102], [ 5, 43, 74, 132, 177, 204]], dtype=torch.int32) # \u6539\u56de\u6210 [1,3,3,2] \u5f62\u72b6\u7684\u5f20\u91cf c = torch . reshape ( b ,[ 1 , 3 , 3 , 2 ]) # b.view([1,3,3,2]) print ( c ) tensor([[[[126, 195], [ 22, 33], [ 78, 161]], [[124, 228], [116, 161], [ 88, 102]], [[ 5, 43], [ 74, 132], [177, 204]]]], dtype=torch.int32) \u5982\u679c\u5f20\u91cf\u5728\u67d0\u4e2a\u7ef4\u5ea6\u4e0a\u53ea\u6709\u4e00\u4e2a\u5143\u7d20\uff0c\u5229\u7528torch.squeeze\u53ef\u4ee5\u6d88\u9664\u8fd9\u4e2a\u7ef4\u5ea6\u3002 torch.unsqueeze\u7684\u4f5c\u7528\u548ctorch.squeeze\u7684\u4f5c\u7528\u76f8\u53cd\u3002 a = torch . tensor ([[ 1.0 , 2.0 ]]) s = torch . squeeze ( a ) print ( a ) print ( s ) print ( a . shape ) print ( s . shape ) tensor([[1., 2.]]) tensor([1., 2.]) torch.Size([1, 2]) torch.Size([2]) #\u5728\u7b2c0\u7ef4\u63d2\u5165\u957f\u5ea6\u4e3a1\u7684\u4e00\u4e2a\u7ef4\u5ea6 d = torch . unsqueeze ( s , axis = 0 ) print ( s ) print ( d ) print ( s . shape ) print ( d . shape ) tensor([1., 2.]) tensor([[1., 2.]]) torch.Size([2]) torch.Size([1, 2]) torch.transpose\u53ef\u4ee5\u4ea4\u6362\u5f20\u91cf\u7684\u7ef4\u5ea6\uff0ctorch.transpose\u5e38\u7528\u4e8e\u56fe\u7247\u5b58\u50a8\u683c\u5f0f\u7684\u53d8\u6362\u4e0a\u3002 \u5982\u679c\u662f\u4e8c\u7ef4\u7684\u77e9\u9635\uff0c\u901a\u5e38\u4f1a\u8c03\u7528\u77e9\u9635\u7684\u8f6c\u7f6e\u65b9\u6cd5 matrix.t()\uff0c\u7b49\u4ef7\u4e8e torch.transpose(matrix,0,1)\u3002 minval = 0 maxval = 255 # Batch,Height,Width,Channel data = torch . floor ( minval + ( maxval - minval ) * torch . rand ([ 100 , 256 , 256 , 4 ])) . int () print ( data . shape ) # \u8f6c\u6362\u6210 Pytorch\u9ed8\u8ba4\u7684\u56fe\u7247\u683c\u5f0f Batch,Channel,Height,Width # \u9700\u8981\u4ea4\u6362\u4e24\u6b21 data_t = torch . transpose ( torch . transpose ( data , 1 , 2 ), 1 , 3 ) print ( data_t . shape ) torch.Size([100, 256, 256, 4]) torch.Size([100, 4, 256, 256]) matrix = torch . tensor ([[ 1 , 2 , 3 ],[ 4 , 5 , 6 ]]) print ( matrix ) print ( matrix . t ()) #\u7b49\u4ef7\u4e8etorch.transpose(matrix,0,1) tensor([[1, 2, 3], [4, 5, 6]]) tensor([[1, 4], [2, 5], [3, 6]])","title":"\u4e09\uff0c\u7ef4\u5ea6\u53d8\u6362"},{"location":"4.%E4%BD%8E%E9%98%B6API/4-1%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%93%E6%9E%84%E6%93%8D%E4%BD%9C/#\u56db\u5408\u5e76\u5206\u5272","text":"\u53ef\u4ee5\u7528torch.cat\u65b9\u6cd5\u548ctorch.stack\u65b9\u6cd5\u5c06\u591a\u4e2a\u5f20\u91cf\u5408\u5e76\uff0c\u53ef\u4ee5\u7528torch.split\u65b9\u6cd5\u628a\u4e00\u4e2a\u5f20\u91cf\u5206\u5272\u6210\u591a\u4e2a\u5f20\u91cf\u3002 torch.cat\u548ctorch.stack\u6709\u7565\u5fae\u7684\u533a\u522b\uff0ctorch.cat\u662f\u8fde\u63a5\uff0c\u4e0d\u4f1a\u589e\u52a0\u7ef4\u5ea6\uff0c\u800ctorch.stack\u662f\u5806\u53e0\uff0c\u4f1a\u589e\u52a0\u7ef4\u5ea6\u3002 a = torch . tensor ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) b = torch . tensor ([[ 5.0 , 6.0 ],[ 7.0 , 8.0 ]]) c = torch . tensor ([[ 9.0 , 10.0 ],[ 11.0 , 12.0 ]]) abc_cat = torch . cat ([ a , b , c ], dim = 0 ) print ( abc_cat . shape ) print ( abc_cat ) torch.Size([6, 2]) tensor([[ 1., 2.], [ 3., 4.], [ 5., 6.], [ 7., 8.], [ 9., 10.], [11., 12.]]) abc_stack = torch . stack ([ a , b , c ], axis = 0 ) #torch\u4e2ddim\u548caxis\u53c2\u6570\u540d\u53ef\u4ee5\u6df7\u7528 print ( abc_stack . shape ) print ( abc_stack ) torch.Size([3, 2, 2]) tensor([[[ 1., 2.], [ 3., 4.]], [[ 5., 6.], [ 7., 8.]], [[ 9., 10.], [11., 12.]]]) torch . cat ([ a , b , c ], axis = 1 ) tensor([[ 1., 2., 5., 6., 9., 10.], [ 3., 4., 7., 8., 11., 12.]]) torch . stack ([ a , b , c ], axis = 1 ) tensor([[[ 1., 2.], [ 5., 6.], [ 9., 10.]], [[ 3., 4.], [ 7., 8.], [11., 12.]]]) torch.split\u662ftorch.cat\u7684\u9006\u8fd0\u7b97\uff0c\u53ef\u4ee5\u6307\u5b9a\u5206\u5272\u4efd\u6570\u5e73\u5747\u5206\u5272\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u6307\u5b9a\u6bcf\u4efd\u7684\u8bb0\u5f55\u6570\u91cf\u8fdb\u884c\u5206\u5272\u3002 print ( abc_cat ) a , b , c = torch . split ( abc_cat , split_size_or_sections = 2 , dim = 0 ) #\u6bcf\u4efd2\u4e2a\u8fdb\u884c\u5206\u5272 print ( a ) print ( b ) print ( c ) print ( abc_cat ) p , q , r = torch . split ( abc_cat , split_size_or_sections = [ 4 , 1 , 1 ], dim = 0 ) #\u6bcf\u4efd\u5206\u522b\u4e3a[4,1,1] print ( p ) print ( q ) print ( r ) tensor([[ 1., 2.], [ 3., 4.], [ 5., 6.], [ 7., 8.], [ 9., 10.], [11., 12.]]) tensor([[1., 2.], [3., 4.], [5., 6.], [7., 8.]]) tensor([[ 9., 10.]]) tensor([[11., 12.]]) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u56db\uff0c\u5408\u5e76\u5206\u5272"},{"location":"4.%E4%BD%8E%E9%98%B6API/4-2%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97/","text":"4-2,\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97 # \u5f20\u91cf\u7684\u64cd\u4f5c\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u548c\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u3002 \u5f20\u91cf\u7ed3\u6784\u64cd\u4f5c\u8bf8\u5982\uff1a\u5f20\u91cf\u521b\u5efa\uff0c\u7d22\u5f15\u5207\u7247\uff0c\u7ef4\u5ea6\u53d8\u6362\uff0c\u5408\u5e76\u5206\u5272\u3002 \u5f20\u91cf\u6570\u5b66\u8fd0\u7b97\u4e3b\u8981\u6709\uff1a\u6807\u91cf\u8fd0\u7b97\uff0c\u5411\u91cf\u8fd0\u7b97\uff0c\u77e9\u9635\u8fd0\u7b97\u3002\u53e6\u5916\u6211\u4eec\u4f1a\u4ecb\u7ecd\u5f20\u91cf\u8fd0\u7b97\u7684\u5e7f\u64ad\u673a\u5236\u3002 \u672c\u7bc7\u6211\u4eec\u4ecb\u7ecd\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u3002 \u672c\u7bc7\u6587\u7ae0\u90e8\u5206\u5185\u5bb9\u53c2\u8003\u5982\u4e0b\u535a\u5ba2\uff1a https://blog.csdn.net/duan_zhihua/article/details/82526505 \u4e00\uff0c\u6807\u91cf\u8fd0\u7b97 # \u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u7b26\u53ef\u4ee5\u5206\u4e3a\u6807\u91cf\u8fd0\u7b97\u7b26\u3001\u5411\u91cf\u8fd0\u7b97\u7b26\u3001\u4ee5\u53ca\u77e9\u9635\u8fd0\u7b97\u7b26\u3002 \u52a0\u51cf\u4e58\u9664\u4e58\u65b9\uff0c\u4ee5\u53ca\u4e09\u89d2\u51fd\u6570\uff0c\u6307\u6570\uff0c\u5bf9\u6570\u7b49\u5e38\u89c1\u51fd\u6570\uff0c\u903b\u8f91\u6bd4\u8f83\u8fd0\u7b97\u7b26\u7b49\u90fd\u662f\u6807\u91cf\u8fd0\u7b97\u7b26\u3002 \u6807\u91cf\u8fd0\u7b97\u7b26\u7684\u7279\u70b9\u662f\u5bf9\u5f20\u91cf\u5b9e\u65bd\u9010\u5143\u7d20\u8fd0\u7b97\u3002 \u6709\u4e9b\u6807\u91cf\u8fd0\u7b97\u7b26\u5bf9\u5e38\u7528\u7684\u6570\u5b66\u8fd0\u7b97\u7b26\u8fdb\u884c\u4e86\u91cd\u8f7d\u3002\u5e76\u4e14\u652f\u6301\u7c7b\u4f3cnumpy\u7684\u5e7f\u64ad\u7279\u6027\u3002 import torch import numpy as np a = torch . tensor ([[ 1.0 , 2 ],[ - 3 , 4.0 ]]) b = torch . tensor ([[ 5.0 , 6 ],[ 7.0 , 8.0 ]]) a + b #\u8fd0\u7b97\u7b26\u91cd\u8f7d tensor([[ 6., 8.], [ 4., 12.]]) a - b tensor([[ -4., -4.], [-10., -4.]]) a * b tensor([[ 5., 12.], [-21., 32.]]) a / b tensor([[ 0.2000, 0.3333], [-0.4286, 0.5000]]) a ** 2 tensor([[ 1., 4.], [ 9., 16.]]) a ** ( 0.5 ) tensor([[1.0000, 1.4142], [ nan, 2.0000]]) a % 3 #\u6c42\u6a21 tensor([[1., 2.], [0., 1.]]) a // 3 #\u5730\u677f\u9664\u6cd5 tensor([[ 0., 0.], [-1., 1.]]) a >= 2 # torch.ge(a,2) #ge: greater_equal\u7f29\u5199 tensor([[False, True], [False, True]]) ( a >= 2 ) & ( a <= 3 ) tensor([[False, True], [False, False]]) ( a >= 2 ) | ( a <= 3 ) tensor([[True, True], [True, True]]) a == 5 #torch.eq(a,5) tensor([[False, False], [False, False]]) torch . sqrt ( a ) tensor([[1.0000, 1.4142], [ nan, 2.0000]]) a = torch . tensor ([ 1.0 , 8.0 ]) b = torch . tensor ([ 5.0 , 6.0 ]) c = torch . tensor ([ 6.0 , 7.0 ]) d = a + b + c print ( d ) tensor([12., 21.]) print ( torch . max ( a , b )) tensor([5., 8.]) print ( torch . min ( a , b )) tensor([1., 6.]) x = torch . tensor ([ 2.6 , - 2.7 ]) print ( torch . round ( x )) #\u4fdd\u7559\u6574\u6570\u90e8\u5206\uff0c\u56db\u820d\u4e94\u5165 print ( torch . floor ( x )) #\u4fdd\u7559\u6574\u6570\u90e8\u5206\uff0c\u5411\u4e0b\u5f52\u6574 print ( torch . ceil ( x )) #\u4fdd\u7559\u6574\u6570\u90e8\u5206\uff0c\u5411\u4e0a\u5f52\u6574 print ( torch . trunc ( x )) #\u4fdd\u7559\u6574\u6570\u90e8\u5206\uff0c\u54110\u5f52\u6574 tensor([ 3., -3.]) tensor([ 2., -3.]) tensor([ 3., -2.]) tensor([ 2., -2.]) x = torch . tensor ([ 2.6 , - 2.7 ]) print ( torch . fmod ( x , 2 )) #\u4f5c\u9664\u6cd5\u53d6\u4f59\u6570 print ( torch . remainder ( x , 2 )) #\u4f5c\u9664\u6cd5\u53d6\u5269\u4f59\u7684\u90e8\u5206\uff0c\u7ed3\u679c\u6052\u6b63 tensor([ 0.6000, -0.7000]) tensor([0.6000, 1.3000]) # \u5e45\u503c\u88c1\u526a x = torch . tensor ([ 0.9 , - 0.8 , 100.0 , - 20.0 , 0.7 ]) y = torch . clamp ( x , min =- 1 , max = 1 ) z = torch . clamp ( x , max = 1 ) print ( y ) print ( z ) tensor([ 0.9000, -0.8000, 1.0000, -1.0000, 0.7000]) tensor([ 0.9000, -0.8000, 1.0000, -20.0000, 0.7000]) \u4e8c\uff0c\u5411\u91cf\u8fd0\u7b97 # \u5411\u91cf\u8fd0\u7b97\u7b26\u53ea\u5728\u4e00\u4e2a\u7279\u5b9a\u8f74\u4e0a\u8fd0\u7b97\uff0c\u5c06\u4e00\u4e2a\u5411\u91cf\u6620\u5c04\u5230\u4e00\u4e2a\u6807\u91cf\u6216\u8005\u53e6\u5916\u4e00\u4e2a\u5411\u91cf\u3002 #\u7edf\u8ba1\u503c a = torch . arange ( 1 , 10 ) . float () print ( torch . sum ( a )) print ( torch . mean ( a )) print ( torch . max ( a )) print ( torch . min ( a )) print ( torch . prod ( a )) #\u7d2f\u4e58 print ( torch . std ( a )) #\u6807\u51c6\u5dee print ( torch . var ( a )) #\u65b9\u5dee print ( torch . median ( a )) #\u4e2d\u4f4d\u6570 tensor(45.) tensor(5.) tensor(9.) tensor(1.) tensor(362880.) tensor(2.7386) tensor(7.5000) tensor(5.) #\u6307\u5b9a\u7ef4\u5ea6\u8ba1\u7b97\u7edf\u8ba1\u503c b = a . view ( 3 , 3 ) print ( b ) print ( torch . max ( b , dim = 0 )) print ( torch . max ( b , dim = 1 )) tensor([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]]) torch.return_types.max( values=tensor([7., 8., 9.]), indices=tensor([2, 2, 2])) torch.return_types.max( values=tensor([3., 6., 9.]), indices=tensor([2, 2, 2])) #cum\u626b\u63cf a = torch . arange ( 1 , 10 ) print ( torch . cumsum ( a , 0 )) print ( torch . cumprod ( a , 0 )) print ( torch . cummax ( a , 0 ) . values ) print ( torch . cummax ( a , 0 ) . indices ) print ( torch . cummin ( a , 0 )) tensor([ 1, 3, 6, 10, 15, 21, 28, 36, 45]) tensor([ 1, 2, 6, 24, 120, 720, 5040, 40320, 362880]) tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]) tensor([0, 1, 2, 3, 4, 5, 6, 7, 8]) torch.return_types.cummin( values=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]), indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0])) #torch.sort\u548ctorch.topk\u53ef\u4ee5\u5bf9\u5f20\u91cf\u6392\u5e8f a = torch . tensor ([[ 9 , 7 , 8 ],[ 1 , 3 , 2 ],[ 5 , 6 , 4 ]]) . float () print ( torch . topk ( a , 2 , dim = 0 ), \" \\n \" ) print ( torch . topk ( a , 2 , dim = 1 ), \" \\n \" ) print ( torch . sort ( a , dim = 1 ), \" \\n \" ) #\u5229\u7528torch.topk\u53ef\u4ee5\u5728Pytorch\u4e2d\u5b9e\u73b0KNN\u7b97\u6cd5 torch.return_types.topk( values=tensor([[9., 7., 8.], [5., 6., 4.]]), indices=tensor([[0, 0, 0], [2, 2, 2]])) torch.return_types.topk( values=tensor([[9., 8.], [3., 2.], [6., 5.]]), indices=tensor([[0, 2], [1, 2], [1, 0]])) torch.return_types.sort( values=tensor([[7., 8., 9.], [1., 2., 3.], [4., 5., 6.]]), indices=tensor([[1, 2, 0], [0, 2, 1], [2, 0, 1]])) \u4e09\uff0c\u77e9\u9635\u8fd0\u7b97 # \u77e9\u9635\u5fc5\u987b\u662f\u4e8c\u7ef4\u7684\u3002\u7c7b\u4f3ctorch.tensor([1,2,3])\u8fd9\u6837\u7684\u4e0d\u662f\u77e9\u9635\u3002 \u77e9\u9635\u8fd0\u7b97\u5305\u62ec\uff1a\u77e9\u9635\u4e58\u6cd5\uff0c\u77e9\u9635\u8f6c\u7f6e\uff0c\u77e9\u9635\u9006\uff0c\u77e9\u9635\u6c42\u8ff9\uff0c\u77e9\u9635\u8303\u6570\uff0c\u77e9\u9635\u884c\u5217\u5f0f\uff0c\u77e9\u9635\u6c42\u7279\u5f81\u503c\uff0c\u77e9\u9635\u5206\u89e3\u7b49\u8fd0\u7b97\u3002 #\u77e9\u9635\u4e58\u6cd5 a = torch . tensor ([[ 1 , 2 ],[ 3 , 4 ]]) b = torch . tensor ([[ 2 , 0 ],[ 0 , 2 ]]) print ( a @b ) #\u7b49\u4ef7\u4e8etorch.matmul(a,b) \u6216 torch.mm(a,b) tensor([[2, 4], [6, 8]]) #\u77e9\u9635\u8f6c\u7f6e a = torch . tensor ([[ 1.0 , 2 ],[ 3 , 4 ]]) print ( a . t ()) tensor([[1., 3.], [2., 4.]]) #\u77e9\u9635\u9006\uff0c\u5fc5\u987b\u4e3a\u6d6e\u70b9\u7c7b\u578b a = torch . tensor ([[ 1.0 , 2 ],[ 3 , 4 ]]) print ( torch . inverse ( a )) tensor([[-2.0000, 1.0000], [ 1.5000, -0.5000]]) #\u77e9\u9635\u6c42trace a = torch . tensor ([[ 1.0 , 2 ],[ 3 , 4 ]]) print ( torch . trace ( a )) tensor(5.) #\u77e9\u9635\u6c42\u8303\u6570 a = torch . tensor ([[ 1.0 , 2 ],[ 3 , 4 ]]) print ( torch . norm ( a )) tensor(5.4772) #\u77e9\u9635\u884c\u5217\u5f0f a = torch . tensor ([[ 1.0 , 2 ],[ 3 , 4 ]]) print ( torch . det ( a )) tensor(-2.0000) #\u77e9\u9635\u7279\u5f81\u503c\u548c\u7279\u5f81\u5411\u91cf a = torch . tensor ([[ 1.0 , 2 ],[ - 5 , 4 ]], dtype = torch . float ) print ( torch . eig ( a , eigenvectors = True )) #\u4e24\u4e2a\u7279\u5f81\u503c\u5206\u522b\u662f -2.5+2.7839j, 2.5-2.7839j torch.return_types.eig( eigenvalues=tensor([[ 2.5000, 2.7839], [ 2.5000, -2.7839]]), eigenvectors=tensor([[ 0.2535, -0.4706], [ 0.8452, 0.0000]])) #\u77e9\u9635QR\u5206\u89e3, \u5c06\u4e00\u4e2a\u65b9\u9635\u5206\u89e3\u4e3a\u4e00\u4e2a\u6b63\u4ea4\u77e9\u9635q\u548c\u4e0a\u4e09\u89d2\u77e9\u9635r #QR\u5206\u89e3\u5b9e\u9645\u4e0a\u662f\u5bf9\u77e9\u9635a\u5b9e\u65bdSchmidt\u6b63\u4ea4\u5316\u5f97\u5230q a = torch . tensor ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) q , r = torch . qr ( a ) print ( q , \" \\n \" ) print ( r , \" \\n \" ) print ( q @r ) #\u77e9\u9635svd\u5206\u89e3 #svd\u5206\u89e3\u53ef\u4ee5\u5c06\u4efb\u610f\u4e00\u4e2a\u77e9\u9635\u5206\u89e3\u4e3a\u4e00\u4e2a\u6b63\u4ea4\u77e9\u9635u,\u4e00\u4e2a\u5bf9\u89d2\u9635s\u548c\u4e00\u4e2a\u6b63\u4ea4\u77e9\u9635v.t()\u7684\u4e58\u79ef #svd\u5e38\u7528\u4e8e\u77e9\u9635\u538b\u7f29\u548c\u964d\u7ef4 a = torch . tensor ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ],[ 5.0 , 6.0 ]]) u , s , v = torch . svd ( a ) print ( u , \" \\n \" ) print ( s , \" \\n \" ) print ( v , \" \\n \" ) print ( u @torch . diag ( s ) @v . t ()) #\u5229\u7528svd\u5206\u89e3\u53ef\u4ee5\u5728Pytorch\u4e2d\u5b9e\u73b0\u4e3b\u6210\u5206\u5206\u6790\u964d\u7ef4 tensor([[-0.2298, 0.8835], [-0.5247, 0.2408], [-0.8196, -0.4019]]) tensor([9.5255, 0.5143]) tensor([[-0.6196, -0.7849], [-0.7849, 0.6196]]) tensor([[1.0000, 2.0000], [3.0000, 4.0000], [5.0000, 6.0000]]) \u56db\uff0c\u5e7f\u64ad\u673a\u5236 # Pytorch\u7684\u5e7f\u64ad\u89c4\u5219\u548cnumpy\u662f\u4e00\u6837\u7684: 1\u3001\u5982\u679c\u5f20\u91cf\u7684\u7ef4\u5ea6\u4e0d\u540c\uff0c\u5c06\u7ef4\u5ea6\u8f83\u5c0f\u7684\u5f20\u91cf\u8fdb\u884c\u6269\u5c55\uff0c\u76f4\u5230\u4e24\u4e2a\u5f20\u91cf\u7684\u7ef4\u5ea6\u90fd\u4e00\u6837\u3002 2\u3001\u5982\u679c\u4e24\u4e2a\u5f20\u91cf\u5728\u67d0\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u957f\u5ea6\u662f\u76f8\u540c\u7684\uff0c\u6216\u8005\u5176\u4e2d\u4e00\u4e2a\u5f20\u91cf\u5728\u8be5\u7ef4\u5ea6\u4e0a\u7684\u957f\u5ea6\u4e3a1\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u8bf4\u8fd9\u4e24\u4e2a\u5f20\u91cf\u5728\u8be5\u7ef4\u5ea6\u4e0a\u662f\u76f8\u5bb9\u7684\u3002 3\u3001\u5982\u679c\u4e24\u4e2a\u5f20\u91cf\u5728\u6240\u6709\u7ef4\u5ea6\u4e0a\u90fd\u662f\u76f8\u5bb9\u7684\uff0c\u5b83\u4eec\u5c31\u80fd\u4f7f\u7528\u5e7f\u64ad\u3002 4\u3001\u5e7f\u64ad\u4e4b\u540e\uff0c\u6bcf\u4e2a\u7ef4\u5ea6\u7684\u957f\u5ea6\u5c06\u53d6\u4e24\u4e2a\u5f20\u91cf\u5728\u8be5\u7ef4\u5ea6\u957f\u5ea6\u7684\u8f83\u5927\u503c\u3002 5\u3001\u5728\u4efb\u4f55\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\uff0c\u5982\u679c\u4e00\u4e2a\u5f20\u91cf\u7684\u957f\u5ea6\u4e3a1\uff0c\u53e6\u4e00\u4e2a\u5f20\u91cf\u957f\u5ea6\u5927\u4e8e1\uff0c\u90a3\u4e48\u5728\u8be5\u7ef4\u5ea6\u4e0a\uff0c\u5c31\u597d\u50cf\u662f\u5bf9\u7b2c\u4e00\u4e2a\u5f20\u91cf\u8fdb\u884c\u4e86\u590d\u5236\u3002 torch.broadcast_tensors\u53ef\u4ee5\u5c06\u591a\u4e2a\u5f20\u91cf\u6839\u636e\u5e7f\u64ad\u89c4\u5219\u8f6c\u6362\u6210\u76f8\u540c\u7684\u7ef4\u5ea6\u3002 a = torch . tensor ([ 1 , 2 , 3 ]) b = torch . tensor ([[ 0 , 0 , 0 ],[ 1 , 1 , 1 ],[ 2 , 2 , 2 ]]) print ( b + a ) tensor([[1, 2, 3], [2, 3, 4], [3, 4, 5]]) a_broad , b_broad = torch . broadcast_tensors ( a , b ) print ( a_broad , \" \\n \" ) print ( b_broad , \" \\n \" ) print ( a_broad + b_broad ) tensor([[1, 2, 3], [1, 2, 3], [1, 2, 3]]) tensor([[0, 0, 0], [1, 1, 1], [2, 2, 2]]) tensor([[1, 2, 3], [2, 3, 4], [3, 4, 5]]) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"4-2,\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97"},{"location":"4.%E4%BD%8E%E9%98%B6API/4-2%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97/#4-2\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97","text":"\u5f20\u91cf\u7684\u64cd\u4f5c\u4e3b\u8981\u5305\u62ec\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u548c\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u3002 \u5f20\u91cf\u7ed3\u6784\u64cd\u4f5c\u8bf8\u5982\uff1a\u5f20\u91cf\u521b\u5efa\uff0c\u7d22\u5f15\u5207\u7247\uff0c\u7ef4\u5ea6\u53d8\u6362\uff0c\u5408\u5e76\u5206\u5272\u3002 \u5f20\u91cf\u6570\u5b66\u8fd0\u7b97\u4e3b\u8981\u6709\uff1a\u6807\u91cf\u8fd0\u7b97\uff0c\u5411\u91cf\u8fd0\u7b97\uff0c\u77e9\u9635\u8fd0\u7b97\u3002\u53e6\u5916\u6211\u4eec\u4f1a\u4ecb\u7ecd\u5f20\u91cf\u8fd0\u7b97\u7684\u5e7f\u64ad\u673a\u5236\u3002 \u672c\u7bc7\u6211\u4eec\u4ecb\u7ecd\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u3002 \u672c\u7bc7\u6587\u7ae0\u90e8\u5206\u5185\u5bb9\u53c2\u8003\u5982\u4e0b\u535a\u5ba2\uff1a https://blog.csdn.net/duan_zhihua/article/details/82526505","title":"4-2,\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97"},{"location":"4.%E4%BD%8E%E9%98%B6API/4-2%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97/#\u4e00\u6807\u91cf\u8fd0\u7b97","text":"\u5f20\u91cf\u7684\u6570\u5b66\u8fd0\u7b97\u7b26\u53ef\u4ee5\u5206\u4e3a\u6807\u91cf\u8fd0\u7b97\u7b26\u3001\u5411\u91cf\u8fd0\u7b97\u7b26\u3001\u4ee5\u53ca\u77e9\u9635\u8fd0\u7b97\u7b26\u3002 \u52a0\u51cf\u4e58\u9664\u4e58\u65b9\uff0c\u4ee5\u53ca\u4e09\u89d2\u51fd\u6570\uff0c\u6307\u6570\uff0c\u5bf9\u6570\u7b49\u5e38\u89c1\u51fd\u6570\uff0c\u903b\u8f91\u6bd4\u8f83\u8fd0\u7b97\u7b26\u7b49\u90fd\u662f\u6807\u91cf\u8fd0\u7b97\u7b26\u3002 \u6807\u91cf\u8fd0\u7b97\u7b26\u7684\u7279\u70b9\u662f\u5bf9\u5f20\u91cf\u5b9e\u65bd\u9010\u5143\u7d20\u8fd0\u7b97\u3002 \u6709\u4e9b\u6807\u91cf\u8fd0\u7b97\u7b26\u5bf9\u5e38\u7528\u7684\u6570\u5b66\u8fd0\u7b97\u7b26\u8fdb\u884c\u4e86\u91cd\u8f7d\u3002\u5e76\u4e14\u652f\u6301\u7c7b\u4f3cnumpy\u7684\u5e7f\u64ad\u7279\u6027\u3002 import torch import numpy as np a = torch . tensor ([[ 1.0 , 2 ],[ - 3 , 4.0 ]]) b = torch . tensor ([[ 5.0 , 6 ],[ 7.0 , 8.0 ]]) a + b #\u8fd0\u7b97\u7b26\u91cd\u8f7d tensor([[ 6., 8.], [ 4., 12.]]) a - b tensor([[ -4., -4.], [-10., -4.]]) a * b tensor([[ 5., 12.], [-21., 32.]]) a / b tensor([[ 0.2000, 0.3333], [-0.4286, 0.5000]]) a ** 2 tensor([[ 1., 4.], [ 9., 16.]]) a ** ( 0.5 ) tensor([[1.0000, 1.4142], [ nan, 2.0000]]) a % 3 #\u6c42\u6a21 tensor([[1., 2.], [0., 1.]]) a // 3 #\u5730\u677f\u9664\u6cd5 tensor([[ 0., 0.], [-1., 1.]]) a >= 2 # torch.ge(a,2) #ge: greater_equal\u7f29\u5199 tensor([[False, True], [False, True]]) ( a >= 2 ) & ( a <= 3 ) tensor([[False, True], [False, False]]) ( a >= 2 ) | ( a <= 3 ) tensor([[True, True], [True, True]]) a == 5 #torch.eq(a,5) tensor([[False, False], [False, False]]) torch . sqrt ( a ) tensor([[1.0000, 1.4142], [ nan, 2.0000]]) a = torch . tensor ([ 1.0 , 8.0 ]) b = torch . tensor ([ 5.0 , 6.0 ]) c = torch . tensor ([ 6.0 , 7.0 ]) d = a + b + c print ( d ) tensor([12., 21.]) print ( torch . max ( a , b )) tensor([5., 8.]) print ( torch . min ( a , b )) tensor([1., 6.]) x = torch . tensor ([ 2.6 , - 2.7 ]) print ( torch . round ( x )) #\u4fdd\u7559\u6574\u6570\u90e8\u5206\uff0c\u56db\u820d\u4e94\u5165 print ( torch . floor ( x )) #\u4fdd\u7559\u6574\u6570\u90e8\u5206\uff0c\u5411\u4e0b\u5f52\u6574 print ( torch . ceil ( x )) #\u4fdd\u7559\u6574\u6570\u90e8\u5206\uff0c\u5411\u4e0a\u5f52\u6574 print ( torch . trunc ( x )) #\u4fdd\u7559\u6574\u6570\u90e8\u5206\uff0c\u54110\u5f52\u6574 tensor([ 3., -3.]) tensor([ 2., -3.]) tensor([ 3., -2.]) tensor([ 2., -2.]) x = torch . tensor ([ 2.6 , - 2.7 ]) print ( torch . fmod ( x , 2 )) #\u4f5c\u9664\u6cd5\u53d6\u4f59\u6570 print ( torch . remainder ( x , 2 )) #\u4f5c\u9664\u6cd5\u53d6\u5269\u4f59\u7684\u90e8\u5206\uff0c\u7ed3\u679c\u6052\u6b63 tensor([ 0.6000, -0.7000]) tensor([0.6000, 1.3000]) # \u5e45\u503c\u88c1\u526a x = torch . tensor ([ 0.9 , - 0.8 , 100.0 , - 20.0 , 0.7 ]) y = torch . clamp ( x , min =- 1 , max = 1 ) z = torch . clamp ( x , max = 1 ) print ( y ) print ( z ) tensor([ 0.9000, -0.8000, 1.0000, -1.0000, 0.7000]) tensor([ 0.9000, -0.8000, 1.0000, -20.0000, 0.7000])","title":"\u4e00\uff0c\u6807\u91cf\u8fd0\u7b97"},{"location":"4.%E4%BD%8E%E9%98%B6API/4-2%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97/#\u4e8c\u5411\u91cf\u8fd0\u7b97","text":"\u5411\u91cf\u8fd0\u7b97\u7b26\u53ea\u5728\u4e00\u4e2a\u7279\u5b9a\u8f74\u4e0a\u8fd0\u7b97\uff0c\u5c06\u4e00\u4e2a\u5411\u91cf\u6620\u5c04\u5230\u4e00\u4e2a\u6807\u91cf\u6216\u8005\u53e6\u5916\u4e00\u4e2a\u5411\u91cf\u3002 #\u7edf\u8ba1\u503c a = torch . arange ( 1 , 10 ) . float () print ( torch . sum ( a )) print ( torch . mean ( a )) print ( torch . max ( a )) print ( torch . min ( a )) print ( torch . prod ( a )) #\u7d2f\u4e58 print ( torch . std ( a )) #\u6807\u51c6\u5dee print ( torch . var ( a )) #\u65b9\u5dee print ( torch . median ( a )) #\u4e2d\u4f4d\u6570 tensor(45.) tensor(5.) tensor(9.) tensor(1.) tensor(362880.) tensor(2.7386) tensor(7.5000) tensor(5.) #\u6307\u5b9a\u7ef4\u5ea6\u8ba1\u7b97\u7edf\u8ba1\u503c b = a . view ( 3 , 3 ) print ( b ) print ( torch . max ( b , dim = 0 )) print ( torch . max ( b , dim = 1 )) tensor([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]]) torch.return_types.max( values=tensor([7., 8., 9.]), indices=tensor([2, 2, 2])) torch.return_types.max( values=tensor([3., 6., 9.]), indices=tensor([2, 2, 2])) #cum\u626b\u63cf a = torch . arange ( 1 , 10 ) print ( torch . cumsum ( a , 0 )) print ( torch . cumprod ( a , 0 )) print ( torch . cummax ( a , 0 ) . values ) print ( torch . cummax ( a , 0 ) . indices ) print ( torch . cummin ( a , 0 )) tensor([ 1, 3, 6, 10, 15, 21, 28, 36, 45]) tensor([ 1, 2, 6, 24, 120, 720, 5040, 40320, 362880]) tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]) tensor([0, 1, 2, 3, 4, 5, 6, 7, 8]) torch.return_types.cummin( values=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]), indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0])) #torch.sort\u548ctorch.topk\u53ef\u4ee5\u5bf9\u5f20\u91cf\u6392\u5e8f a = torch . tensor ([[ 9 , 7 , 8 ],[ 1 , 3 , 2 ],[ 5 , 6 , 4 ]]) . float () print ( torch . topk ( a , 2 , dim = 0 ), \" \\n \" ) print ( torch . topk ( a , 2 , dim = 1 ), \" \\n \" ) print ( torch . sort ( a , dim = 1 ), \" \\n \" ) #\u5229\u7528torch.topk\u53ef\u4ee5\u5728Pytorch\u4e2d\u5b9e\u73b0KNN\u7b97\u6cd5 torch.return_types.topk( values=tensor([[9., 7., 8.], [5., 6., 4.]]), indices=tensor([[0, 0, 0], [2, 2, 2]])) torch.return_types.topk( values=tensor([[9., 8.], [3., 2.], [6., 5.]]), indices=tensor([[0, 2], [1, 2], [1, 0]])) torch.return_types.sort( values=tensor([[7., 8., 9.], [1., 2., 3.], [4., 5., 6.]]), indices=tensor([[1, 2, 0], [0, 2, 1], [2, 0, 1]]))","title":"\u4e8c\uff0c\u5411\u91cf\u8fd0\u7b97"},{"location":"4.%E4%BD%8E%E9%98%B6API/4-2%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97/#\u4e09\u77e9\u9635\u8fd0\u7b97","text":"\u77e9\u9635\u5fc5\u987b\u662f\u4e8c\u7ef4\u7684\u3002\u7c7b\u4f3ctorch.tensor([1,2,3])\u8fd9\u6837\u7684\u4e0d\u662f\u77e9\u9635\u3002 \u77e9\u9635\u8fd0\u7b97\u5305\u62ec\uff1a\u77e9\u9635\u4e58\u6cd5\uff0c\u77e9\u9635\u8f6c\u7f6e\uff0c\u77e9\u9635\u9006\uff0c\u77e9\u9635\u6c42\u8ff9\uff0c\u77e9\u9635\u8303\u6570\uff0c\u77e9\u9635\u884c\u5217\u5f0f\uff0c\u77e9\u9635\u6c42\u7279\u5f81\u503c\uff0c\u77e9\u9635\u5206\u89e3\u7b49\u8fd0\u7b97\u3002 #\u77e9\u9635\u4e58\u6cd5 a = torch . tensor ([[ 1 , 2 ],[ 3 , 4 ]]) b = torch . tensor ([[ 2 , 0 ],[ 0 , 2 ]]) print ( a @b ) #\u7b49\u4ef7\u4e8etorch.matmul(a,b) \u6216 torch.mm(a,b) tensor([[2, 4], [6, 8]]) #\u77e9\u9635\u8f6c\u7f6e a = torch . tensor ([[ 1.0 , 2 ],[ 3 , 4 ]]) print ( a . t ()) tensor([[1., 3.], [2., 4.]]) #\u77e9\u9635\u9006\uff0c\u5fc5\u987b\u4e3a\u6d6e\u70b9\u7c7b\u578b a = torch . tensor ([[ 1.0 , 2 ],[ 3 , 4 ]]) print ( torch . inverse ( a )) tensor([[-2.0000, 1.0000], [ 1.5000, -0.5000]]) #\u77e9\u9635\u6c42trace a = torch . tensor ([[ 1.0 , 2 ],[ 3 , 4 ]]) print ( torch . trace ( a )) tensor(5.) #\u77e9\u9635\u6c42\u8303\u6570 a = torch . tensor ([[ 1.0 , 2 ],[ 3 , 4 ]]) print ( torch . norm ( a )) tensor(5.4772) #\u77e9\u9635\u884c\u5217\u5f0f a = torch . tensor ([[ 1.0 , 2 ],[ 3 , 4 ]]) print ( torch . det ( a )) tensor(-2.0000) #\u77e9\u9635\u7279\u5f81\u503c\u548c\u7279\u5f81\u5411\u91cf a = torch . tensor ([[ 1.0 , 2 ],[ - 5 , 4 ]], dtype = torch . float ) print ( torch . eig ( a , eigenvectors = True )) #\u4e24\u4e2a\u7279\u5f81\u503c\u5206\u522b\u662f -2.5+2.7839j, 2.5-2.7839j torch.return_types.eig( eigenvalues=tensor([[ 2.5000, 2.7839], [ 2.5000, -2.7839]]), eigenvectors=tensor([[ 0.2535, -0.4706], [ 0.8452, 0.0000]])) #\u77e9\u9635QR\u5206\u89e3, \u5c06\u4e00\u4e2a\u65b9\u9635\u5206\u89e3\u4e3a\u4e00\u4e2a\u6b63\u4ea4\u77e9\u9635q\u548c\u4e0a\u4e09\u89d2\u77e9\u9635r #QR\u5206\u89e3\u5b9e\u9645\u4e0a\u662f\u5bf9\u77e9\u9635a\u5b9e\u65bdSchmidt\u6b63\u4ea4\u5316\u5f97\u5230q a = torch . tensor ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ]]) q , r = torch . qr ( a ) print ( q , \" \\n \" ) print ( r , \" \\n \" ) print ( q @r ) #\u77e9\u9635svd\u5206\u89e3 #svd\u5206\u89e3\u53ef\u4ee5\u5c06\u4efb\u610f\u4e00\u4e2a\u77e9\u9635\u5206\u89e3\u4e3a\u4e00\u4e2a\u6b63\u4ea4\u77e9\u9635u,\u4e00\u4e2a\u5bf9\u89d2\u9635s\u548c\u4e00\u4e2a\u6b63\u4ea4\u77e9\u9635v.t()\u7684\u4e58\u79ef #svd\u5e38\u7528\u4e8e\u77e9\u9635\u538b\u7f29\u548c\u964d\u7ef4 a = torch . tensor ([[ 1.0 , 2.0 ],[ 3.0 , 4.0 ],[ 5.0 , 6.0 ]]) u , s , v = torch . svd ( a ) print ( u , \" \\n \" ) print ( s , \" \\n \" ) print ( v , \" \\n \" ) print ( u @torch . diag ( s ) @v . t ()) #\u5229\u7528svd\u5206\u89e3\u53ef\u4ee5\u5728Pytorch\u4e2d\u5b9e\u73b0\u4e3b\u6210\u5206\u5206\u6790\u964d\u7ef4 tensor([[-0.2298, 0.8835], [-0.5247, 0.2408], [-0.8196, -0.4019]]) tensor([9.5255, 0.5143]) tensor([[-0.6196, -0.7849], [-0.7849, 0.6196]]) tensor([[1.0000, 2.0000], [3.0000, 4.0000], [5.0000, 6.0000]])","title":"\u4e09\uff0c\u77e9\u9635\u8fd0\u7b97"},{"location":"4.%E4%BD%8E%E9%98%B6API/4-2%2C%E5%BC%A0%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97/#\u56db\u5e7f\u64ad\u673a\u5236","text":"Pytorch\u7684\u5e7f\u64ad\u89c4\u5219\u548cnumpy\u662f\u4e00\u6837\u7684: 1\u3001\u5982\u679c\u5f20\u91cf\u7684\u7ef4\u5ea6\u4e0d\u540c\uff0c\u5c06\u7ef4\u5ea6\u8f83\u5c0f\u7684\u5f20\u91cf\u8fdb\u884c\u6269\u5c55\uff0c\u76f4\u5230\u4e24\u4e2a\u5f20\u91cf\u7684\u7ef4\u5ea6\u90fd\u4e00\u6837\u3002 2\u3001\u5982\u679c\u4e24\u4e2a\u5f20\u91cf\u5728\u67d0\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u957f\u5ea6\u662f\u76f8\u540c\u7684\uff0c\u6216\u8005\u5176\u4e2d\u4e00\u4e2a\u5f20\u91cf\u5728\u8be5\u7ef4\u5ea6\u4e0a\u7684\u957f\u5ea6\u4e3a1\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u8bf4\u8fd9\u4e24\u4e2a\u5f20\u91cf\u5728\u8be5\u7ef4\u5ea6\u4e0a\u662f\u76f8\u5bb9\u7684\u3002 3\u3001\u5982\u679c\u4e24\u4e2a\u5f20\u91cf\u5728\u6240\u6709\u7ef4\u5ea6\u4e0a\u90fd\u662f\u76f8\u5bb9\u7684\uff0c\u5b83\u4eec\u5c31\u80fd\u4f7f\u7528\u5e7f\u64ad\u3002 4\u3001\u5e7f\u64ad\u4e4b\u540e\uff0c\u6bcf\u4e2a\u7ef4\u5ea6\u7684\u957f\u5ea6\u5c06\u53d6\u4e24\u4e2a\u5f20\u91cf\u5728\u8be5\u7ef4\u5ea6\u957f\u5ea6\u7684\u8f83\u5927\u503c\u3002 5\u3001\u5728\u4efb\u4f55\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\uff0c\u5982\u679c\u4e00\u4e2a\u5f20\u91cf\u7684\u957f\u5ea6\u4e3a1\uff0c\u53e6\u4e00\u4e2a\u5f20\u91cf\u957f\u5ea6\u5927\u4e8e1\uff0c\u90a3\u4e48\u5728\u8be5\u7ef4\u5ea6\u4e0a\uff0c\u5c31\u597d\u50cf\u662f\u5bf9\u7b2c\u4e00\u4e2a\u5f20\u91cf\u8fdb\u884c\u4e86\u590d\u5236\u3002 torch.broadcast_tensors\u53ef\u4ee5\u5c06\u591a\u4e2a\u5f20\u91cf\u6839\u636e\u5e7f\u64ad\u89c4\u5219\u8f6c\u6362\u6210\u76f8\u540c\u7684\u7ef4\u5ea6\u3002 a = torch . tensor ([ 1 , 2 , 3 ]) b = torch . tensor ([[ 0 , 0 , 0 ],[ 1 , 1 , 1 ],[ 2 , 2 , 2 ]]) print ( b + a ) tensor([[1, 2, 3], [2, 3, 4], [3, 4, 5]]) a_broad , b_broad = torch . broadcast_tensors ( a , b ) print ( a_broad , \" \\n \" ) print ( b_broad , \" \\n \" ) print ( a_broad + b_broad ) tensor([[1, 2, 3], [1, 2, 3], [1, 2, 3]]) tensor([[0, 0, 0], [1, 1, 1], [2, 2, 2]]) tensor([[1, 2, 3], [2, 3, 4], [3, 4, 5]]) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u56db\uff0c\u5e7f\u64ad\u673a\u5236"},{"location":"4.%E4%BD%8E%E9%98%B6API/4-3%2Cnn.functional%E5%92%8Cnn.Module/","text":"4-3,nn.functional \u548c nn.Module # import os import datetime #\u6253\u5370\u65f6\u95f4 def printbar (): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) #mac\u7cfb\u7edf\u4e0apytorch\u548cmatplotlib\u5728jupyter\u4e2d\u540c\u65f6\u8dd1\u9700\u8981\u66f4\u6539\u73af\u5883\u53d8\u91cf os . environ [ \"KMP_DUPLICATE_LIB_OK\" ] = \"TRUE\" \u4e00\uff0cnn.functional \u548c nn.Module # \u524d\u9762\u6211\u4eec\u4ecb\u7ecd\u4e86Pytorch\u7684\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u548c\u6570\u5b66\u8fd0\u7b97\u4e2d\u7684\u4e00\u4e9b\u5e38\u7528API\u3002 \u5229\u7528\u8fd9\u4e9b\u5f20\u91cf\u7684API\u6211\u4eec\u53ef\u4ee5\u6784\u5efa\u51fa\u795e\u7ecf\u7f51\u7edc\u76f8\u5173\u7684\u7ec4\u4ef6(\u5982\u6fc0\u6d3b\u51fd\u6570\uff0c\u6a21\u578b\u5c42\uff0c\u635f\u5931\u51fd\u6570)\u3002 Pytorch\u548c\u795e\u7ecf\u7f51\u7edc\u76f8\u5173\u7684\u529f\u80fd\u7ec4\u4ef6\u5927\u591a\u90fd\u5c01\u88c5\u5728 torch.nn\u6a21\u5757\u4e0b\u3002 \u8fd9\u4e9b\u529f\u80fd\u7ec4\u4ef6\u7684\u7edd\u5927\u90e8\u5206\u65e2\u6709\u51fd\u6570\u5f62\u5f0f\u5b9e\u73b0\uff0c\u4e5f\u6709\u7c7b\u5f62\u5f0f\u5b9e\u73b0\u3002 \u5176\u4e2dnn.functional(\u4e00\u822c\u5f15\u5165\u540e\u6539\u540d\u4e3aF)\u6709\u5404\u79cd\u529f\u80fd\u7ec4\u4ef6\u7684\u51fd\u6570\u5b9e\u73b0\u3002\u4f8b\u5982\uff1a (\u6fc0\u6d3b\u51fd\u6570) * F.relu * F.sigmoid * F.tanh * F.softmax (\u6a21\u578b\u5c42) * F.linear * F.conv2d * F.max_pool2d * F.dropout2d * F.embedding (\u635f\u5931\u51fd\u6570) * F.binary_cross_entropy * F.mse_loss * F.cross_entropy \u4e3a\u4e86\u4fbf\u4e8e\u5bf9\u53c2\u6570\u8fdb\u884c\u7ba1\u7406\uff0c\u4e00\u822c\u901a\u8fc7\u7ee7\u627f nn.Module \u8f6c\u6362\u6210\u4e3a\u7c7b\u7684\u5b9e\u73b0\u5f62\u5f0f\uff0c\u5e76\u76f4\u63a5\u5c01\u88c5\u5728 nn \u6a21\u5757\u4e0b\u3002\u4f8b\u5982\uff1a (\u6fc0\u6d3b\u51fd\u6570) * nn.ReLU * nn.Sigmoid * nn.Tanh * nn.Softmax (\u6a21\u578b\u5c42) * nn.Linear * nn.Conv2d * nn.MaxPool2d * nn.Dropout2d * nn.Embedding (\u635f\u5931\u51fd\u6570) * nn.BCELoss * nn.MSELoss * nn.CrossEntropyLoss \u5b9e\u9645\u4e0ann.Module\u9664\u4e86\u53ef\u4ee5\u7ba1\u7406\u5176\u5f15\u7528\u7684\u5404\u79cd\u53c2\u6570\uff0c\u8fd8\u53ef\u4ee5\u7ba1\u7406\u5176\u5f15\u7528\u7684\u5b50\u6a21\u5757\uff0c\u529f\u80fd\u5341\u5206\u5f3a\u5927\u3002 \u4e8c\uff0c\u4f7f\u7528nn.Module\u6765\u7ba1\u7406\u53c2\u6570 # \u5728Pytorch\u4e2d\uff0c\u6a21\u578b\u7684\u53c2\u6570\u662f\u9700\u8981\u88ab\u4f18\u5316\u5668\u8bad\u7ec3\u7684\uff0c\u56e0\u6b64\uff0c\u901a\u5e38\u8981\u8bbe\u7f6e\u53c2\u6570\u4e3a requires_grad = True \u7684\u5f20\u91cf\u3002 \u540c\u65f6\uff0c\u5728\u4e00\u4e2a\u6a21\u578b\u4e2d\uff0c\u5f80\u5f80\u6709\u8bb8\u591a\u7684\u53c2\u6570\uff0c\u8981\u624b\u52a8\u7ba1\u7406\u8fd9\u4e9b\u53c2\u6570\u5e76\u4e0d\u662f\u4e00\u4ef6\u5bb9\u6613\u7684\u4e8b\u60c5\u3002 Pytorch\u4e00\u822c\u5c06\u53c2\u6570\u7528nn.Parameter\u6765\u8868\u793a\uff0c\u5e76\u4e14\u7528nn.Module\u6765\u7ba1\u7406\u5176\u7ed3\u6784\u4e0b\u7684\u6240\u6709\u53c2\u6570\u3002 import torch from torch import nn import torch.nn.functional as F from matplotlib import pyplot as plt # nn.Parameter \u5177\u6709 requires_grad = True \u5c5e\u6027 w = nn . Parameter ( torch . randn ( 2 , 2 )) print ( w ) print ( w . requires_grad ) Parameter containing: tensor([[ 0.3544, -1.1643], [ 1.2302, 1.3952]], requires_grad=True) True # nn.ParameterList \u53ef\u4ee5\u5c06\u591a\u4e2ann.Parameter\u7ec4\u6210\u4e00\u4e2a\u5217\u8868 params_list = nn . ParameterList ([ nn . Parameter ( torch . rand ( 8 , i )) for i in range ( 1 , 3 )]) print ( params_list ) print ( params_list [ 0 ] . requires_grad ) ParameterList( (0): Parameter containing: [torch.FloatTensor of size 8x1] (1): Parameter containing: [torch.FloatTensor of size 8x2] ) True # nn.ParameterDict \u53ef\u4ee5\u5c06\u591a\u4e2ann.Parameter\u7ec4\u6210\u4e00\u4e2a\u5b57\u5178 params_dict = nn . ParameterDict ({ \"a\" : nn . Parameter ( torch . rand ( 2 , 2 )), \"b\" : nn . Parameter ( torch . zeros ( 2 ))}) print ( params_dict ) print ( params_dict [ \"a\" ] . requires_grad ) ParameterDict( (a): Parameter containing: [torch.FloatTensor of size 2x2] (b): Parameter containing: [torch.FloatTensor of size 2] ) True # \u53ef\u4ee5\u7528Module\u5c06\u5b83\u4eec\u7ba1\u7406\u8d77\u6765 # module.parameters()\u8fd4\u56de\u4e00\u4e2a\u751f\u6210\u5668\uff0c\u5305\u62ec\u5176\u7ed3\u6784\u4e0b\u7684\u6240\u6709parameters module = nn . Module () module . w = w module . params_list = params_list module . params_dict = params_dict num_param = 0 for param in module . parameters (): print ( param , \" \\n \" ) num_param = num_param + 1 print ( \"number of Parameters =\" , num_param ) Parameter containing: tensor([[ 0.3544, -1.1643], [ 1.2302, 1.3952]], requires_grad=True) Parameter containing: tensor([[0.9391], [0.7590], [0.6899], [0.4786], [0.2392], [0.9645], [0.1968], [0.1353]], requires_grad=True) Parameter containing: tensor([[0.8012, 0.9587], [0.0276, 0.5995], [0.7338, 0.5559], [0.1704, 0.5814], [0.7626, 0.1179], [0.4945, 0.2408], [0.7179, 0.0575], [0.3418, 0.7291]], requires_grad=True) Parameter containing: tensor([[0.7729, 0.2383], [0.7054, 0.9937]], requires_grad=True) Parameter containing: tensor([0., 0.], requires_grad=True) number of Parameters = 5 #\u5b9e\u8df5\u5f53\u4e2d\uff0c\u4e00\u822c\u901a\u8fc7\u7ee7\u627fnn.Module\u6765\u6784\u5efa\u6a21\u5757\u7c7b\uff0c\u5e76\u5c06\u6240\u6709\u542b\u6709\u9700\u8981\u5b66\u4e60\u7684\u53c2\u6570\u7684\u90e8\u5206\u653e\u5728\u6784\u9020\u51fd\u6570\u4e2d\u3002 #\u4ee5\u4e0b\u8303\u4f8b\u4e3aPytorch\u4e2dnn.Linear\u7684\u6e90\u7801\u7684\u7b80\u5316\u7248\u672c #\u53ef\u4ee5\u770b\u5230\u5b83\u5c06\u9700\u8981\u5b66\u4e60\u7684\u53c2\u6570\u653e\u5728\u4e86__init__\u6784\u9020\u51fd\u6570\u4e2d\uff0c\u5e76\u5728forward\u4e2d\u8c03\u7528F.linear\u51fd\u6570\u6765\u5b9e\u73b0\u8ba1\u7b97\u903b\u8f91\u3002 class Linear ( nn . Module ): __constants__ = [ 'in_features' , 'out_features' ] def __init__ ( self , in_features , out_features , bias = True ): super ( Linear , self ) . __init__ () self . in_features = in_features self . out_features = out_features self . weight = nn . Parameter ( torch . Tensor ( out_features , in_features )) if bias : self . bias = nn . Parameter ( torch . Tensor ( out_features )) else : self . register_parameter ( 'bias' , None ) def forward ( self , input ): return F . linear ( input , self . weight , self . bias ) \u4e09\uff0c\u4f7f\u7528nn.Module\u6765\u7ba1\u7406\u5b50\u6a21\u5757 # \u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u90fd\u5f88\u5c11\u76f4\u63a5\u4f7f\u7528 nn.Parameter\u6765\u5b9a\u4e49\u53c2\u6570\u6784\u5efa\u6a21\u578b\uff0c\u800c\u662f\u901a\u8fc7\u4e00\u4e9b\u62fc\u88c5\u4e00\u4e9b\u5e38\u7528\u7684\u6a21\u578b\u5c42\u6765\u6784\u9020\u6a21\u578b\u3002 \u8fd9\u4e9b\u6a21\u578b\u5c42\u4e5f\u662f\u7ee7\u627f\u81eann.Module\u7684\u5bf9\u8c61,\u672c\u8eab\u4e5f\u5305\u62ec\u53c2\u6570\uff0c\u5c5e\u4e8e\u6211\u4eec\u8981\u5b9a\u4e49\u7684\u6a21\u5757\u7684\u5b50\u6a21\u5757\u3002 nn.Module\u63d0\u4f9b\u4e86\u4e00\u4e9b\u65b9\u6cd5\u53ef\u4ee5\u7ba1\u7406\u8fd9\u4e9b\u5b50\u6a21\u5757\u3002 children() \u65b9\u6cd5: \u8fd4\u56de\u751f\u6210\u5668\uff0c\u5305\u62ec\u6a21\u5757\u4e0b\u7684\u6240\u6709\u5b50\u6a21\u5757\u3002 named_children()\u65b9\u6cd5\uff1a\u8fd4\u56de\u4e00\u4e2a\u751f\u6210\u5668\uff0c\u5305\u62ec\u6a21\u5757\u4e0b\u7684\u6240\u6709\u5b50\u6a21\u5757\uff0c\u4ee5\u53ca\u5b83\u4eec\u7684\u540d\u5b57\u3002 modules()\u65b9\u6cd5\uff1a\u8fd4\u56de\u4e00\u4e2a\u751f\u6210\u5668\uff0c\u5305\u62ec\u6a21\u5757\u4e0b\u7684\u6240\u6709\u5404\u4e2a\u5c42\u7ea7\u7684\u6a21\u5757\uff0c\u5305\u62ec\u6a21\u5757\u672c\u8eab\u3002 named_modules()\u65b9\u6cd5\uff1a\u8fd4\u56de\u4e00\u4e2a\u751f\u6210\u5668\uff0c\u5305\u62ec\u6a21\u5757\u4e0b\u7684\u6240\u6709\u5404\u4e2a\u5c42\u7ea7\u7684\u6a21\u5757\u4ee5\u53ca\u5b83\u4eec\u7684\u540d\u5b57\uff0c\u5305\u62ec\u6a21\u5757\u672c\u8eab\u3002 \u5176\u4e2dchidren()\u65b9\u6cd5\u548cnamed_children()\u65b9\u6cd5\u8f83\u591a\u4f7f\u7528\u3002 modules()\u65b9\u6cd5\u548cnamed_modules()\u65b9\u6cd5\u8f83\u5c11\u4f7f\u7528\uff0c\u5176\u529f\u80fd\u53ef\u4ee5\u901a\u8fc7\u591a\u4e2anamed_children()\u7684\u5d4c\u5957\u4f7f\u7528\u5b9e\u73b0\u3002 class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . embedding = nn . Embedding ( num_embeddings = 10000 , embedding_dim = 3 , padding_idx = 1 ) self . conv = nn . Sequential () self . conv . add_module ( \"conv_1\" , nn . Conv1d ( in_channels = 3 , out_channels = 16 , kernel_size = 5 )) self . conv . add_module ( \"pool_1\" , nn . MaxPool1d ( kernel_size = 2 )) self . conv . add_module ( \"relu_1\" , nn . ReLU ()) self . conv . add_module ( \"conv_2\" , nn . Conv1d ( in_channels = 16 , out_channels = 128 , kernel_size = 2 )) self . conv . add_module ( \"pool_2\" , nn . MaxPool1d ( kernel_size = 2 )) self . conv . add_module ( \"relu_2\" , nn . ReLU ()) self . dense = nn . Sequential () self . dense . add_module ( \"flatten\" , nn . Flatten ()) self . dense . add_module ( \"linear\" , nn . Linear ( 6144 , 1 )) self . dense . add_module ( \"sigmoid\" , nn . Sigmoid ()) def forward ( self , x ): x = self . embedding ( x ) . transpose ( 1 , 2 ) x = self . conv ( x ) y = self . dense ( x ) return y net = Net () i = 0 for child in net . children (): i += 1 print ( child , \" \\n \" ) print ( \"child number\" , i ) Embedding(10000, 3, padding_idx=1) Sequential( (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,)) (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_1): ReLU() (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,)) (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_2): ReLU() ) Sequential( (flatten): Flatten() (linear): Linear(in_features=6144, out_features=1, bias=True) (sigmoid): Sigmoid() ) child number 3 i = 0 for name , child in net . named_children (): i += 1 print ( name , \":\" , child , \" \\n \" ) print ( \"child number\" , i ) embedding : Embedding(10000, 3, padding_idx=1) conv : Sequential( (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,)) (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_1): ReLU() (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,)) (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_2): ReLU() ) dense : Sequential( (flatten): Flatten() (linear): Linear(in_features=6144, out_features=1, bias=True) (sigmoid): Sigmoid() ) child number 3 i = 0 for module in net . modules (): i += 1 print ( module ) print ( \"module number:\" , i ) Net( (embedding): Embedding(10000, 3, padding_idx=1) (conv): Sequential( (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,)) (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_1): ReLU() (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,)) (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_2): ReLU() ) (dense): Sequential( (flatten): Flatten() (linear): Linear(in_features=6144, out_features=1, bias=True) (sigmoid): Sigmoid() ) ) Embedding(10000, 3, padding_idx=1) Sequential( (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,)) (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_1): ReLU() (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,)) (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_2): ReLU() ) Conv1d(3, 16, kernel_size=(5,), stride=(1,)) MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ReLU() Conv1d(16, 128, kernel_size=(2,), stride=(1,)) MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ReLU() Sequential( (flatten): Flatten() (linear): Linear(in_features=6144, out_features=1, bias=True) (sigmoid): Sigmoid() ) Flatten() Linear(in_features=6144, out_features=1, bias=True) Sigmoid() module number: 13 \u4e0b\u9762\u6211\u4eec\u901a\u8fc7named_children\u65b9\u6cd5\u627e\u5230embedding\u5c42\uff0c\u5e76\u5c06\u5176\u53c2\u6570\u8bbe\u7f6e\u4e3a\u4e0d\u53ef\u8bad\u7ec3(\u76f8\u5f53\u4e8e\u51bb\u7ed3embedding\u5c42)\u3002 children_dict = { name : module for name , module in net . named_children ()} print ( children_dict ) embedding = children_dict [ \"embedding\" ] embedding . requires_grad_ ( False ) #\u51bb\u7ed3\u5176\u53c2\u6570 {'embedding': Embedding(10000, 3, padding_idx=1), 'conv': Sequential( (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,)) (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_1): ReLU() (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,)) (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_2): ReLU() ), 'dense': Sequential( (flatten): Flatten() (linear): Linear(in_features=6144, out_features=1, bias=True) (sigmoid): Sigmoid() )} #\u53ef\u4ee5\u770b\u5230\u5176\u7b2c\u4e00\u5c42\u7684\u53c2\u6570\u5df2\u7ecf\u4e0d\u53ef\u4ee5\u88ab\u8bad\u7ec3\u4e86\u3002 for param in embedding . parameters (): print ( param . requires_grad ) print ( param . numel ()) False 30000 from torchkeras import summary summary ( net , input_shape = ( 200 ,), input_dtype = torch . LongTensor ) # \u4e0d\u53ef\u8bad\u7ec3\u53c2\u6570\u6570\u91cf\u589e\u52a0 ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Embedding-1 [-1, 200, 3] 30,000 Conv1d-2 [-1, 16, 196] 256 MaxPool1d-3 [-1, 16, 98] 0 ReLU-4 [-1, 16, 98] 0 Conv1d-5 [-1, 128, 97] 4,224 MaxPool1d-6 [-1, 128, 48] 0 ReLU-7 [-1, 128, 48] 0 Flatten-8 [-1, 6144] 0 Linear-9 [-1, 1] 6,145 Sigmoid-10 [-1, 1] 0 ================================================================ Total params: 40,625 Trainable params: 10,625 Non-trainable params: 30,000 ---------------------------------------------------------------- Input size (MB): 0.000763 Forward/backward pass size (MB): 0.287796 Params size (MB): 0.154972 Estimated Total Size (MB): 0.443531 ---------------------------------------------------------------- \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"4-3,nn.functional \u548c nn.Module"},{"location":"4.%E4%BD%8E%E9%98%B6API/4-3%2Cnn.functional%E5%92%8Cnn.Module/#4-3nnfunctional-\u548c-nnmodule","text":"import os import datetime #\u6253\u5370\u65f6\u95f4 def printbar (): nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) #mac\u7cfb\u7edf\u4e0apytorch\u548cmatplotlib\u5728jupyter\u4e2d\u540c\u65f6\u8dd1\u9700\u8981\u66f4\u6539\u73af\u5883\u53d8\u91cf os . environ [ \"KMP_DUPLICATE_LIB_OK\" ] = \"TRUE\"","title":"4-3,nn.functional \u548c nn.Module"},{"location":"4.%E4%BD%8E%E9%98%B6API/4-3%2Cnn.functional%E5%92%8Cnn.Module/#\u4e00nnfunctional-\u548c-nnmodule","text":"\u524d\u9762\u6211\u4eec\u4ecb\u7ecd\u4e86Pytorch\u7684\u5f20\u91cf\u7684\u7ed3\u6784\u64cd\u4f5c\u548c\u6570\u5b66\u8fd0\u7b97\u4e2d\u7684\u4e00\u4e9b\u5e38\u7528API\u3002 \u5229\u7528\u8fd9\u4e9b\u5f20\u91cf\u7684API\u6211\u4eec\u53ef\u4ee5\u6784\u5efa\u51fa\u795e\u7ecf\u7f51\u7edc\u76f8\u5173\u7684\u7ec4\u4ef6(\u5982\u6fc0\u6d3b\u51fd\u6570\uff0c\u6a21\u578b\u5c42\uff0c\u635f\u5931\u51fd\u6570)\u3002 Pytorch\u548c\u795e\u7ecf\u7f51\u7edc\u76f8\u5173\u7684\u529f\u80fd\u7ec4\u4ef6\u5927\u591a\u90fd\u5c01\u88c5\u5728 torch.nn\u6a21\u5757\u4e0b\u3002 \u8fd9\u4e9b\u529f\u80fd\u7ec4\u4ef6\u7684\u7edd\u5927\u90e8\u5206\u65e2\u6709\u51fd\u6570\u5f62\u5f0f\u5b9e\u73b0\uff0c\u4e5f\u6709\u7c7b\u5f62\u5f0f\u5b9e\u73b0\u3002 \u5176\u4e2dnn.functional(\u4e00\u822c\u5f15\u5165\u540e\u6539\u540d\u4e3aF)\u6709\u5404\u79cd\u529f\u80fd\u7ec4\u4ef6\u7684\u51fd\u6570\u5b9e\u73b0\u3002\u4f8b\u5982\uff1a (\u6fc0\u6d3b\u51fd\u6570) * F.relu * F.sigmoid * F.tanh * F.softmax (\u6a21\u578b\u5c42) * F.linear * F.conv2d * F.max_pool2d * F.dropout2d * F.embedding (\u635f\u5931\u51fd\u6570) * F.binary_cross_entropy * F.mse_loss * F.cross_entropy \u4e3a\u4e86\u4fbf\u4e8e\u5bf9\u53c2\u6570\u8fdb\u884c\u7ba1\u7406\uff0c\u4e00\u822c\u901a\u8fc7\u7ee7\u627f nn.Module \u8f6c\u6362\u6210\u4e3a\u7c7b\u7684\u5b9e\u73b0\u5f62\u5f0f\uff0c\u5e76\u76f4\u63a5\u5c01\u88c5\u5728 nn \u6a21\u5757\u4e0b\u3002\u4f8b\u5982\uff1a (\u6fc0\u6d3b\u51fd\u6570) * nn.ReLU * nn.Sigmoid * nn.Tanh * nn.Softmax (\u6a21\u578b\u5c42) * nn.Linear * nn.Conv2d * nn.MaxPool2d * nn.Dropout2d * nn.Embedding (\u635f\u5931\u51fd\u6570) * nn.BCELoss * nn.MSELoss * nn.CrossEntropyLoss \u5b9e\u9645\u4e0ann.Module\u9664\u4e86\u53ef\u4ee5\u7ba1\u7406\u5176\u5f15\u7528\u7684\u5404\u79cd\u53c2\u6570\uff0c\u8fd8\u53ef\u4ee5\u7ba1\u7406\u5176\u5f15\u7528\u7684\u5b50\u6a21\u5757\uff0c\u529f\u80fd\u5341\u5206\u5f3a\u5927\u3002","title":"\u4e00\uff0cnn.functional \u548c nn.Module"},{"location":"4.%E4%BD%8E%E9%98%B6API/4-3%2Cnn.functional%E5%92%8Cnn.Module/#\u4e8c\u4f7f\u7528nnmodule\u6765\u7ba1\u7406\u53c2\u6570","text":"\u5728Pytorch\u4e2d\uff0c\u6a21\u578b\u7684\u53c2\u6570\u662f\u9700\u8981\u88ab\u4f18\u5316\u5668\u8bad\u7ec3\u7684\uff0c\u56e0\u6b64\uff0c\u901a\u5e38\u8981\u8bbe\u7f6e\u53c2\u6570\u4e3a requires_grad = True \u7684\u5f20\u91cf\u3002 \u540c\u65f6\uff0c\u5728\u4e00\u4e2a\u6a21\u578b\u4e2d\uff0c\u5f80\u5f80\u6709\u8bb8\u591a\u7684\u53c2\u6570\uff0c\u8981\u624b\u52a8\u7ba1\u7406\u8fd9\u4e9b\u53c2\u6570\u5e76\u4e0d\u662f\u4e00\u4ef6\u5bb9\u6613\u7684\u4e8b\u60c5\u3002 Pytorch\u4e00\u822c\u5c06\u53c2\u6570\u7528nn.Parameter\u6765\u8868\u793a\uff0c\u5e76\u4e14\u7528nn.Module\u6765\u7ba1\u7406\u5176\u7ed3\u6784\u4e0b\u7684\u6240\u6709\u53c2\u6570\u3002 import torch from torch import nn import torch.nn.functional as F from matplotlib import pyplot as plt # nn.Parameter \u5177\u6709 requires_grad = True \u5c5e\u6027 w = nn . Parameter ( torch . randn ( 2 , 2 )) print ( w ) print ( w . requires_grad ) Parameter containing: tensor([[ 0.3544, -1.1643], [ 1.2302, 1.3952]], requires_grad=True) True # nn.ParameterList \u53ef\u4ee5\u5c06\u591a\u4e2ann.Parameter\u7ec4\u6210\u4e00\u4e2a\u5217\u8868 params_list = nn . ParameterList ([ nn . Parameter ( torch . rand ( 8 , i )) for i in range ( 1 , 3 )]) print ( params_list ) print ( params_list [ 0 ] . requires_grad ) ParameterList( (0): Parameter containing: [torch.FloatTensor of size 8x1] (1): Parameter containing: [torch.FloatTensor of size 8x2] ) True # nn.ParameterDict \u53ef\u4ee5\u5c06\u591a\u4e2ann.Parameter\u7ec4\u6210\u4e00\u4e2a\u5b57\u5178 params_dict = nn . ParameterDict ({ \"a\" : nn . Parameter ( torch . rand ( 2 , 2 )), \"b\" : nn . Parameter ( torch . zeros ( 2 ))}) print ( params_dict ) print ( params_dict [ \"a\" ] . requires_grad ) ParameterDict( (a): Parameter containing: [torch.FloatTensor of size 2x2] (b): Parameter containing: [torch.FloatTensor of size 2] ) True # \u53ef\u4ee5\u7528Module\u5c06\u5b83\u4eec\u7ba1\u7406\u8d77\u6765 # module.parameters()\u8fd4\u56de\u4e00\u4e2a\u751f\u6210\u5668\uff0c\u5305\u62ec\u5176\u7ed3\u6784\u4e0b\u7684\u6240\u6709parameters module = nn . Module () module . w = w module . params_list = params_list module . params_dict = params_dict num_param = 0 for param in module . parameters (): print ( param , \" \\n \" ) num_param = num_param + 1 print ( \"number of Parameters =\" , num_param ) Parameter containing: tensor([[ 0.3544, -1.1643], [ 1.2302, 1.3952]], requires_grad=True) Parameter containing: tensor([[0.9391], [0.7590], [0.6899], [0.4786], [0.2392], [0.9645], [0.1968], [0.1353]], requires_grad=True) Parameter containing: tensor([[0.8012, 0.9587], [0.0276, 0.5995], [0.7338, 0.5559], [0.1704, 0.5814], [0.7626, 0.1179], [0.4945, 0.2408], [0.7179, 0.0575], [0.3418, 0.7291]], requires_grad=True) Parameter containing: tensor([[0.7729, 0.2383], [0.7054, 0.9937]], requires_grad=True) Parameter containing: tensor([0., 0.], requires_grad=True) number of Parameters = 5 #\u5b9e\u8df5\u5f53\u4e2d\uff0c\u4e00\u822c\u901a\u8fc7\u7ee7\u627fnn.Module\u6765\u6784\u5efa\u6a21\u5757\u7c7b\uff0c\u5e76\u5c06\u6240\u6709\u542b\u6709\u9700\u8981\u5b66\u4e60\u7684\u53c2\u6570\u7684\u90e8\u5206\u653e\u5728\u6784\u9020\u51fd\u6570\u4e2d\u3002 #\u4ee5\u4e0b\u8303\u4f8b\u4e3aPytorch\u4e2dnn.Linear\u7684\u6e90\u7801\u7684\u7b80\u5316\u7248\u672c #\u53ef\u4ee5\u770b\u5230\u5b83\u5c06\u9700\u8981\u5b66\u4e60\u7684\u53c2\u6570\u653e\u5728\u4e86__init__\u6784\u9020\u51fd\u6570\u4e2d\uff0c\u5e76\u5728forward\u4e2d\u8c03\u7528F.linear\u51fd\u6570\u6765\u5b9e\u73b0\u8ba1\u7b97\u903b\u8f91\u3002 class Linear ( nn . Module ): __constants__ = [ 'in_features' , 'out_features' ] def __init__ ( self , in_features , out_features , bias = True ): super ( Linear , self ) . __init__ () self . in_features = in_features self . out_features = out_features self . weight = nn . Parameter ( torch . Tensor ( out_features , in_features )) if bias : self . bias = nn . Parameter ( torch . Tensor ( out_features )) else : self . register_parameter ( 'bias' , None ) def forward ( self , input ): return F . linear ( input , self . weight , self . bias )","title":"\u4e8c\uff0c\u4f7f\u7528nn.Module\u6765\u7ba1\u7406\u53c2\u6570"},{"location":"4.%E4%BD%8E%E9%98%B6API/4-3%2Cnn.functional%E5%92%8Cnn.Module/#\u4e09\u4f7f\u7528nnmodule\u6765\u7ba1\u7406\u5b50\u6a21\u5757","text":"\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u90fd\u5f88\u5c11\u76f4\u63a5\u4f7f\u7528 nn.Parameter\u6765\u5b9a\u4e49\u53c2\u6570\u6784\u5efa\u6a21\u578b\uff0c\u800c\u662f\u901a\u8fc7\u4e00\u4e9b\u62fc\u88c5\u4e00\u4e9b\u5e38\u7528\u7684\u6a21\u578b\u5c42\u6765\u6784\u9020\u6a21\u578b\u3002 \u8fd9\u4e9b\u6a21\u578b\u5c42\u4e5f\u662f\u7ee7\u627f\u81eann.Module\u7684\u5bf9\u8c61,\u672c\u8eab\u4e5f\u5305\u62ec\u53c2\u6570\uff0c\u5c5e\u4e8e\u6211\u4eec\u8981\u5b9a\u4e49\u7684\u6a21\u5757\u7684\u5b50\u6a21\u5757\u3002 nn.Module\u63d0\u4f9b\u4e86\u4e00\u4e9b\u65b9\u6cd5\u53ef\u4ee5\u7ba1\u7406\u8fd9\u4e9b\u5b50\u6a21\u5757\u3002 children() \u65b9\u6cd5: \u8fd4\u56de\u751f\u6210\u5668\uff0c\u5305\u62ec\u6a21\u5757\u4e0b\u7684\u6240\u6709\u5b50\u6a21\u5757\u3002 named_children()\u65b9\u6cd5\uff1a\u8fd4\u56de\u4e00\u4e2a\u751f\u6210\u5668\uff0c\u5305\u62ec\u6a21\u5757\u4e0b\u7684\u6240\u6709\u5b50\u6a21\u5757\uff0c\u4ee5\u53ca\u5b83\u4eec\u7684\u540d\u5b57\u3002 modules()\u65b9\u6cd5\uff1a\u8fd4\u56de\u4e00\u4e2a\u751f\u6210\u5668\uff0c\u5305\u62ec\u6a21\u5757\u4e0b\u7684\u6240\u6709\u5404\u4e2a\u5c42\u7ea7\u7684\u6a21\u5757\uff0c\u5305\u62ec\u6a21\u5757\u672c\u8eab\u3002 named_modules()\u65b9\u6cd5\uff1a\u8fd4\u56de\u4e00\u4e2a\u751f\u6210\u5668\uff0c\u5305\u62ec\u6a21\u5757\u4e0b\u7684\u6240\u6709\u5404\u4e2a\u5c42\u7ea7\u7684\u6a21\u5757\u4ee5\u53ca\u5b83\u4eec\u7684\u540d\u5b57\uff0c\u5305\u62ec\u6a21\u5757\u672c\u8eab\u3002 \u5176\u4e2dchidren()\u65b9\u6cd5\u548cnamed_children()\u65b9\u6cd5\u8f83\u591a\u4f7f\u7528\u3002 modules()\u65b9\u6cd5\u548cnamed_modules()\u65b9\u6cd5\u8f83\u5c11\u4f7f\u7528\uff0c\u5176\u529f\u80fd\u53ef\u4ee5\u901a\u8fc7\u591a\u4e2anamed_children()\u7684\u5d4c\u5957\u4f7f\u7528\u5b9e\u73b0\u3002 class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . embedding = nn . Embedding ( num_embeddings = 10000 , embedding_dim = 3 , padding_idx = 1 ) self . conv = nn . Sequential () self . conv . add_module ( \"conv_1\" , nn . Conv1d ( in_channels = 3 , out_channels = 16 , kernel_size = 5 )) self . conv . add_module ( \"pool_1\" , nn . MaxPool1d ( kernel_size = 2 )) self . conv . add_module ( \"relu_1\" , nn . ReLU ()) self . conv . add_module ( \"conv_2\" , nn . Conv1d ( in_channels = 16 , out_channels = 128 , kernel_size = 2 )) self . conv . add_module ( \"pool_2\" , nn . MaxPool1d ( kernel_size = 2 )) self . conv . add_module ( \"relu_2\" , nn . ReLU ()) self . dense = nn . Sequential () self . dense . add_module ( \"flatten\" , nn . Flatten ()) self . dense . add_module ( \"linear\" , nn . Linear ( 6144 , 1 )) self . dense . add_module ( \"sigmoid\" , nn . Sigmoid ()) def forward ( self , x ): x = self . embedding ( x ) . transpose ( 1 , 2 ) x = self . conv ( x ) y = self . dense ( x ) return y net = Net () i = 0 for child in net . children (): i += 1 print ( child , \" \\n \" ) print ( \"child number\" , i ) Embedding(10000, 3, padding_idx=1) Sequential( (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,)) (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_1): ReLU() (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,)) (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_2): ReLU() ) Sequential( (flatten): Flatten() (linear): Linear(in_features=6144, out_features=1, bias=True) (sigmoid): Sigmoid() ) child number 3 i = 0 for name , child in net . named_children (): i += 1 print ( name , \":\" , child , \" \\n \" ) print ( \"child number\" , i ) embedding : Embedding(10000, 3, padding_idx=1) conv : Sequential( (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,)) (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_1): ReLU() (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,)) (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_2): ReLU() ) dense : Sequential( (flatten): Flatten() (linear): Linear(in_features=6144, out_features=1, bias=True) (sigmoid): Sigmoid() ) child number 3 i = 0 for module in net . modules (): i += 1 print ( module ) print ( \"module number:\" , i ) Net( (embedding): Embedding(10000, 3, padding_idx=1) (conv): Sequential( (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,)) (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_1): ReLU() (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,)) (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_2): ReLU() ) (dense): Sequential( (flatten): Flatten() (linear): Linear(in_features=6144, out_features=1, bias=True) (sigmoid): Sigmoid() ) ) Embedding(10000, 3, padding_idx=1) Sequential( (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,)) (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_1): ReLU() (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,)) (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_2): ReLU() ) Conv1d(3, 16, kernel_size=(5,), stride=(1,)) MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ReLU() Conv1d(16, 128, kernel_size=(2,), stride=(1,)) MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ReLU() Sequential( (flatten): Flatten() (linear): Linear(in_features=6144, out_features=1, bias=True) (sigmoid): Sigmoid() ) Flatten() Linear(in_features=6144, out_features=1, bias=True) Sigmoid() module number: 13 \u4e0b\u9762\u6211\u4eec\u901a\u8fc7named_children\u65b9\u6cd5\u627e\u5230embedding\u5c42\uff0c\u5e76\u5c06\u5176\u53c2\u6570\u8bbe\u7f6e\u4e3a\u4e0d\u53ef\u8bad\u7ec3(\u76f8\u5f53\u4e8e\u51bb\u7ed3embedding\u5c42)\u3002 children_dict = { name : module for name , module in net . named_children ()} print ( children_dict ) embedding = children_dict [ \"embedding\" ] embedding . requires_grad_ ( False ) #\u51bb\u7ed3\u5176\u53c2\u6570 {'embedding': Embedding(10000, 3, padding_idx=1), 'conv': Sequential( (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,)) (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_1): ReLU() (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,)) (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_2): ReLU() ), 'dense': Sequential( (flatten): Flatten() (linear): Linear(in_features=6144, out_features=1, bias=True) (sigmoid): Sigmoid() )} #\u53ef\u4ee5\u770b\u5230\u5176\u7b2c\u4e00\u5c42\u7684\u53c2\u6570\u5df2\u7ecf\u4e0d\u53ef\u4ee5\u88ab\u8bad\u7ec3\u4e86\u3002 for param in embedding . parameters (): print ( param . requires_grad ) print ( param . numel ()) False 30000 from torchkeras import summary summary ( net , input_shape = ( 200 ,), input_dtype = torch . LongTensor ) # \u4e0d\u53ef\u8bad\u7ec3\u53c2\u6570\u6570\u91cf\u589e\u52a0 ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Embedding-1 [-1, 200, 3] 30,000 Conv1d-2 [-1, 16, 196] 256 MaxPool1d-3 [-1, 16, 98] 0 ReLU-4 [-1, 16, 98] 0 Conv1d-5 [-1, 128, 97] 4,224 MaxPool1d-6 [-1, 128, 48] 0 ReLU-7 [-1, 128, 48] 0 Flatten-8 [-1, 6144] 0 Linear-9 [-1, 1] 6,145 Sigmoid-10 [-1, 1] 0 ================================================================ Total params: 40,625 Trainable params: 10,625 Non-trainable params: 30,000 ---------------------------------------------------------------- Input size (MB): 0.000763 Forward/backward pass size (MB): 0.287796 Params size (MB): 0.154972 Estimated Total Size (MB): 0.443531 ---------------------------------------------------------------- \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e09\uff0c\u4f7f\u7528nn.Module\u6765\u7ba1\u7406\u5b50\u6a21\u5757"},{"location":"5.%E4%B8%AD%E9%98%B6API/","text":"\u4e94\u3001Pytorch\u7684\u4e2d\u9636API # \u6211\u4eec\u5c06\u4e3b\u8981\u4ecb\u7ecdPytorch\u7684\u5982\u4e0b\u4e2d\u9636API \u6570\u636e\u7ba1\u9053 \u6a21\u578b\u5c42 \u635f\u5931\u51fd\u6570 TensorBoard\u53ef\u89c6\u5316 \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u4e2d\u9636API\u5c31\u662f\u3010\u6a21\u578b\u4e4b\u5899\u3011\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e94\u3001Pytorch\u7684\u4e2d\u9636API"},{"location":"5.%E4%B8%AD%E9%98%B6API/#\u4e94pytorch\u7684\u4e2d\u9636api","text":"\u6211\u4eec\u5c06\u4e3b\u8981\u4ecb\u7ecdPytorch\u7684\u5982\u4e0b\u4e2d\u9636API \u6570\u636e\u7ba1\u9053 \u6a21\u578b\u5c42 \u635f\u5931\u51fd\u6570 TensorBoard\u53ef\u89c6\u5316 \u5982\u679c\u628a\u6a21\u578b\u6bd4\u4f5c\u4e00\u4e2a\u623f\u5b50\uff0c\u90a3\u4e48\u4e2d\u9636API\u5c31\u662f\u3010\u6a21\u578b\u4e4b\u5899\u3011\u3002 \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e94\u3001Pytorch\u7684\u4e2d\u9636API"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-1%2CDataset%E5%92%8CDataLoader/","text":"5-1, Dataset\u548cDataLoader # Pytorch\u901a\u5e38\u4f7f\u7528Dataset\u548cDataLoader\u8fd9\u4e24\u4e2a\u5de5\u5177\u7c7b\u6765\u6784\u5efa\u6570\u636e\u7ba1\u9053\u3002 Dataset\u5b9a\u4e49\u4e86\u6570\u636e\u96c6\u7684\u5185\u5bb9\uff0c\u5b83\u76f8\u5f53\u4e8e\u4e00\u4e2a\u7c7b\u4f3c\u5217\u8868\u7684\u6570\u636e\u7ed3\u6784\uff0c\u5177\u6709\u786e\u5b9a\u7684\u957f\u5ea6\uff0c\u80fd\u591f\u7528\u7d22\u5f15\u83b7\u53d6\u6570\u636e\u96c6\u4e2d\u7684\u5143\u7d20\u3002 \u800cDataLoader\u5b9a\u4e49\u4e86\u6309batch\u52a0\u8f7d\u6570\u636e\u96c6\u7684\u65b9\u6cd5\uff0c\u5b83\u662f\u4e00\u4e2a\u5b9e\u73b0\u4e86 __iter__ \u65b9\u6cd5\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\uff0c\u6bcf\u6b21\u8fed\u4ee3\u8f93\u51fa\u4e00\u4e2abatch\u7684\u6570\u636e\u3002 DataLoader\u80fd\u591f\u63a7\u5236batch\u7684\u5927\u5c0f\uff0cbatch\u4e2d\u5143\u7d20\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5c06batch\u7ed3\u679c\u6574\u7406\u6210\u6a21\u578b\u6240\u9700\u8f93\u5165\u5f62\u5f0f\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u80fd\u591f\u4f7f\u7528\u591a\u8fdb\u7a0b\u8bfb\u53d6\u6570\u636e\u3002 \u5728\u7edd\u5927\u90e8\u5206\u60c5\u51b5\u4e0b\uff0c\u7528\u6237\u53ea\u9700\u5b9e\u73b0Dataset\u7684 __len__ \u65b9\u6cd5\u548c __getitem__ \u65b9\u6cd5\uff0c\u5c31\u53ef\u4ee5\u8f7b\u677e\u6784\u5efa\u81ea\u5df1\u7684\u6570\u636e\u96c6\uff0c\u5e76\u7528\u9ed8\u8ba4\u6570\u636e\u7ba1\u9053\u8fdb\u884c\u52a0\u8f7d\u3002 \u4e00\uff0cDataset\u548cDataLoader\u6982\u8ff0 # 1\uff0c\u83b7\u53d6\u4e00\u4e2abatch\u6570\u636e\u7684\u6b65\u9aa4 \u8ba9\u6211\u4eec\u8003\u8651\u4e00\u4e0b\u4ece\u4e00\u4e2a\u6570\u636e\u96c6\u4e2d\u83b7\u53d6\u4e00\u4e2abatch\u7684\u6570\u636e\u9700\u8981\u54ea\u4e9b\u6b65\u9aa4\u3002 (\u5047\u5b9a\u6570\u636e\u96c6\u7684\u7279\u5f81\u548c\u6807\u7b7e\u5206\u522b\u8868\u793a\u4e3a\u5f20\u91cf X \u548c Y \uff0c\u6570\u636e\u96c6\u53ef\u4ee5\u8868\u793a\u4e3a (X,Y) , \u5047\u5b9abatch\u5927\u5c0f\u4e3a m ) 1\uff0c\u9996\u5148\u6211\u4eec\u8981\u786e\u5b9a\u6570\u636e\u96c6\u7684\u957f\u5ea6 n \u3002 \u7ed3\u679c\u7c7b\u4f3c\uff1a n = 1000 \u3002 2\uff0c\u7136\u540e\u6211\u4eec\u4ece 0 \u5230 n-1 \u7684\u8303\u56f4\u4e2d\u62bd\u6837\u51fa m \u4e2a\u6570(batch\u5927\u5c0f)\u3002 \u5047\u5b9a m=4 , \u62ff\u5230\u7684\u7ed3\u679c\u662f\u4e00\u4e2a\u5217\u8868\uff0c\u7c7b\u4f3c\uff1a indices = [1,4,8,9] 3\uff0c\u63a5\u7740\u6211\u4eec\u4ece\u6570\u636e\u96c6\u4e2d\u53bb\u53d6\u8fd9 m \u4e2a\u6570\u5bf9\u5e94\u4e0b\u6807\u7684\u5143\u7d20\u3002 \u62ff\u5230\u7684\u7ed3\u679c\u662f\u4e00\u4e2a\u5143\u7ec4\u5217\u8868\uff0c\u7c7b\u4f3c\uff1a samples = [(X[1],Y[1]),(X[4],Y[4]),(X[8],Y[8]),(X[9],Y[9])] 4\uff0c\u6700\u540e\u6211\u4eec\u5c06\u7ed3\u679c\u6574\u7406\u6210\u4e24\u4e2a\u5f20\u91cf\u4f5c\u4e3a\u8f93\u51fa\u3002 \u62ff\u5230\u7684\u7ed3\u679c\u662f\u4e24\u4e2a\u5f20\u91cf\uff0c\u7c7b\u4f3c batch = (features,labels) \uff0c \u5176\u4e2d features = torch.stack([X[1],X[4],X[8],X[9]]) labels = torch.stack([Y[1],Y[4],Y[8],Y[9]]) 2\uff0cDataset\u548cDataLoader\u7684\u529f\u80fd\u5206\u5de5 \u4e0a\u8ff0\u7b2c1\u4e2a\u6b65\u9aa4\u786e\u5b9a\u6570\u636e\u96c6\u7684\u957f\u5ea6\u662f\u7531 Dataset\u7684 __len__ \u65b9\u6cd5\u5b9e\u73b0\u7684\u3002 \u7b2c2\u4e2a\u6b65\u9aa4\u4ece 0 \u5230 n-1 \u7684\u8303\u56f4\u4e2d\u62bd\u6837\u51fa m \u4e2a\u6570\u7684\u65b9\u6cd5\u662f\u7531 DataLoader\u7684 sampler \u548c batch_sampler \u53c2\u6570\u6307\u5b9a\u7684\u3002 sampler \u53c2\u6570\u6307\u5b9a\u5355\u4e2a\u5143\u7d20\u62bd\u6837\u65b9\u6cd5\uff0c\u4e00\u822c\u65e0\u9700\u7528\u6237\u8bbe\u7f6e\uff0c\u7a0b\u5e8f\u9ed8\u8ba4\u5728DataLoader\u7684\u53c2\u6570 shuffle=True \u65f6\u91c7\u7528\u968f\u673a\u62bd\u6837\uff0c shuffle=False \u65f6\u91c7\u7528\u987a\u5e8f\u62bd\u6837\u3002 batch_sampler \u53c2\u6570\u5c06\u591a\u4e2a\u62bd\u6837\u7684\u5143\u7d20\u6574\u7406\u6210\u4e00\u4e2a\u5217\u8868\uff0c\u4e00\u822c\u65e0\u9700\u7528\u6237\u8bbe\u7f6e\uff0c\u9ed8\u8ba4\u65b9\u6cd5\u5728DataLoader\u7684\u53c2\u6570 drop_last=True \u65f6\u4f1a\u4e22\u5f03\u6570\u636e\u96c6\u6700\u540e\u4e00\u4e2a\u957f\u5ea6\u4e0d\u80fd\u88abbatch\u5927\u5c0f\u6574\u9664\u7684\u6279\u6b21\uff0c\u5728 drop_last=False \u65f6\u4fdd\u7559\u6700\u540e\u4e00\u4e2a\u6279\u6b21\u3002 \u7b2c3\u4e2a\u6b65\u9aa4\u7684\u6838\u5fc3\u903b\u8f91\u6839\u636e\u4e0b\u6807\u53d6\u6570\u636e\u96c6\u4e2d\u7684\u5143\u7d20 \u662f\u7531 Dataset\u7684 __getitem__ \u65b9\u6cd5\u5b9e\u73b0\u7684\u3002 \u7b2c4\u4e2a\u6b65\u9aa4\u7684\u903b\u8f91\u7531DataLoader\u7684\u53c2\u6570 collate_fn \u6307\u5b9a\u3002\u4e00\u822c\u60c5\u51b5\u4e0b\u4e5f\u65e0\u9700\u7528\u6237\u8bbe\u7f6e\u3002 3\uff0cDataset\u548cDataLoader\u7684\u4e3b\u8981\u63a5\u53e3 \u4ee5\u4e0b\u662f Dataset\u548c DataLoader\u7684\u6838\u5fc3\u63a5\u53e3\u903b\u8f91\u4f2a\u4ee3\u7801\uff0c\u4e0d\u5b8c\u5168\u548c\u6e90\u7801\u4e00\u81f4\u3002 import torch class Dataset ( object ): def __init__ ( self ): pass def __len__ ( self ): raise NotImplementedError def __getitem__ ( self , index ): raise NotImplementedError class DataLoader ( object ): def __init__ ( self , dataset , batch_size , collate_fn , shuffle = True , drop_last = False ): self . dataset = dataset self . sampler = torch . utils . data . RandomSampler if shuffle else \\ torch . utils . data . SequentialSampler self . batch_sampler = torch . utils . data . BatchSampler self . sample_iter = self . batch_sampler ( self . sampler ( range ( len ( dataset ))), batch_size = batch_size , drop_last = drop_last ) def __next__ ( self ): indices = next ( self . sample_iter ) batch = self . collate_fn ([ self . dataset [ i ] for i in indices ]) return batch \u4e8c\uff0c\u4f7f\u7528Dataset\u521b\u5efa\u6570\u636e\u96c6 # Dataset\u521b\u5efa\u6570\u636e\u96c6\u5e38\u7528\u7684\u65b9\u6cd5\u6709\uff1a \u4f7f\u7528 torch.utils.data.TensorDataset \u6839\u636eTensor\u521b\u5efa\u6570\u636e\u96c6(numpy\u7684array\uff0cPandas\u7684DataFrame\u9700\u8981\u5148\u8f6c\u6362\u6210Tensor)\u3002 \u4f7f\u7528 torchvision.datasets.ImageFolder \u6839\u636e\u56fe\u7247\u76ee\u5f55\u521b\u5efa\u56fe\u7247\u6570\u636e\u96c6\u3002 \u7ee7\u627f torch.utils.data.Dataset \u521b\u5efa\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u3002 \u6b64\u5916\uff0c\u8fd8\u53ef\u4ee5\u901a\u8fc7 torch.utils.data.random_split \u5c06\u4e00\u4e2a\u6570\u636e\u96c6\u5206\u5272\u6210\u591a\u4efd\uff0c\u5e38\u7528\u4e8e\u5206\u5272\u8bad\u7ec3\u96c6\uff0c\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u3002 \u8c03\u7528Dataset\u7684\u52a0\u6cd5\u8fd0\u7b97\u7b26( + )\u5c06\u591a\u4e2a\u6570\u636e\u96c6\u5408\u5e76\u6210\u4e00\u4e2a\u6570\u636e\u96c6\u3002 1\uff0c\u6839\u636eTensor\u521b\u5efa\u6570\u636e\u96c6 import numpy as np import torch from torch.utils.data import TensorDataset , Dataset , DataLoader , random_split # \u6839\u636eTensor\u521b\u5efa\u6570\u636e\u96c6 from sklearn import datasets iris = datasets . load_iris () ds_iris = TensorDataset ( torch . tensor ( iris . data ), torch . tensor ( iris . target )) # \u5206\u5272\u6210\u8bad\u7ec3\u96c6\u548c\u9884\u6d4b\u96c6 n_train = int ( len ( ds_iris ) * 0.8 ) n_valid = len ( ds_iris ) - n_train ds_train , ds_valid = random_split ( ds_iris ,[ n_train , n_valid ]) print ( type ( ds_iris )) print ( type ( ds_train )) # \u4f7f\u7528DataLoader\u52a0\u8f7d\u6570\u636e\u96c6 dl_train , dl_valid = DataLoader ( ds_train , batch_size = 8 ), DataLoader ( ds_valid , batch_size = 8 ) for features , labels in dl_train : print ( features , labels ) break # \u6f14\u793a\u52a0\u6cd5\u8fd0\u7b97\u7b26\uff08`+`\uff09\u7684\u5408\u5e76\u4f5c\u7528 ds_data = ds_train + ds_valid print ( 'len(ds_train) = ' , len ( ds_train )) print ( 'len(ds_valid) = ' , len ( ds_valid )) print ( 'len(ds_train+ds_valid) = ' , len ( ds_data )) print ( type ( ds_data )) 2\uff0c\u6839\u636e\u56fe\u7247\u76ee\u5f55\u521b\u5efa\u56fe\u7247\u6570\u636e\u96c6 import numpy as np import torch from torch.utils.data import DataLoader from torchvision import transforms , datasets #\u6f14\u793a\u4e00\u4e9b\u5e38\u7528\u7684\u56fe\u7247\u589e\u5f3a\u64cd\u4f5c from PIL import Image img = Image . open ( '../data/cat.jpeg' ) img # \u968f\u673a\u6570\u503c\u7ffb\u8f6c transforms . RandomVerticalFlip ()( img ) #\u968f\u673a\u65cb\u8f6c transforms . RandomRotation ( 45 )( img ) # \u5b9a\u4e49\u56fe\u7247\u589e\u5f3a\u64cd\u4f5c transform_train = transforms . Compose ([ transforms . RandomHorizontalFlip (), #\u968f\u673a\u6c34\u5e73\u7ffb\u8f6c transforms . RandomVerticalFlip (), #\u968f\u673a\u5782\u76f4\u7ffb\u8f6c transforms . RandomRotation ( 45 ), #\u968f\u673a\u572845\u5ea6\u89d2\u5ea6\u5185\u65cb\u8f6c transforms . ToTensor () #\u8f6c\u6362\u6210\u5f20\u91cf ] ) transform_valid = transforms . Compose ([ transforms . ToTensor () ] ) # \u6839\u636e\u56fe\u7247\u76ee\u5f55\u521b\u5efa\u6570\u636e\u96c6 ds_train = datasets . ImageFolder ( \"../data/cifar2/train/\" , transform = transform_train , target_transform = lambda t : torch . tensor ([ t ]) . float ()) ds_valid = datasets . ImageFolder ( \"../data/cifar2/test/\" , transform = transform_train , target_transform = lambda t : torch . tensor ([ t ]) . float ()) print ( ds_train . class_to_idx ) {'0_airplane': 0, '1_automobile': 1} # \u4f7f\u7528DataLoader\u52a0\u8f7d\u6570\u636e\u96c6 dl_train = DataLoader ( ds_train , batch_size = 50 , shuffle = True , num_workers = 3 ) dl_valid = DataLoader ( ds_valid , batch_size = 50 , shuffle = True , num_workers = 3 ) for features , labels in dl_train : print ( features . shape ) print ( labels . shape ) break torch.Size([50, 3, 32, 32]) torch.Size([50, 1]) 3\uff0c\u521b\u5efa\u81ea\u5b9a\u4e49\u6570\u636e\u96c6 \u4e0b\u9762\u901a\u8fc7\u7ee7\u627fDataset\u7c7b\u521b\u5efaimdb\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u7684\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u3002 \u5927\u6982\u601d\u8def\u5982\u4e0b\uff1a\u9996\u5148\uff0c\u5bf9\u8bad\u7ec3\u96c6\u6587\u672c\u5206\u8bcd\u6784\u5efa\u8bcd\u5178\u3002\u7136\u540e\u5c06\u8bad\u7ec3\u96c6\u6587\u672c\u548c\u6d4b\u8bd5\u96c6\u6587\u672c\u6570\u636e\u8f6c\u6362\u6210token\u5355\u8bcd\u7f16\u7801\u3002 \u63a5\u7740\u5c06\u8f6c\u6362\u6210\u5355\u8bcd\u7f16\u7801\u7684\u8bad\u7ec3\u96c6\u6570\u636e\u548c\u6d4b\u8bd5\u96c6\u6570\u636e\u6309\u6837\u672c\u5206\u5272\u6210\u591a\u4e2a\u6587\u4ef6\uff0c\u4e00\u4e2a\u6587\u4ef6\u4ee3\u8868\u4e00\u4e2a\u6837\u672c\u3002 \u6700\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u6839\u636e\u6587\u4ef6\u540d\u5217\u8868\u83b7\u53d6\u5bf9\u5e94\u5e8f\u53f7\u7684\u6837\u672c\u5185\u5bb9\uff0c\u4ece\u800c\u6784\u5efaDataset\u6570\u636e\u96c6\u3002 import numpy as np import pandas as pd from collections import OrderedDict import re , string MAX_WORDS = 10000 # \u4ec5\u8003\u8651\u6700\u9ad8\u9891\u768410000\u4e2a\u8bcd MAX_LEN = 200 # \u6bcf\u4e2a\u6837\u672c\u4fdd\u7559200\u4e2a\u8bcd\u7684\u957f\u5ea6 BATCH_SIZE = 20 train_data_path = 'data/imdb/train.tsv' test_data_path = 'data/imdb/test.tsv' train_token_path = 'data/imdb/train_token.tsv' test_token_path = 'data/imdb/test_token.tsv' train_samples_path = 'data/imdb/train_samples/' test_samples_path = 'data/imdb/test_samples/' \u9996\u5148\u6211\u4eec\u6784\u5efa\u8bcd\u5178\uff0c\u5e76\u4fdd\u7559\u6700\u9ad8\u9891\u7684MAX_WORDS\u4e2a\u8bcd\u3002 ##\u6784\u5efa\u8bcd\u5178 word_count_dict = {} #\u6e05\u6d17\u6587\u672c def clean_text ( text ): lowercase = text . lower () . replace ( \" \\n \" , \" \" ) stripped_html = re . sub ( '<br />' , ' ' , lowercase ) cleaned_punctuation = re . sub ( '[ %s ]' % re . escape ( string . punctuation ), '' , stripped_html ) return cleaned_punctuation with open ( train_data_path , \"r\" , encoding = 'utf-8' ) as f : for line in f : label , text = line . split ( \" \\t \" ) cleaned_text = clean_text ( text ) for word in cleaned_text . split ( \" \" ): word_count_dict [ word ] = word_count_dict . get ( word , 0 ) + 1 df_word_dict = pd . DataFrame ( pd . Series ( word_count_dict , name = \"count\" )) df_word_dict = df_word_dict . sort_values ( by = \"count\" , ascending = False ) df_word_dict = df_word_dict [ 0 : MAX_WORDS - 2 ] # df_word_dict [ \"word_id\" ] = range ( 2 , MAX_WORDS ) #\u7f16\u53f70\u548c1\u5206\u522b\u7559\u7ed9\u672a\u77e5\u8bcd<unkown>\u548c\u586b\u5145<padding> word_id_dict = df_word_dict [ \"word_id\" ] . to_dict () df_word_dict . head ( 10 ) \u7136\u540e\u6211\u4eec\u5229\u7528\u6784\u5efa\u597d\u7684\u8bcd\u5178\uff0c\u5c06\u6587\u672c\u8f6c\u6362\u6210token\u5e8f\u53f7\u3002 #\u8f6c\u6362token # \u586b\u5145\u6587\u672c def pad ( data_list , pad_length ): padded_list = data_list . copy () if len ( data_list ) > pad_length : padded_list = data_list [ - pad_length :] if len ( data_list ) < pad_length : padded_list = [ 1 ] * ( pad_length - len ( data_list )) + data_list return padded_list def text_to_token ( text_file , token_file ): with open ( text_file , \"r\" , encoding = 'utf-8' ) as fin , \\ open ( token_file , \"w\" , encoding = 'utf-8' ) as fout : for line in fin : label , text = line . split ( \" \\t \" ) cleaned_text = clean_text ( text ) word_token_list = [ word_id_dict . get ( word , 0 ) for word in cleaned_text . split ( \" \" )] pad_list = pad ( word_token_list , MAX_LEN ) out_line = label + \" \\t \" + \" \" . join ([ str ( x ) for x in pad_list ]) fout . write ( out_line + \" \\n \" ) text_to_token ( train_data_path , train_token_path ) text_to_token ( test_data_path , test_token_path ) \u63a5\u7740\u5c06token\u6587\u672c\u6309\u7167\u6837\u672c\u5206\u5272\uff0c\u6bcf\u4e2a\u6587\u4ef6\u5b58\u653e\u4e00\u4e2a\u6837\u672c\u7684\u6570\u636e\u3002 # \u5206\u5272\u6837\u672c import os if not os . path . exists ( train_samples_path ): os . mkdir ( train_samples_path ) if not os . path . exists ( test_samples_path ): os . mkdir ( test_samples_path ) def split_samples ( token_path , samples_dir ): with open ( token_path , \"r\" , encoding = 'utf-8' ) as fin : i = 0 for line in fin : with open ( samples_dir + \" %d .txt\" % i , \"w\" , encoding = \"utf-8\" ) as fout : fout . write ( line ) i = i + 1 split_samples ( train_token_path , train_samples_path ) split_samples ( test_token_path , test_samples_path ) print ( os . listdir ( train_samples_path )[ 0 : 100 ]) ['11303.txt', '3644.txt', '19987.txt', '18441.txt', '5235.txt', '17772.txt', '1053.txt', '13514.txt', '8711.txt', '15165.txt', '7422.txt', '8077.txt', '15603.txt', '7344.txt', '1735.txt', '13272.txt', '9369.txt', '18327.txt', '5553.txt', '17014.txt', '4895.txt', '11465.txt', '3122.txt', '19039.txt', '5547.txt', '18333.txt', '17000.txt', '4881.txt', '2228.txt', '11471.txt', '3136.txt', '4659.txt', '15617.txt', '8063.txt', '7350.txt', '12178.txt', '1721.txt', '13266.txt', '14509.txt', '6728.txt', '1047.txt', '13500.txt', '15171.txt', '8705.txt', '7436.txt', '16478.txt', '11317.txt', '3650.txt', '19993.txt', '10009.txt', '5221.txt', '18455.txt', '17766.txt', '3888.txt', '6700.txt', '14247.txt', '9433.txt', '13528.txt', '12636.txt', '15159.txt', '16450.txt', '4117.txt', '19763.txt', '3678.txt', '17996.txt', '2566.txt', '10021.txt', '5209.txt', '17028.txt', '2200.txt', '10747.txt', '11459.txt', '16336.txt', '4671.txt', '19005.txt', '7378.txt', '12150.txt', '1709.txt', '6066.txt', '14521.txt', '9355.txt', '12144.txt', '289.txt', '6072.txt', '9341.txt', '14535.txt', '2214.txt', '10753.txt', '16322.txt', '19011.txt', '4665.txt', '16444.txt', '19777.txt', '4103.txt', '17982.txt', '2572.txt', '10035.txt', '18469.txt', '6714.txt', '9427.txt'] \u4e00\u5207\u51c6\u5907\u5c31\u7eea\uff0c\u6211\u4eec\u53ef\u4ee5\u521b\u5efa\u6570\u636e\u96c6Dataset, \u4ece\u6587\u4ef6\u540d\u79f0\u5217\u8868\u4e2d\u8bfb\u53d6\u6587\u4ef6\u5185\u5bb9\u4e86\u3002 import os class imdbDataset ( Dataset ): def __init__ ( self , samples_dir ): self . samples_dir = samples_dir self . samples_paths = os . listdir ( samples_dir ) def __len__ ( self ): return len ( self . samples_paths ) def __getitem__ ( self , index ): path = self . samples_dir + self . samples_paths [ index ] with open ( path , \"r\" , encoding = \"utf-8\" ) as f : line = f . readline () label , tokens = line . split ( \" \\t \" ) label = torch . tensor ([ float ( label )], dtype = torch . float ) feature = torch . tensor ([ int ( x ) for x in tokens . split ( \" \" )], dtype = torch . long ) return ( feature , label ) ds_train = imdbDataset ( train_samples_path ) ds_test = imdbDataset ( test_samples_path ) print ( len ( ds_train )) print ( len ( ds_test )) 20000 5000 dl_train = DataLoader ( ds_train , batch_size = BATCH_SIZE , shuffle = True , num_workers = 4 ) dl_test = DataLoader ( ds_test , batch_size = BATCH_SIZE , num_workers = 4 ) for features , labels in dl_train : print ( features ) print ( labels ) break tensor([[ 1, 1, 1, ..., 29, 8, 8], [ 13, 11, 247, ..., 0, 0, 8], [8587, 555, 12, ..., 3, 0, 8], ..., [ 1, 1, 1, ..., 2, 0, 8], [ 618, 62, 25, ..., 20, 204, 8], [ 1, 1, 1, ..., 71, 85, 8]]) tensor([[1.], [0.], [0.], [1.], [0.], [1.], [0.], [1.], [1.], [1.], [0.], [0.], [0.], [1.], [0.], [1.], [1.], [1.], [0.], [1.]]) \u6700\u540e\u6784\u5efa\u6a21\u578b\u6d4b\u8bd5\u4e00\u4e0b\u6570\u636e\u96c6\u7ba1\u9053\u662f\u5426\u53ef\u7528\u3002 import torch from torch import nn import importlib from torchkeras import Model , summary class Net ( Model ): def __init__ ( self ): super ( Net , self ) . __init__ () #\u8bbe\u7f6epadding_idx\u53c2\u6570\u540e\u5c06\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5c06\u586b\u5145\u7684token\u59cb\u7ec8\u8d4b\u503c\u4e3a0\u5411\u91cf self . embedding = nn . Embedding ( num_embeddings = MAX_WORDS , embedding_dim = 3 , padding_idx = 1 ) self . conv = nn . Sequential () self . conv . add_module ( \"conv_1\" , nn . Conv1d ( in_channels = 3 , out_channels = 16 , kernel_size = 5 )) self . conv . add_module ( \"pool_1\" , nn . MaxPool1d ( kernel_size = 2 )) self . conv . add_module ( \"relu_1\" , nn . ReLU ()) self . conv . add_module ( \"conv_2\" , nn . Conv1d ( in_channels = 16 , out_channels = 128 , kernel_size = 2 )) self . conv . add_module ( \"pool_2\" , nn . MaxPool1d ( kernel_size = 2 )) self . conv . add_module ( \"relu_2\" , nn . ReLU ()) self . dense = nn . Sequential () self . dense . add_module ( \"flatten\" , nn . Flatten ()) self . dense . add_module ( \"linear\" , nn . Linear ( 6144 , 1 )) self . dense . add_module ( \"sigmoid\" , nn . Sigmoid ()) def forward ( self , x ): x = self . embedding ( x ) . transpose ( 1 , 2 ) x = self . conv ( x ) y = self . dense ( x ) return y model = Net () print ( model ) model . summary ( input_shape = ( 200 ,), input_dtype = torch . LongTensor ) Net( (embedding): Embedding(10000, 3, padding_idx=1) (conv): Sequential( (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,)) (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_1): ReLU() (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,)) (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_2): ReLU() ) (dense): Sequential( (flatten): Flatten() (linear): Linear(in_features=6144, out_features=1, bias=True) (sigmoid): Sigmoid() ) ) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Embedding-1 [-1, 200, 3] 30,000 Conv1d-2 [-1, 16, 196] 256 MaxPool1d-3 [-1, 16, 98] 0 ReLU-4 [-1, 16, 98] 0 Conv1d-5 [-1, 128, 97] 4,224 MaxPool1d-6 [-1, 128, 48] 0 ReLU-7 [-1, 128, 48] 0 Flatten-8 [-1, 6144] 0 Linear-9 [-1, 1] 6,145 Sigmoid-10 [-1, 1] 0 ================================================================ Total params: 40,625 Trainable params: 40,625 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.000763 Forward/backward pass size (MB): 0.287796 Params size (MB): 0.154972 Estimated Total Size (MB): 0.443531 ---------------------------------------------------------------- # \u7f16\u8bd1\u6a21\u578b def accuracy ( y_pred , y_true ): y_pred = torch . where ( y_pred > 0.5 , torch . ones_like ( y_pred , dtype = torch . float32 ), torch . zeros_like ( y_pred , dtype = torch . float32 )) acc = torch . mean ( 1 - torch . abs ( y_true - y_pred )) return acc model . compile ( loss_func = nn . BCELoss (), optimizer = torch . optim . Adagrad ( model . parameters (), lr = 0.02 ), metrics_dict = { \"accuracy\" : accuracy }) # \u8bad\u7ec3\u6a21\u578b dfhistory = model . fit ( 10 , dl_train , dl_val = dl_test , log_step_freq = 200 ) Start Training ... ================================================================================2020-07-11 23:21:53 {'step': 200, 'loss': 0.956, 'accuracy': 0.521} {'step': 400, 'loss': 0.823, 'accuracy': 0.53} {'step': 600, 'loss': 0.774, 'accuracy': 0.545} {'step': 800, 'loss': 0.747, 'accuracy': 0.56} {'step': 1000, 'loss': 0.726, 'accuracy': 0.572} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 1 | 0.726 | 0.572 | 0.661 | 0.613 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-11 23:22:20 {'step': 200, 'loss': 0.605, 'accuracy': 0.668} {'step': 400, 'loss': 0.602, 'accuracy': 0.674} {'step': 600, 'loss': 0.592, 'accuracy': 0.681} {'step': 800, 'loss': 0.584, 'accuracy': 0.687} {'step': 1000, 'loss': 0.575, 'accuracy': 0.696} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 2 | 0.575 | 0.696 | 0.553 | 0.716 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-11 23:25:53 {'step': 200, 'loss': 0.294, 'accuracy': 0.877} {'step': 400, 'loss': 0.299, 'accuracy': 0.875} {'step': 600, 'loss': 0.298, 'accuracy': 0.875} {'step': 800, 'loss': 0.296, 'accuracy': 0.876} {'step': 1000, 'loss': 0.298, 'accuracy': 0.875} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 10 | 0.298 | 0.875 | 0.464 | 0.795 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-11 23:26:19 Finished Training... \u4e09\uff0c\u4f7f\u7528DataLoader\u52a0\u8f7d\u6570\u636e\u96c6 # DataLoader\u80fd\u591f\u63a7\u5236batch\u7684\u5927\u5c0f\uff0cbatch\u4e2d\u5143\u7d20\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5c06batch\u7ed3\u679c\u6574\u7406\u6210\u6a21\u578b\u6240\u9700\u8f93\u5165\u5f62\u5f0f\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u80fd\u591f\u4f7f\u7528\u591a\u8fdb\u7a0b\u8bfb\u53d6\u6570\u636e\u3002 DataLoader\u7684\u51fd\u6570\u7b7e\u540d\u5982\u4e0b\u3002 DataLoader ( dataset , batch_size = 1 , shuffle = False , sampler = None , batch_sampler = None , num_workers = 0 , collate_fn = None , pin_memory = False , drop_last = False , timeout = 0 , worker_init_fn = None , multiprocessing_context = None , ) \u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u4ec5\u4ec5\u4f1a\u914d\u7f6e dataset, batch_size, shuffle, num_workers, drop_last\u8fd9\u4e94\u4e2a\u53c2\u6570\uff0c\u5176\u4ed6\u53c2\u6570\u4f7f\u7528\u9ed8\u8ba4\u503c\u5373\u53ef\u3002 DataLoader\u9664\u4e86\u53ef\u4ee5\u52a0\u8f7d\u6211\u4eec\u524d\u9762\u8bb2\u7684 torch.utils.data.Dataset \u5916\uff0c\u8fd8\u80fd\u591f\u52a0\u8f7d\u53e6\u5916\u4e00\u79cd\u6570\u636e\u96c6 torch.utils.data.IterableDataset\u3002 \u548cDataset\u6570\u636e\u96c6\u76f8\u5f53\u4e8e\u4e00\u79cd\u5217\u8868\u7ed3\u6784\u4e0d\u540c\uff0cIterableDataset\u76f8\u5f53\u4e8e\u4e00\u79cd\u8fed\u4ee3\u5668\u7ed3\u6784\u3002 \u5b83\u66f4\u52a0\u590d\u6742\uff0c\u4e00\u822c\u8f83\u5c11\u4f7f\u7528\u3002 dataset : \u6570\u636e\u96c6 batch_size: \u6279\u6b21\u5927\u5c0f shuffle: \u662f\u5426\u4e71\u5e8f sampler: \u6837\u672c\u91c7\u6837\u51fd\u6570\uff0c\u4e00\u822c\u65e0\u9700\u8bbe\u7f6e\u3002 batch_sampler: \u6279\u6b21\u91c7\u6837\u51fd\u6570\uff0c\u4e00\u822c\u65e0\u9700\u8bbe\u7f6e\u3002 num_workers: \u4f7f\u7528\u591a\u8fdb\u7a0b\u8bfb\u53d6\u6570\u636e\uff0c\u8bbe\u7f6e\u7684\u8fdb\u7a0b\u6570\u3002 collate_fn: \u6574\u7406\u4e00\u4e2a\u6279\u6b21\u6570\u636e\u7684\u51fd\u6570\u3002 pin_memory: \u662f\u5426\u8bbe\u7f6e\u4e3a\u9501\u4e1a\u5185\u5b58\u3002\u9ed8\u8ba4\u4e3aFalse\uff0c\u9501\u4e1a\u5185\u5b58\u4e0d\u4f1a\u4f7f\u7528\u865a\u62df\u5185\u5b58(\u786c\u76d8)\uff0c\u4ece\u9501\u4e1a\u5185\u5b58\u62f7\u8d1d\u5230GPU\u4e0a\u901f\u5ea6\u4f1a\u66f4\u5feb\u3002 drop_last: \u662f\u5426\u4e22\u5f03\u6700\u540e\u4e00\u4e2a\u6837\u672c\u6570\u91cf\u4e0d\u8db3batch_size\u6279\u6b21\u6570\u636e\u3002 timeout: \u52a0\u8f7d\u4e00\u4e2a\u6570\u636e\u6279\u6b21\u7684\u6700\u957f\u7b49\u5f85\u65f6\u95f4\uff0c\u4e00\u822c\u65e0\u9700\u8bbe\u7f6e\u3002 worker_init_fn: \u6bcf\u4e2aworker\u4e2ddataset\u7684\u521d\u59cb\u5316\u51fd\u6570\uff0c\u5e38\u7528\u4e8e IterableDataset\u3002\u4e00\u822c\u4e0d\u4f7f\u7528\u3002 #\u6784\u5efa\u8f93\u5165\u6570\u636e\u7ba1\u9053 ds = TensorDataset ( torch . arange ( 1 , 50 )) dl = DataLoader ( ds , batch_size = 10 , shuffle = True , num_workers = 2 , drop_last = True ) #\u8fed\u4ee3\u6570\u636e for batch , in dl : print ( batch ) tensor([43, 44, 21, 36, 9, 5, 28, 16, 20, 14]) tensor([23, 49, 35, 38, 2, 34, 45, 18, 15, 40]) tensor([26, 6, 27, 39, 8, 4, 24, 19, 32, 17]) tensor([ 1, 29, 11, 47, 12, 22, 48, 42, 10, 7]) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"5-1, Dataset\u548cDataLoader"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-1%2CDataset%E5%92%8CDataLoader/#5-1-dataset\u548cdataloader","text":"Pytorch\u901a\u5e38\u4f7f\u7528Dataset\u548cDataLoader\u8fd9\u4e24\u4e2a\u5de5\u5177\u7c7b\u6765\u6784\u5efa\u6570\u636e\u7ba1\u9053\u3002 Dataset\u5b9a\u4e49\u4e86\u6570\u636e\u96c6\u7684\u5185\u5bb9\uff0c\u5b83\u76f8\u5f53\u4e8e\u4e00\u4e2a\u7c7b\u4f3c\u5217\u8868\u7684\u6570\u636e\u7ed3\u6784\uff0c\u5177\u6709\u786e\u5b9a\u7684\u957f\u5ea6\uff0c\u80fd\u591f\u7528\u7d22\u5f15\u83b7\u53d6\u6570\u636e\u96c6\u4e2d\u7684\u5143\u7d20\u3002 \u800cDataLoader\u5b9a\u4e49\u4e86\u6309batch\u52a0\u8f7d\u6570\u636e\u96c6\u7684\u65b9\u6cd5\uff0c\u5b83\u662f\u4e00\u4e2a\u5b9e\u73b0\u4e86 __iter__ \u65b9\u6cd5\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\uff0c\u6bcf\u6b21\u8fed\u4ee3\u8f93\u51fa\u4e00\u4e2abatch\u7684\u6570\u636e\u3002 DataLoader\u80fd\u591f\u63a7\u5236batch\u7684\u5927\u5c0f\uff0cbatch\u4e2d\u5143\u7d20\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5c06batch\u7ed3\u679c\u6574\u7406\u6210\u6a21\u578b\u6240\u9700\u8f93\u5165\u5f62\u5f0f\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u80fd\u591f\u4f7f\u7528\u591a\u8fdb\u7a0b\u8bfb\u53d6\u6570\u636e\u3002 \u5728\u7edd\u5927\u90e8\u5206\u60c5\u51b5\u4e0b\uff0c\u7528\u6237\u53ea\u9700\u5b9e\u73b0Dataset\u7684 __len__ \u65b9\u6cd5\u548c __getitem__ \u65b9\u6cd5\uff0c\u5c31\u53ef\u4ee5\u8f7b\u677e\u6784\u5efa\u81ea\u5df1\u7684\u6570\u636e\u96c6\uff0c\u5e76\u7528\u9ed8\u8ba4\u6570\u636e\u7ba1\u9053\u8fdb\u884c\u52a0\u8f7d\u3002","title":"5-1, Dataset\u548cDataLoader"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-1%2CDataset%E5%92%8CDataLoader/#\u4e00dataset\u548cdataloader\u6982\u8ff0","text":"1\uff0c\u83b7\u53d6\u4e00\u4e2abatch\u6570\u636e\u7684\u6b65\u9aa4 \u8ba9\u6211\u4eec\u8003\u8651\u4e00\u4e0b\u4ece\u4e00\u4e2a\u6570\u636e\u96c6\u4e2d\u83b7\u53d6\u4e00\u4e2abatch\u7684\u6570\u636e\u9700\u8981\u54ea\u4e9b\u6b65\u9aa4\u3002 (\u5047\u5b9a\u6570\u636e\u96c6\u7684\u7279\u5f81\u548c\u6807\u7b7e\u5206\u522b\u8868\u793a\u4e3a\u5f20\u91cf X \u548c Y \uff0c\u6570\u636e\u96c6\u53ef\u4ee5\u8868\u793a\u4e3a (X,Y) , \u5047\u5b9abatch\u5927\u5c0f\u4e3a m ) 1\uff0c\u9996\u5148\u6211\u4eec\u8981\u786e\u5b9a\u6570\u636e\u96c6\u7684\u957f\u5ea6 n \u3002 \u7ed3\u679c\u7c7b\u4f3c\uff1a n = 1000 \u3002 2\uff0c\u7136\u540e\u6211\u4eec\u4ece 0 \u5230 n-1 \u7684\u8303\u56f4\u4e2d\u62bd\u6837\u51fa m \u4e2a\u6570(batch\u5927\u5c0f)\u3002 \u5047\u5b9a m=4 , \u62ff\u5230\u7684\u7ed3\u679c\u662f\u4e00\u4e2a\u5217\u8868\uff0c\u7c7b\u4f3c\uff1a indices = [1,4,8,9] 3\uff0c\u63a5\u7740\u6211\u4eec\u4ece\u6570\u636e\u96c6\u4e2d\u53bb\u53d6\u8fd9 m \u4e2a\u6570\u5bf9\u5e94\u4e0b\u6807\u7684\u5143\u7d20\u3002 \u62ff\u5230\u7684\u7ed3\u679c\u662f\u4e00\u4e2a\u5143\u7ec4\u5217\u8868\uff0c\u7c7b\u4f3c\uff1a samples = [(X[1],Y[1]),(X[4],Y[4]),(X[8],Y[8]),(X[9],Y[9])] 4\uff0c\u6700\u540e\u6211\u4eec\u5c06\u7ed3\u679c\u6574\u7406\u6210\u4e24\u4e2a\u5f20\u91cf\u4f5c\u4e3a\u8f93\u51fa\u3002 \u62ff\u5230\u7684\u7ed3\u679c\u662f\u4e24\u4e2a\u5f20\u91cf\uff0c\u7c7b\u4f3c batch = (features,labels) \uff0c \u5176\u4e2d features = torch.stack([X[1],X[4],X[8],X[9]]) labels = torch.stack([Y[1],Y[4],Y[8],Y[9]]) 2\uff0cDataset\u548cDataLoader\u7684\u529f\u80fd\u5206\u5de5 \u4e0a\u8ff0\u7b2c1\u4e2a\u6b65\u9aa4\u786e\u5b9a\u6570\u636e\u96c6\u7684\u957f\u5ea6\u662f\u7531 Dataset\u7684 __len__ \u65b9\u6cd5\u5b9e\u73b0\u7684\u3002 \u7b2c2\u4e2a\u6b65\u9aa4\u4ece 0 \u5230 n-1 \u7684\u8303\u56f4\u4e2d\u62bd\u6837\u51fa m \u4e2a\u6570\u7684\u65b9\u6cd5\u662f\u7531 DataLoader\u7684 sampler \u548c batch_sampler \u53c2\u6570\u6307\u5b9a\u7684\u3002 sampler \u53c2\u6570\u6307\u5b9a\u5355\u4e2a\u5143\u7d20\u62bd\u6837\u65b9\u6cd5\uff0c\u4e00\u822c\u65e0\u9700\u7528\u6237\u8bbe\u7f6e\uff0c\u7a0b\u5e8f\u9ed8\u8ba4\u5728DataLoader\u7684\u53c2\u6570 shuffle=True \u65f6\u91c7\u7528\u968f\u673a\u62bd\u6837\uff0c shuffle=False \u65f6\u91c7\u7528\u987a\u5e8f\u62bd\u6837\u3002 batch_sampler \u53c2\u6570\u5c06\u591a\u4e2a\u62bd\u6837\u7684\u5143\u7d20\u6574\u7406\u6210\u4e00\u4e2a\u5217\u8868\uff0c\u4e00\u822c\u65e0\u9700\u7528\u6237\u8bbe\u7f6e\uff0c\u9ed8\u8ba4\u65b9\u6cd5\u5728DataLoader\u7684\u53c2\u6570 drop_last=True \u65f6\u4f1a\u4e22\u5f03\u6570\u636e\u96c6\u6700\u540e\u4e00\u4e2a\u957f\u5ea6\u4e0d\u80fd\u88abbatch\u5927\u5c0f\u6574\u9664\u7684\u6279\u6b21\uff0c\u5728 drop_last=False \u65f6\u4fdd\u7559\u6700\u540e\u4e00\u4e2a\u6279\u6b21\u3002 \u7b2c3\u4e2a\u6b65\u9aa4\u7684\u6838\u5fc3\u903b\u8f91\u6839\u636e\u4e0b\u6807\u53d6\u6570\u636e\u96c6\u4e2d\u7684\u5143\u7d20 \u662f\u7531 Dataset\u7684 __getitem__ \u65b9\u6cd5\u5b9e\u73b0\u7684\u3002 \u7b2c4\u4e2a\u6b65\u9aa4\u7684\u903b\u8f91\u7531DataLoader\u7684\u53c2\u6570 collate_fn \u6307\u5b9a\u3002\u4e00\u822c\u60c5\u51b5\u4e0b\u4e5f\u65e0\u9700\u7528\u6237\u8bbe\u7f6e\u3002 3\uff0cDataset\u548cDataLoader\u7684\u4e3b\u8981\u63a5\u53e3 \u4ee5\u4e0b\u662f Dataset\u548c DataLoader\u7684\u6838\u5fc3\u63a5\u53e3\u903b\u8f91\u4f2a\u4ee3\u7801\uff0c\u4e0d\u5b8c\u5168\u548c\u6e90\u7801\u4e00\u81f4\u3002 import torch class Dataset ( object ): def __init__ ( self ): pass def __len__ ( self ): raise NotImplementedError def __getitem__ ( self , index ): raise NotImplementedError class DataLoader ( object ): def __init__ ( self , dataset , batch_size , collate_fn , shuffle = True , drop_last = False ): self . dataset = dataset self . sampler = torch . utils . data . RandomSampler if shuffle else \\ torch . utils . data . SequentialSampler self . batch_sampler = torch . utils . data . BatchSampler self . sample_iter = self . batch_sampler ( self . sampler ( range ( len ( dataset ))), batch_size = batch_size , drop_last = drop_last ) def __next__ ( self ): indices = next ( self . sample_iter ) batch = self . collate_fn ([ self . dataset [ i ] for i in indices ]) return batch","title":"\u4e00\uff0cDataset\u548cDataLoader\u6982\u8ff0"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-1%2CDataset%E5%92%8CDataLoader/#\u4e8c\u4f7f\u7528dataset\u521b\u5efa\u6570\u636e\u96c6","text":"Dataset\u521b\u5efa\u6570\u636e\u96c6\u5e38\u7528\u7684\u65b9\u6cd5\u6709\uff1a \u4f7f\u7528 torch.utils.data.TensorDataset \u6839\u636eTensor\u521b\u5efa\u6570\u636e\u96c6(numpy\u7684array\uff0cPandas\u7684DataFrame\u9700\u8981\u5148\u8f6c\u6362\u6210Tensor)\u3002 \u4f7f\u7528 torchvision.datasets.ImageFolder \u6839\u636e\u56fe\u7247\u76ee\u5f55\u521b\u5efa\u56fe\u7247\u6570\u636e\u96c6\u3002 \u7ee7\u627f torch.utils.data.Dataset \u521b\u5efa\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u3002 \u6b64\u5916\uff0c\u8fd8\u53ef\u4ee5\u901a\u8fc7 torch.utils.data.random_split \u5c06\u4e00\u4e2a\u6570\u636e\u96c6\u5206\u5272\u6210\u591a\u4efd\uff0c\u5e38\u7528\u4e8e\u5206\u5272\u8bad\u7ec3\u96c6\uff0c\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u3002 \u8c03\u7528Dataset\u7684\u52a0\u6cd5\u8fd0\u7b97\u7b26( + )\u5c06\u591a\u4e2a\u6570\u636e\u96c6\u5408\u5e76\u6210\u4e00\u4e2a\u6570\u636e\u96c6\u3002 1\uff0c\u6839\u636eTensor\u521b\u5efa\u6570\u636e\u96c6 import numpy as np import torch from torch.utils.data import TensorDataset , Dataset , DataLoader , random_split # \u6839\u636eTensor\u521b\u5efa\u6570\u636e\u96c6 from sklearn import datasets iris = datasets . load_iris () ds_iris = TensorDataset ( torch . tensor ( iris . data ), torch . tensor ( iris . target )) # \u5206\u5272\u6210\u8bad\u7ec3\u96c6\u548c\u9884\u6d4b\u96c6 n_train = int ( len ( ds_iris ) * 0.8 ) n_valid = len ( ds_iris ) - n_train ds_train , ds_valid = random_split ( ds_iris ,[ n_train , n_valid ]) print ( type ( ds_iris )) print ( type ( ds_train )) # \u4f7f\u7528DataLoader\u52a0\u8f7d\u6570\u636e\u96c6 dl_train , dl_valid = DataLoader ( ds_train , batch_size = 8 ), DataLoader ( ds_valid , batch_size = 8 ) for features , labels in dl_train : print ( features , labels ) break # \u6f14\u793a\u52a0\u6cd5\u8fd0\u7b97\u7b26\uff08`+`\uff09\u7684\u5408\u5e76\u4f5c\u7528 ds_data = ds_train + ds_valid print ( 'len(ds_train) = ' , len ( ds_train )) print ( 'len(ds_valid) = ' , len ( ds_valid )) print ( 'len(ds_train+ds_valid) = ' , len ( ds_data )) print ( type ( ds_data )) 2\uff0c\u6839\u636e\u56fe\u7247\u76ee\u5f55\u521b\u5efa\u56fe\u7247\u6570\u636e\u96c6 import numpy as np import torch from torch.utils.data import DataLoader from torchvision import transforms , datasets #\u6f14\u793a\u4e00\u4e9b\u5e38\u7528\u7684\u56fe\u7247\u589e\u5f3a\u64cd\u4f5c from PIL import Image img = Image . open ( '../data/cat.jpeg' ) img # \u968f\u673a\u6570\u503c\u7ffb\u8f6c transforms . RandomVerticalFlip ()( img ) #\u968f\u673a\u65cb\u8f6c transforms . RandomRotation ( 45 )( img ) # \u5b9a\u4e49\u56fe\u7247\u589e\u5f3a\u64cd\u4f5c transform_train = transforms . Compose ([ transforms . RandomHorizontalFlip (), #\u968f\u673a\u6c34\u5e73\u7ffb\u8f6c transforms . RandomVerticalFlip (), #\u968f\u673a\u5782\u76f4\u7ffb\u8f6c transforms . RandomRotation ( 45 ), #\u968f\u673a\u572845\u5ea6\u89d2\u5ea6\u5185\u65cb\u8f6c transforms . ToTensor () #\u8f6c\u6362\u6210\u5f20\u91cf ] ) transform_valid = transforms . Compose ([ transforms . ToTensor () ] ) # \u6839\u636e\u56fe\u7247\u76ee\u5f55\u521b\u5efa\u6570\u636e\u96c6 ds_train = datasets . ImageFolder ( \"../data/cifar2/train/\" , transform = transform_train , target_transform = lambda t : torch . tensor ([ t ]) . float ()) ds_valid = datasets . ImageFolder ( \"../data/cifar2/test/\" , transform = transform_train , target_transform = lambda t : torch . tensor ([ t ]) . float ()) print ( ds_train . class_to_idx ) {'0_airplane': 0, '1_automobile': 1} # \u4f7f\u7528DataLoader\u52a0\u8f7d\u6570\u636e\u96c6 dl_train = DataLoader ( ds_train , batch_size = 50 , shuffle = True , num_workers = 3 ) dl_valid = DataLoader ( ds_valid , batch_size = 50 , shuffle = True , num_workers = 3 ) for features , labels in dl_train : print ( features . shape ) print ( labels . shape ) break torch.Size([50, 3, 32, 32]) torch.Size([50, 1]) 3\uff0c\u521b\u5efa\u81ea\u5b9a\u4e49\u6570\u636e\u96c6 \u4e0b\u9762\u901a\u8fc7\u7ee7\u627fDataset\u7c7b\u521b\u5efaimdb\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u7684\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u3002 \u5927\u6982\u601d\u8def\u5982\u4e0b\uff1a\u9996\u5148\uff0c\u5bf9\u8bad\u7ec3\u96c6\u6587\u672c\u5206\u8bcd\u6784\u5efa\u8bcd\u5178\u3002\u7136\u540e\u5c06\u8bad\u7ec3\u96c6\u6587\u672c\u548c\u6d4b\u8bd5\u96c6\u6587\u672c\u6570\u636e\u8f6c\u6362\u6210token\u5355\u8bcd\u7f16\u7801\u3002 \u63a5\u7740\u5c06\u8f6c\u6362\u6210\u5355\u8bcd\u7f16\u7801\u7684\u8bad\u7ec3\u96c6\u6570\u636e\u548c\u6d4b\u8bd5\u96c6\u6570\u636e\u6309\u6837\u672c\u5206\u5272\u6210\u591a\u4e2a\u6587\u4ef6\uff0c\u4e00\u4e2a\u6587\u4ef6\u4ee3\u8868\u4e00\u4e2a\u6837\u672c\u3002 \u6700\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u6839\u636e\u6587\u4ef6\u540d\u5217\u8868\u83b7\u53d6\u5bf9\u5e94\u5e8f\u53f7\u7684\u6837\u672c\u5185\u5bb9\uff0c\u4ece\u800c\u6784\u5efaDataset\u6570\u636e\u96c6\u3002 import numpy as np import pandas as pd from collections import OrderedDict import re , string MAX_WORDS = 10000 # \u4ec5\u8003\u8651\u6700\u9ad8\u9891\u768410000\u4e2a\u8bcd MAX_LEN = 200 # \u6bcf\u4e2a\u6837\u672c\u4fdd\u7559200\u4e2a\u8bcd\u7684\u957f\u5ea6 BATCH_SIZE = 20 train_data_path = 'data/imdb/train.tsv' test_data_path = 'data/imdb/test.tsv' train_token_path = 'data/imdb/train_token.tsv' test_token_path = 'data/imdb/test_token.tsv' train_samples_path = 'data/imdb/train_samples/' test_samples_path = 'data/imdb/test_samples/' \u9996\u5148\u6211\u4eec\u6784\u5efa\u8bcd\u5178\uff0c\u5e76\u4fdd\u7559\u6700\u9ad8\u9891\u7684MAX_WORDS\u4e2a\u8bcd\u3002 ##\u6784\u5efa\u8bcd\u5178 word_count_dict = {} #\u6e05\u6d17\u6587\u672c def clean_text ( text ): lowercase = text . lower () . replace ( \" \\n \" , \" \" ) stripped_html = re . sub ( '<br />' , ' ' , lowercase ) cleaned_punctuation = re . sub ( '[ %s ]' % re . escape ( string . punctuation ), '' , stripped_html ) return cleaned_punctuation with open ( train_data_path , \"r\" , encoding = 'utf-8' ) as f : for line in f : label , text = line . split ( \" \\t \" ) cleaned_text = clean_text ( text ) for word in cleaned_text . split ( \" \" ): word_count_dict [ word ] = word_count_dict . get ( word , 0 ) + 1 df_word_dict = pd . DataFrame ( pd . Series ( word_count_dict , name = \"count\" )) df_word_dict = df_word_dict . sort_values ( by = \"count\" , ascending = False ) df_word_dict = df_word_dict [ 0 : MAX_WORDS - 2 ] # df_word_dict [ \"word_id\" ] = range ( 2 , MAX_WORDS ) #\u7f16\u53f70\u548c1\u5206\u522b\u7559\u7ed9\u672a\u77e5\u8bcd<unkown>\u548c\u586b\u5145<padding> word_id_dict = df_word_dict [ \"word_id\" ] . to_dict () df_word_dict . head ( 10 ) \u7136\u540e\u6211\u4eec\u5229\u7528\u6784\u5efa\u597d\u7684\u8bcd\u5178\uff0c\u5c06\u6587\u672c\u8f6c\u6362\u6210token\u5e8f\u53f7\u3002 #\u8f6c\u6362token # \u586b\u5145\u6587\u672c def pad ( data_list , pad_length ): padded_list = data_list . copy () if len ( data_list ) > pad_length : padded_list = data_list [ - pad_length :] if len ( data_list ) < pad_length : padded_list = [ 1 ] * ( pad_length - len ( data_list )) + data_list return padded_list def text_to_token ( text_file , token_file ): with open ( text_file , \"r\" , encoding = 'utf-8' ) as fin , \\ open ( token_file , \"w\" , encoding = 'utf-8' ) as fout : for line in fin : label , text = line . split ( \" \\t \" ) cleaned_text = clean_text ( text ) word_token_list = [ word_id_dict . get ( word , 0 ) for word in cleaned_text . split ( \" \" )] pad_list = pad ( word_token_list , MAX_LEN ) out_line = label + \" \\t \" + \" \" . join ([ str ( x ) for x in pad_list ]) fout . write ( out_line + \" \\n \" ) text_to_token ( train_data_path , train_token_path ) text_to_token ( test_data_path , test_token_path ) \u63a5\u7740\u5c06token\u6587\u672c\u6309\u7167\u6837\u672c\u5206\u5272\uff0c\u6bcf\u4e2a\u6587\u4ef6\u5b58\u653e\u4e00\u4e2a\u6837\u672c\u7684\u6570\u636e\u3002 # \u5206\u5272\u6837\u672c import os if not os . path . exists ( train_samples_path ): os . mkdir ( train_samples_path ) if not os . path . exists ( test_samples_path ): os . mkdir ( test_samples_path ) def split_samples ( token_path , samples_dir ): with open ( token_path , \"r\" , encoding = 'utf-8' ) as fin : i = 0 for line in fin : with open ( samples_dir + \" %d .txt\" % i , \"w\" , encoding = \"utf-8\" ) as fout : fout . write ( line ) i = i + 1 split_samples ( train_token_path , train_samples_path ) split_samples ( test_token_path , test_samples_path ) print ( os . listdir ( train_samples_path )[ 0 : 100 ]) ['11303.txt', '3644.txt', '19987.txt', '18441.txt', '5235.txt', '17772.txt', '1053.txt', '13514.txt', '8711.txt', '15165.txt', '7422.txt', '8077.txt', '15603.txt', '7344.txt', '1735.txt', '13272.txt', '9369.txt', '18327.txt', '5553.txt', '17014.txt', '4895.txt', '11465.txt', '3122.txt', '19039.txt', '5547.txt', '18333.txt', '17000.txt', '4881.txt', '2228.txt', '11471.txt', '3136.txt', '4659.txt', '15617.txt', '8063.txt', '7350.txt', '12178.txt', '1721.txt', '13266.txt', '14509.txt', '6728.txt', '1047.txt', '13500.txt', '15171.txt', '8705.txt', '7436.txt', '16478.txt', '11317.txt', '3650.txt', '19993.txt', '10009.txt', '5221.txt', '18455.txt', '17766.txt', '3888.txt', '6700.txt', '14247.txt', '9433.txt', '13528.txt', '12636.txt', '15159.txt', '16450.txt', '4117.txt', '19763.txt', '3678.txt', '17996.txt', '2566.txt', '10021.txt', '5209.txt', '17028.txt', '2200.txt', '10747.txt', '11459.txt', '16336.txt', '4671.txt', '19005.txt', '7378.txt', '12150.txt', '1709.txt', '6066.txt', '14521.txt', '9355.txt', '12144.txt', '289.txt', '6072.txt', '9341.txt', '14535.txt', '2214.txt', '10753.txt', '16322.txt', '19011.txt', '4665.txt', '16444.txt', '19777.txt', '4103.txt', '17982.txt', '2572.txt', '10035.txt', '18469.txt', '6714.txt', '9427.txt'] \u4e00\u5207\u51c6\u5907\u5c31\u7eea\uff0c\u6211\u4eec\u53ef\u4ee5\u521b\u5efa\u6570\u636e\u96c6Dataset, \u4ece\u6587\u4ef6\u540d\u79f0\u5217\u8868\u4e2d\u8bfb\u53d6\u6587\u4ef6\u5185\u5bb9\u4e86\u3002 import os class imdbDataset ( Dataset ): def __init__ ( self , samples_dir ): self . samples_dir = samples_dir self . samples_paths = os . listdir ( samples_dir ) def __len__ ( self ): return len ( self . samples_paths ) def __getitem__ ( self , index ): path = self . samples_dir + self . samples_paths [ index ] with open ( path , \"r\" , encoding = \"utf-8\" ) as f : line = f . readline () label , tokens = line . split ( \" \\t \" ) label = torch . tensor ([ float ( label )], dtype = torch . float ) feature = torch . tensor ([ int ( x ) for x in tokens . split ( \" \" )], dtype = torch . long ) return ( feature , label ) ds_train = imdbDataset ( train_samples_path ) ds_test = imdbDataset ( test_samples_path ) print ( len ( ds_train )) print ( len ( ds_test )) 20000 5000 dl_train = DataLoader ( ds_train , batch_size = BATCH_SIZE , shuffle = True , num_workers = 4 ) dl_test = DataLoader ( ds_test , batch_size = BATCH_SIZE , num_workers = 4 ) for features , labels in dl_train : print ( features ) print ( labels ) break tensor([[ 1, 1, 1, ..., 29, 8, 8], [ 13, 11, 247, ..., 0, 0, 8], [8587, 555, 12, ..., 3, 0, 8], ..., [ 1, 1, 1, ..., 2, 0, 8], [ 618, 62, 25, ..., 20, 204, 8], [ 1, 1, 1, ..., 71, 85, 8]]) tensor([[1.], [0.], [0.], [1.], [0.], [1.], [0.], [1.], [1.], [1.], [0.], [0.], [0.], [1.], [0.], [1.], [1.], [1.], [0.], [1.]]) \u6700\u540e\u6784\u5efa\u6a21\u578b\u6d4b\u8bd5\u4e00\u4e0b\u6570\u636e\u96c6\u7ba1\u9053\u662f\u5426\u53ef\u7528\u3002 import torch from torch import nn import importlib from torchkeras import Model , summary class Net ( Model ): def __init__ ( self ): super ( Net , self ) . __init__ () #\u8bbe\u7f6epadding_idx\u53c2\u6570\u540e\u5c06\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5c06\u586b\u5145\u7684token\u59cb\u7ec8\u8d4b\u503c\u4e3a0\u5411\u91cf self . embedding = nn . Embedding ( num_embeddings = MAX_WORDS , embedding_dim = 3 , padding_idx = 1 ) self . conv = nn . Sequential () self . conv . add_module ( \"conv_1\" , nn . Conv1d ( in_channels = 3 , out_channels = 16 , kernel_size = 5 )) self . conv . add_module ( \"pool_1\" , nn . MaxPool1d ( kernel_size = 2 )) self . conv . add_module ( \"relu_1\" , nn . ReLU ()) self . conv . add_module ( \"conv_2\" , nn . Conv1d ( in_channels = 16 , out_channels = 128 , kernel_size = 2 )) self . conv . add_module ( \"pool_2\" , nn . MaxPool1d ( kernel_size = 2 )) self . conv . add_module ( \"relu_2\" , nn . ReLU ()) self . dense = nn . Sequential () self . dense . add_module ( \"flatten\" , nn . Flatten ()) self . dense . add_module ( \"linear\" , nn . Linear ( 6144 , 1 )) self . dense . add_module ( \"sigmoid\" , nn . Sigmoid ()) def forward ( self , x ): x = self . embedding ( x ) . transpose ( 1 , 2 ) x = self . conv ( x ) y = self . dense ( x ) return y model = Net () print ( model ) model . summary ( input_shape = ( 200 ,), input_dtype = torch . LongTensor ) Net( (embedding): Embedding(10000, 3, padding_idx=1) (conv): Sequential( (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,)) (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_1): ReLU() (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,)) (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu_2): ReLU() ) (dense): Sequential( (flatten): Flatten() (linear): Linear(in_features=6144, out_features=1, bias=True) (sigmoid): Sigmoid() ) ) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Embedding-1 [-1, 200, 3] 30,000 Conv1d-2 [-1, 16, 196] 256 MaxPool1d-3 [-1, 16, 98] 0 ReLU-4 [-1, 16, 98] 0 Conv1d-5 [-1, 128, 97] 4,224 MaxPool1d-6 [-1, 128, 48] 0 ReLU-7 [-1, 128, 48] 0 Flatten-8 [-1, 6144] 0 Linear-9 [-1, 1] 6,145 Sigmoid-10 [-1, 1] 0 ================================================================ Total params: 40,625 Trainable params: 40,625 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.000763 Forward/backward pass size (MB): 0.287796 Params size (MB): 0.154972 Estimated Total Size (MB): 0.443531 ---------------------------------------------------------------- # \u7f16\u8bd1\u6a21\u578b def accuracy ( y_pred , y_true ): y_pred = torch . where ( y_pred > 0.5 , torch . ones_like ( y_pred , dtype = torch . float32 ), torch . zeros_like ( y_pred , dtype = torch . float32 )) acc = torch . mean ( 1 - torch . abs ( y_true - y_pred )) return acc model . compile ( loss_func = nn . BCELoss (), optimizer = torch . optim . Adagrad ( model . parameters (), lr = 0.02 ), metrics_dict = { \"accuracy\" : accuracy }) # \u8bad\u7ec3\u6a21\u578b dfhistory = model . fit ( 10 , dl_train , dl_val = dl_test , log_step_freq = 200 ) Start Training ... ================================================================================2020-07-11 23:21:53 {'step': 200, 'loss': 0.956, 'accuracy': 0.521} {'step': 400, 'loss': 0.823, 'accuracy': 0.53} {'step': 600, 'loss': 0.774, 'accuracy': 0.545} {'step': 800, 'loss': 0.747, 'accuracy': 0.56} {'step': 1000, 'loss': 0.726, 'accuracy': 0.572} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 1 | 0.726 | 0.572 | 0.661 | 0.613 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-11 23:22:20 {'step': 200, 'loss': 0.605, 'accuracy': 0.668} {'step': 400, 'loss': 0.602, 'accuracy': 0.674} {'step': 600, 'loss': 0.592, 'accuracy': 0.681} {'step': 800, 'loss': 0.584, 'accuracy': 0.687} {'step': 1000, 'loss': 0.575, 'accuracy': 0.696} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 2 | 0.575 | 0.696 | 0.553 | 0.716 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-11 23:25:53 {'step': 200, 'loss': 0.294, 'accuracy': 0.877} {'step': 400, 'loss': 0.299, 'accuracy': 0.875} {'step': 600, 'loss': 0.298, 'accuracy': 0.875} {'step': 800, 'loss': 0.296, 'accuracy': 0.876} {'step': 1000, 'loss': 0.298, 'accuracy': 0.875} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 10 | 0.298 | 0.875 | 0.464 | 0.795 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-11 23:26:19 Finished Training...","title":"\u4e8c\uff0c\u4f7f\u7528Dataset\u521b\u5efa\u6570\u636e\u96c6"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-1%2CDataset%E5%92%8CDataLoader/#\u4e09\u4f7f\u7528dataloader\u52a0\u8f7d\u6570\u636e\u96c6","text":"DataLoader\u80fd\u591f\u63a7\u5236batch\u7684\u5927\u5c0f\uff0cbatch\u4e2d\u5143\u7d20\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5c06batch\u7ed3\u679c\u6574\u7406\u6210\u6a21\u578b\u6240\u9700\u8f93\u5165\u5f62\u5f0f\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u80fd\u591f\u4f7f\u7528\u591a\u8fdb\u7a0b\u8bfb\u53d6\u6570\u636e\u3002 DataLoader\u7684\u51fd\u6570\u7b7e\u540d\u5982\u4e0b\u3002 DataLoader ( dataset , batch_size = 1 , shuffle = False , sampler = None , batch_sampler = None , num_workers = 0 , collate_fn = None , pin_memory = False , drop_last = False , timeout = 0 , worker_init_fn = None , multiprocessing_context = None , ) \u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u4ec5\u4ec5\u4f1a\u914d\u7f6e dataset, batch_size, shuffle, num_workers, drop_last\u8fd9\u4e94\u4e2a\u53c2\u6570\uff0c\u5176\u4ed6\u53c2\u6570\u4f7f\u7528\u9ed8\u8ba4\u503c\u5373\u53ef\u3002 DataLoader\u9664\u4e86\u53ef\u4ee5\u52a0\u8f7d\u6211\u4eec\u524d\u9762\u8bb2\u7684 torch.utils.data.Dataset \u5916\uff0c\u8fd8\u80fd\u591f\u52a0\u8f7d\u53e6\u5916\u4e00\u79cd\u6570\u636e\u96c6 torch.utils.data.IterableDataset\u3002 \u548cDataset\u6570\u636e\u96c6\u76f8\u5f53\u4e8e\u4e00\u79cd\u5217\u8868\u7ed3\u6784\u4e0d\u540c\uff0cIterableDataset\u76f8\u5f53\u4e8e\u4e00\u79cd\u8fed\u4ee3\u5668\u7ed3\u6784\u3002 \u5b83\u66f4\u52a0\u590d\u6742\uff0c\u4e00\u822c\u8f83\u5c11\u4f7f\u7528\u3002 dataset : \u6570\u636e\u96c6 batch_size: \u6279\u6b21\u5927\u5c0f shuffle: \u662f\u5426\u4e71\u5e8f sampler: \u6837\u672c\u91c7\u6837\u51fd\u6570\uff0c\u4e00\u822c\u65e0\u9700\u8bbe\u7f6e\u3002 batch_sampler: \u6279\u6b21\u91c7\u6837\u51fd\u6570\uff0c\u4e00\u822c\u65e0\u9700\u8bbe\u7f6e\u3002 num_workers: \u4f7f\u7528\u591a\u8fdb\u7a0b\u8bfb\u53d6\u6570\u636e\uff0c\u8bbe\u7f6e\u7684\u8fdb\u7a0b\u6570\u3002 collate_fn: \u6574\u7406\u4e00\u4e2a\u6279\u6b21\u6570\u636e\u7684\u51fd\u6570\u3002 pin_memory: \u662f\u5426\u8bbe\u7f6e\u4e3a\u9501\u4e1a\u5185\u5b58\u3002\u9ed8\u8ba4\u4e3aFalse\uff0c\u9501\u4e1a\u5185\u5b58\u4e0d\u4f1a\u4f7f\u7528\u865a\u62df\u5185\u5b58(\u786c\u76d8)\uff0c\u4ece\u9501\u4e1a\u5185\u5b58\u62f7\u8d1d\u5230GPU\u4e0a\u901f\u5ea6\u4f1a\u66f4\u5feb\u3002 drop_last: \u662f\u5426\u4e22\u5f03\u6700\u540e\u4e00\u4e2a\u6837\u672c\u6570\u91cf\u4e0d\u8db3batch_size\u6279\u6b21\u6570\u636e\u3002 timeout: \u52a0\u8f7d\u4e00\u4e2a\u6570\u636e\u6279\u6b21\u7684\u6700\u957f\u7b49\u5f85\u65f6\u95f4\uff0c\u4e00\u822c\u65e0\u9700\u8bbe\u7f6e\u3002 worker_init_fn: \u6bcf\u4e2aworker\u4e2ddataset\u7684\u521d\u59cb\u5316\u51fd\u6570\uff0c\u5e38\u7528\u4e8e IterableDataset\u3002\u4e00\u822c\u4e0d\u4f7f\u7528\u3002 #\u6784\u5efa\u8f93\u5165\u6570\u636e\u7ba1\u9053 ds = TensorDataset ( torch . arange ( 1 , 50 )) dl = DataLoader ( ds , batch_size = 10 , shuffle = True , num_workers = 2 , drop_last = True ) #\u8fed\u4ee3\u6570\u636e for batch , in dl : print ( batch ) tensor([43, 44, 21, 36, 9, 5, 28, 16, 20, 14]) tensor([23, 49, 35, 38, 2, 34, 45, 18, 15, 40]) tensor([26, 6, 27, 39, 8, 4, 24, 19, 32, 17]) tensor([ 1, 29, 11, 47, 12, 22, 48, 42, 10, 7]) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e09\uff0c\u4f7f\u7528DataLoader\u52a0\u8f7d\u6570\u636e\u96c6"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-2%2C%E6%A8%A1%E5%9E%8B%E5%B1%82/","text":"5-2,\u6a21\u578b\u5c42layers # \u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e00\u822c\u7531\u5404\u79cd\u6a21\u578b\u5c42\u7ec4\u5408\u800c\u6210\u3002 torch.nn\u4e2d\u5185\u7f6e\u4e86\u975e\u5e38\u4e30\u5bcc\u7684\u5404\u79cd\u6a21\u578b\u5c42\u3002\u5b83\u4eec\u90fd\u5c5e\u4e8enn.Module\u7684\u5b50\u7c7b\uff0c\u5177\u5907\u53c2\u6570\u7ba1\u7406\u529f\u80fd\u3002 \u4f8b\u5982\uff1a nn.Linear, nn.Flatten, nn.Dropout, nn.BatchNorm2d nn.Conv2d,nn.AvgPool2d,nn.Conv1d,nn.ConvTranspose2d nn.Embedding,nn.GRU,nn.LSTM nn.Transformer \u5982\u679c\u8fd9\u4e9b\u5185\u7f6e\u6a21\u578b\u5c42\u4e0d\u80fd\u591f\u6ee1\u8db3\u9700\u6c42\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\u5c42\u3002 \u5b9e\u9645\u4e0a\uff0cpytorch\u4e0d\u533a\u5206\u6a21\u578b\u548c\u6a21\u578b\u5c42\uff0c\u90fd\u662f\u901a\u8fc7\u7ee7\u627fnn.Module\u8fdb\u884c\u6784\u5efa\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u53ea\u8981\u7ee7\u627fnn.Module\u57fa\u7c7b\u5e76\u5b9e\u73b0forward\u65b9\u6cd5\u5373\u53ef\u81ea\u5b9a\u4e49\u6a21\u578b\u5c42\u3002 \u4e00\uff0c\u5185\u7f6e\u6a21\u578b\u5c42 # import numpy as np import torch from torch import nn \u4e00\u4e9b\u5e38\u7528\u7684\u5185\u7f6e\u6a21\u578b\u5c42\u7b80\u5355\u4ecb\u7ecd\u5982\u4e0b\u3002 \u57fa\u7840\u5c42 nn.Linear\uff1a\u5168\u8fde\u63a5\u5c42\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u5c42\u7279\u5f81\u6570\u00d7 \u8f93\u51fa\u5c42\u7279\u5f81\u6570(weight)\uff0b \u8f93\u51fa\u5c42\u7279\u5f81\u6570(bias) nn.Flatten\uff1a\u538b\u5e73\u5c42\uff0c\u7528\u4e8e\u5c06\u591a\u7ef4\u5f20\u91cf\u6837\u672c\u538b\u6210\u4e00\u7ef4\u5f20\u91cf\u6837\u672c\u3002 nn.BatchNorm1d\uff1a\u4e00\u7ef4\u6279\u6807\u51c6\u5316\u5c42\u3002\u901a\u8fc7\u7ebf\u6027\u53d8\u6362\u5c06\u8f93\u5165\u6279\u6b21\u7f29\u653e\u5e73\u79fb\u5230\u7a33\u5b9a\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee\u3002\u53ef\u4ee5\u589e\u5f3a\u6a21\u578b\u5bf9\u8f93\u5165\u4e0d\u540c\u5206\u5e03\u7684\u9002\u5e94\u6027\uff0c\u52a0\u5feb\u6a21\u578b\u8bad\u7ec3\u901f\u5ea6\uff0c\u6709\u8f7b\u5fae\u6b63\u5219\u5316\u6548\u679c\u3002\u4e00\u822c\u5728\u6fc0\u6d3b\u51fd\u6570\u4e4b\u524d\u4f7f\u7528\u3002\u53ef\u4ee5\u7528afine\u53c2\u6570\u8bbe\u7f6e\u8be5\u5c42\u662f\u5426\u542b\u6709\u53ef\u4ee5\u8bad\u7ec3\u7684\u53c2\u6570\u3002 nn.BatchNorm2d\uff1a\u4e8c\u7ef4\u6279\u6807\u51c6\u5316\u5c42\u3002 nn.BatchNorm3d\uff1a\u4e09\u7ef4\u6279\u6807\u51c6\u5316\u5c42\u3002 nn.Dropout\uff1a\u4e00\u7ef4\u968f\u673a\u4e22\u5f03\u5c42\u3002\u4e00\u79cd\u6b63\u5219\u5316\u624b\u6bb5\u3002 nn.Dropout2d\uff1a\u4e8c\u7ef4\u968f\u673a\u4e22\u5f03\u5c42\u3002 nn.Dropout3d\uff1a\u4e09\u7ef4\u968f\u673a\u4e22\u5f03\u5c42\u3002 nn.Threshold\uff1a\u9650\u5e45\u5c42\u3002\u5f53\u8f93\u5165\u5927\u4e8e\u6216\u5c0f\u4e8e\u9608\u503c\u8303\u56f4\u65f6\uff0c\u622a\u65ad\u4e4b\u3002 nn.ConstantPad2d\uff1a \u4e8c\u7ef4\u5e38\u6570\u586b\u5145\u5c42\u3002\u5bf9\u4e8c\u7ef4\u5f20\u91cf\u6837\u672c\u586b\u5145\u5e38\u6570\u6269\u5c55\u957f\u5ea6\u3002 nn.ReplicationPad1d\uff1a \u4e00\u7ef4\u590d\u5236\u586b\u5145\u5c42\u3002\u5bf9\u4e00\u7ef4\u5f20\u91cf\u6837\u672c\u901a\u8fc7\u590d\u5236\u8fb9\u7f18\u503c\u586b\u5145\u6269\u5c55\u957f\u5ea6\u3002 nn.ZeroPad2d\uff1a\u4e8c\u7ef4\u96f6\u503c\u586b\u5145\u5c42\u3002\u5bf9\u4e8c\u7ef4\u5f20\u91cf\u6837\u672c\u5728\u8fb9\u7f18\u586b\u51450\u503c. nn.GroupNorm\uff1a\u7ec4\u5f52\u4e00\u5316\u3002\u4e00\u79cd\u66ff\u4ee3\u6279\u5f52\u4e00\u5316\u7684\u65b9\u6cd5\uff0c\u5c06\u901a\u9053\u5206\u6210\u82e5\u5e72\u7ec4\u8fdb\u884c\u5f52\u4e00\u3002\u4e0d\u53d7batch\u5927\u5c0f\u9650\u5236\uff0c\u636e\u79f0\u6027\u80fd\u548c\u6548\u679c\u90fd\u4f18\u4e8eBatchNorm\u3002 nn.LayerNorm\uff1a\u5c42\u5f52\u4e00\u5316\u3002\u8f83\u5c11\u4f7f\u7528\u3002 nn.InstanceNorm2d: \u6837\u672c\u5f52\u4e00\u5316\u3002\u8f83\u5c11\u4f7f\u7528\u3002 \u5404\u79cd\u5f52\u4e00\u5316\u6280\u672f\u53c2\u8003\u5982\u4e0b\u77e5\u4e4e\u6587\u7ae0\u300aFAIR\u4f55\u607a\u660e\u7b49\u4eba\u63d0\u51fa\u7ec4\u5f52\u4e00\u5316\uff1a\u66ff\u4ee3\u6279\u5f52\u4e00\u5316\uff0c\u4e0d\u53d7\u6279\u91cf\u5927\u5c0f\u9650\u5236\u300b https://zhuanlan.zhihu.com/p/34858971 \u5377\u79ef\u7f51\u7edc\u76f8\u5173\u5c42 nn.Conv1d\uff1a\u666e\u901a\u4e00\u7ef4\u5377\u79ef\uff0c\u5e38\u7528\u4e8e\u6587\u672c\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u901a\u9053\u6570\u00d7\u5377\u79ef\u6838\u5c3a\u5bf8(\u59823)\u00d7\u5377\u79ef\u6838\u4e2a\u6570 + \u5377\u79ef\u6838\u5c3a\u5bf8(\u59823\uff09 nn.Conv2d\uff1a\u666e\u901a\u4e8c\u7ef4\u5377\u79ef\uff0c\u5e38\u7528\u4e8e\u56fe\u50cf\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u901a\u9053\u6570\u00d7\u5377\u79ef\u6838\u5c3a\u5bf8(\u59823\u4e583)\u00d7\u5377\u79ef\u6838\u4e2a\u6570 + \u5377\u79ef\u6838\u5c3a\u5bf8(\u59823\u4e583) \u901a\u8fc7\u8c03\u6574dilation\u53c2\u6570\u5927\u4e8e1\uff0c\u53ef\u4ee5\u53d8\u6210\u7a7a\u6d1e\u5377\u79ef\uff0c\u589e\u5927\u5377\u79ef\u6838\u611f\u53d7\u91ce\u3002 \u901a\u8fc7\u8c03\u6574groups\u53c2\u6570\u4e0d\u4e3a1\uff0c\u53ef\u4ee5\u53d8\u6210\u5206\u7ec4\u5377\u79ef\u3002\u5206\u7ec4\u5377\u79ef\u4e2d\u4e0d\u540c\u5206\u7ec4\u4f7f\u7528\u76f8\u540c\u7684\u5377\u79ef\u6838\uff0c\u663e\u8457\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u3002 \u5f53groups\u53c2\u6570\u7b49\u4e8e\u901a\u9053\u6570\u65f6\uff0c\u76f8\u5f53\u4e8etensorflow\u4e2d\u7684\u4e8c\u7ef4\u6df1\u5ea6\u5377\u79ef\u5c42tf.keras.layers.DepthwiseConv2D\u3002 \u5229\u7528\u5206\u7ec4\u5377\u79ef\u548c1\u4e581\u5377\u79ef\u7684\u7ec4\u5408\u64cd\u4f5c\uff0c\u53ef\u4ee5\u6784\u9020\u76f8\u5f53\u4e8eKeras\u4e2d\u7684\u4e8c\u7ef4\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u5c42tf.keras.layers.SeparableConv2D\u3002 nn.Conv3d\uff1a\u666e\u901a\u4e09\u7ef4\u5377\u79ef\uff0c\u5e38\u7528\u4e8e\u89c6\u9891\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u901a\u9053\u6570\u00d7\u5377\u79ef\u6838\u5c3a\u5bf8(\u59823\u4e583\u4e583)\u00d7\u5377\u79ef\u6838\u4e2a\u6570 + \u5377\u79ef\u6838\u5c3a\u5bf8(\u59823\u4e583\u4e583) \u3002 nn.MaxPool1d: \u4e00\u7ef4\u6700\u5927\u6c60\u5316\u3002 nn.MaxPool2d\uff1a\u4e8c\u7ef4\u6700\u5927\u6c60\u5316\u3002\u4e00\u79cd\u4e0b\u91c7\u6837\u65b9\u5f0f\u3002\u6ca1\u6709\u9700\u8981\u8bad\u7ec3\u7684\u53c2\u6570\u3002 nn.MaxPool3d\uff1a\u4e09\u7ef4\u6700\u5927\u6c60\u5316\u3002 nn.AdaptiveMaxPool2d\uff1a\u4e8c\u7ef4\u81ea\u9002\u5e94\u6700\u5927\u6c60\u5316\u3002\u65e0\u8bba\u8f93\u5165\u56fe\u50cf\u7684\u5c3a\u5bf8\u5982\u4f55\u53d8\u5316\uff0c\u8f93\u51fa\u7684\u56fe\u50cf\u5c3a\u5bf8\u662f\u56fa\u5b9a\u7684\u3002 \u8be5\u51fd\u6570\u7684\u5b9e\u73b0\u539f\u7406\uff0c\u5927\u6982\u662f\u901a\u8fc7\u8f93\u5165\u56fe\u50cf\u7684\u5c3a\u5bf8\u548c\u8981\u5f97\u5230\u7684\u8f93\u51fa\u56fe\u50cf\u7684\u5c3a\u5bf8\u6765\u53cd\u5411\u63a8\u7b97\u6c60\u5316\u7b97\u5b50\u7684padding,stride\u7b49\u53c2\u6570\u3002 nn.FractionalMaxPool2d\uff1a\u4e8c\u7ef4\u5206\u6570\u6700\u5927\u6c60\u5316\u3002\u666e\u901a\u6700\u5927\u6c60\u5316\u901a\u5e38\u8f93\u5165\u5c3a\u5bf8\u662f\u8f93\u51fa\u7684\u6574\u6570\u500d\u3002\u800c\u5206\u6570\u6700\u5927\u6c60\u5316\u5219\u53ef\u4ee5\u4e0d\u5fc5\u662f\u6574\u6570\u3002\u5206\u6570\u6700\u5927\u6c60\u5316\u4f7f\u7528\u4e86\u4e00\u4e9b\u968f\u673a\u91c7\u6837\u7b56\u7565\uff0c\u6709\u4e00\u5b9a\u7684\u6b63\u5219\u6548\u679c\uff0c\u53ef\u4ee5\u7528\u5b83\u6765\u4ee3\u66ff\u666e\u901a\u6700\u5927\u6c60\u5316\u548cDropout\u5c42\u3002 nn.AvgPool2d\uff1a\u4e8c\u7ef4\u5e73\u5747\u6c60\u5316\u3002 nn.AdaptiveAvgPool2d\uff1a\u4e8c\u7ef4\u81ea\u9002\u5e94\u5e73\u5747\u6c60\u5316\u3002\u65e0\u8bba\u8f93\u5165\u7684\u7ef4\u5ea6\u5982\u4f55\u53d8\u5316\uff0c\u8f93\u51fa\u7684\u7ef4\u5ea6\u662f\u56fa\u5b9a\u7684\u3002 nn.ConvTranspose2d\uff1a\u4e8c\u7ef4\u5377\u79ef\u8f6c\u7f6e\u5c42\uff0c\u4fd7\u79f0\u53cd\u5377\u79ef\u5c42\u3002\u5e76\u975e\u5377\u79ef\u7684\u9006\u64cd\u4f5c\uff0c\u4f46\u5728\u5377\u79ef\u6838\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\uff0c\u5f53\u5176\u8f93\u5165\u5c3a\u5bf8\u662f\u5377\u79ef\u64cd\u4f5c\u8f93\u51fa\u5c3a\u5bf8\u7684\u60c5\u51b5\u4e0b\uff0c\u5377\u79ef\u8f6c\u7f6e\u7684\u8f93\u51fa\u5c3a\u5bf8\u6070\u597d\u662f\u5377\u79ef\u64cd\u4f5c\u7684\u8f93\u5165\u5c3a\u5bf8\u3002\u5728\u8bed\u4e49\u5206\u5272\u4e2d\u53ef\u7528\u4e8e\u4e0a\u91c7\u6837\u3002 nn.Upsample\uff1a\u4e0a\u91c7\u6837\u5c42\uff0c\u64cd\u4f5c\u6548\u679c\u548c\u6c60\u5316\u76f8\u53cd\u3002\u53ef\u4ee5\u901a\u8fc7mode\u53c2\u6570\u63a7\u5236\u4e0a\u91c7\u6837\u7b56\u7565\u4e3a\"nearest\"\u6700\u90bb\u8fd1\u7b56\u7565\u6216\"linear\"\u7ebf\u6027\u63d2\u503c\u7b56\u7565\u3002 nn.Unfold\uff1a\u6ed1\u52a8\u7a97\u53e3\u63d0\u53d6\u5c42\u3002\u5176\u53c2\u6570\u548c\u5377\u79ef\u64cd\u4f5cnn.Conv2d\u76f8\u540c\u3002\u5b9e\u9645\u4e0a\uff0c\u5377\u79ef\u64cd\u4f5c\u53ef\u4ee5\u7b49\u4ef7\u4e8enn.Unfold\u548cnn.Linear\u4ee5\u53cann.Fold\u7684\u4e00\u4e2a\u7ec4\u5408\u3002 \u5176\u4e2dnn.Unfold\u64cd\u4f5c\u53ef\u4ee5\u4ece\u8f93\u5165\u4e2d\u63d0\u53d6\u5404\u4e2a\u6ed1\u52a8\u7a97\u53e3\u7684\u6570\u503c\u77e9\u9635\uff0c\u5e76\u5c06\u5176\u538b\u5e73\u6210\u4e00\u7ef4\u3002\u5229\u7528nn.Linear\u5c06nn.Unfold\u7684\u8f93\u51fa\u548c\u5377\u79ef\u6838\u505a\u4e58\u6cd5\u540e\uff0c\u518d\u4f7f\u7528 nn.Fold\u64cd\u4f5c\u5c06\u7ed3\u679c\u8f6c\u6362\u6210\u8f93\u51fa\u56fe\u7247\u5f62\u72b6\u3002 nn.Fold\uff1a\u9006\u6ed1\u52a8\u7a97\u53e3\u63d0\u53d6\u5c42\u3002 \u5faa\u73af\u7f51\u7edc\u76f8\u5173\u5c42 nn.Embedding\uff1a\u5d4c\u5165\u5c42\u3002\u4e00\u79cd\u6bd4Onehot\u66f4\u52a0\u6709\u6548\u7684\u5bf9\u79bb\u6563\u7279\u5f81\u8fdb\u884c\u7f16\u7801\u7684\u65b9\u6cd5\u3002\u4e00\u822c\u7528\u4e8e\u5c06\u8f93\u5165\u4e2d\u7684\u5355\u8bcd\u6620\u5c04\u4e3a\u7a20\u5bc6\u5411\u91cf\u3002\u5d4c\u5165\u5c42\u7684\u53c2\u6570\u9700\u8981\u5b66\u4e60\u3002 nn.LSTM\uff1a\u957f\u77ed\u8bb0\u5fc6\u5faa\u73af\u7f51\u7edc\u5c42\u3010\u652f\u6301\u591a\u5c42\u3011\u3002\u6700\u666e\u904d\u4f7f\u7528\u7684\u5faa\u73af\u7f51\u7edc\u5c42\u3002\u5177\u6709\u643a\u5e26\u8f68\u9053\uff0c\u9057\u5fd8\u95e8\uff0c\u66f4\u65b0\u95e8\uff0c\u8f93\u51fa\u95e8\u3002\u53ef\u4ee5\u8f83\u4e3a\u6709\u6548\u5730\u7f13\u89e3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u4ece\u800c\u80fd\u591f\u9002\u7528\u957f\u671f\u4f9d\u8d56\u95ee\u9898\u3002\u8bbe\u7f6ebidirectional = True\u65f6\u53ef\u4ee5\u5f97\u5230\u53cc\u5411LSTM\u3002\u9700\u8981\u6ce8\u610f\u7684\u65f6\uff0c\u9ed8\u8ba4\u7684\u8f93\u5165\u548c\u8f93\u51fa\u5f62\u72b6\u662f(seq,batch,feature), \u5982\u679c\u9700\u8981\u5c06batch\u7ef4\u5ea6\u653e\u5728\u7b2c0\u7ef4\uff0c\u5219\u8981\u8bbe\u7f6ebatch_first\u53c2\u6570\u8bbe\u7f6e\u4e3aTrue\u3002 nn.GRU\uff1a\u95e8\u63a7\u5faa\u73af\u7f51\u7edc\u5c42\u3010\u652f\u6301\u591a\u5c42\u3011\u3002LSTM\u7684\u4f4e\u914d\u7248\uff0c\u4e0d\u5177\u6709\u643a\u5e26\u8f68\u9053\uff0c\u53c2\u6570\u6570\u91cf\u5c11\u4e8eLSTM\uff0c\u8bad\u7ec3\u901f\u5ea6\u66f4\u5feb\u3002 nn.RNN\uff1a\u7b80\u5355\u5faa\u73af\u7f51\u7edc\u5c42\u3010\u652f\u6301\u591a\u5c42\u3011\u3002\u5bb9\u6613\u5b58\u5728\u68af\u5ea6\u6d88\u5931\uff0c\u4e0d\u80fd\u591f\u9002\u7528\u957f\u671f\u4f9d\u8d56\u95ee\u9898\u3002\u4e00\u822c\u8f83\u5c11\u4f7f\u7528\u3002 nn.LSTMCell\uff1a\u957f\u77ed\u8bb0\u5fc6\u5faa\u73af\u7f51\u7edc\u5355\u5143\u3002\u548cnn.LSTM\u5728\u6574\u4e2a\u5e8f\u5217\u4e0a\u8fed\u4ee3\u76f8\u6bd4\uff0c\u5b83\u4ec5\u5728\u5e8f\u5217\u4e0a\u8fed\u4ee3\u4e00\u6b65\u3002\u4e00\u822c\u8f83\u5c11\u4f7f\u7528\u3002 nn.GRUCell\uff1a\u95e8\u63a7\u5faa\u73af\u7f51\u7edc\u5355\u5143\u3002\u548cnn.GRU\u5728\u6574\u4e2a\u5e8f\u5217\u4e0a\u8fed\u4ee3\u76f8\u6bd4\uff0c\u5b83\u4ec5\u5728\u5e8f\u5217\u4e0a\u8fed\u4ee3\u4e00\u6b65\u3002\u4e00\u822c\u8f83\u5c11\u4f7f\u7528\u3002 nn.RNNCell\uff1a\u7b80\u5355\u5faa\u73af\u7f51\u7edc\u5355\u5143\u3002\u548cnn.RNN\u5728\u6574\u4e2a\u5e8f\u5217\u4e0a\u8fed\u4ee3\u76f8\u6bd4\uff0c\u5b83\u4ec5\u5728\u5e8f\u5217\u4e0a\u8fed\u4ee3\u4e00\u6b65\u3002\u4e00\u822c\u8f83\u5c11\u4f7f\u7528\u3002 Transformer\u76f8\u5173\u5c42 nn.Transformer\uff1aTransformer\u7f51\u7edc\u7ed3\u6784\u3002Transformer\u7f51\u7edc\u7ed3\u6784\u662f\u66ff\u4ee3\u5faa\u73af\u7f51\u7edc\u7684\u4e00\u79cd\u7ed3\u6784\uff0c\u89e3\u51b3\u4e86\u5faa\u73af\u7f51\u7edc\u96be\u4ee5\u5e76\u884c\uff0c\u96be\u4ee5\u6355\u6349\u957f\u671f\u4f9d\u8d56\u7684\u7f3a\u9677\u3002\u5b83\u662f\u76ee\u524dNLP\u4efb\u52a1\u7684\u4e3b\u6d41\u6a21\u578b\u7684\u4e3b\u8981\u6784\u6210\u90e8\u5206\u3002Transformer\u7f51\u7edc\u7ed3\u6784\u7531TransformerEncoder\u7f16\u7801\u5668\u548cTransformerDecoder\u89e3\u7801\u5668\u7ec4\u6210\u3002\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u7684\u6838\u5fc3\u662fMultiheadAttention\u591a\u5934\u6ce8\u610f\u529b\u5c42\u3002 nn.TransformerEncoder\uff1aTransformer\u7f16\u7801\u5668\u7ed3\u6784\u3002\u7531\u591a\u4e2a nn.TransformerEncoderLayer\u7f16\u7801\u5668\u5c42\u7ec4\u6210\u3002 nn.TransformerDecoder\uff1aTransformer\u89e3\u7801\u5668\u7ed3\u6784\u3002\u7531\u591a\u4e2a nn.TransformerDecoderLayer\u89e3\u7801\u5668\u5c42\u7ec4\u6210\u3002 nn.TransformerEncoderLayer\uff1aTransformer\u7684\u7f16\u7801\u5668\u5c42\u3002 nn.TransformerDecoderLayer\uff1aTransformer\u7684\u89e3\u7801\u5668\u5c42\u3002 nn.MultiheadAttention\uff1a\u591a\u5934\u6ce8\u610f\u529b\u5c42\u3002 Transformer\u539f\u7406\u4ecb\u7ecd\u53ef\u4ee5\u53c2\u8003\u5982\u4e0b\u77e5\u4e4e\u6587\u7ae0\u300a\u8be6\u89e3Transformer(Attention Is All You Need)\u300b https://zhuanlan.zhihu.com/p/48508221 \u4e8c\uff0c\u81ea\u5b9a\u4e49\u6a21\u578b\u5c42 # \u5982\u679cPytorch\u7684\u5185\u7f6e\u6a21\u578b\u5c42\u4e0d\u80fd\u591f\u6ee1\u8db3\u9700\u6c42\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\u5c42\u3002 \u5b9e\u9645\u4e0a\uff0cpytorch\u4e0d\u533a\u5206\u6a21\u578b\u548c\u6a21\u578b\u5c42\uff0c\u90fd\u662f\u901a\u8fc7\u7ee7\u627fnn.Module\u8fdb\u884c\u6784\u5efa\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u53ea\u8981\u7ee7\u627fnn.Module\u57fa\u7c7b\u5e76\u5b9e\u73b0forward\u65b9\u6cd5\u5373\u53ef\u81ea\u5b9a\u4e49\u6a21\u578b\u5c42\u3002 \u4e0b\u9762\u662fPytorch\u7684nn.Linear\u5c42\u7684\u6e90\u7801\uff0c\u6211\u4eec\u53ef\u4ee5\u4eff\u7167\u5b83\u6765\u81ea\u5b9a\u4e49\u6a21\u578b\u5c42\u3002 import torch from torch import nn import torch.nn.functional as F class Linear ( nn . Module ): __constants__ = [ 'in_features' , 'out_features' ] def __init__ ( self , in_features , out_features , bias = True ): super ( Linear , self ) . __init__ () self . in_features = in_features self . out_features = out_features self . weight = nn . Parameter ( torch . Tensor ( out_features , in_features )) if bias : self . bias = nn . Parameter ( torch . Tensor ( out_features )) else : self . register_parameter ( 'bias' , None ) self . reset_parameters () def reset_parameters ( self ): nn . init . kaiming_uniform_ ( self . weight , a = math . sqrt ( 5 )) if self . bias is not None : fan_in , _ = nn . init . _calculate_fan_in_and_fan_out ( self . weight ) bound = 1 / math . sqrt ( fan_in ) nn . init . uniform_ ( self . bias , - bound , bound ) def forward ( self , input ): return F . linear ( input , self . weight , self . bias ) def extra_repr ( self ): return 'in_features= {} , out_features= {} , bias= {} ' . format ( self . in_features , self . out_features , self . bias is not None ) linear = nn . Linear ( 20 , 30 ) inputs = torch . randn ( 128 , 20 ) output = linear ( inputs ) print ( output . size ()) torch.Size([128, 30]) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"5-2,\u6a21\u578b\u5c42layers"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-2%2C%E6%A8%A1%E5%9E%8B%E5%B1%82/#5-2\u6a21\u578b\u5c42layers","text":"\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e00\u822c\u7531\u5404\u79cd\u6a21\u578b\u5c42\u7ec4\u5408\u800c\u6210\u3002 torch.nn\u4e2d\u5185\u7f6e\u4e86\u975e\u5e38\u4e30\u5bcc\u7684\u5404\u79cd\u6a21\u578b\u5c42\u3002\u5b83\u4eec\u90fd\u5c5e\u4e8enn.Module\u7684\u5b50\u7c7b\uff0c\u5177\u5907\u53c2\u6570\u7ba1\u7406\u529f\u80fd\u3002 \u4f8b\u5982\uff1a nn.Linear, nn.Flatten, nn.Dropout, nn.BatchNorm2d nn.Conv2d,nn.AvgPool2d,nn.Conv1d,nn.ConvTranspose2d nn.Embedding,nn.GRU,nn.LSTM nn.Transformer \u5982\u679c\u8fd9\u4e9b\u5185\u7f6e\u6a21\u578b\u5c42\u4e0d\u80fd\u591f\u6ee1\u8db3\u9700\u6c42\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\u5c42\u3002 \u5b9e\u9645\u4e0a\uff0cpytorch\u4e0d\u533a\u5206\u6a21\u578b\u548c\u6a21\u578b\u5c42\uff0c\u90fd\u662f\u901a\u8fc7\u7ee7\u627fnn.Module\u8fdb\u884c\u6784\u5efa\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u53ea\u8981\u7ee7\u627fnn.Module\u57fa\u7c7b\u5e76\u5b9e\u73b0forward\u65b9\u6cd5\u5373\u53ef\u81ea\u5b9a\u4e49\u6a21\u578b\u5c42\u3002","title":"5-2,\u6a21\u578b\u5c42layers"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-2%2C%E6%A8%A1%E5%9E%8B%E5%B1%82/#\u4e00\u5185\u7f6e\u6a21\u578b\u5c42","text":"import numpy as np import torch from torch import nn \u4e00\u4e9b\u5e38\u7528\u7684\u5185\u7f6e\u6a21\u578b\u5c42\u7b80\u5355\u4ecb\u7ecd\u5982\u4e0b\u3002 \u57fa\u7840\u5c42 nn.Linear\uff1a\u5168\u8fde\u63a5\u5c42\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u5c42\u7279\u5f81\u6570\u00d7 \u8f93\u51fa\u5c42\u7279\u5f81\u6570(weight)\uff0b \u8f93\u51fa\u5c42\u7279\u5f81\u6570(bias) nn.Flatten\uff1a\u538b\u5e73\u5c42\uff0c\u7528\u4e8e\u5c06\u591a\u7ef4\u5f20\u91cf\u6837\u672c\u538b\u6210\u4e00\u7ef4\u5f20\u91cf\u6837\u672c\u3002 nn.BatchNorm1d\uff1a\u4e00\u7ef4\u6279\u6807\u51c6\u5316\u5c42\u3002\u901a\u8fc7\u7ebf\u6027\u53d8\u6362\u5c06\u8f93\u5165\u6279\u6b21\u7f29\u653e\u5e73\u79fb\u5230\u7a33\u5b9a\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee\u3002\u53ef\u4ee5\u589e\u5f3a\u6a21\u578b\u5bf9\u8f93\u5165\u4e0d\u540c\u5206\u5e03\u7684\u9002\u5e94\u6027\uff0c\u52a0\u5feb\u6a21\u578b\u8bad\u7ec3\u901f\u5ea6\uff0c\u6709\u8f7b\u5fae\u6b63\u5219\u5316\u6548\u679c\u3002\u4e00\u822c\u5728\u6fc0\u6d3b\u51fd\u6570\u4e4b\u524d\u4f7f\u7528\u3002\u53ef\u4ee5\u7528afine\u53c2\u6570\u8bbe\u7f6e\u8be5\u5c42\u662f\u5426\u542b\u6709\u53ef\u4ee5\u8bad\u7ec3\u7684\u53c2\u6570\u3002 nn.BatchNorm2d\uff1a\u4e8c\u7ef4\u6279\u6807\u51c6\u5316\u5c42\u3002 nn.BatchNorm3d\uff1a\u4e09\u7ef4\u6279\u6807\u51c6\u5316\u5c42\u3002 nn.Dropout\uff1a\u4e00\u7ef4\u968f\u673a\u4e22\u5f03\u5c42\u3002\u4e00\u79cd\u6b63\u5219\u5316\u624b\u6bb5\u3002 nn.Dropout2d\uff1a\u4e8c\u7ef4\u968f\u673a\u4e22\u5f03\u5c42\u3002 nn.Dropout3d\uff1a\u4e09\u7ef4\u968f\u673a\u4e22\u5f03\u5c42\u3002 nn.Threshold\uff1a\u9650\u5e45\u5c42\u3002\u5f53\u8f93\u5165\u5927\u4e8e\u6216\u5c0f\u4e8e\u9608\u503c\u8303\u56f4\u65f6\uff0c\u622a\u65ad\u4e4b\u3002 nn.ConstantPad2d\uff1a \u4e8c\u7ef4\u5e38\u6570\u586b\u5145\u5c42\u3002\u5bf9\u4e8c\u7ef4\u5f20\u91cf\u6837\u672c\u586b\u5145\u5e38\u6570\u6269\u5c55\u957f\u5ea6\u3002 nn.ReplicationPad1d\uff1a \u4e00\u7ef4\u590d\u5236\u586b\u5145\u5c42\u3002\u5bf9\u4e00\u7ef4\u5f20\u91cf\u6837\u672c\u901a\u8fc7\u590d\u5236\u8fb9\u7f18\u503c\u586b\u5145\u6269\u5c55\u957f\u5ea6\u3002 nn.ZeroPad2d\uff1a\u4e8c\u7ef4\u96f6\u503c\u586b\u5145\u5c42\u3002\u5bf9\u4e8c\u7ef4\u5f20\u91cf\u6837\u672c\u5728\u8fb9\u7f18\u586b\u51450\u503c. nn.GroupNorm\uff1a\u7ec4\u5f52\u4e00\u5316\u3002\u4e00\u79cd\u66ff\u4ee3\u6279\u5f52\u4e00\u5316\u7684\u65b9\u6cd5\uff0c\u5c06\u901a\u9053\u5206\u6210\u82e5\u5e72\u7ec4\u8fdb\u884c\u5f52\u4e00\u3002\u4e0d\u53d7batch\u5927\u5c0f\u9650\u5236\uff0c\u636e\u79f0\u6027\u80fd\u548c\u6548\u679c\u90fd\u4f18\u4e8eBatchNorm\u3002 nn.LayerNorm\uff1a\u5c42\u5f52\u4e00\u5316\u3002\u8f83\u5c11\u4f7f\u7528\u3002 nn.InstanceNorm2d: \u6837\u672c\u5f52\u4e00\u5316\u3002\u8f83\u5c11\u4f7f\u7528\u3002 \u5404\u79cd\u5f52\u4e00\u5316\u6280\u672f\u53c2\u8003\u5982\u4e0b\u77e5\u4e4e\u6587\u7ae0\u300aFAIR\u4f55\u607a\u660e\u7b49\u4eba\u63d0\u51fa\u7ec4\u5f52\u4e00\u5316\uff1a\u66ff\u4ee3\u6279\u5f52\u4e00\u5316\uff0c\u4e0d\u53d7\u6279\u91cf\u5927\u5c0f\u9650\u5236\u300b https://zhuanlan.zhihu.com/p/34858971 \u5377\u79ef\u7f51\u7edc\u76f8\u5173\u5c42 nn.Conv1d\uff1a\u666e\u901a\u4e00\u7ef4\u5377\u79ef\uff0c\u5e38\u7528\u4e8e\u6587\u672c\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u901a\u9053\u6570\u00d7\u5377\u79ef\u6838\u5c3a\u5bf8(\u59823)\u00d7\u5377\u79ef\u6838\u4e2a\u6570 + \u5377\u79ef\u6838\u5c3a\u5bf8(\u59823\uff09 nn.Conv2d\uff1a\u666e\u901a\u4e8c\u7ef4\u5377\u79ef\uff0c\u5e38\u7528\u4e8e\u56fe\u50cf\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u901a\u9053\u6570\u00d7\u5377\u79ef\u6838\u5c3a\u5bf8(\u59823\u4e583)\u00d7\u5377\u79ef\u6838\u4e2a\u6570 + \u5377\u79ef\u6838\u5c3a\u5bf8(\u59823\u4e583) \u901a\u8fc7\u8c03\u6574dilation\u53c2\u6570\u5927\u4e8e1\uff0c\u53ef\u4ee5\u53d8\u6210\u7a7a\u6d1e\u5377\u79ef\uff0c\u589e\u5927\u5377\u79ef\u6838\u611f\u53d7\u91ce\u3002 \u901a\u8fc7\u8c03\u6574groups\u53c2\u6570\u4e0d\u4e3a1\uff0c\u53ef\u4ee5\u53d8\u6210\u5206\u7ec4\u5377\u79ef\u3002\u5206\u7ec4\u5377\u79ef\u4e2d\u4e0d\u540c\u5206\u7ec4\u4f7f\u7528\u76f8\u540c\u7684\u5377\u79ef\u6838\uff0c\u663e\u8457\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u3002 \u5f53groups\u53c2\u6570\u7b49\u4e8e\u901a\u9053\u6570\u65f6\uff0c\u76f8\u5f53\u4e8etensorflow\u4e2d\u7684\u4e8c\u7ef4\u6df1\u5ea6\u5377\u79ef\u5c42tf.keras.layers.DepthwiseConv2D\u3002 \u5229\u7528\u5206\u7ec4\u5377\u79ef\u548c1\u4e581\u5377\u79ef\u7684\u7ec4\u5408\u64cd\u4f5c\uff0c\u53ef\u4ee5\u6784\u9020\u76f8\u5f53\u4e8eKeras\u4e2d\u7684\u4e8c\u7ef4\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u5c42tf.keras.layers.SeparableConv2D\u3002 nn.Conv3d\uff1a\u666e\u901a\u4e09\u7ef4\u5377\u79ef\uff0c\u5e38\u7528\u4e8e\u89c6\u9891\u3002\u53c2\u6570\u4e2a\u6570 = \u8f93\u5165\u901a\u9053\u6570\u00d7\u5377\u79ef\u6838\u5c3a\u5bf8(\u59823\u4e583\u4e583)\u00d7\u5377\u79ef\u6838\u4e2a\u6570 + \u5377\u79ef\u6838\u5c3a\u5bf8(\u59823\u4e583\u4e583) \u3002 nn.MaxPool1d: \u4e00\u7ef4\u6700\u5927\u6c60\u5316\u3002 nn.MaxPool2d\uff1a\u4e8c\u7ef4\u6700\u5927\u6c60\u5316\u3002\u4e00\u79cd\u4e0b\u91c7\u6837\u65b9\u5f0f\u3002\u6ca1\u6709\u9700\u8981\u8bad\u7ec3\u7684\u53c2\u6570\u3002 nn.MaxPool3d\uff1a\u4e09\u7ef4\u6700\u5927\u6c60\u5316\u3002 nn.AdaptiveMaxPool2d\uff1a\u4e8c\u7ef4\u81ea\u9002\u5e94\u6700\u5927\u6c60\u5316\u3002\u65e0\u8bba\u8f93\u5165\u56fe\u50cf\u7684\u5c3a\u5bf8\u5982\u4f55\u53d8\u5316\uff0c\u8f93\u51fa\u7684\u56fe\u50cf\u5c3a\u5bf8\u662f\u56fa\u5b9a\u7684\u3002 \u8be5\u51fd\u6570\u7684\u5b9e\u73b0\u539f\u7406\uff0c\u5927\u6982\u662f\u901a\u8fc7\u8f93\u5165\u56fe\u50cf\u7684\u5c3a\u5bf8\u548c\u8981\u5f97\u5230\u7684\u8f93\u51fa\u56fe\u50cf\u7684\u5c3a\u5bf8\u6765\u53cd\u5411\u63a8\u7b97\u6c60\u5316\u7b97\u5b50\u7684padding,stride\u7b49\u53c2\u6570\u3002 nn.FractionalMaxPool2d\uff1a\u4e8c\u7ef4\u5206\u6570\u6700\u5927\u6c60\u5316\u3002\u666e\u901a\u6700\u5927\u6c60\u5316\u901a\u5e38\u8f93\u5165\u5c3a\u5bf8\u662f\u8f93\u51fa\u7684\u6574\u6570\u500d\u3002\u800c\u5206\u6570\u6700\u5927\u6c60\u5316\u5219\u53ef\u4ee5\u4e0d\u5fc5\u662f\u6574\u6570\u3002\u5206\u6570\u6700\u5927\u6c60\u5316\u4f7f\u7528\u4e86\u4e00\u4e9b\u968f\u673a\u91c7\u6837\u7b56\u7565\uff0c\u6709\u4e00\u5b9a\u7684\u6b63\u5219\u6548\u679c\uff0c\u53ef\u4ee5\u7528\u5b83\u6765\u4ee3\u66ff\u666e\u901a\u6700\u5927\u6c60\u5316\u548cDropout\u5c42\u3002 nn.AvgPool2d\uff1a\u4e8c\u7ef4\u5e73\u5747\u6c60\u5316\u3002 nn.AdaptiveAvgPool2d\uff1a\u4e8c\u7ef4\u81ea\u9002\u5e94\u5e73\u5747\u6c60\u5316\u3002\u65e0\u8bba\u8f93\u5165\u7684\u7ef4\u5ea6\u5982\u4f55\u53d8\u5316\uff0c\u8f93\u51fa\u7684\u7ef4\u5ea6\u662f\u56fa\u5b9a\u7684\u3002 nn.ConvTranspose2d\uff1a\u4e8c\u7ef4\u5377\u79ef\u8f6c\u7f6e\u5c42\uff0c\u4fd7\u79f0\u53cd\u5377\u79ef\u5c42\u3002\u5e76\u975e\u5377\u79ef\u7684\u9006\u64cd\u4f5c\uff0c\u4f46\u5728\u5377\u79ef\u6838\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\uff0c\u5f53\u5176\u8f93\u5165\u5c3a\u5bf8\u662f\u5377\u79ef\u64cd\u4f5c\u8f93\u51fa\u5c3a\u5bf8\u7684\u60c5\u51b5\u4e0b\uff0c\u5377\u79ef\u8f6c\u7f6e\u7684\u8f93\u51fa\u5c3a\u5bf8\u6070\u597d\u662f\u5377\u79ef\u64cd\u4f5c\u7684\u8f93\u5165\u5c3a\u5bf8\u3002\u5728\u8bed\u4e49\u5206\u5272\u4e2d\u53ef\u7528\u4e8e\u4e0a\u91c7\u6837\u3002 nn.Upsample\uff1a\u4e0a\u91c7\u6837\u5c42\uff0c\u64cd\u4f5c\u6548\u679c\u548c\u6c60\u5316\u76f8\u53cd\u3002\u53ef\u4ee5\u901a\u8fc7mode\u53c2\u6570\u63a7\u5236\u4e0a\u91c7\u6837\u7b56\u7565\u4e3a\"nearest\"\u6700\u90bb\u8fd1\u7b56\u7565\u6216\"linear\"\u7ebf\u6027\u63d2\u503c\u7b56\u7565\u3002 nn.Unfold\uff1a\u6ed1\u52a8\u7a97\u53e3\u63d0\u53d6\u5c42\u3002\u5176\u53c2\u6570\u548c\u5377\u79ef\u64cd\u4f5cnn.Conv2d\u76f8\u540c\u3002\u5b9e\u9645\u4e0a\uff0c\u5377\u79ef\u64cd\u4f5c\u53ef\u4ee5\u7b49\u4ef7\u4e8enn.Unfold\u548cnn.Linear\u4ee5\u53cann.Fold\u7684\u4e00\u4e2a\u7ec4\u5408\u3002 \u5176\u4e2dnn.Unfold\u64cd\u4f5c\u53ef\u4ee5\u4ece\u8f93\u5165\u4e2d\u63d0\u53d6\u5404\u4e2a\u6ed1\u52a8\u7a97\u53e3\u7684\u6570\u503c\u77e9\u9635\uff0c\u5e76\u5c06\u5176\u538b\u5e73\u6210\u4e00\u7ef4\u3002\u5229\u7528nn.Linear\u5c06nn.Unfold\u7684\u8f93\u51fa\u548c\u5377\u79ef\u6838\u505a\u4e58\u6cd5\u540e\uff0c\u518d\u4f7f\u7528 nn.Fold\u64cd\u4f5c\u5c06\u7ed3\u679c\u8f6c\u6362\u6210\u8f93\u51fa\u56fe\u7247\u5f62\u72b6\u3002 nn.Fold\uff1a\u9006\u6ed1\u52a8\u7a97\u53e3\u63d0\u53d6\u5c42\u3002 \u5faa\u73af\u7f51\u7edc\u76f8\u5173\u5c42 nn.Embedding\uff1a\u5d4c\u5165\u5c42\u3002\u4e00\u79cd\u6bd4Onehot\u66f4\u52a0\u6709\u6548\u7684\u5bf9\u79bb\u6563\u7279\u5f81\u8fdb\u884c\u7f16\u7801\u7684\u65b9\u6cd5\u3002\u4e00\u822c\u7528\u4e8e\u5c06\u8f93\u5165\u4e2d\u7684\u5355\u8bcd\u6620\u5c04\u4e3a\u7a20\u5bc6\u5411\u91cf\u3002\u5d4c\u5165\u5c42\u7684\u53c2\u6570\u9700\u8981\u5b66\u4e60\u3002 nn.LSTM\uff1a\u957f\u77ed\u8bb0\u5fc6\u5faa\u73af\u7f51\u7edc\u5c42\u3010\u652f\u6301\u591a\u5c42\u3011\u3002\u6700\u666e\u904d\u4f7f\u7528\u7684\u5faa\u73af\u7f51\u7edc\u5c42\u3002\u5177\u6709\u643a\u5e26\u8f68\u9053\uff0c\u9057\u5fd8\u95e8\uff0c\u66f4\u65b0\u95e8\uff0c\u8f93\u51fa\u95e8\u3002\u53ef\u4ee5\u8f83\u4e3a\u6709\u6548\u5730\u7f13\u89e3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u4ece\u800c\u80fd\u591f\u9002\u7528\u957f\u671f\u4f9d\u8d56\u95ee\u9898\u3002\u8bbe\u7f6ebidirectional = True\u65f6\u53ef\u4ee5\u5f97\u5230\u53cc\u5411LSTM\u3002\u9700\u8981\u6ce8\u610f\u7684\u65f6\uff0c\u9ed8\u8ba4\u7684\u8f93\u5165\u548c\u8f93\u51fa\u5f62\u72b6\u662f(seq,batch,feature), \u5982\u679c\u9700\u8981\u5c06batch\u7ef4\u5ea6\u653e\u5728\u7b2c0\u7ef4\uff0c\u5219\u8981\u8bbe\u7f6ebatch_first\u53c2\u6570\u8bbe\u7f6e\u4e3aTrue\u3002 nn.GRU\uff1a\u95e8\u63a7\u5faa\u73af\u7f51\u7edc\u5c42\u3010\u652f\u6301\u591a\u5c42\u3011\u3002LSTM\u7684\u4f4e\u914d\u7248\uff0c\u4e0d\u5177\u6709\u643a\u5e26\u8f68\u9053\uff0c\u53c2\u6570\u6570\u91cf\u5c11\u4e8eLSTM\uff0c\u8bad\u7ec3\u901f\u5ea6\u66f4\u5feb\u3002 nn.RNN\uff1a\u7b80\u5355\u5faa\u73af\u7f51\u7edc\u5c42\u3010\u652f\u6301\u591a\u5c42\u3011\u3002\u5bb9\u6613\u5b58\u5728\u68af\u5ea6\u6d88\u5931\uff0c\u4e0d\u80fd\u591f\u9002\u7528\u957f\u671f\u4f9d\u8d56\u95ee\u9898\u3002\u4e00\u822c\u8f83\u5c11\u4f7f\u7528\u3002 nn.LSTMCell\uff1a\u957f\u77ed\u8bb0\u5fc6\u5faa\u73af\u7f51\u7edc\u5355\u5143\u3002\u548cnn.LSTM\u5728\u6574\u4e2a\u5e8f\u5217\u4e0a\u8fed\u4ee3\u76f8\u6bd4\uff0c\u5b83\u4ec5\u5728\u5e8f\u5217\u4e0a\u8fed\u4ee3\u4e00\u6b65\u3002\u4e00\u822c\u8f83\u5c11\u4f7f\u7528\u3002 nn.GRUCell\uff1a\u95e8\u63a7\u5faa\u73af\u7f51\u7edc\u5355\u5143\u3002\u548cnn.GRU\u5728\u6574\u4e2a\u5e8f\u5217\u4e0a\u8fed\u4ee3\u76f8\u6bd4\uff0c\u5b83\u4ec5\u5728\u5e8f\u5217\u4e0a\u8fed\u4ee3\u4e00\u6b65\u3002\u4e00\u822c\u8f83\u5c11\u4f7f\u7528\u3002 nn.RNNCell\uff1a\u7b80\u5355\u5faa\u73af\u7f51\u7edc\u5355\u5143\u3002\u548cnn.RNN\u5728\u6574\u4e2a\u5e8f\u5217\u4e0a\u8fed\u4ee3\u76f8\u6bd4\uff0c\u5b83\u4ec5\u5728\u5e8f\u5217\u4e0a\u8fed\u4ee3\u4e00\u6b65\u3002\u4e00\u822c\u8f83\u5c11\u4f7f\u7528\u3002 Transformer\u76f8\u5173\u5c42 nn.Transformer\uff1aTransformer\u7f51\u7edc\u7ed3\u6784\u3002Transformer\u7f51\u7edc\u7ed3\u6784\u662f\u66ff\u4ee3\u5faa\u73af\u7f51\u7edc\u7684\u4e00\u79cd\u7ed3\u6784\uff0c\u89e3\u51b3\u4e86\u5faa\u73af\u7f51\u7edc\u96be\u4ee5\u5e76\u884c\uff0c\u96be\u4ee5\u6355\u6349\u957f\u671f\u4f9d\u8d56\u7684\u7f3a\u9677\u3002\u5b83\u662f\u76ee\u524dNLP\u4efb\u52a1\u7684\u4e3b\u6d41\u6a21\u578b\u7684\u4e3b\u8981\u6784\u6210\u90e8\u5206\u3002Transformer\u7f51\u7edc\u7ed3\u6784\u7531TransformerEncoder\u7f16\u7801\u5668\u548cTransformerDecoder\u89e3\u7801\u5668\u7ec4\u6210\u3002\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u7684\u6838\u5fc3\u662fMultiheadAttention\u591a\u5934\u6ce8\u610f\u529b\u5c42\u3002 nn.TransformerEncoder\uff1aTransformer\u7f16\u7801\u5668\u7ed3\u6784\u3002\u7531\u591a\u4e2a nn.TransformerEncoderLayer\u7f16\u7801\u5668\u5c42\u7ec4\u6210\u3002 nn.TransformerDecoder\uff1aTransformer\u89e3\u7801\u5668\u7ed3\u6784\u3002\u7531\u591a\u4e2a nn.TransformerDecoderLayer\u89e3\u7801\u5668\u5c42\u7ec4\u6210\u3002 nn.TransformerEncoderLayer\uff1aTransformer\u7684\u7f16\u7801\u5668\u5c42\u3002 nn.TransformerDecoderLayer\uff1aTransformer\u7684\u89e3\u7801\u5668\u5c42\u3002 nn.MultiheadAttention\uff1a\u591a\u5934\u6ce8\u610f\u529b\u5c42\u3002 Transformer\u539f\u7406\u4ecb\u7ecd\u53ef\u4ee5\u53c2\u8003\u5982\u4e0b\u77e5\u4e4e\u6587\u7ae0\u300a\u8be6\u89e3Transformer(Attention Is All You Need)\u300b https://zhuanlan.zhihu.com/p/48508221","title":"\u4e00\uff0c\u5185\u7f6e\u6a21\u578b\u5c42"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-2%2C%E6%A8%A1%E5%9E%8B%E5%B1%82/#\u4e8c\u81ea\u5b9a\u4e49\u6a21\u578b\u5c42","text":"\u5982\u679cPytorch\u7684\u5185\u7f6e\u6a21\u578b\u5c42\u4e0d\u80fd\u591f\u6ee1\u8db3\u9700\u6c42\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\u5c42\u3002 \u5b9e\u9645\u4e0a\uff0cpytorch\u4e0d\u533a\u5206\u6a21\u578b\u548c\u6a21\u578b\u5c42\uff0c\u90fd\u662f\u901a\u8fc7\u7ee7\u627fnn.Module\u8fdb\u884c\u6784\u5efa\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u53ea\u8981\u7ee7\u627fnn.Module\u57fa\u7c7b\u5e76\u5b9e\u73b0forward\u65b9\u6cd5\u5373\u53ef\u81ea\u5b9a\u4e49\u6a21\u578b\u5c42\u3002 \u4e0b\u9762\u662fPytorch\u7684nn.Linear\u5c42\u7684\u6e90\u7801\uff0c\u6211\u4eec\u53ef\u4ee5\u4eff\u7167\u5b83\u6765\u81ea\u5b9a\u4e49\u6a21\u578b\u5c42\u3002 import torch from torch import nn import torch.nn.functional as F class Linear ( nn . Module ): __constants__ = [ 'in_features' , 'out_features' ] def __init__ ( self , in_features , out_features , bias = True ): super ( Linear , self ) . __init__ () self . in_features = in_features self . out_features = out_features self . weight = nn . Parameter ( torch . Tensor ( out_features , in_features )) if bias : self . bias = nn . Parameter ( torch . Tensor ( out_features )) else : self . register_parameter ( 'bias' , None ) self . reset_parameters () def reset_parameters ( self ): nn . init . kaiming_uniform_ ( self . weight , a = math . sqrt ( 5 )) if self . bias is not None : fan_in , _ = nn . init . _calculate_fan_in_and_fan_out ( self . weight ) bound = 1 / math . sqrt ( fan_in ) nn . init . uniform_ ( self . bias , - bound , bound ) def forward ( self , input ): return F . linear ( input , self . weight , self . bias ) def extra_repr ( self ): return 'in_features= {} , out_features= {} , bias= {} ' . format ( self . in_features , self . out_features , self . bias is not None ) linear = nn . Linear ( 20 , 30 ) inputs = torch . randn ( 128 , 20 ) output = linear ( inputs ) print ( output . size ()) torch.Size([128, 30]) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e8c\uff0c\u81ea\u5b9a\u4e49\u6a21\u578b\u5c42"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-3%2C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/","text":"5-5,\u635f\u5931\u51fd\u6570losses # \u4e00\u822c\u6765\u8bf4\uff0c\u76d1\u7763\u5b66\u4e60\u7684\u76ee\u6807\u51fd\u6570\u7531\u635f\u5931\u51fd\u6570\u548c\u6b63\u5219\u5316\u9879\u7ec4\u6210\u3002(Objective = Loss + Regularization) Pytorch\u4e2d\u7684\u635f\u5931\u51fd\u6570\u4e00\u822c\u5728\u8bad\u7ec3\u6a21\u578b\u65f6\u5019\u6307\u5b9a\u3002 \u6ce8\u610fPytorch\u4e2d\u5185\u7f6e\u7684\u635f\u5931\u51fd\u6570\u7684\u53c2\u6570\u548ctensorflow\u4e0d\u540c\uff0c\u662fy_pred\u5728\u524d\uff0cy_true\u5728\u540e\uff0c\u800cTensorflow\u662fy_true\u5728\u524d\uff0cy_pred\u5728\u540e\u3002 \u5bf9\u4e8e\u56de\u5f52\u6a21\u578b\uff0c\u901a\u5e38\u4f7f\u7528\u7684\u5185\u7f6e\u635f\u5931\u51fd\u6570\u662f\u5747\u65b9\u635f\u5931\u51fd\u6570nn.MSELoss \u3002 \u5bf9\u4e8e\u4e8c\u5206\u7c7b\u6a21\u578b\uff0c\u901a\u5e38\u4f7f\u7528\u7684\u662f\u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570nn.BCELoss (\u8f93\u5165\u5df2\u7ecf\u662fsigmoid\u6fc0\u6d3b\u51fd\u6570\u4e4b\u540e\u7684\u7ed3\u679c) \u6216\u8005 nn.BCEWithLogitsLoss (\u8f93\u5165\u5c1a\u672a\u7ecf\u8fc7nn.Sigmoid\u6fc0\u6d3b\u51fd\u6570) \u3002 \u5bf9\u4e8e\u591a\u5206\u7c7b\u6a21\u578b\uff0c\u4e00\u822c\u63a8\u8350\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 nn.CrossEntropyLoss\u3002 (y_true\u9700\u8981\u662f\u4e00\u7ef4\u7684\uff0c\u662f\u7c7b\u522b\u7f16\u7801\u3002y_pred\u672a\u7ecf\u8fc7nn.Softmax\u6fc0\u6d3b\u3002) \u6b64\u5916\uff0c\u5982\u679c\u591a\u5206\u7c7b\u7684y_pred\u7ecf\u8fc7\u4e86nn.LogSoftmax\u6fc0\u6d3b\uff0c\u53ef\u4ee5\u4f7f\u7528nn.NLLLoss\u635f\u5931\u51fd\u6570(The negative log likelihood loss)\u3002 \u8fd9\u79cd\u65b9\u6cd5\u548c\u76f4\u63a5\u4f7f\u7528nn.CrossEntropyLoss\u7b49\u4ef7\u3002 \u5982\u679c\u6709\u9700\u8981\uff0c\u4e5f\u53ef\u4ee5\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff0c\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u9700\u8981\u63a5\u6536\u4e24\u4e2a\u5f20\u91cfy_pred\uff0cy_true\u4f5c\u4e3a\u8f93\u5165\u53c2\u6570\uff0c\u5e76\u8f93\u51fa\u4e00\u4e2a\u6807\u91cf\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\u503c\u3002 Pytorch\u4e2d\u7684\u6b63\u5219\u5316\u9879\u4e00\u822c\u901a\u8fc7\u81ea\u5b9a\u4e49\u7684\u65b9\u5f0f\u548c\u635f\u5931\u51fd\u6570\u4e00\u8d77\u6dfb\u52a0\u4f5c\u4e3a\u76ee\u6807\u51fd\u6570\u3002 \u5982\u679c\u4ec5\u4ec5\u4f7f\u7528L2\u6b63\u5219\u5316\uff0c\u4e5f\u53ef\u4ee5\u5229\u7528\u4f18\u5316\u5668\u7684weight_decay\u53c2\u6570\u6765\u5b9e\u73b0\u76f8\u540c\u7684\u6548\u679c\u3002 \u4e00\uff0c\u5185\u7f6e\u635f\u5931\u51fd\u6570 # import numpy as np import pandas as pd import torch from torch import nn import torch.nn.functional as F y_pred = torch . tensor ([[ 10.0 , 0.0 , - 10.0 ],[ 8.0 , 8.0 , 8.0 ]]) y_true = torch . tensor ([ 0 , 2 ]) # \u76f4\u63a5\u8c03\u7528\u4ea4\u53c9\u71b5\u635f\u5931 ce = nn . CrossEntropyLoss ()( y_pred , y_true ) print ( ce ) # \u7b49\u4ef7\u4e8e\u5148\u8ba1\u7b97nn.LogSoftmax\u6fc0\u6d3b\uff0c\u518d\u8c03\u7528NLLLoss y_pred_logsoftmax = nn . LogSoftmax ( dim = 1 )( y_pred ) nll = nn . NLLLoss ()( y_pred_logsoftmax , y_true ) print ( nll ) tensor(0.5493) tensor(0.5493) \u5185\u7f6e\u7684\u635f\u5931\u51fd\u6570\u4e00\u822c\u6709\u7c7b\u7684\u5b9e\u73b0\u548c\u51fd\u6570\u7684\u5b9e\u73b0\u4e24\u79cd\u5f62\u5f0f\u3002 \u5982\uff1ann.BCE \u548c F.binary_cross_entropy \u90fd\u662f\u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u524d\u8005\u662f\u7c7b\u7684\u5b9e\u73b0\u5f62\u5f0f\uff0c\u540e\u8005\u662f\u51fd\u6570\u7684\u5b9e\u73b0\u5f62\u5f0f\u3002 \u5b9e\u9645\u4e0a\u7c7b\u7684\u5b9e\u73b0\u5f62\u5f0f\u901a\u5e38\u662f\u8c03\u7528\u51fd\u6570\u7684\u5b9e\u73b0\u5f62\u5f0f\u5e76\u7528nn.Module\u5c01\u88c5\u540e\u5f97\u5230\u7684\u3002 \u4e00\u822c\u6211\u4eec\u5e38\u7528\u7684\u662f\u7c7b\u7684\u5b9e\u73b0\u5f62\u5f0f\u3002\u5b83\u4eec\u5c01\u88c5\u5728torch.nn\u6a21\u5757\u4e0b\uff0c\u5e76\u4e14\u7c7b\u540d\u4ee5Loss\u7ed3\u5c3e\u3002 \u5e38\u7528\u7684\u4e00\u4e9b\u5185\u7f6e\u635f\u5931\u51fd\u6570\u8bf4\u660e\u5982\u4e0b\u3002 nn.MSELoss\uff08\u5747\u65b9\u8bef\u5dee\u635f\u5931\uff0c\u4e5f\u53eb\u505aL2\u635f\u5931\uff0c\u7528\u4e8e\u56de\u5f52\uff09 nn.L1Loss \uff08L1\u635f\u5931\uff0c\u4e5f\u53eb\u505a\u7edd\u5bf9\u503c\u8bef\u5dee\u635f\u5931\uff0c\u7528\u4e8e\u56de\u5f52\uff09 nn.SmoothL1Loss (\u5e73\u6ed1L1\u635f\u5931\uff0c\u5f53\u8f93\u5165\u5728-1\u52301\u4e4b\u95f4\u65f6\uff0c\u5e73\u6ed1\u4e3aL2\u635f\u5931\uff0c\u7528\u4e8e\u56de\u5f52) nn.BCELoss (\u4e8c\u5143\u4ea4\u53c9\u71b5\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b\uff0c\u8f93\u5165\u5df2\u7ecf\u8fc7nn.Sigmoid\u6fc0\u6d3b\uff0c\u5bf9\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u53ef\u4ee5\u7528weigths\u53c2\u6570\u8c03\u6574\u7c7b\u522b\u6743\u91cd) nn.BCEWithLogitsLoss (\u4e8c\u5143\u4ea4\u53c9\u71b5\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b\uff0c\u8f93\u5165\u672a\u7ecf\u8fc7nn.Sigmoid\u6fc0\u6d3b) nn.CrossEntropyLoss (\u4ea4\u53c9\u71b5\uff0c\u7528\u4e8e\u591a\u5206\u7c7b\uff0c\u8981\u6c42label\u4e3a\u7a00\u758f\u7f16\u7801\uff0c\u8f93\u5165\u672a\u7ecf\u8fc7nn.Softmax\u6fc0\u6d3b\uff0c\u5bf9\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u53ef\u4ee5\u7528weigths\u53c2\u6570\u8c03\u6574\u7c7b\u522b\u6743\u91cd) nn.NLLLoss (\u8d1f\u5bf9\u6570\u4f3c\u7136\u635f\u5931\uff0c\u7528\u4e8e\u591a\u5206\u7c7b\uff0c\u8981\u6c42label\u4e3a\u7a00\u758f\u7f16\u7801\uff0c\u8f93\u5165\u7ecf\u8fc7nn.LogSoftmax\u6fc0\u6d3b) nn.CosineSimilarity(\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff0c\u53ef\u7528\u4e8e\u591a\u5206\u7c7b) nn.AdaptiveLogSoftmaxWithLoss (\u4e00\u79cd\u9002\u5408\u975e\u5e38\u591a\u7c7b\u522b\u4e14\u7c7b\u522b\u5206\u5e03\u5f88\u4e0d\u5747\u8861\u7684\u635f\u5931\u51fd\u6570\uff0c\u4f1a\u81ea\u9002\u5e94\u5730\u5c06\u591a\u4e2a\u5c0f\u7c7b\u522b\u5408\u6210\u4e00\u4e2acluster) \u66f4\u591a\u635f\u5931\u51fd\u6570\u7684\u4ecb\u7ecd\u53c2\u8003\u5982\u4e0b\u77e5\u4e4e\u6587\u7ae0\uff1a \u300aPyTorch\u7684\u5341\u516b\u4e2a\u635f\u5931\u51fd\u6570\u300b https://zhuanlan.zhihu.com/p/61379965 \u4e8c\uff0c\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570 # \u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u63a5\u6536\u4e24\u4e2a\u5f20\u91cfy_pred,y_true\u4f5c\u4e3a\u8f93\u5165\u53c2\u6570\uff0c\u5e76\u8f93\u51fa\u4e00\u4e2a\u6807\u91cf\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\u503c\u3002 \u4e5f\u53ef\u4ee5\u5bf9nn.Module\u8fdb\u884c\u5b50\u7c7b\u5316\uff0c\u91cd\u5199forward\u65b9\u6cd5\u5b9e\u73b0\u635f\u5931\u7684\u8ba1\u7b97\u903b\u8f91\uff0c\u4ece\u800c\u5f97\u5230\u635f\u5931\u51fd\u6570\u7684\u7c7b\u7684\u5b9e\u73b0\u3002 \u4e0b\u9762\u662f\u4e00\u4e2aFocal Loss\u7684\u81ea\u5b9a\u4e49\u5b9e\u73b0\u793a\u8303\u3002Focal Loss\u662f\u4e00\u79cd\u5bf9binary_crossentropy\u7684\u6539\u8fdb\u635f\u5931\u51fd\u6570\u5f62\u5f0f\u3002 \u5b83\u5728\u6837\u672c\u4e0d\u5747\u8861\u548c\u5b58\u5728\u8f83\u591a\u6613\u5206\u7c7b\u7684\u6837\u672c\u65f6\u76f8\u6bd4binary_crossentropy\u5177\u6709\u660e\u663e\u7684\u4f18\u52bf\u3002 \u5b83\u6709\u4e24\u4e2a\u53ef\u8c03\u53c2\u6570\uff0calpha\u53c2\u6570\u548cgamma\u53c2\u6570\u3002\u5176\u4e2dalpha\u53c2\u6570\u4e3b\u8981\u7528\u4e8e\u8870\u51cf\u8d1f\u6837\u672c\u7684\u6743\u91cd\uff0cgamma\u53c2\u6570\u4e3b\u8981\u7528\u4e8e\u8870\u51cf\u5bb9\u6613\u8bad\u7ec3\u6837\u672c\u7684\u6743\u91cd\u3002 \u4ece\u800c\u8ba9\u6a21\u578b\u66f4\u52a0\u805a\u7126\u5728\u6b63\u6837\u672c\u548c\u56f0\u96be\u6837\u672c\u4e0a\u3002\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\u53eb\u505aFocal Loss\u3002 \u8be6\u89c1\u300a5\u5206\u949f\u7406\u89e3Focal Loss\u4e0eGHM\u2014\u2014\u89e3\u51b3\u6837\u672c\u4e0d\u5e73\u8861\u5229\u5668\u300b https://zhuanlan.zhihu.com/p/80594704 focal\\_loss(y,p) = \\begin{cases} -\\alpha (1-p)^{\\gamma}\\log(p) & \\text{if y = 1}\\\\ -(1-\\alpha) p^{\\gamma}\\log(1-p) & \\text{if y = 0} \\end{cases} focal\\_loss(y,p) = \\begin{cases} -\\alpha (1-p)^{\\gamma}\\log(p) & \\text{if y = 1}\\\\ -(1-\\alpha) p^{\\gamma}\\log(1-p) & \\text{if y = 0} \\end{cases} class FocalLoss ( nn . Module ): def __init__ ( self , gamma = 2.0 , alpha = 0.75 ): super () . __init__ () self . gamma = gamma self . alpha = alpha def forward ( self , y_pred , y_true ): bce = torch . nn . BCELoss ( reduction = \"none\" )( y_pred , y_true ) p_t = ( y_true * y_pred ) + (( 1 - y_true ) * ( 1 - y_pred )) alpha_factor = y_true * self . alpha + ( 1 - y_true ) * ( 1 - self . alpha ) modulating_factor = torch . pow ( 1.0 - p_t , self . gamma ) loss = torch . mean ( alpha_factor * modulating_factor * bce ) return loss #\u56f0\u96be\u6837\u672c y_pred_hard = torch . tensor ([[ 0.5 ],[ 0.5 ]]) y_true_hard = torch . tensor ([[ 1.0 ],[ 0.0 ]]) #\u5bb9\u6613\u6837\u672c y_pred_easy = torch . tensor ([[ 0.9 ],[ 0.1 ]]) y_true_easy = torch . tensor ([[ 1.0 ],[ 0.0 ]]) focal_loss = FocalLoss () bce_loss = nn . BCELoss () print ( \"focal_loss(hard samples):\" , focal_loss ( y_pred_hard , y_true_hard )) print ( \"bce_loss(hard samples):\" , bce_loss ( y_pred_hard , y_true_hard )) print ( \"focal_loss(easy samples):\" , focal_loss ( y_pred_easy , y_true_easy )) print ( \"bce_loss(easy samples):\" , bce_loss ( y_pred_easy , y_true_easy )) #\u53ef\u89c1 focal_loss\u8ba9\u5bb9\u6613\u6837\u672c\u7684\u6743\u91cd\u8870\u51cf\u5230\u539f\u6765\u7684 0.0005/0.1054 = 0.00474 #\u800c\u8ba9\u56f0\u96be\u6837\u672c\u7684\u6743\u91cd\u53ea\u8870\u51cf\u5230\u539f\u6765\u7684 0.0866/0.6931=0.12496 # \u56e0\u6b64\u76f8\u5bf9\u800c\u8a00\uff0cfocal_loss\u53ef\u4ee5\u8870\u51cf\u5bb9\u6613\u6837\u672c\u7684\u6743\u91cd\u3002 focal_loss(hard samples): tensor(0.0866) bce_loss(hard samples): tensor(0.6931) focal_loss(easy samples): tensor(0.0005) bce_loss(easy samples): tensor(0.1054) FocalLoss\u7684\u4f7f\u7528\u5b8c\u6574\u8303\u4f8b\u53ef\u4ee5\u53c2\u8003\u4e0b\u9762\u4e2d \u81ea\u5b9a\u4e49L1\u548cL2\u6b63\u5219\u5316\u9879 \u4e2d\u7684\u8303\u4f8b\uff0c\u8be5\u8303\u4f8b\u65e2\u6f14\u793a\u4e86\u81ea\u5b9a\u4e49\u6b63\u5219\u5316\u9879\u7684\u65b9\u6cd5\uff0c\u4e5f\u6f14\u793a\u4e86FocalLoss\u7684\u4f7f\u7528\u65b9\u6cd5\u3002 \u4e09\uff0c\u81ea\u5b9a\u4e49L1\u548cL2\u6b63\u5219\u5316\u9879 # \u901a\u5e38\u8ba4\u4e3aL1 \u6b63\u5219\u5316\u53ef\u4ee5\u4ea7\u751f\u7a00\u758f\u6743\u503c\u77e9\u9635\uff0c\u5373\u4ea7\u751f\u4e00\u4e2a\u7a00\u758f\u6a21\u578b\uff0c\u53ef\u4ee5\u7528\u4e8e\u7279\u5f81\u9009\u62e9\u3002 \u800cL2 \u6b63\u5219\u5316\u53ef\u4ee5\u9632\u6b62\u6a21\u578b\u8fc7\u62df\u5408\uff08overfitting\uff09\u3002\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\uff0cL1\u4e5f\u53ef\u4ee5\u9632\u6b62\u8fc7\u62df\u5408\u3002 \u4e0b\u9762\u4ee5\u4e00\u4e2a\u4e8c\u5206\u7c7b\u95ee\u9898\u4e3a\u4f8b\uff0c\u6f14\u793a\u7ed9\u6a21\u578b\u7684\u76ee\u6807\u51fd\u6570\u6dfb\u52a0\u81ea\u5b9a\u4e49L1\u548cL2\u6b63\u5219\u5316\u9879\u7684\u65b9\u6cd5\u3002 \u8fd9\u4e2a\u8303\u4f8b\u540c\u65f6\u6f14\u793a\u4e86\u4e0a\u4e00\u4e2a\u90e8\u5206\u7684FocalLoss\u7684\u4f7f\u7528\u3002 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import torch from torch import nn import torch.nn.functional as F from torch.utils.data import Dataset , DataLoader , TensorDataset import torchkeras % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u6b63\u8d1f\u6837\u672c\u6570\u91cf n_positive , n_negative = 200 , 6000 #\u751f\u6210\u6b63\u6837\u672c, \u5c0f\u5706\u73af\u5206\u5e03 r_p = 5.0 + torch . normal ( 0.0 , 1.0 , size = [ n_positive , 1 ]) theta_p = 2 * np . pi * torch . rand ([ n_positive , 1 ]) Xp = torch . cat ([ r_p * torch . cos ( theta_p ), r_p * torch . sin ( theta_p )], axis = 1 ) Yp = torch . ones_like ( r_p ) #\u751f\u6210\u8d1f\u6837\u672c, \u5927\u5706\u73af\u5206\u5e03 r_n = 8.0 + torch . normal ( 0.0 , 1.0 , size = [ n_negative , 1 ]) theta_n = 2 * np . pi * torch . rand ([ n_negative , 1 ]) Xn = torch . cat ([ r_n * torch . cos ( theta_n ), r_n * torch . sin ( theta_n )], axis = 1 ) Yn = torch . zeros_like ( r_n ) #\u6c47\u603b\u6837\u672c X = torch . cat ([ Xp , Xn ], axis = 0 ) Y = torch . cat ([ Yp , Yn ], axis = 0 ) #\u53ef\u89c6\u5316 plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) plt . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); ds = TensorDataset ( X , Y ) ds_train , ds_valid = torch . utils . data . random_split ( ds ,[ int ( len ( ds ) * 0.7 ), len ( ds ) - int ( len ( ds ) * 0.7 )]) dl_train = DataLoader ( ds_train , batch_size = 100 , shuffle = True , num_workers = 2 ) dl_valid = DataLoader ( ds_valid , batch_size = 100 , num_workers = 2 ) 2\uff0c\u5b9a\u4e49\u6a21\u578b class DNNModel ( torchkeras . Model ): def __init__ ( self ): super ( DNNModel , self ) . __init__ () self . fc1 = nn . Linear ( 2 , 4 ) self . fc2 = nn . Linear ( 4 , 8 ) self . fc3 = nn . Linear ( 8 , 1 ) def forward ( self , x ): x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) y = nn . Sigmoid ()( self . fc3 ( x )) return y model = DNNModel () model . summary ( input_shape = ( 2 ,)) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Linear-1 [-1, 4] 12 Linear-2 [-1, 8] 40 Linear-3 [-1, 1] 9 ================================================================ Total params: 61 Trainable params: 61 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.000008 Forward/backward pass size (MB): 0.000099 Params size (MB): 0.000233 Estimated Total Size (MB): 0.000340 ---------------------------------------------------------------- 3\uff0c\u8bad\u7ec3\u6a21\u578b # \u51c6\u786e\u7387 def accuracy ( y_pred , y_true ): y_pred = torch . where ( y_pred > 0.5 , torch . ones_like ( y_pred , dtype = torch . float32 ), torch . zeros_like ( y_pred , dtype = torch . float32 )) acc = torch . mean ( 1 - torch . abs ( y_true - y_pred )) return acc # L2\u6b63\u5219\u5316 def L2Loss ( model , alpha ): l2_loss = torch . tensor ( 0.0 , requires_grad = True ) for name , param in model . named_parameters (): if 'bias' not in name : #\u4e00\u822c\u4e0d\u5bf9\u504f\u7f6e\u9879\u4f7f\u7528\u6b63\u5219 l2_loss = l2_loss + ( 0.5 * alpha * torch . sum ( torch . pow ( param , 2 ))) return l2_loss # L1\u6b63\u5219\u5316 def L1Loss ( model , beta ): l1_loss = torch . tensor ( 0.0 , requires_grad = True ) for name , param in model . named_parameters (): if 'bias' not in name : l1_loss = l1_loss + beta * torch . sum ( torch . abs ( param )) return l1_loss # \u5c06L2\u6b63\u5219\u548cL1\u6b63\u5219\u6dfb\u52a0\u5230FocalLoss\u635f\u5931\uff0c\u4e00\u8d77\u4f5c\u4e3a\u76ee\u6807\u51fd\u6570 def focal_loss_with_regularization ( y_pred , y_true ): focal = FocalLoss ()( y_pred , y_true ) l2_loss = L2Loss ( model , 0.001 ) #\u6ce8\u610f\u8bbe\u7f6e\u6b63\u5219\u5316\u9879\u7cfb\u6570 l1_loss = L1Loss ( model , 0.001 ) total_loss = focal + l2_loss + l1_loss return total_loss model . compile ( loss_func = focal_loss_with_regularization , optimizer = torch . optim . Adam ( model . parameters (), lr = 0.01 ), metrics_dict = { \"accuracy\" : accuracy }) dfhistory = model . fit ( 30 , dl_train = dl_train , dl_val = dl_valid , log_step_freq = 30 ) Start Training ... ================================================================================2020-07-11 23:34:17 {'step': 30, 'loss': 0.021, 'accuracy': 0.972} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 1 | 0.022 | 0.971 | 0.025 | 0.96 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-11 23:34:27 {'step': 30, 'loss': 0.016, 'accuracy': 0.984} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 30 | 0.016 | 0.981 | 0.017 | 0.983 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-11 23:34:27 Finished Training... # \u7ed3\u679c\u53ef\u89c6\u5316 fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) ax1 . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = X [ torch . squeeze ( model . forward ( X ) >= 0.5 )] Xn_pred = X [ torch . squeeze ( model . forward ( X ) < 0.5 )] ax2 . scatter ( Xp_pred [:, 0 ], Xp_pred [:, 1 ], c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ], Xn_pred [:, 1 ], c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" ); \u56db\uff0c\u901a\u8fc7\u4f18\u5316\u5668\u5b9e\u73b0L2\u6b63\u5219\u5316 # \u5982\u679c\u4ec5\u4ec5\u9700\u8981\u4f7f\u7528L2\u6b63\u5219\u5316\uff0c\u90a3\u4e48\u4e5f\u53ef\u4ee5\u5229\u7528\u4f18\u5316\u5668\u7684weight_decay\u53c2\u6570\u6765\u5b9e\u73b0\u3002 weight_decay\u53c2\u6570\u53ef\u4ee5\u8bbe\u7f6e\u53c2\u6570\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u8870\u51cf\uff0c\u8fd9\u548cL2\u6b63\u5219\u5316\u7684\u4f5c\u7528\u6548\u679c\u7b49\u4ef7\u3002 before L2 regularization: gradient descent: w = w - lr * dloss_dw after L2 regularization: gradient descent: w = w - lr * (dloss_dw+beta*w) = (1-lr*beta)*w - lr*dloss_dw so \uff081-lr*beta\uff09is the weight decay ratio. Pytorch\u7684\u4f18\u5316\u5668\u652f\u6301\u4e00\u79cd\u79f0\u4e4b\u4e3aPer-parameter options\u7684\u64cd\u4f5c\uff0c\u5c31\u662f\u5bf9\u6bcf\u4e00\u4e2a\u53c2\u6570\u8fdb\u884c\u7279\u5b9a\u7684\u5b66\u4e60\u7387\uff0c\u6743\u91cd\u8870\u51cf\u7387\u6307\u5b9a\uff0c\u4ee5\u6ee1\u8db3\u66f4\u4e3a\u7ec6\u81f4\u7684\u8981\u6c42\u3002 weight_params = [ param for name , param in model . named_parameters () if \"bias\" not in name ] bias_params = [ param for name , param in model . named_parameters () if \"bias\" in name ] optimizer = torch . optim . SGD ([{ 'params' : weight_params , 'weight_decay' : 1e-5 }, { 'params' : bias_params , 'weight_decay' : 0 }], lr = 1e-2 , momentum = 0.9 ) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"5-5,\u635f\u5931\u51fd\u6570losses"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-3%2C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/#5-5\u635f\u5931\u51fd\u6570losses","text":"\u4e00\u822c\u6765\u8bf4\uff0c\u76d1\u7763\u5b66\u4e60\u7684\u76ee\u6807\u51fd\u6570\u7531\u635f\u5931\u51fd\u6570\u548c\u6b63\u5219\u5316\u9879\u7ec4\u6210\u3002(Objective = Loss + Regularization) Pytorch\u4e2d\u7684\u635f\u5931\u51fd\u6570\u4e00\u822c\u5728\u8bad\u7ec3\u6a21\u578b\u65f6\u5019\u6307\u5b9a\u3002 \u6ce8\u610fPytorch\u4e2d\u5185\u7f6e\u7684\u635f\u5931\u51fd\u6570\u7684\u53c2\u6570\u548ctensorflow\u4e0d\u540c\uff0c\u662fy_pred\u5728\u524d\uff0cy_true\u5728\u540e\uff0c\u800cTensorflow\u662fy_true\u5728\u524d\uff0cy_pred\u5728\u540e\u3002 \u5bf9\u4e8e\u56de\u5f52\u6a21\u578b\uff0c\u901a\u5e38\u4f7f\u7528\u7684\u5185\u7f6e\u635f\u5931\u51fd\u6570\u662f\u5747\u65b9\u635f\u5931\u51fd\u6570nn.MSELoss \u3002 \u5bf9\u4e8e\u4e8c\u5206\u7c7b\u6a21\u578b\uff0c\u901a\u5e38\u4f7f\u7528\u7684\u662f\u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570nn.BCELoss (\u8f93\u5165\u5df2\u7ecf\u662fsigmoid\u6fc0\u6d3b\u51fd\u6570\u4e4b\u540e\u7684\u7ed3\u679c) \u6216\u8005 nn.BCEWithLogitsLoss (\u8f93\u5165\u5c1a\u672a\u7ecf\u8fc7nn.Sigmoid\u6fc0\u6d3b\u51fd\u6570) \u3002 \u5bf9\u4e8e\u591a\u5206\u7c7b\u6a21\u578b\uff0c\u4e00\u822c\u63a8\u8350\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 nn.CrossEntropyLoss\u3002 (y_true\u9700\u8981\u662f\u4e00\u7ef4\u7684\uff0c\u662f\u7c7b\u522b\u7f16\u7801\u3002y_pred\u672a\u7ecf\u8fc7nn.Softmax\u6fc0\u6d3b\u3002) \u6b64\u5916\uff0c\u5982\u679c\u591a\u5206\u7c7b\u7684y_pred\u7ecf\u8fc7\u4e86nn.LogSoftmax\u6fc0\u6d3b\uff0c\u53ef\u4ee5\u4f7f\u7528nn.NLLLoss\u635f\u5931\u51fd\u6570(The negative log likelihood loss)\u3002 \u8fd9\u79cd\u65b9\u6cd5\u548c\u76f4\u63a5\u4f7f\u7528nn.CrossEntropyLoss\u7b49\u4ef7\u3002 \u5982\u679c\u6709\u9700\u8981\uff0c\u4e5f\u53ef\u4ee5\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff0c\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u9700\u8981\u63a5\u6536\u4e24\u4e2a\u5f20\u91cfy_pred\uff0cy_true\u4f5c\u4e3a\u8f93\u5165\u53c2\u6570\uff0c\u5e76\u8f93\u51fa\u4e00\u4e2a\u6807\u91cf\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\u503c\u3002 Pytorch\u4e2d\u7684\u6b63\u5219\u5316\u9879\u4e00\u822c\u901a\u8fc7\u81ea\u5b9a\u4e49\u7684\u65b9\u5f0f\u548c\u635f\u5931\u51fd\u6570\u4e00\u8d77\u6dfb\u52a0\u4f5c\u4e3a\u76ee\u6807\u51fd\u6570\u3002 \u5982\u679c\u4ec5\u4ec5\u4f7f\u7528L2\u6b63\u5219\u5316\uff0c\u4e5f\u53ef\u4ee5\u5229\u7528\u4f18\u5316\u5668\u7684weight_decay\u53c2\u6570\u6765\u5b9e\u73b0\u76f8\u540c\u7684\u6548\u679c\u3002","title":"5-5,\u635f\u5931\u51fd\u6570losses"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-3%2C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/#\u4e00\u5185\u7f6e\u635f\u5931\u51fd\u6570","text":"import numpy as np import pandas as pd import torch from torch import nn import torch.nn.functional as F y_pred = torch . tensor ([[ 10.0 , 0.0 , - 10.0 ],[ 8.0 , 8.0 , 8.0 ]]) y_true = torch . tensor ([ 0 , 2 ]) # \u76f4\u63a5\u8c03\u7528\u4ea4\u53c9\u71b5\u635f\u5931 ce = nn . CrossEntropyLoss ()( y_pred , y_true ) print ( ce ) # \u7b49\u4ef7\u4e8e\u5148\u8ba1\u7b97nn.LogSoftmax\u6fc0\u6d3b\uff0c\u518d\u8c03\u7528NLLLoss y_pred_logsoftmax = nn . LogSoftmax ( dim = 1 )( y_pred ) nll = nn . NLLLoss ()( y_pred_logsoftmax , y_true ) print ( nll ) tensor(0.5493) tensor(0.5493) \u5185\u7f6e\u7684\u635f\u5931\u51fd\u6570\u4e00\u822c\u6709\u7c7b\u7684\u5b9e\u73b0\u548c\u51fd\u6570\u7684\u5b9e\u73b0\u4e24\u79cd\u5f62\u5f0f\u3002 \u5982\uff1ann.BCE \u548c F.binary_cross_entropy \u90fd\u662f\u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u524d\u8005\u662f\u7c7b\u7684\u5b9e\u73b0\u5f62\u5f0f\uff0c\u540e\u8005\u662f\u51fd\u6570\u7684\u5b9e\u73b0\u5f62\u5f0f\u3002 \u5b9e\u9645\u4e0a\u7c7b\u7684\u5b9e\u73b0\u5f62\u5f0f\u901a\u5e38\u662f\u8c03\u7528\u51fd\u6570\u7684\u5b9e\u73b0\u5f62\u5f0f\u5e76\u7528nn.Module\u5c01\u88c5\u540e\u5f97\u5230\u7684\u3002 \u4e00\u822c\u6211\u4eec\u5e38\u7528\u7684\u662f\u7c7b\u7684\u5b9e\u73b0\u5f62\u5f0f\u3002\u5b83\u4eec\u5c01\u88c5\u5728torch.nn\u6a21\u5757\u4e0b\uff0c\u5e76\u4e14\u7c7b\u540d\u4ee5Loss\u7ed3\u5c3e\u3002 \u5e38\u7528\u7684\u4e00\u4e9b\u5185\u7f6e\u635f\u5931\u51fd\u6570\u8bf4\u660e\u5982\u4e0b\u3002 nn.MSELoss\uff08\u5747\u65b9\u8bef\u5dee\u635f\u5931\uff0c\u4e5f\u53eb\u505aL2\u635f\u5931\uff0c\u7528\u4e8e\u56de\u5f52\uff09 nn.L1Loss \uff08L1\u635f\u5931\uff0c\u4e5f\u53eb\u505a\u7edd\u5bf9\u503c\u8bef\u5dee\u635f\u5931\uff0c\u7528\u4e8e\u56de\u5f52\uff09 nn.SmoothL1Loss (\u5e73\u6ed1L1\u635f\u5931\uff0c\u5f53\u8f93\u5165\u5728-1\u52301\u4e4b\u95f4\u65f6\uff0c\u5e73\u6ed1\u4e3aL2\u635f\u5931\uff0c\u7528\u4e8e\u56de\u5f52) nn.BCELoss (\u4e8c\u5143\u4ea4\u53c9\u71b5\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b\uff0c\u8f93\u5165\u5df2\u7ecf\u8fc7nn.Sigmoid\u6fc0\u6d3b\uff0c\u5bf9\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u53ef\u4ee5\u7528weigths\u53c2\u6570\u8c03\u6574\u7c7b\u522b\u6743\u91cd) nn.BCEWithLogitsLoss (\u4e8c\u5143\u4ea4\u53c9\u71b5\uff0c\u7528\u4e8e\u4e8c\u5206\u7c7b\uff0c\u8f93\u5165\u672a\u7ecf\u8fc7nn.Sigmoid\u6fc0\u6d3b) nn.CrossEntropyLoss (\u4ea4\u53c9\u71b5\uff0c\u7528\u4e8e\u591a\u5206\u7c7b\uff0c\u8981\u6c42label\u4e3a\u7a00\u758f\u7f16\u7801\uff0c\u8f93\u5165\u672a\u7ecf\u8fc7nn.Softmax\u6fc0\u6d3b\uff0c\u5bf9\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u53ef\u4ee5\u7528weigths\u53c2\u6570\u8c03\u6574\u7c7b\u522b\u6743\u91cd) nn.NLLLoss (\u8d1f\u5bf9\u6570\u4f3c\u7136\u635f\u5931\uff0c\u7528\u4e8e\u591a\u5206\u7c7b\uff0c\u8981\u6c42label\u4e3a\u7a00\u758f\u7f16\u7801\uff0c\u8f93\u5165\u7ecf\u8fc7nn.LogSoftmax\u6fc0\u6d3b) nn.CosineSimilarity(\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff0c\u53ef\u7528\u4e8e\u591a\u5206\u7c7b) nn.AdaptiveLogSoftmaxWithLoss (\u4e00\u79cd\u9002\u5408\u975e\u5e38\u591a\u7c7b\u522b\u4e14\u7c7b\u522b\u5206\u5e03\u5f88\u4e0d\u5747\u8861\u7684\u635f\u5931\u51fd\u6570\uff0c\u4f1a\u81ea\u9002\u5e94\u5730\u5c06\u591a\u4e2a\u5c0f\u7c7b\u522b\u5408\u6210\u4e00\u4e2acluster) \u66f4\u591a\u635f\u5931\u51fd\u6570\u7684\u4ecb\u7ecd\u53c2\u8003\u5982\u4e0b\u77e5\u4e4e\u6587\u7ae0\uff1a \u300aPyTorch\u7684\u5341\u516b\u4e2a\u635f\u5931\u51fd\u6570\u300b https://zhuanlan.zhihu.com/p/61379965","title":"\u4e00\uff0c\u5185\u7f6e\u635f\u5931\u51fd\u6570"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-3%2C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/#\u4e8c\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570","text":"\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u63a5\u6536\u4e24\u4e2a\u5f20\u91cfy_pred,y_true\u4f5c\u4e3a\u8f93\u5165\u53c2\u6570\uff0c\u5e76\u8f93\u51fa\u4e00\u4e2a\u6807\u91cf\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\u503c\u3002 \u4e5f\u53ef\u4ee5\u5bf9nn.Module\u8fdb\u884c\u5b50\u7c7b\u5316\uff0c\u91cd\u5199forward\u65b9\u6cd5\u5b9e\u73b0\u635f\u5931\u7684\u8ba1\u7b97\u903b\u8f91\uff0c\u4ece\u800c\u5f97\u5230\u635f\u5931\u51fd\u6570\u7684\u7c7b\u7684\u5b9e\u73b0\u3002 \u4e0b\u9762\u662f\u4e00\u4e2aFocal Loss\u7684\u81ea\u5b9a\u4e49\u5b9e\u73b0\u793a\u8303\u3002Focal Loss\u662f\u4e00\u79cd\u5bf9binary_crossentropy\u7684\u6539\u8fdb\u635f\u5931\u51fd\u6570\u5f62\u5f0f\u3002 \u5b83\u5728\u6837\u672c\u4e0d\u5747\u8861\u548c\u5b58\u5728\u8f83\u591a\u6613\u5206\u7c7b\u7684\u6837\u672c\u65f6\u76f8\u6bd4binary_crossentropy\u5177\u6709\u660e\u663e\u7684\u4f18\u52bf\u3002 \u5b83\u6709\u4e24\u4e2a\u53ef\u8c03\u53c2\u6570\uff0calpha\u53c2\u6570\u548cgamma\u53c2\u6570\u3002\u5176\u4e2dalpha\u53c2\u6570\u4e3b\u8981\u7528\u4e8e\u8870\u51cf\u8d1f\u6837\u672c\u7684\u6743\u91cd\uff0cgamma\u53c2\u6570\u4e3b\u8981\u7528\u4e8e\u8870\u51cf\u5bb9\u6613\u8bad\u7ec3\u6837\u672c\u7684\u6743\u91cd\u3002 \u4ece\u800c\u8ba9\u6a21\u578b\u66f4\u52a0\u805a\u7126\u5728\u6b63\u6837\u672c\u548c\u56f0\u96be\u6837\u672c\u4e0a\u3002\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\u53eb\u505aFocal Loss\u3002 \u8be6\u89c1\u300a5\u5206\u949f\u7406\u89e3Focal Loss\u4e0eGHM\u2014\u2014\u89e3\u51b3\u6837\u672c\u4e0d\u5e73\u8861\u5229\u5668\u300b https://zhuanlan.zhihu.com/p/80594704 focal\\_loss(y,p) = \\begin{cases} -\\alpha (1-p)^{\\gamma}\\log(p) & \\text{if y = 1}\\\\ -(1-\\alpha) p^{\\gamma}\\log(1-p) & \\text{if y = 0} \\end{cases} focal\\_loss(y,p) = \\begin{cases} -\\alpha (1-p)^{\\gamma}\\log(p) & \\text{if y = 1}\\\\ -(1-\\alpha) p^{\\gamma}\\log(1-p) & \\text{if y = 0} \\end{cases} class FocalLoss ( nn . Module ): def __init__ ( self , gamma = 2.0 , alpha = 0.75 ): super () . __init__ () self . gamma = gamma self . alpha = alpha def forward ( self , y_pred , y_true ): bce = torch . nn . BCELoss ( reduction = \"none\" )( y_pred , y_true ) p_t = ( y_true * y_pred ) + (( 1 - y_true ) * ( 1 - y_pred )) alpha_factor = y_true * self . alpha + ( 1 - y_true ) * ( 1 - self . alpha ) modulating_factor = torch . pow ( 1.0 - p_t , self . gamma ) loss = torch . mean ( alpha_factor * modulating_factor * bce ) return loss #\u56f0\u96be\u6837\u672c y_pred_hard = torch . tensor ([[ 0.5 ],[ 0.5 ]]) y_true_hard = torch . tensor ([[ 1.0 ],[ 0.0 ]]) #\u5bb9\u6613\u6837\u672c y_pred_easy = torch . tensor ([[ 0.9 ],[ 0.1 ]]) y_true_easy = torch . tensor ([[ 1.0 ],[ 0.0 ]]) focal_loss = FocalLoss () bce_loss = nn . BCELoss () print ( \"focal_loss(hard samples):\" , focal_loss ( y_pred_hard , y_true_hard )) print ( \"bce_loss(hard samples):\" , bce_loss ( y_pred_hard , y_true_hard )) print ( \"focal_loss(easy samples):\" , focal_loss ( y_pred_easy , y_true_easy )) print ( \"bce_loss(easy samples):\" , bce_loss ( y_pred_easy , y_true_easy )) #\u53ef\u89c1 focal_loss\u8ba9\u5bb9\u6613\u6837\u672c\u7684\u6743\u91cd\u8870\u51cf\u5230\u539f\u6765\u7684 0.0005/0.1054 = 0.00474 #\u800c\u8ba9\u56f0\u96be\u6837\u672c\u7684\u6743\u91cd\u53ea\u8870\u51cf\u5230\u539f\u6765\u7684 0.0866/0.6931=0.12496 # \u56e0\u6b64\u76f8\u5bf9\u800c\u8a00\uff0cfocal_loss\u53ef\u4ee5\u8870\u51cf\u5bb9\u6613\u6837\u672c\u7684\u6743\u91cd\u3002 focal_loss(hard samples): tensor(0.0866) bce_loss(hard samples): tensor(0.6931) focal_loss(easy samples): tensor(0.0005) bce_loss(easy samples): tensor(0.1054) FocalLoss\u7684\u4f7f\u7528\u5b8c\u6574\u8303\u4f8b\u53ef\u4ee5\u53c2\u8003\u4e0b\u9762\u4e2d \u81ea\u5b9a\u4e49L1\u548cL2\u6b63\u5219\u5316\u9879 \u4e2d\u7684\u8303\u4f8b\uff0c\u8be5\u8303\u4f8b\u65e2\u6f14\u793a\u4e86\u81ea\u5b9a\u4e49\u6b63\u5219\u5316\u9879\u7684\u65b9\u6cd5\uff0c\u4e5f\u6f14\u793a\u4e86FocalLoss\u7684\u4f7f\u7528\u65b9\u6cd5\u3002","title":"\u4e8c\uff0c\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-3%2C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/#\u4e09\u81ea\u5b9a\u4e49l1\u548cl2\u6b63\u5219\u5316\u9879","text":"\u901a\u5e38\u8ba4\u4e3aL1 \u6b63\u5219\u5316\u53ef\u4ee5\u4ea7\u751f\u7a00\u758f\u6743\u503c\u77e9\u9635\uff0c\u5373\u4ea7\u751f\u4e00\u4e2a\u7a00\u758f\u6a21\u578b\uff0c\u53ef\u4ee5\u7528\u4e8e\u7279\u5f81\u9009\u62e9\u3002 \u800cL2 \u6b63\u5219\u5316\u53ef\u4ee5\u9632\u6b62\u6a21\u578b\u8fc7\u62df\u5408\uff08overfitting\uff09\u3002\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\uff0cL1\u4e5f\u53ef\u4ee5\u9632\u6b62\u8fc7\u62df\u5408\u3002 \u4e0b\u9762\u4ee5\u4e00\u4e2a\u4e8c\u5206\u7c7b\u95ee\u9898\u4e3a\u4f8b\uff0c\u6f14\u793a\u7ed9\u6a21\u578b\u7684\u76ee\u6807\u51fd\u6570\u6dfb\u52a0\u81ea\u5b9a\u4e49L1\u548cL2\u6b63\u5219\u5316\u9879\u7684\u65b9\u6cd5\u3002 \u8fd9\u4e2a\u8303\u4f8b\u540c\u65f6\u6f14\u793a\u4e86\u4e0a\u4e00\u4e2a\u90e8\u5206\u7684FocalLoss\u7684\u4f7f\u7528\u3002 1\uff0c\u51c6\u5907\u6570\u636e import numpy as np import pandas as pd from matplotlib import pyplot as plt import torch from torch import nn import torch.nn.functional as F from torch.utils.data import Dataset , DataLoader , TensorDataset import torchkeras % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u6b63\u8d1f\u6837\u672c\u6570\u91cf n_positive , n_negative = 200 , 6000 #\u751f\u6210\u6b63\u6837\u672c, \u5c0f\u5706\u73af\u5206\u5e03 r_p = 5.0 + torch . normal ( 0.0 , 1.0 , size = [ n_positive , 1 ]) theta_p = 2 * np . pi * torch . rand ([ n_positive , 1 ]) Xp = torch . cat ([ r_p * torch . cos ( theta_p ), r_p * torch . sin ( theta_p )], axis = 1 ) Yp = torch . ones_like ( r_p ) #\u751f\u6210\u8d1f\u6837\u672c, \u5927\u5706\u73af\u5206\u5e03 r_n = 8.0 + torch . normal ( 0.0 , 1.0 , size = [ n_negative , 1 ]) theta_n = 2 * np . pi * torch . rand ([ n_negative , 1 ]) Xn = torch . cat ([ r_n * torch . cos ( theta_n ), r_n * torch . sin ( theta_n )], axis = 1 ) Yn = torch . zeros_like ( r_n ) #\u6c47\u603b\u6837\u672c X = torch . cat ([ Xp , Xn ], axis = 0 ) Y = torch . cat ([ Yp , Yn ], axis = 0 ) #\u53ef\u89c6\u5316 plt . figure ( figsize = ( 6 , 6 )) plt . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) plt . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) plt . legend ([ \"positive\" , \"negative\" ]); ds = TensorDataset ( X , Y ) ds_train , ds_valid = torch . utils . data . random_split ( ds ,[ int ( len ( ds ) * 0.7 ), len ( ds ) - int ( len ( ds ) * 0.7 )]) dl_train = DataLoader ( ds_train , batch_size = 100 , shuffle = True , num_workers = 2 ) dl_valid = DataLoader ( ds_valid , batch_size = 100 , num_workers = 2 ) 2\uff0c\u5b9a\u4e49\u6a21\u578b class DNNModel ( torchkeras . Model ): def __init__ ( self ): super ( DNNModel , self ) . __init__ () self . fc1 = nn . Linear ( 2 , 4 ) self . fc2 = nn . Linear ( 4 , 8 ) self . fc3 = nn . Linear ( 8 , 1 ) def forward ( self , x ): x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) y = nn . Sigmoid ()( self . fc3 ( x )) return y model = DNNModel () model . summary ( input_shape = ( 2 ,)) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Linear-1 [-1, 4] 12 Linear-2 [-1, 8] 40 Linear-3 [-1, 1] 9 ================================================================ Total params: 61 Trainable params: 61 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.000008 Forward/backward pass size (MB): 0.000099 Params size (MB): 0.000233 Estimated Total Size (MB): 0.000340 ---------------------------------------------------------------- 3\uff0c\u8bad\u7ec3\u6a21\u578b # \u51c6\u786e\u7387 def accuracy ( y_pred , y_true ): y_pred = torch . where ( y_pred > 0.5 , torch . ones_like ( y_pred , dtype = torch . float32 ), torch . zeros_like ( y_pred , dtype = torch . float32 )) acc = torch . mean ( 1 - torch . abs ( y_true - y_pred )) return acc # L2\u6b63\u5219\u5316 def L2Loss ( model , alpha ): l2_loss = torch . tensor ( 0.0 , requires_grad = True ) for name , param in model . named_parameters (): if 'bias' not in name : #\u4e00\u822c\u4e0d\u5bf9\u504f\u7f6e\u9879\u4f7f\u7528\u6b63\u5219 l2_loss = l2_loss + ( 0.5 * alpha * torch . sum ( torch . pow ( param , 2 ))) return l2_loss # L1\u6b63\u5219\u5316 def L1Loss ( model , beta ): l1_loss = torch . tensor ( 0.0 , requires_grad = True ) for name , param in model . named_parameters (): if 'bias' not in name : l1_loss = l1_loss + beta * torch . sum ( torch . abs ( param )) return l1_loss # \u5c06L2\u6b63\u5219\u548cL1\u6b63\u5219\u6dfb\u52a0\u5230FocalLoss\u635f\u5931\uff0c\u4e00\u8d77\u4f5c\u4e3a\u76ee\u6807\u51fd\u6570 def focal_loss_with_regularization ( y_pred , y_true ): focal = FocalLoss ()( y_pred , y_true ) l2_loss = L2Loss ( model , 0.001 ) #\u6ce8\u610f\u8bbe\u7f6e\u6b63\u5219\u5316\u9879\u7cfb\u6570 l1_loss = L1Loss ( model , 0.001 ) total_loss = focal + l2_loss + l1_loss return total_loss model . compile ( loss_func = focal_loss_with_regularization , optimizer = torch . optim . Adam ( model . parameters (), lr = 0.01 ), metrics_dict = { \"accuracy\" : accuracy }) dfhistory = model . fit ( 30 , dl_train = dl_train , dl_val = dl_valid , log_step_freq = 30 ) Start Training ... ================================================================================2020-07-11 23:34:17 {'step': 30, 'loss': 0.021, 'accuracy': 0.972} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 1 | 0.022 | 0.971 | 0.025 | 0.96 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-11 23:34:27 {'step': 30, 'loss': 0.016, 'accuracy': 0.984} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 30 | 0.016 | 0.981 | 0.017 | 0.983 | +-------+-------+----------+----------+--------------+ ================================================================================2020-07-11 23:34:27 Finished Training... # \u7ed3\u679c\u53ef\u89c6\u5316 fig , ( ax1 , ax2 ) = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 12 , 5 )) ax1 . scatter ( Xp [:, 0 ], Xp [:, 1 ], c = \"r\" ) ax1 . scatter ( Xn [:, 0 ], Xn [:, 1 ], c = \"g\" ) ax1 . legend ([ \"positive\" , \"negative\" ]); ax1 . set_title ( \"y_true\" ); Xp_pred = X [ torch . squeeze ( model . forward ( X ) >= 0.5 )] Xn_pred = X [ torch . squeeze ( model . forward ( X ) < 0.5 )] ax2 . scatter ( Xp_pred [:, 0 ], Xp_pred [:, 1 ], c = \"r\" ) ax2 . scatter ( Xn_pred [:, 0 ], Xn_pred [:, 1 ], c = \"g\" ) ax2 . legend ([ \"positive\" , \"negative\" ]); ax2 . set_title ( \"y_pred\" );","title":"\u4e09\uff0c\u81ea\u5b9a\u4e49L1\u548cL2\u6b63\u5219\u5316\u9879"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-3%2C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/#\u56db\u901a\u8fc7\u4f18\u5316\u5668\u5b9e\u73b0l2\u6b63\u5219\u5316","text":"\u5982\u679c\u4ec5\u4ec5\u9700\u8981\u4f7f\u7528L2\u6b63\u5219\u5316\uff0c\u90a3\u4e48\u4e5f\u53ef\u4ee5\u5229\u7528\u4f18\u5316\u5668\u7684weight_decay\u53c2\u6570\u6765\u5b9e\u73b0\u3002 weight_decay\u53c2\u6570\u53ef\u4ee5\u8bbe\u7f6e\u53c2\u6570\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u8870\u51cf\uff0c\u8fd9\u548cL2\u6b63\u5219\u5316\u7684\u4f5c\u7528\u6548\u679c\u7b49\u4ef7\u3002 before L2 regularization: gradient descent: w = w - lr * dloss_dw after L2 regularization: gradient descent: w = w - lr * (dloss_dw+beta*w) = (1-lr*beta)*w - lr*dloss_dw so \uff081-lr*beta\uff09is the weight decay ratio. Pytorch\u7684\u4f18\u5316\u5668\u652f\u6301\u4e00\u79cd\u79f0\u4e4b\u4e3aPer-parameter options\u7684\u64cd\u4f5c\uff0c\u5c31\u662f\u5bf9\u6bcf\u4e00\u4e2a\u53c2\u6570\u8fdb\u884c\u7279\u5b9a\u7684\u5b66\u4e60\u7387\uff0c\u6743\u91cd\u8870\u51cf\u7387\u6307\u5b9a\uff0c\u4ee5\u6ee1\u8db3\u66f4\u4e3a\u7ec6\u81f4\u7684\u8981\u6c42\u3002 weight_params = [ param for name , param in model . named_parameters () if \"bias\" not in name ] bias_params = [ param for name , param in model . named_parameters () if \"bias\" in name ] optimizer = torch . optim . SGD ([{ 'params' : weight_params , 'weight_decay' : 1e-5 }, { 'params' : bias_params , 'weight_decay' : 0 }], lr = 1e-2 , momentum = 0.9 ) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u56db\uff0c\u901a\u8fc7\u4f18\u5316\u5668\u5b9e\u73b0L2\u6b63\u5219\u5316"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-4%2CTensorBoard%E5%8F%AF%E8%A7%86%E5%8C%96/","text":"5-4,TensorBoard\u53ef\u89c6\u5316 # \u5728\u6211\u4eec\u7684\u70bc\u4e39\u8fc7\u7a0b\u4e2d\uff0c\u5982\u679c\u80fd\u591f\u4f7f\u7528\u4e30\u5bcc\u7684\u56fe\u50cf\u6765\u5c55\u793a\u6a21\u578b\u7684\u7ed3\u6784\uff0c\u6307\u6807\u7684\u53d8\u5316\uff0c\u53c2\u6570\u7684\u5206\u5e03\uff0c\u8f93\u5165\u7684\u5f62\u6001\u7b49\u4fe1\u606f\uff0c\u65e0\u7591\u4f1a\u63d0\u5347\u6211\u4eec\u5bf9\u95ee\u9898\u7684\u6d1e\u5bdf\u529b\uff0c\u5e76\u589e\u52a0\u8bb8\u591a\u70bc\u4e39\u7684\u4e50\u8da3\u3002 TensorBoard\u6b63\u662f\u8fd9\u6837\u4e00\u4e2a\u795e\u5947\u7684\u70bc\u4e39\u53ef\u89c6\u5316\u8f85\u52a9\u5de5\u5177\u3002\u5b83\u539f\u662fTensorFlow\u7684\u5c0f\u5f1f\uff0c\u4f46\u5b83\u4e5f\u80fd\u591f\u5f88\u597d\u5730\u548cPytorch\u8fdb\u884c\u914d\u5408\u3002\u751a\u81f3\u5728Pytorch\u4e2d\u4f7f\u7528TensorBoard\u6bd4TensorFlow\u4e2d\u4f7f\u7528TensorBoard\u8fd8\u8981\u6765\u7684\u66f4\u52a0\u7b80\u5355\u548c\u81ea\u7136\u3002 Pytorch\u4e2d\u5229\u7528TensorBoard\u53ef\u89c6\u5316\u7684\u5927\u6982\u8fc7\u7a0b\u5982\u4e0b\uff1a \u9996\u5148\u5728Pytorch\u4e2d\u6307\u5b9a\u4e00\u4e2a\u76ee\u5f55\u521b\u5efa\u4e00\u4e2atorch.utils.tensorboard.SummaryWriter\u65e5\u5fd7\u5199\u5165\u5668\u3002 \u7136\u540e\u6839\u636e\u9700\u8981\u53ef\u89c6\u5316\u7684\u4fe1\u606f\uff0c\u5229\u7528\u65e5\u5fd7\u5199\u5165\u5668\u5c06\u76f8\u5e94\u4fe1\u606f\u65e5\u5fd7\u5199\u5165\u6211\u4eec\u6307\u5b9a\u7684\u76ee\u5f55\u3002 \u6700\u540e\u5c31\u53ef\u4ee5\u4f20\u5165\u65e5\u5fd7\u76ee\u5f55\u4f5c\u4e3a\u53c2\u6570\u542f\u52a8TensorBoard\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u5728TensorBoard\u4e2d\u6109\u5feb\u5730\u770b\u7247\u4e86\u3002 \u6211\u4eec\u4e3b\u8981\u4ecb\u7ecdPytorch\u4e2d\u5229\u7528TensorBoard\u8fdb\u884c\u5982\u4e0b\u65b9\u9762\u4fe1\u606f\u7684\u53ef\u89c6\u5316\u7684\u65b9\u6cd5\u3002 \u53ef\u89c6\u5316\u6a21\u578b\u7ed3\u6784\uff1a writer.add_graph \u53ef\u89c6\u5316\u6307\u6807\u53d8\u5316\uff1a writer.add_scalar \u53ef\u89c6\u5316\u53c2\u6570\u5206\u5e03\uff1a writer.add_histogram \u53ef\u89c6\u5316\u539f\u59cb\u56fe\u50cf\uff1a writer.add_image \u6216 writer.add_images \u53ef\u89c6\u5316\u4eba\u5de5\u7ed8\u56fe\uff1a writer.add_figure \u4e00\uff0c\u53ef\u89c6\u5316\u6a21\u578b\u7ed3\u6784 # import torch from torch import nn from torch.utils.tensorboard import SummaryWriter from torchkeras import Model , summary class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 ) self . pool = nn . MaxPool2d ( kernel_size = 2 , stride = 2 ) self . conv2 = nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ) self . dropout = nn . Dropout2d ( p = 0.1 ) self . adaptive_pool = nn . AdaptiveMaxPool2d (( 1 , 1 )) self . flatten = nn . Flatten () self . linear1 = nn . Linear ( 64 , 32 ) self . relu = nn . ReLU () self . linear2 = nn . Linear ( 32 , 1 ) self . sigmoid = nn . Sigmoid () def forward ( self , x ): x = self . conv1 ( x ) x = self . pool ( x ) x = self . conv2 ( x ) x = self . pool ( x ) x = self . dropout ( x ) x = self . adaptive_pool ( x ) x = self . flatten ( x ) x = self . linear1 ( x ) x = self . relu ( x ) x = self . linear2 ( x ) y = self . sigmoid ( x ) return y net = Net () print ( net ) Net( (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (dropout): Dropout2d(p=0.1, inplace=False) (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1)) (flatten): Flatten() (linear1): Linear(in_features=64, out_features=32, bias=True) (relu): ReLU() (linear2): Linear(in_features=32, out_features=1, bias=True) (sigmoid): Sigmoid() ) summary ( net , input_shape = ( 3 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 896 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 1] 33 Sigmoid-11 [-1, 1] 0 ================================================================ Total params: 54,273 Trainable params: 54,273 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.011719 Forward/backward pass size (MB): 0.359634 Params size (MB): 0.207035 Estimated Total Size (MB): 0.578388 ---------------------------------------------------------------- writer = SummaryWriter ( '../data/tensorboard' ) writer . add_graph ( net , input_to_model = torch . rand ( 1 , 3 , 32 , 32 )) writer . close () % load_ext tensorboard #%tensorboard --logdir ../data/tensorboard from tensorboard import notebook #\u67e5\u770b\u542f\u52a8\u7684tensorboard\u7a0b\u5e8f notebook . list () #\u542f\u52a8tensorboard\u7a0b\u5e8f notebook . start ( \"--logdir ../data/tensorboard\" ) #\u7b49\u4ef7\u4e8e\u5728\u547d\u4ee4\u884c\u4e2d\u6267\u884c tensorboard --logdir ../data/tensorboard #\u53ef\u4ee5\u5728\u6d4f\u89c8\u5668\u4e2d\u6253\u5f00 http://localhost:6006/ \u67e5\u770b \u4e8c\uff0c\u53ef\u89c6\u5316\u6307\u6807\u53d8\u5316 # \u6709\u65f6\u5019\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u5982\u679c\u80fd\u591f\u5b9e\u65f6\u52a8\u6001\u5730\u67e5\u770bloss\u548c\u5404\u79cdmetric\u7684\u53d8\u5316\u66f2\u7ebf\uff0c\u90a3\u4e48\u65e0\u7591\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u66f4\u52a0\u76f4\u89c2\u5730\u4e86\u89e3\u6a21\u578b\u7684\u8bad\u7ec3\u60c5\u51b5\u3002 \u6ce8\u610f\uff0cwriter.add_scalar\u4ec5\u80fd\u5bf9\u6807\u91cf\u7684\u503c\u7684\u53d8\u5316\u8fdb\u884c\u53ef\u89c6\u5316\u3002\u56e0\u6b64\u5b83\u4e00\u822c\u7528\u4e8e\u5bf9loss\u548cmetric\u7684\u53d8\u5316\u8fdb\u884c\u53ef\u89c6\u5316\u5206\u6790\u3002 import numpy as np import torch from torch.utils.tensorboard import SummaryWriter # f(x) = a*x**2 + b*x + c\u7684\u6700\u5c0f\u503c x = torch . tensor ( 0.0 , requires_grad = True ) # x\u9700\u8981\u88ab\u6c42\u5bfc a = torch . tensor ( 1.0 ) b = torch . tensor ( - 2.0 ) c = torch . tensor ( 1.0 ) optimizer = torch . optim . SGD ( params = [ x ], lr = 0.01 ) def f ( x ): result = a * torch . pow ( x , 2 ) + b * x + c return ( result ) writer = SummaryWriter ( '../data/tensorboard' ) for i in range ( 500 ): optimizer . zero_grad () y = f ( x ) y . backward () optimizer . step () writer . add_scalar ( \"x\" , x . item (), i ) #\u65e5\u5fd7\u4e2d\u8bb0\u5f55x\u5728\u7b2cstep i \u7684\u503c writer . add_scalar ( \"y\" , y . item (), i ) #\u65e5\u5fd7\u4e2d\u8bb0\u5f55y\u5728\u7b2cstep i \u7684\u503c writer . close () print ( \"y=\" , f ( x ) . data , \";\" , \"x=\" , x . data ) y= tensor(0.) ; x= tensor(1.0000) \u4e09\uff0c\u53ef\u89c6\u5316\u53c2\u6570\u5206\u5e03 # \u5982\u679c\u9700\u8981\u5bf9\u6a21\u578b\u7684\u53c2\u6570(\u4e00\u822c\u975e\u6807\u91cf)\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u53d8\u5316\u8fdb\u884c\u53ef\u89c6\u5316\uff0c\u53ef\u4ee5\u4f7f\u7528 writer.add_histogram\u3002 \u5b83\u80fd\u591f\u89c2\u6d4b\u5f20\u91cf\u503c\u5206\u5e03\u7684\u76f4\u65b9\u56fe\u968f\u8bad\u7ec3\u6b65\u9aa4\u7684\u53d8\u5316\u8d8b\u52bf\u3002 import numpy as np import torch from torch.utils.tensorboard import SummaryWriter # \u521b\u5efa\u6b63\u6001\u5206\u5e03\u7684\u5f20\u91cf\u6a21\u62df\u53c2\u6570\u77e9\u9635 def norm ( mean , std ): t = std * torch . randn (( 100 , 20 )) + mean return t writer = SummaryWriter ( '../data/tensorboard' ) for step , mean in enumerate ( range ( - 10 , 10 , 1 )): w = norm ( mean , 1 ) writer . add_histogram ( \"w\" , w , step ) writer . flush () writer . close () \u56db\uff0c\u53ef\u89c6\u5316\u539f\u59cb\u56fe\u50cf # \u5982\u679c\u6211\u4eec\u505a\u56fe\u50cf\u76f8\u5173\u7684\u4efb\u52a1\uff0c\u4e5f\u53ef\u4ee5\u5c06\u539f\u59cb\u7684\u56fe\u7247\u5728tensorboard\u4e2d\u8fdb\u884c\u53ef\u89c6\u5316\u5c55\u793a\u3002 \u5982\u679c\u53ea\u5199\u5165\u4e00\u5f20\u56fe\u7247\u4fe1\u606f\uff0c\u53ef\u4ee5\u4f7f\u7528writer.add_image\u3002 \u5982\u679c\u8981\u5199\u5165\u591a\u5f20\u56fe\u7247\u4fe1\u606f\uff0c\u53ef\u4ee5\u4f7f\u7528writer.add_images\u3002 \u4e5f\u53ef\u4ee5\u7528 torchvision.utils.make_grid\u5c06\u591a\u5f20\u56fe\u7247\u62fc\u6210\u4e00\u5f20\u56fe\u7247\uff0c\u7136\u540e\u7528writer.add_image\u5199\u5165\u3002 \u6ce8\u610f\uff0c\u4f20\u5165\u7684\u662f\u4ee3\u8868\u56fe\u7247\u4fe1\u606f\u7684Pytorch\u4e2d\u7684\u5f20\u91cf\u6570\u636e\u3002 import torch import torchvision from torch import nn from torch.utils.data import Dataset , DataLoader from torchvision import transforms , datasets transform_train = transforms . Compose ( [ transforms . ToTensor ()]) transform_valid = transforms . Compose ( [ transforms . ToTensor ()]) ds_train = datasets . ImageFolder ( \"../data/cifar2/train/\" , transform = transform_train , target_transform = lambda t : torch . tensor ([ t ]) . float ()) ds_valid = datasets . ImageFolder ( \"../data/cifar2/test/\" , transform = transform_train , target_transform = lambda t : torch . tensor ([ t ]) . float ()) print ( ds_train . class_to_idx ) dl_train = DataLoader ( ds_train , batch_size = 50 , shuffle = True , num_workers = 3 ) dl_valid = DataLoader ( ds_valid , batch_size = 50 , shuffle = True , num_workers = 3 ) dl_train_iter = iter ( dl_train ) images , labels = dl_train_iter . next () # \u4ec5\u67e5\u770b\u4e00\u5f20\u56fe\u7247 writer = SummaryWriter ( '../data/tensorboard' ) writer . add_image ( 'images[0]' , images [ 0 ]) writer . close () # \u5c06\u591a\u5f20\u56fe\u7247\u62fc\u63a5\u6210\u4e00\u5f20\u56fe\u7247\uff0c\u4e2d\u95f4\u7528\u9ed1\u8272\u7f51\u683c\u5206\u5272 writer = SummaryWriter ( '../data/tensorboard' ) # create grid of images img_grid = torchvision . utils . make_grid ( images ) writer . add_image ( 'image_grid' , img_grid ) writer . close () # \u5c06\u591a\u5f20\u56fe\u7247\u76f4\u63a5\u5199\u5165 writer = SummaryWriter ( '../data/tensorboard' ) writer . add_images ( \"images\" , images , global_step = 0 ) writer . close () {'0_airplane': 0, '1_automobile': 1} \u4e94\uff0c\u53ef\u89c6\u5316\u4eba\u5de5\u7ed8\u56fe # \u5982\u679c\u6211\u4eec\u5c06matplotlib\u7ed8\u56fe\u7684\u7ed3\u679c\u518d tensorboard\u4e2d\u5c55\u793a\uff0c\u53ef\u4ee5\u4f7f\u7528 add_figure. \u6ce8\u610f\uff0c\u548cwriter.add_image\u4e0d\u540c\u7684\u662f\uff0cwriter.add_figure\u9700\u8981\u4f20\u5165matplotlib\u7684figure\u5bf9\u8c61\u3002 import torch import torchvision from torch import nn from torch.utils.data import Dataset , DataLoader from torchvision import transforms , datasets transform_train = transforms . Compose ( [ transforms . ToTensor ()]) transform_valid = transforms . Compose ( [ transforms . ToTensor ()]) ds_train = datasets . ImageFolder ( \"../data/cifar2/train/\" , transform = transform_train , target_transform = lambda t : torch . tensor ([ t ]) . float ()) ds_valid = datasets . ImageFolder ( \"../data/cifar2/test/\" , transform = transform_train , target_transform = lambda t : torch . tensor ([ t ]) . float ()) print ( ds_train . class_to_idx ) {'0_airplane': 0, '1_automobile': 1} % matplotlib inline % config InlineBackend . figure_format = 'svg' from matplotlib import pyplot as plt figure = plt . figure ( figsize = ( 8 , 8 )) for i in range ( 9 ): img , label = ds_train [ i ] img = img . permute ( 1 , 2 , 0 ) ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow ( img . numpy ()) ax . set_title ( \"label = %d \" % label . item ()) ax . set_xticks ([]) ax . set_yticks ([]) plt . show () writer = SummaryWriter ( '../data/tensorboard' ) writer . add_figure ( 'figure' , figure , global_step = 0 ) writer . close () \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"5-4,TensorBoard\u53ef\u89c6\u5316"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-4%2CTensorBoard%E5%8F%AF%E8%A7%86%E5%8C%96/#5-4tensorboard\u53ef\u89c6\u5316","text":"\u5728\u6211\u4eec\u7684\u70bc\u4e39\u8fc7\u7a0b\u4e2d\uff0c\u5982\u679c\u80fd\u591f\u4f7f\u7528\u4e30\u5bcc\u7684\u56fe\u50cf\u6765\u5c55\u793a\u6a21\u578b\u7684\u7ed3\u6784\uff0c\u6307\u6807\u7684\u53d8\u5316\uff0c\u53c2\u6570\u7684\u5206\u5e03\uff0c\u8f93\u5165\u7684\u5f62\u6001\u7b49\u4fe1\u606f\uff0c\u65e0\u7591\u4f1a\u63d0\u5347\u6211\u4eec\u5bf9\u95ee\u9898\u7684\u6d1e\u5bdf\u529b\uff0c\u5e76\u589e\u52a0\u8bb8\u591a\u70bc\u4e39\u7684\u4e50\u8da3\u3002 TensorBoard\u6b63\u662f\u8fd9\u6837\u4e00\u4e2a\u795e\u5947\u7684\u70bc\u4e39\u53ef\u89c6\u5316\u8f85\u52a9\u5de5\u5177\u3002\u5b83\u539f\u662fTensorFlow\u7684\u5c0f\u5f1f\uff0c\u4f46\u5b83\u4e5f\u80fd\u591f\u5f88\u597d\u5730\u548cPytorch\u8fdb\u884c\u914d\u5408\u3002\u751a\u81f3\u5728Pytorch\u4e2d\u4f7f\u7528TensorBoard\u6bd4TensorFlow\u4e2d\u4f7f\u7528TensorBoard\u8fd8\u8981\u6765\u7684\u66f4\u52a0\u7b80\u5355\u548c\u81ea\u7136\u3002 Pytorch\u4e2d\u5229\u7528TensorBoard\u53ef\u89c6\u5316\u7684\u5927\u6982\u8fc7\u7a0b\u5982\u4e0b\uff1a \u9996\u5148\u5728Pytorch\u4e2d\u6307\u5b9a\u4e00\u4e2a\u76ee\u5f55\u521b\u5efa\u4e00\u4e2atorch.utils.tensorboard.SummaryWriter\u65e5\u5fd7\u5199\u5165\u5668\u3002 \u7136\u540e\u6839\u636e\u9700\u8981\u53ef\u89c6\u5316\u7684\u4fe1\u606f\uff0c\u5229\u7528\u65e5\u5fd7\u5199\u5165\u5668\u5c06\u76f8\u5e94\u4fe1\u606f\u65e5\u5fd7\u5199\u5165\u6211\u4eec\u6307\u5b9a\u7684\u76ee\u5f55\u3002 \u6700\u540e\u5c31\u53ef\u4ee5\u4f20\u5165\u65e5\u5fd7\u76ee\u5f55\u4f5c\u4e3a\u53c2\u6570\u542f\u52a8TensorBoard\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u5728TensorBoard\u4e2d\u6109\u5feb\u5730\u770b\u7247\u4e86\u3002 \u6211\u4eec\u4e3b\u8981\u4ecb\u7ecdPytorch\u4e2d\u5229\u7528TensorBoard\u8fdb\u884c\u5982\u4e0b\u65b9\u9762\u4fe1\u606f\u7684\u53ef\u89c6\u5316\u7684\u65b9\u6cd5\u3002 \u53ef\u89c6\u5316\u6a21\u578b\u7ed3\u6784\uff1a writer.add_graph \u53ef\u89c6\u5316\u6307\u6807\u53d8\u5316\uff1a writer.add_scalar \u53ef\u89c6\u5316\u53c2\u6570\u5206\u5e03\uff1a writer.add_histogram \u53ef\u89c6\u5316\u539f\u59cb\u56fe\u50cf\uff1a writer.add_image \u6216 writer.add_images \u53ef\u89c6\u5316\u4eba\u5de5\u7ed8\u56fe\uff1a writer.add_figure","title":"5-4,TensorBoard\u53ef\u89c6\u5316"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-4%2CTensorBoard%E5%8F%AF%E8%A7%86%E5%8C%96/#\u4e00\u53ef\u89c6\u5316\u6a21\u578b\u7ed3\u6784","text":"import torch from torch import nn from torch.utils.tensorboard import SummaryWriter from torchkeras import Model , summary class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 ) self . pool = nn . MaxPool2d ( kernel_size = 2 , stride = 2 ) self . conv2 = nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ) self . dropout = nn . Dropout2d ( p = 0.1 ) self . adaptive_pool = nn . AdaptiveMaxPool2d (( 1 , 1 )) self . flatten = nn . Flatten () self . linear1 = nn . Linear ( 64 , 32 ) self . relu = nn . ReLU () self . linear2 = nn . Linear ( 32 , 1 ) self . sigmoid = nn . Sigmoid () def forward ( self , x ): x = self . conv1 ( x ) x = self . pool ( x ) x = self . conv2 ( x ) x = self . pool ( x ) x = self . dropout ( x ) x = self . adaptive_pool ( x ) x = self . flatten ( x ) x = self . linear1 ( x ) x = self . relu ( x ) x = self . linear2 ( x ) y = self . sigmoid ( x ) return y net = Net () print ( net ) Net( (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (dropout): Dropout2d(p=0.1, inplace=False) (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1)) (flatten): Flatten() (linear1): Linear(in_features=64, out_features=32, bias=True) (relu): ReLU() (linear2): Linear(in_features=32, out_features=1, bias=True) (sigmoid): Sigmoid() ) summary ( net , input_shape = ( 3 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 896 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 1] 33 Sigmoid-11 [-1, 1] 0 ================================================================ Total params: 54,273 Trainable params: 54,273 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.011719 Forward/backward pass size (MB): 0.359634 Params size (MB): 0.207035 Estimated Total Size (MB): 0.578388 ---------------------------------------------------------------- writer = SummaryWriter ( '../data/tensorboard' ) writer . add_graph ( net , input_to_model = torch . rand ( 1 , 3 , 32 , 32 )) writer . close () % load_ext tensorboard #%tensorboard --logdir ../data/tensorboard from tensorboard import notebook #\u67e5\u770b\u542f\u52a8\u7684tensorboard\u7a0b\u5e8f notebook . list () #\u542f\u52a8tensorboard\u7a0b\u5e8f notebook . start ( \"--logdir ../data/tensorboard\" ) #\u7b49\u4ef7\u4e8e\u5728\u547d\u4ee4\u884c\u4e2d\u6267\u884c tensorboard --logdir ../data/tensorboard #\u53ef\u4ee5\u5728\u6d4f\u89c8\u5668\u4e2d\u6253\u5f00 http://localhost:6006/ \u67e5\u770b","title":"\u4e00\uff0c\u53ef\u89c6\u5316\u6a21\u578b\u7ed3\u6784"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-4%2CTensorBoard%E5%8F%AF%E8%A7%86%E5%8C%96/#\u4e8c\u53ef\u89c6\u5316\u6307\u6807\u53d8\u5316","text":"\u6709\u65f6\u5019\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u5982\u679c\u80fd\u591f\u5b9e\u65f6\u52a8\u6001\u5730\u67e5\u770bloss\u548c\u5404\u79cdmetric\u7684\u53d8\u5316\u66f2\u7ebf\uff0c\u90a3\u4e48\u65e0\u7591\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u66f4\u52a0\u76f4\u89c2\u5730\u4e86\u89e3\u6a21\u578b\u7684\u8bad\u7ec3\u60c5\u51b5\u3002 \u6ce8\u610f\uff0cwriter.add_scalar\u4ec5\u80fd\u5bf9\u6807\u91cf\u7684\u503c\u7684\u53d8\u5316\u8fdb\u884c\u53ef\u89c6\u5316\u3002\u56e0\u6b64\u5b83\u4e00\u822c\u7528\u4e8e\u5bf9loss\u548cmetric\u7684\u53d8\u5316\u8fdb\u884c\u53ef\u89c6\u5316\u5206\u6790\u3002 import numpy as np import torch from torch.utils.tensorboard import SummaryWriter # f(x) = a*x**2 + b*x + c\u7684\u6700\u5c0f\u503c x = torch . tensor ( 0.0 , requires_grad = True ) # x\u9700\u8981\u88ab\u6c42\u5bfc a = torch . tensor ( 1.0 ) b = torch . tensor ( - 2.0 ) c = torch . tensor ( 1.0 ) optimizer = torch . optim . SGD ( params = [ x ], lr = 0.01 ) def f ( x ): result = a * torch . pow ( x , 2 ) + b * x + c return ( result ) writer = SummaryWriter ( '../data/tensorboard' ) for i in range ( 500 ): optimizer . zero_grad () y = f ( x ) y . backward () optimizer . step () writer . add_scalar ( \"x\" , x . item (), i ) #\u65e5\u5fd7\u4e2d\u8bb0\u5f55x\u5728\u7b2cstep i \u7684\u503c writer . add_scalar ( \"y\" , y . item (), i ) #\u65e5\u5fd7\u4e2d\u8bb0\u5f55y\u5728\u7b2cstep i \u7684\u503c writer . close () print ( \"y=\" , f ( x ) . data , \";\" , \"x=\" , x . data ) y= tensor(0.) ; x= tensor(1.0000)","title":"\u4e8c\uff0c\u53ef\u89c6\u5316\u6307\u6807\u53d8\u5316"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-4%2CTensorBoard%E5%8F%AF%E8%A7%86%E5%8C%96/#\u4e09\u53ef\u89c6\u5316\u53c2\u6570\u5206\u5e03","text":"\u5982\u679c\u9700\u8981\u5bf9\u6a21\u578b\u7684\u53c2\u6570(\u4e00\u822c\u975e\u6807\u91cf)\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u53d8\u5316\u8fdb\u884c\u53ef\u89c6\u5316\uff0c\u53ef\u4ee5\u4f7f\u7528 writer.add_histogram\u3002 \u5b83\u80fd\u591f\u89c2\u6d4b\u5f20\u91cf\u503c\u5206\u5e03\u7684\u76f4\u65b9\u56fe\u968f\u8bad\u7ec3\u6b65\u9aa4\u7684\u53d8\u5316\u8d8b\u52bf\u3002 import numpy as np import torch from torch.utils.tensorboard import SummaryWriter # \u521b\u5efa\u6b63\u6001\u5206\u5e03\u7684\u5f20\u91cf\u6a21\u62df\u53c2\u6570\u77e9\u9635 def norm ( mean , std ): t = std * torch . randn (( 100 , 20 )) + mean return t writer = SummaryWriter ( '../data/tensorboard' ) for step , mean in enumerate ( range ( - 10 , 10 , 1 )): w = norm ( mean , 1 ) writer . add_histogram ( \"w\" , w , step ) writer . flush () writer . close ()","title":"\u4e09\uff0c\u53ef\u89c6\u5316\u53c2\u6570\u5206\u5e03"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-4%2CTensorBoard%E5%8F%AF%E8%A7%86%E5%8C%96/#\u56db\u53ef\u89c6\u5316\u539f\u59cb\u56fe\u50cf","text":"\u5982\u679c\u6211\u4eec\u505a\u56fe\u50cf\u76f8\u5173\u7684\u4efb\u52a1\uff0c\u4e5f\u53ef\u4ee5\u5c06\u539f\u59cb\u7684\u56fe\u7247\u5728tensorboard\u4e2d\u8fdb\u884c\u53ef\u89c6\u5316\u5c55\u793a\u3002 \u5982\u679c\u53ea\u5199\u5165\u4e00\u5f20\u56fe\u7247\u4fe1\u606f\uff0c\u53ef\u4ee5\u4f7f\u7528writer.add_image\u3002 \u5982\u679c\u8981\u5199\u5165\u591a\u5f20\u56fe\u7247\u4fe1\u606f\uff0c\u53ef\u4ee5\u4f7f\u7528writer.add_images\u3002 \u4e5f\u53ef\u4ee5\u7528 torchvision.utils.make_grid\u5c06\u591a\u5f20\u56fe\u7247\u62fc\u6210\u4e00\u5f20\u56fe\u7247\uff0c\u7136\u540e\u7528writer.add_image\u5199\u5165\u3002 \u6ce8\u610f\uff0c\u4f20\u5165\u7684\u662f\u4ee3\u8868\u56fe\u7247\u4fe1\u606f\u7684Pytorch\u4e2d\u7684\u5f20\u91cf\u6570\u636e\u3002 import torch import torchvision from torch import nn from torch.utils.data import Dataset , DataLoader from torchvision import transforms , datasets transform_train = transforms . Compose ( [ transforms . ToTensor ()]) transform_valid = transforms . Compose ( [ transforms . ToTensor ()]) ds_train = datasets . ImageFolder ( \"../data/cifar2/train/\" , transform = transform_train , target_transform = lambda t : torch . tensor ([ t ]) . float ()) ds_valid = datasets . ImageFolder ( \"../data/cifar2/test/\" , transform = transform_train , target_transform = lambda t : torch . tensor ([ t ]) . float ()) print ( ds_train . class_to_idx ) dl_train = DataLoader ( ds_train , batch_size = 50 , shuffle = True , num_workers = 3 ) dl_valid = DataLoader ( ds_valid , batch_size = 50 , shuffle = True , num_workers = 3 ) dl_train_iter = iter ( dl_train ) images , labels = dl_train_iter . next () # \u4ec5\u67e5\u770b\u4e00\u5f20\u56fe\u7247 writer = SummaryWriter ( '../data/tensorboard' ) writer . add_image ( 'images[0]' , images [ 0 ]) writer . close () # \u5c06\u591a\u5f20\u56fe\u7247\u62fc\u63a5\u6210\u4e00\u5f20\u56fe\u7247\uff0c\u4e2d\u95f4\u7528\u9ed1\u8272\u7f51\u683c\u5206\u5272 writer = SummaryWriter ( '../data/tensorboard' ) # create grid of images img_grid = torchvision . utils . make_grid ( images ) writer . add_image ( 'image_grid' , img_grid ) writer . close () # \u5c06\u591a\u5f20\u56fe\u7247\u76f4\u63a5\u5199\u5165 writer = SummaryWriter ( '../data/tensorboard' ) writer . add_images ( \"images\" , images , global_step = 0 ) writer . close () {'0_airplane': 0, '1_automobile': 1}","title":"\u56db\uff0c\u53ef\u89c6\u5316\u539f\u59cb\u56fe\u50cf"},{"location":"5.%E4%B8%AD%E9%98%B6API/5-4%2CTensorBoard%E5%8F%AF%E8%A7%86%E5%8C%96/#\u4e94\u53ef\u89c6\u5316\u4eba\u5de5\u7ed8\u56fe","text":"\u5982\u679c\u6211\u4eec\u5c06matplotlib\u7ed8\u56fe\u7684\u7ed3\u679c\u518d tensorboard\u4e2d\u5c55\u793a\uff0c\u53ef\u4ee5\u4f7f\u7528 add_figure. \u6ce8\u610f\uff0c\u548cwriter.add_image\u4e0d\u540c\u7684\u662f\uff0cwriter.add_figure\u9700\u8981\u4f20\u5165matplotlib\u7684figure\u5bf9\u8c61\u3002 import torch import torchvision from torch import nn from torch.utils.data import Dataset , DataLoader from torchvision import transforms , datasets transform_train = transforms . Compose ( [ transforms . ToTensor ()]) transform_valid = transforms . Compose ( [ transforms . ToTensor ()]) ds_train = datasets . ImageFolder ( \"../data/cifar2/train/\" , transform = transform_train , target_transform = lambda t : torch . tensor ([ t ]) . float ()) ds_valid = datasets . ImageFolder ( \"../data/cifar2/test/\" , transform = transform_train , target_transform = lambda t : torch . tensor ([ t ]) . float ()) print ( ds_train . class_to_idx ) {'0_airplane': 0, '1_automobile': 1} % matplotlib inline % config InlineBackend . figure_format = 'svg' from matplotlib import pyplot as plt figure = plt . figure ( figsize = ( 8 , 8 )) for i in range ( 9 ): img , label = ds_train [ i ] img = img . permute ( 1 , 2 , 0 ) ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow ( img . numpy ()) ax . set_title ( \"label = %d \" % label . item ()) ax . set_xticks ([]) ax . set_yticks ([]) plt . show () writer = SummaryWriter ( '../data/tensorboard' ) writer . add_figure ( 'figure' , figure , global_step = 0 ) writer . close () \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e94\uff0c\u53ef\u89c6\u5316\u4eba\u5de5\u7ed8\u56fe"},{"location":"6.%E9%AB%98%E9%98%B6API/","text":"\u516d\u3001Pytorch\u7684\u9ad8\u9636API # Pytorch\u6ca1\u6709\u5b98\u65b9\u7684\u9ad8\u9636API\u3002\u4e00\u822c\u901a\u8fc7nn.Module\u6765\u6784\u5efa\u6a21\u578b\u5e76\u7f16\u5199\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u3002 \u4e3a\u4e86\u66f4\u52a0\u65b9\u4fbf\u5730\u8bad\u7ec3\u6a21\u578b\uff0c\u4f5c\u8005\u7f16\u5199\u4e86\u4effkeras\u7684Pytorch\u6a21\u578b\u63a5\u53e3\uff1atorchkeras\uff0c \u4f5c\u4e3aPytorch\u7684\u9ad8\u9636API\u3002 \u672c\u7ae0\u6211\u4eec\u4e3b\u8981\u8be6\u7ec6\u4ecb\u7ecdPytorch\u7684\u9ad8\u9636API\u5982\u4e0b\u76f8\u5173\u7684\u5185\u5bb9\u3002 \u6784\u5efa\u6a21\u578b\u76843\u79cd\u65b9\u6cd5(\u7ee7\u627fnn.Module\u57fa\u7c7b\uff0c\u4f7f\u7528nn.Sequential\uff0c\u8f85\u52a9\u5e94\u7528\u6a21\u578b\u5bb9\u5668) \u8bad\u7ec3\u6a21\u578b\u76843\u79cd\u65b9\u6cd5(\u811a\u672c\u98ce\u683c\uff0c\u51fd\u6570\u98ce\u683c\uff0ctorchkeras.Model\u7c7b\u98ce\u683c) \u4f7f\u7528GPU\u8bad\u7ec3\u6a21\u578b(\u5355GPU\u8bad\u7ec3\uff0c\u591aGPU\u8bad\u7ec3) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u516d\u3001Pytorch\u7684\u9ad8\u9636API"},{"location":"6.%E9%AB%98%E9%98%B6API/#\u516dpytorch\u7684\u9ad8\u9636api","text":"Pytorch\u6ca1\u6709\u5b98\u65b9\u7684\u9ad8\u9636API\u3002\u4e00\u822c\u901a\u8fc7nn.Module\u6765\u6784\u5efa\u6a21\u578b\u5e76\u7f16\u5199\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\u3002 \u4e3a\u4e86\u66f4\u52a0\u65b9\u4fbf\u5730\u8bad\u7ec3\u6a21\u578b\uff0c\u4f5c\u8005\u7f16\u5199\u4e86\u4effkeras\u7684Pytorch\u6a21\u578b\u63a5\u53e3\uff1atorchkeras\uff0c \u4f5c\u4e3aPytorch\u7684\u9ad8\u9636API\u3002 \u672c\u7ae0\u6211\u4eec\u4e3b\u8981\u8be6\u7ec6\u4ecb\u7ecdPytorch\u7684\u9ad8\u9636API\u5982\u4e0b\u76f8\u5173\u7684\u5185\u5bb9\u3002 \u6784\u5efa\u6a21\u578b\u76843\u79cd\u65b9\u6cd5(\u7ee7\u627fnn.Module\u57fa\u7c7b\uff0c\u4f7f\u7528nn.Sequential\uff0c\u8f85\u52a9\u5e94\u7528\u6a21\u578b\u5bb9\u5668) \u8bad\u7ec3\u6a21\u578b\u76843\u79cd\u65b9\u6cd5(\u811a\u672c\u98ce\u683c\uff0c\u51fd\u6570\u98ce\u683c\uff0ctorchkeras.Model\u7c7b\u98ce\u683c) \u4f7f\u7528GPU\u8bad\u7ec3\u6a21\u578b(\u5355GPU\u8bad\u7ec3\uff0c\u591aGPU\u8bad\u7ec3) \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u516d\u3001Pytorch\u7684\u9ad8\u9636API"},{"location":"6.%E9%AB%98%E9%98%B6API/6-1%2C%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/","text":"6-1,\u6784\u5efa\u6a21\u578b\u76843\u79cd\u65b9\u6cd5 # \u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b3\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a 1\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 2\uff0c\u4f7f\u7528nn.Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\u3002 3\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u6a21\u578b\u5e76\u8f85\u52a9\u5e94\u7528\u6a21\u578b\u5bb9\u5668\u8fdb\u884c\u5c01\u88c5(nn.Sequential,nn.ModuleList,nn.ModuleDict)\u3002 \u5176\u4e2d \u7b2c1\u79cd\u65b9\u5f0f\u6700\u4e3a\u5e38\u89c1\uff0c\u7b2c2\u79cd\u65b9\u5f0f\u6700\u7b80\u5355\uff0c\u7b2c3\u79cd\u65b9\u5f0f\u6700\u4e3a\u7075\u6d3b\u4e5f\u8f83\u4e3a\u590d\u6742\u3002 \u63a8\u8350\u4f7f\u7528\u7b2c1\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\u3002 import torch from torch import nn from torchkeras import summary \u4e00\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b # \u4ee5\u4e0b\u662f\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u7684\u4e00\u4e2a\u8303\u4f8b\u3002\u6a21\u578b\u4e2d\u7684\u7528\u5230\u7684\u5c42\u4e00\u822c\u5728 __init__ \u51fd\u6570\u4e2d\u5b9a\u4e49\uff0c\u7136\u540e\u5728 forward \u65b9\u6cd5\u4e2d\u5b9a\u4e49\u6a21\u578b\u7684\u6b63\u5411\u4f20\u64ad\u903b\u8f91\u3002 class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 ) self . pool1 = nn . MaxPool2d ( kernel_size = 2 , stride = 2 ) self . conv2 = nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ) self . pool2 = nn . MaxPool2d ( kernel_size = 2 , stride = 2 ) self . dropout = nn . Dropout2d ( p = 0.1 ) self . adaptive_pool = nn . AdaptiveMaxPool2d (( 1 , 1 )) self . flatten = nn . Flatten () self . linear1 = nn . Linear ( 64 , 32 ) self . relu = nn . ReLU () self . linear2 = nn . Linear ( 32 , 1 ) self . sigmoid = nn . Sigmoid () def forward ( self , x ): x = self . conv1 ( x ) x = self . pool1 ( x ) x = self . conv2 ( x ) x = self . pool2 ( x ) x = self . dropout ( x ) x = self . adaptive_pool ( x ) x = self . flatten ( x ) x = self . linear1 ( x ) x = self . relu ( x ) x = self . linear2 ( x ) y = self . sigmoid ( x ) return y net = Net () print ( net ) Net( (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (dropout): Dropout2d(p=0.1, inplace=False) (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1)) (flatten): Flatten() (linear1): Linear(in_features=64, out_features=32, bias=True) (relu): ReLU() (linear2): Linear(in_features=32, out_features=1, bias=True) (sigmoid): Sigmoid() ) summary ( net , input_shape = ( 3 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 896 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 1] 33 Sigmoid-11 [-1, 1] 0 ================================================================ Total params: 54,273 Trainable params: 54,273 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.011719 Forward/backward pass size (MB): 0.359634 Params size (MB): 0.207035 Estimated Total Size (MB): 0.578388 ---------------------------------------------------------------- \u4e8c\uff0c\u4f7f\u7528nn.Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b # \u4f7f\u7528nn.Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\u65e0\u9700\u5b9a\u4e49forward\u65b9\u6cd5\u3002\u4ec5\u4ec5\u9002\u5408\u4e8e\u7b80\u5355\u7684\u6a21\u578b\u3002 \u4ee5\u4e0b\u662f\u4f7f\u7528nn.Sequential\u642d\u5efa\u6a21\u578b\u7684\u4e00\u4e9b\u7b49\u4ef7\u65b9\u6cd5\u3002 1\uff0c\u5229\u7528add_module\u65b9\u6cd5 net = nn . Sequential () net . add_module ( \"conv1\" , nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 )) net . add_module ( \"pool1\" , nn . MaxPool2d ( kernel_size = 2 , stride = 2 )) net . add_module ( \"conv2\" , nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 )) net . add_module ( \"pool2\" , nn . MaxPool2d ( kernel_size = 2 , stride = 2 )) net . add_module ( \"dropout\" , nn . Dropout2d ( p = 0.1 )) net . add_module ( \"adaptive_pool\" , nn . AdaptiveMaxPool2d (( 1 , 1 ))) net . add_module ( \"flatten\" , nn . Flatten ()) net . add_module ( \"linear1\" , nn . Linear ( 64 , 32 )) net . add_module ( \"relu\" , nn . ReLU ()) net . add_module ( \"linear2\" , nn . Linear ( 32 , 1 )) net . add_module ( \"sigmoid\" , nn . Sigmoid ()) print ( net ) Sequential( (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (dropout): Dropout2d(p=0.1, inplace=False) (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1)) (flatten): Flatten() (linear1): Linear(in_features=64, out_features=32, bias=True) (relu): ReLU() (linear2): Linear(in_features=32, out_features=1, bias=True) (sigmoid): Sigmoid() ) 2\uff0c\u5229\u7528\u53d8\u957f\u53c2\u6570 \u8fd9\u79cd\u65b9\u5f0f\u6784\u5efa\u65f6\u4e0d\u80fd\u7ed9\u6bcf\u4e2a\u5c42\u6307\u5b9a\u540d\u79f0\u3002 net = nn . Sequential ( nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Dropout2d ( p = 0.1 ), nn . AdaptiveMaxPool2d (( 1 , 1 )), nn . Flatten (), nn . Linear ( 64 , 32 ), nn . ReLU (), nn . Linear ( 32 , 1 ), nn . Sigmoid () ) print ( net ) Sequential( (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (4): Dropout2d(p=0.1, inplace=False) (5): AdaptiveMaxPool2d(output_size=(1, 1)) (6): Flatten() (7): Linear(in_features=64, out_features=32, bias=True) (8): ReLU() (9): Linear(in_features=32, out_features=1, bias=True) (10): Sigmoid() ) 3\uff0c\u5229\u7528OrderedDict from collections import OrderedDict net = nn . Sequential ( OrderedDict ( [( \"conv1\" , nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 )), ( \"pool1\" , nn . MaxPool2d ( kernel_size = 2 , stride = 2 )), ( \"conv2\" , nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 )), ( \"pool2\" , nn . MaxPool2d ( kernel_size = 2 , stride = 2 )), ( \"dropout\" , nn . Dropout2d ( p = 0.1 )), ( \"adaptive_pool\" , nn . AdaptiveMaxPool2d (( 1 , 1 ))), ( \"flatten\" , nn . Flatten ()), ( \"linear1\" , nn . Linear ( 64 , 32 )), ( \"relu\" , nn . ReLU ()), ( \"linear2\" , nn . Linear ( 32 , 1 )), ( \"sigmoid\" , nn . Sigmoid ()) ]) ) print ( net ) Sequential( (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (dropout): Dropout2d(p=0.1, inplace=False) (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1)) (flatten): Flatten() (linear1): Linear(in_features=64, out_features=32, bias=True) (relu): ReLU() (linear2): Linear(in_features=32, out_features=1, bias=True) (sigmoid): Sigmoid() ) summary ( net , input_shape = ( 3 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 896 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 1] 33 Sigmoid-11 [-1, 1] 0 ================================================================ Total params: 54,273 Trainable params: 54,273 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.011719 Forward/backward pass size (MB): 0.359634 Params size (MB): 0.207035 Estimated Total Size (MB): 0.578388 ---------------------------------------------------------------- \u4e09\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u6a21\u578b\u5e76\u8f85\u52a9\u5e94\u7528\u6a21\u578b\u5bb9\u5668\u8fdb\u884c\u5c01\u88c5 # \u5f53\u6a21\u578b\u7684\u7ed3\u6784\u6bd4\u8f83\u590d\u6742\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u5e94\u7528\u6a21\u578b\u5bb9\u5668(nn.Sequential,nn.ModuleList,nn.ModuleDict)\u5bf9\u6a21\u578b\u7684\u90e8\u5206\u7ed3\u6784\u8fdb\u884c\u5c01\u88c5\u3002 \u8fd9\u6837\u505a\u4f1a\u8ba9\u6a21\u578b\u6574\u4f53\u66f4\u52a0\u6709\u5c42\u6b21\u611f\uff0c\u6709\u65f6\u5019\u4e5f\u80fd\u51cf\u5c11\u4ee3\u7801\u91cf\u3002 \u6ce8\u610f\uff0c\u5728\u4e0b\u9762\u7684\u8303\u4f8b\u4e2d\u6211\u4eec\u6bcf\u6b21\u4ec5\u4ec5\u4f7f\u7528\u4e00\u79cd\u6a21\u578b\u5bb9\u5668\uff0c\u4f46\u5b9e\u9645\u4e0a\u8fd9\u4e9b\u6a21\u578b\u5bb9\u5668\u7684\u4f7f\u7528\u662f\u975e\u5e38\u7075\u6d3b\u7684\uff0c\u53ef\u4ee5\u5728\u4e00\u4e2a\u6a21\u578b\u4e2d\u4efb\u610f\u7ec4\u5408\u4efb\u610f\u5d4c\u5957\u4f7f\u7528\u3002 1\uff0cnn.Sequential\u4f5c\u4e3a\u6a21\u578b\u5bb9\u5668 class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv = nn . Sequential ( nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Dropout2d ( p = 0.1 ), nn . AdaptiveMaxPool2d (( 1 , 1 )) ) self . dense = nn . Sequential ( nn . Flatten (), nn . Linear ( 64 , 32 ), nn . ReLU (), nn . Linear ( 32 , 1 ), nn . Sigmoid () ) def forward ( self , x ): x = self . conv ( x ) y = self . dense ( x ) return y net = Net () print ( net ) Net( (conv): Sequential( (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (4): Dropout2d(p=0.1, inplace=False) (5): AdaptiveMaxPool2d(output_size=(1, 1)) ) (dense): Sequential( (0): Flatten() (1): Linear(in_features=64, out_features=32, bias=True) (2): ReLU() (3): Linear(in_features=32, out_features=1, bias=True) (4): Sigmoid() ) ) 2\uff0cnn.ModuleList\u4f5c\u4e3a\u6a21\u578b\u5bb9\u5668 \u6ce8\u610f\u4e0b\u9762\u4e2d\u7684ModuleList\u4e0d\u80fd\u7528Python\u4e2d\u7684\u5217\u8868\u4ee3\u66ff\u3002 class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . layers = nn . ModuleList ([ nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Dropout2d ( p = 0.1 ), nn . AdaptiveMaxPool2d (( 1 , 1 )), nn . Flatten (), nn . Linear ( 64 , 32 ), nn . ReLU (), nn . Linear ( 32 , 1 ), nn . Sigmoid ()] ) def forward ( self , x ): for layer in self . layers : x = layer ( x ) return x net = Net () print ( net ) Net( (layers): ModuleList( (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (4): Dropout2d(p=0.1, inplace=False) (5): AdaptiveMaxPool2d(output_size=(1, 1)) (6): Flatten() (7): Linear(in_features=64, out_features=32, bias=True) (8): ReLU() (9): Linear(in_features=32, out_features=1, bias=True) (10): Sigmoid() ) ) summary ( net , input_shape = ( 3 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 896 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 1] 33 Sigmoid-11 [-1, 1] 0 ================================================================ Total params: 54,273 Trainable params: 54,273 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.011719 Forward/backward pass size (MB): 0.359634 Params size (MB): 0.207035 Estimated Total Size (MB): 0.578388 ---------------------------------------------------------------- 3\uff0cnn.ModuleDict\u4f5c\u4e3a\u6a21\u578b\u5bb9\u5668 \u6ce8\u610f\u4e0b\u9762\u4e2d\u7684ModuleDict\u4e0d\u80fd\u7528Python\u4e2d\u7684\u5b57\u5178\u4ee3\u66ff\u3002 class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . layers_dict = nn . ModuleDict ({ \"conv1\" : nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 ), \"pool\" : nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), \"conv2\" : nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ), \"dropout\" : nn . Dropout2d ( p = 0.1 ), \"adaptive\" : nn . AdaptiveMaxPool2d (( 1 , 1 )), \"flatten\" : nn . Flatten (), \"linear1\" : nn . Linear ( 64 , 32 ), \"relu\" : nn . ReLU (), \"linear2\" : nn . Linear ( 32 , 1 ), \"sigmoid\" : nn . Sigmoid () }) def forward ( self , x ): layers = [ \"conv1\" , \"pool\" , \"conv2\" , \"pool\" , \"dropout\" , \"adaptive\" , \"flatten\" , \"linear1\" , \"relu\" , \"linear2\" , \"sigmoid\" ] for layer in layers : x = self . layers_dict [ layer ]( x ) return x net = Net () print ( net ) Net( (layers_dict): ModuleDict( (adaptive): AdaptiveMaxPool2d(output_size=(1, 1)) (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (dropout): Dropout2d(p=0.1, inplace=False) (flatten): Flatten() (linear1): Linear(in_features=64, out_features=32, bias=True) (linear2): Linear(in_features=32, out_features=1, bias=True) (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu): ReLU() (sigmoid): Sigmoid() ) ) summary ( net , input_shape = ( 3 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 896 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 1] 33 Sigmoid-11 [-1, 1] 0 ================================================================ Total params: 54,273 Trainable params: 54,273 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.011719 Forward/backward pass size (MB): 0.359634 Params size (MB): 0.207035 Estimated Total Size (MB): 0.578388 ---------------------------------------------------------------- \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"6-1,\u6784\u5efa\u6a21\u578b\u76843\u79cd\u65b9\u6cd5"},{"location":"6.%E9%AB%98%E9%98%B6API/6-1%2C%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/#6-1\u6784\u5efa\u6a21\u578b\u76843\u79cd\u65b9\u6cd5","text":"\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b3\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\uff1a 1\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u3002 2\uff0c\u4f7f\u7528nn.Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\u3002 3\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u6a21\u578b\u5e76\u8f85\u52a9\u5e94\u7528\u6a21\u578b\u5bb9\u5668\u8fdb\u884c\u5c01\u88c5(nn.Sequential,nn.ModuleList,nn.ModuleDict)\u3002 \u5176\u4e2d \u7b2c1\u79cd\u65b9\u5f0f\u6700\u4e3a\u5e38\u89c1\uff0c\u7b2c2\u79cd\u65b9\u5f0f\u6700\u7b80\u5355\uff0c\u7b2c3\u79cd\u65b9\u5f0f\u6700\u4e3a\u7075\u6d3b\u4e5f\u8f83\u4e3a\u590d\u6742\u3002 \u63a8\u8350\u4f7f\u7528\u7b2c1\u79cd\u65b9\u5f0f\u6784\u5efa\u6a21\u578b\u3002 import torch from torch import nn from torchkeras import summary","title":"6-1,\u6784\u5efa\u6a21\u578b\u76843\u79cd\u65b9\u6cd5"},{"location":"6.%E9%AB%98%E9%98%B6API/6-1%2C%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/#\u4e00\u7ee7\u627fnnmodule\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b","text":"\u4ee5\u4e0b\u662f\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b\u7684\u4e00\u4e2a\u8303\u4f8b\u3002\u6a21\u578b\u4e2d\u7684\u7528\u5230\u7684\u5c42\u4e00\u822c\u5728 __init__ \u51fd\u6570\u4e2d\u5b9a\u4e49\uff0c\u7136\u540e\u5728 forward \u65b9\u6cd5\u4e2d\u5b9a\u4e49\u6a21\u578b\u7684\u6b63\u5411\u4f20\u64ad\u903b\u8f91\u3002 class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 ) self . pool1 = nn . MaxPool2d ( kernel_size = 2 , stride = 2 ) self . conv2 = nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ) self . pool2 = nn . MaxPool2d ( kernel_size = 2 , stride = 2 ) self . dropout = nn . Dropout2d ( p = 0.1 ) self . adaptive_pool = nn . AdaptiveMaxPool2d (( 1 , 1 )) self . flatten = nn . Flatten () self . linear1 = nn . Linear ( 64 , 32 ) self . relu = nn . ReLU () self . linear2 = nn . Linear ( 32 , 1 ) self . sigmoid = nn . Sigmoid () def forward ( self , x ): x = self . conv1 ( x ) x = self . pool1 ( x ) x = self . conv2 ( x ) x = self . pool2 ( x ) x = self . dropout ( x ) x = self . adaptive_pool ( x ) x = self . flatten ( x ) x = self . linear1 ( x ) x = self . relu ( x ) x = self . linear2 ( x ) y = self . sigmoid ( x ) return y net = Net () print ( net ) Net( (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (dropout): Dropout2d(p=0.1, inplace=False) (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1)) (flatten): Flatten() (linear1): Linear(in_features=64, out_features=32, bias=True) (relu): ReLU() (linear2): Linear(in_features=32, out_features=1, bias=True) (sigmoid): Sigmoid() ) summary ( net , input_shape = ( 3 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 896 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 1] 33 Sigmoid-11 [-1, 1] 0 ================================================================ Total params: 54,273 Trainable params: 54,273 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.011719 Forward/backward pass size (MB): 0.359634 Params size (MB): 0.207035 Estimated Total Size (MB): 0.578388 ----------------------------------------------------------------","title":"\u4e00\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u81ea\u5b9a\u4e49\u6a21\u578b"},{"location":"6.%E9%AB%98%E9%98%B6API/6-1%2C%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/#\u4e8c\u4f7f\u7528nnsequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b","text":"\u4f7f\u7528nn.Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b\u65e0\u9700\u5b9a\u4e49forward\u65b9\u6cd5\u3002\u4ec5\u4ec5\u9002\u5408\u4e8e\u7b80\u5355\u7684\u6a21\u578b\u3002 \u4ee5\u4e0b\u662f\u4f7f\u7528nn.Sequential\u642d\u5efa\u6a21\u578b\u7684\u4e00\u4e9b\u7b49\u4ef7\u65b9\u6cd5\u3002 1\uff0c\u5229\u7528add_module\u65b9\u6cd5 net = nn . Sequential () net . add_module ( \"conv1\" , nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 )) net . add_module ( \"pool1\" , nn . MaxPool2d ( kernel_size = 2 , stride = 2 )) net . add_module ( \"conv2\" , nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 )) net . add_module ( \"pool2\" , nn . MaxPool2d ( kernel_size = 2 , stride = 2 )) net . add_module ( \"dropout\" , nn . Dropout2d ( p = 0.1 )) net . add_module ( \"adaptive_pool\" , nn . AdaptiveMaxPool2d (( 1 , 1 ))) net . add_module ( \"flatten\" , nn . Flatten ()) net . add_module ( \"linear1\" , nn . Linear ( 64 , 32 )) net . add_module ( \"relu\" , nn . ReLU ()) net . add_module ( \"linear2\" , nn . Linear ( 32 , 1 )) net . add_module ( \"sigmoid\" , nn . Sigmoid ()) print ( net ) Sequential( (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (dropout): Dropout2d(p=0.1, inplace=False) (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1)) (flatten): Flatten() (linear1): Linear(in_features=64, out_features=32, bias=True) (relu): ReLU() (linear2): Linear(in_features=32, out_features=1, bias=True) (sigmoid): Sigmoid() ) 2\uff0c\u5229\u7528\u53d8\u957f\u53c2\u6570 \u8fd9\u79cd\u65b9\u5f0f\u6784\u5efa\u65f6\u4e0d\u80fd\u7ed9\u6bcf\u4e2a\u5c42\u6307\u5b9a\u540d\u79f0\u3002 net = nn . Sequential ( nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Dropout2d ( p = 0.1 ), nn . AdaptiveMaxPool2d (( 1 , 1 )), nn . Flatten (), nn . Linear ( 64 , 32 ), nn . ReLU (), nn . Linear ( 32 , 1 ), nn . Sigmoid () ) print ( net ) Sequential( (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (4): Dropout2d(p=0.1, inplace=False) (5): AdaptiveMaxPool2d(output_size=(1, 1)) (6): Flatten() (7): Linear(in_features=64, out_features=32, bias=True) (8): ReLU() (9): Linear(in_features=32, out_features=1, bias=True) (10): Sigmoid() ) 3\uff0c\u5229\u7528OrderedDict from collections import OrderedDict net = nn . Sequential ( OrderedDict ( [( \"conv1\" , nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 )), ( \"pool1\" , nn . MaxPool2d ( kernel_size = 2 , stride = 2 )), ( \"conv2\" , nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 )), ( \"pool2\" , nn . MaxPool2d ( kernel_size = 2 , stride = 2 )), ( \"dropout\" , nn . Dropout2d ( p = 0.1 )), ( \"adaptive_pool\" , nn . AdaptiveMaxPool2d (( 1 , 1 ))), ( \"flatten\" , nn . Flatten ()), ( \"linear1\" , nn . Linear ( 64 , 32 )), ( \"relu\" , nn . ReLU ()), ( \"linear2\" , nn . Linear ( 32 , 1 )), ( \"sigmoid\" , nn . Sigmoid ()) ]) ) print ( net ) Sequential( (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (dropout): Dropout2d(p=0.1, inplace=False) (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1)) (flatten): Flatten() (linear1): Linear(in_features=64, out_features=32, bias=True) (relu): ReLU() (linear2): Linear(in_features=32, out_features=1, bias=True) (sigmoid): Sigmoid() ) summary ( net , input_shape = ( 3 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 896 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 1] 33 Sigmoid-11 [-1, 1] 0 ================================================================ Total params: 54,273 Trainable params: 54,273 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.011719 Forward/backward pass size (MB): 0.359634 Params size (MB): 0.207035 Estimated Total Size (MB): 0.578388 ----------------------------------------------------------------","title":"\u4e8c\uff0c\u4f7f\u7528nn.Sequential\u6309\u5c42\u987a\u5e8f\u6784\u5efa\u6a21\u578b"},{"location":"6.%E9%AB%98%E9%98%B6API/6-1%2C%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/#\u4e09\u7ee7\u627fnnmodule\u57fa\u7c7b\u6784\u5efa\u6a21\u578b\u5e76\u8f85\u52a9\u5e94\u7528\u6a21\u578b\u5bb9\u5668\u8fdb\u884c\u5c01\u88c5","text":"\u5f53\u6a21\u578b\u7684\u7ed3\u6784\u6bd4\u8f83\u590d\u6742\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u5e94\u7528\u6a21\u578b\u5bb9\u5668(nn.Sequential,nn.ModuleList,nn.ModuleDict)\u5bf9\u6a21\u578b\u7684\u90e8\u5206\u7ed3\u6784\u8fdb\u884c\u5c01\u88c5\u3002 \u8fd9\u6837\u505a\u4f1a\u8ba9\u6a21\u578b\u6574\u4f53\u66f4\u52a0\u6709\u5c42\u6b21\u611f\uff0c\u6709\u65f6\u5019\u4e5f\u80fd\u51cf\u5c11\u4ee3\u7801\u91cf\u3002 \u6ce8\u610f\uff0c\u5728\u4e0b\u9762\u7684\u8303\u4f8b\u4e2d\u6211\u4eec\u6bcf\u6b21\u4ec5\u4ec5\u4f7f\u7528\u4e00\u79cd\u6a21\u578b\u5bb9\u5668\uff0c\u4f46\u5b9e\u9645\u4e0a\u8fd9\u4e9b\u6a21\u578b\u5bb9\u5668\u7684\u4f7f\u7528\u662f\u975e\u5e38\u7075\u6d3b\u7684\uff0c\u53ef\u4ee5\u5728\u4e00\u4e2a\u6a21\u578b\u4e2d\u4efb\u610f\u7ec4\u5408\u4efb\u610f\u5d4c\u5957\u4f7f\u7528\u3002 1\uff0cnn.Sequential\u4f5c\u4e3a\u6a21\u578b\u5bb9\u5668 class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv = nn . Sequential ( nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Dropout2d ( p = 0.1 ), nn . AdaptiveMaxPool2d (( 1 , 1 )) ) self . dense = nn . Sequential ( nn . Flatten (), nn . Linear ( 64 , 32 ), nn . ReLU (), nn . Linear ( 32 , 1 ), nn . Sigmoid () ) def forward ( self , x ): x = self . conv ( x ) y = self . dense ( x ) return y net = Net () print ( net ) Net( (conv): Sequential( (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (4): Dropout2d(p=0.1, inplace=False) (5): AdaptiveMaxPool2d(output_size=(1, 1)) ) (dense): Sequential( (0): Flatten() (1): Linear(in_features=64, out_features=32, bias=True) (2): ReLU() (3): Linear(in_features=32, out_features=1, bias=True) (4): Sigmoid() ) ) 2\uff0cnn.ModuleList\u4f5c\u4e3a\u6a21\u578b\u5bb9\u5668 \u6ce8\u610f\u4e0b\u9762\u4e2d\u7684ModuleList\u4e0d\u80fd\u7528Python\u4e2d\u7684\u5217\u8868\u4ee3\u66ff\u3002 class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . layers = nn . ModuleList ([ nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Dropout2d ( p = 0.1 ), nn . AdaptiveMaxPool2d (( 1 , 1 )), nn . Flatten (), nn . Linear ( 64 , 32 ), nn . ReLU (), nn . Linear ( 32 , 1 ), nn . Sigmoid ()] ) def forward ( self , x ): for layer in self . layers : x = layer ( x ) return x net = Net () print ( net ) Net( (layers): ModuleList( (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (4): Dropout2d(p=0.1, inplace=False) (5): AdaptiveMaxPool2d(output_size=(1, 1)) (6): Flatten() (7): Linear(in_features=64, out_features=32, bias=True) (8): ReLU() (9): Linear(in_features=32, out_features=1, bias=True) (10): Sigmoid() ) ) summary ( net , input_shape = ( 3 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 896 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 1] 33 Sigmoid-11 [-1, 1] 0 ================================================================ Total params: 54,273 Trainable params: 54,273 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.011719 Forward/backward pass size (MB): 0.359634 Params size (MB): 0.207035 Estimated Total Size (MB): 0.578388 ---------------------------------------------------------------- 3\uff0cnn.ModuleDict\u4f5c\u4e3a\u6a21\u578b\u5bb9\u5668 \u6ce8\u610f\u4e0b\u9762\u4e2d\u7684ModuleDict\u4e0d\u80fd\u7528Python\u4e2d\u7684\u5b57\u5178\u4ee3\u66ff\u3002 class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . layers_dict = nn . ModuleDict ({ \"conv1\" : nn . Conv2d ( in_channels = 3 , out_channels = 32 , kernel_size = 3 ), \"pool\" : nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), \"conv2\" : nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ), \"dropout\" : nn . Dropout2d ( p = 0.1 ), \"adaptive\" : nn . AdaptiveMaxPool2d (( 1 , 1 )), \"flatten\" : nn . Flatten (), \"linear1\" : nn . Linear ( 64 , 32 ), \"relu\" : nn . ReLU (), \"linear2\" : nn . Linear ( 32 , 1 ), \"sigmoid\" : nn . Sigmoid () }) def forward ( self , x ): layers = [ \"conv1\" , \"pool\" , \"conv2\" , \"pool\" , \"dropout\" , \"adaptive\" , \"flatten\" , \"linear1\" , \"relu\" , \"linear2\" , \"sigmoid\" ] for layer in layers : x = self . layers_dict [ layer ]( x ) return x net = Net () print ( net ) Net( (layers_dict): ModuleDict( (adaptive): AdaptiveMaxPool2d(output_size=(1, 1)) (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)) (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (dropout): Dropout2d(p=0.1, inplace=False) (flatten): Flatten() (linear1): Linear(in_features=64, out_features=32, bias=True) (linear2): Linear(in_features=32, out_features=1, bias=True) (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (relu): ReLU() (sigmoid): Sigmoid() ) ) summary ( net , input_shape = ( 3 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 896 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 1] 33 Sigmoid-11 [-1, 1] 0 ================================================================ Total params: 54,273 Trainable params: 54,273 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.011719 Forward/backward pass size (MB): 0.359634 Params size (MB): 0.207035 Estimated Total Size (MB): 0.578388 ---------------------------------------------------------------- \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e09\uff0c\u7ee7\u627fnn.Module\u57fa\u7c7b\u6784\u5efa\u6a21\u578b\u5e76\u8f85\u52a9\u5e94\u7528\u6a21\u578b\u5bb9\u5668\u8fdb\u884c\u5c01\u88c5"},{"location":"6.%E9%AB%98%E9%98%B6API/6-2%2C%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/","text":"6-2,\u8bad\u7ec3\u6a21\u578b\u76843\u79cd\u65b9\u6cd5 # Pytorch\u901a\u5e38\u9700\u8981\u7528\u6237\u7f16\u5199\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\uff0c\u8bad\u7ec3\u5faa\u73af\u7684\u4ee3\u7801\u98ce\u683c\u56e0\u4eba\u800c\u5f02\u3002 \u67093\u7c7b\u5178\u578b\u7684\u8bad\u7ec3\u5faa\u73af\u4ee3\u7801\u98ce\u683c\uff1a\u811a\u672c\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u51fd\u6570\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u7c7b\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\u3002 \u4e0b\u9762\u4ee5minist\u6570\u636e\u96c6\u7684\u5206\u7c7b\u6a21\u578b\u7684\u8bad\u7ec3\u4e3a\u4f8b\uff0c\u6f14\u793a\u8fd93\u79cd\u8bad\u7ec3\u6a21\u578b\u7684\u98ce\u683c\u3002 \u3007\uff0c\u51c6\u5907\u6570\u636e # import torch from torch import nn from torchkeras import summary , Model import torchvision from torchvision import transforms transform = transforms . Compose ([ transforms . ToTensor ()]) ds_train = torchvision . datasets . MNIST ( root = \"../data/minist/\" , train = True , download = True , transform = transform ) ds_valid = torchvision . datasets . MNIST ( root = \"../data/minist/\" , train = False , download = True , transform = transform ) dl_train = torch . utils . data . DataLoader ( ds_train , batch_size = 128 , shuffle = True , num_workers = 4 ) dl_valid = torch . utils . data . DataLoader ( ds_valid , batch_size = 128 , shuffle = False , num_workers = 4 ) print ( len ( ds_train )) print ( len ( ds_valid )) 60000 10000 % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u67e5\u770b\u90e8\u5206\u6837\u672c from matplotlib import pyplot as plt plt . figure ( figsize = ( 8 , 8 )) for i in range ( 9 ): img , label = ds_train [ i ] img = torch . squeeze ( img ) ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow ( img . numpy ()) ax . set_title ( \"label = %d \" % label ) ax . set_xticks ([]) ax . set_yticks ([]) plt . show () \u4e00\uff0c\u811a\u672c\u98ce\u683c # \u811a\u672c\u98ce\u683c\u7684\u8bad\u7ec3\u5faa\u73af\u6700\u4e3a\u5e38\u89c1\u3002 net = nn . Sequential () net . add_module ( \"conv1\" , nn . Conv2d ( in_channels = 1 , out_channels = 32 , kernel_size = 3 )) net . add_module ( \"pool1\" , nn . MaxPool2d ( kernel_size = 2 , stride = 2 )) net . add_module ( \"conv2\" , nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 )) net . add_module ( \"pool2\" , nn . MaxPool2d ( kernel_size = 2 , stride = 2 )) net . add_module ( \"dropout\" , nn . Dropout2d ( p = 0.1 )) net . add_module ( \"adaptive_pool\" , nn . AdaptiveMaxPool2d (( 1 , 1 ))) net . add_module ( \"flatten\" , nn . Flatten ()) net . add_module ( \"linear1\" , nn . Linear ( 64 , 32 )) net . add_module ( \"relu\" , nn . ReLU ()) net . add_module ( \"linear2\" , nn . Linear ( 32 , 10 )) print ( net ) Sequential( (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1)) (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (dropout): Dropout2d(p=0.1, inplace=False) (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1)) (flatten): Flatten() (linear1): Linear(in_features=64, out_features=32, bias=True) (relu): ReLU() (linear2): Linear(in_features=32, out_features=10, bias=True) ) summary ( net , input_shape = ( 1 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 320 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 10] 330 ================================================================ Total params: 53,994 Trainable params: 53,994 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.003906 Forward/backward pass size (MB): 0.359695 Params size (MB): 0.205971 Estimated Total Size (MB): 0.569572 ---------------------------------------------------------------- import datetime import numpy as np import pandas as pd from sklearn.metrics import accuracy_score def accuracy ( y_pred , y_true ): y_pred_cls = torch . argmax ( nn . Softmax ( dim = 1 )( y_pred ), dim = 1 ) . data return accuracy_score ( y_true , y_pred_cls ) loss_func = nn . CrossEntropyLoss () optimizer = torch . optim . Adam ( params = net . parameters (), lr = 0.01 ) metric_func = accuracy metric_name = \"accuracy\" epochs = 3 log_step_freq = 100 dfhistory = pd . DataFrame ( columns = [ \"epoch\" , \"loss\" , metric_name , \"val_loss\" , \"val_\" + metric_name ]) print ( \"Start Training...\" ) nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \"==========\" * 8 + \" %s \" % nowtime ) for epoch in range ( 1 , epochs + 1 ): # 1\uff0c\u8bad\u7ec3\u5faa\u73af------------------------------------------------- net . train () loss_sum = 0.0 metric_sum = 0.0 step = 1 for step , ( features , labels ) in enumerate ( dl_train , 1 ): # \u68af\u5ea6\u6e05\u96f6 optimizer . zero_grad () # \u6b63\u5411\u4f20\u64ad\u6c42\u635f\u5931 predictions = net ( features ) loss = loss_func ( predictions , labels ) metric = metric_func ( predictions , labels ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 loss . backward () optimizer . step () # \u6253\u5370batch\u7ea7\u522b\u65e5\u5fd7 loss_sum += loss . item () metric_sum += metric . item () if step % log_step_freq == 0 : print (( \"[step = %d ] loss: %.3f , \" + metric_name + \": %.3f \" ) % ( step , loss_sum / step , metric_sum / step )) # 2\uff0c\u9a8c\u8bc1\u5faa\u73af------------------------------------------------- net . eval () val_loss_sum = 0.0 val_metric_sum = 0.0 val_step = 1 for val_step , ( features , labels ) in enumerate ( dl_valid , 1 ): with torch . no_grad (): predictions = net ( features ) val_loss = loss_func ( predictions , labels ) val_metric = metric_func ( predictions , labels ) val_loss_sum += val_loss . item () val_metric_sum += val_metric . item () # 3\uff0c\u8bb0\u5f55\u65e5\u5fd7------------------------------------------------- info = ( epoch , loss_sum / step , metric_sum / step , val_loss_sum / val_step , val_metric_sum / val_step ) dfhistory . loc [ epoch - 1 ] = info # \u6253\u5370epoch\u7ea7\u522b\u65e5\u5fd7 print (( \" \\n EPOCH = %d , loss = %.3f ,\" + metric_name + \\ \" = %.3f , val_loss = %.3f , \" + \"val_\" + metric_name + \" = %.3f \" ) % info ) nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) print ( 'Finished Training...' ) Start Training... ================================================================================2020-06-26 12:49:16 [step = 100] loss: 0.742, accuracy: 0.745 [step = 200] loss: 0.466, accuracy: 0.843 [step = 300] loss: 0.363, accuracy: 0.880 [step = 400] loss: 0.310, accuracy: 0.898 EPOCH = 1, loss = 0.281,accuracy = 0.908, val_loss = 0.087, val_accuracy = 0.972 ================================================================================2020-06-26 12:50:32 [step = 100] loss: 0.103, accuracy: 0.970 [step = 200] loss: 0.114, accuracy: 0.966 [step = 300] loss: 0.112, accuracy: 0.967 [step = 400] loss: 0.108, accuracy: 0.968 EPOCH = 2, loss = 0.111,accuracy = 0.967, val_loss = 0.082, val_accuracy = 0.976 ================================================================================2020-06-26 12:51:47 [step = 100] loss: 0.093, accuracy: 0.972 [step = 200] loss: 0.095, accuracy: 0.971 [step = 300] loss: 0.092, accuracy: 0.972 [step = 400] loss: 0.093, accuracy: 0.972 EPOCH = 3, loss = 0.098,accuracy = 0.971, val_loss = 0.113, val_accuracy = 0.970 ================================================================================2020-06-26 12:53:09 Finished Training... \u4e8c\uff0c\u51fd\u6570\u98ce\u683c # \u8be5\u98ce\u683c\u5728\u811a\u672c\u5f62\u5f0f\u4e0a\u4f5c\u4e86\u7b80\u5355\u7684\u51fd\u6570\u5c01\u88c5\u3002 class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . layers = nn . ModuleList ([ nn . Conv2d ( in_channels = 1 , out_channels = 32 , kernel_size = 3 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Dropout2d ( p = 0.1 ), nn . AdaptiveMaxPool2d (( 1 , 1 )), nn . Flatten (), nn . Linear ( 64 , 32 ), nn . ReLU (), nn . Linear ( 32 , 10 )] ) def forward ( self , x ): for layer in self . layers : x = layer ( x ) return x net = Net () print ( net ) Net( (layers): ModuleList( (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (4): Dropout2d(p=0.1, inplace=False) (5): AdaptiveMaxPool2d(output_size=(1, 1)) (6): Flatten() (7): Linear(in_features=64, out_features=32, bias=True) (8): ReLU() (9): Linear(in_features=32, out_features=10, bias=True) ) ) summary ( net , input_shape = ( 1 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 320 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 10] 330 ================================================================ Total params: 53,994 Trainable params: 53,994 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.003906 Forward/backward pass size (MB): 0.359695 Params size (MB): 0.205971 Estimated Total Size (MB): 0.569572 ---------------------------------------------------------------- import datetime import numpy as np import pandas as pd from sklearn.metrics import accuracy_score def accuracy ( y_pred , y_true ): y_pred_cls = torch . argmax ( nn . Softmax ( dim = 1 )( y_pred ), dim = 1 ) . data return accuracy_score ( y_true , y_pred_cls ) model = net model . optimizer = torch . optim . SGD ( model . parameters (), lr = 0.01 ) model . loss_func = nn . CrossEntropyLoss () model . metric_func = accuracy model . metric_name = \"accuracy\" def train_step ( model , features , labels ): # \u8bad\u7ec3\u6a21\u5f0f\uff0cdropout\u5c42\u53d1\u751f\u4f5c\u7528 model . train () # \u68af\u5ea6\u6e05\u96f6 model . optimizer . zero_grad () # \u6b63\u5411\u4f20\u64ad\u6c42\u635f\u5931 predictions = model ( features ) loss = model . loss_func ( predictions , labels ) metric = model . metric_func ( predictions , labels ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 loss . backward () model . optimizer . step () return loss . item (), metric . item () @torch . no_grad () def valid_step ( model , features , labels ): # \u9884\u6d4b\u6a21\u5f0f\uff0cdropout\u5c42\u4e0d\u53d1\u751f\u4f5c\u7528 model . eval () predictions = model ( features ) loss = model . loss_func ( predictions , labels ) metric = model . metric_func ( predictions , labels ) return loss . item (), metric . item () # \u6d4b\u8bd5train_step\u6548\u679c features , labels = next ( iter ( dl_train )) train_step ( model , features , labels ) (2.32741117477417, 0.1015625) def train_model ( model , epochs , dl_train , dl_valid , log_step_freq ): metric_name = model . metric_name dfhistory = pd . DataFrame ( columns = [ \"epoch\" , \"loss\" , metric_name , \"val_loss\" , \"val_\" + metric_name ]) print ( \"Start Training...\" ) nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \"==========\" * 8 + \" %s \" % nowtime ) for epoch in range ( 1 , epochs + 1 ): # 1\uff0c\u8bad\u7ec3\u5faa\u73af------------------------------------------------- loss_sum = 0.0 metric_sum = 0.0 step = 1 for step , ( features , labels ) in enumerate ( dl_train , 1 ): loss , metric = train_step ( model , features , labels ) # \u6253\u5370batch\u7ea7\u522b\u65e5\u5fd7 loss_sum += loss metric_sum += metric if step % log_step_freq == 0 : print (( \"[step = %d ] loss: %.3f , \" + metric_name + \": %.3f \" ) % ( step , loss_sum / step , metric_sum / step )) # 2\uff0c\u9a8c\u8bc1\u5faa\u73af------------------------------------------------- val_loss_sum = 0.0 val_metric_sum = 0.0 val_step = 1 for val_step , ( features , labels ) in enumerate ( dl_valid , 1 ): val_loss , val_metric = valid_step ( model , features , labels ) val_loss_sum += val_loss val_metric_sum += val_metric # 3\uff0c\u8bb0\u5f55\u65e5\u5fd7------------------------------------------------- info = ( epoch , loss_sum / step , metric_sum / step , val_loss_sum / val_step , val_metric_sum / val_step ) dfhistory . loc [ epoch - 1 ] = info # \u6253\u5370epoch\u7ea7\u522b\u65e5\u5fd7 print (( \" \\n EPOCH = %d , loss = %.3f ,\" + metric_name + \\ \" = %.3f , val_loss = %.3f , \" + \"val_\" + metric_name + \" = %.3f \" ) % info ) nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) print ( 'Finished Training...' ) return dfhistory epochs = 3 dfhistory = train_model ( model , epochs , dl_train , dl_valid , log_step_freq = 100 ) Start Training... ================================================================================2020-06-26 13:10:00 [step = 100] loss: 2.298, accuracy: 0.137 [step = 200] loss: 2.288, accuracy: 0.145 [step = 300] loss: 2.278, accuracy: 0.165 [step = 400] loss: 2.265, accuracy: 0.183 EPOCH = 1, loss = 2.254,accuracy = 0.195, val_loss = 2.158, val_accuracy = 0.301 ================================================================================2020-06-26 13:11:23 [step = 100] loss: 2.127, accuracy: 0.302 [step = 200] loss: 2.080, accuracy: 0.338 [step = 300] loss: 2.025, accuracy: 0.374 [step = 400] loss: 1.957, accuracy: 0.411 EPOCH = 2, loss = 1.905,accuracy = 0.435, val_loss = 1.469, val_accuracy = 0.710 ================================================================================2020-06-26 13:12:43 [step = 100] loss: 1.435, accuracy: 0.615 [step = 200] loss: 1.324, accuracy: 0.647 [step = 300] loss: 1.221, accuracy: 0.672 [step = 400] loss: 1.132, accuracy: 0.696 EPOCH = 3, loss = 1.074,accuracy = 0.711, val_loss = 0.582, val_accuracy = 0.878 ================================================================================2020-06-26 13:13:59 Finished Training... \u4e09\uff0c\u7c7b\u98ce\u683c # \u6b64\u5904\u4f7f\u7528torchkeras\u4e2d\u5b9a\u4e49\u7684\u6a21\u578b\u63a5\u53e3\u6784\u5efa\u6a21\u578b\uff0c\u5e76\u8c03\u7528compile\u65b9\u6cd5\u548cfit\u65b9\u6cd5\u8bad\u7ec3\u6a21\u578b\u3002 \u4f7f\u7528\u8be5\u5f62\u5f0f\u8bad\u7ec3\u6a21\u578b\u975e\u5e38\u7b80\u6d01\u660e\u4e86\u3002\u63a8\u8350\u4f7f\u7528\u8be5\u5f62\u5f0f\u3002 class CnnModel ( nn . Module ): def __init__ ( self ): super () . __init__ () self . layers = nn . ModuleList ([ nn . Conv2d ( in_channels = 1 , out_channels = 32 , kernel_size = 3 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Dropout2d ( p = 0.1 ), nn . AdaptiveMaxPool2d (( 1 , 1 )), nn . Flatten (), nn . Linear ( 64 , 32 ), nn . ReLU (), nn . Linear ( 32 , 10 )] ) def forward ( self , x ): for layer in self . layers : x = layer ( x ) return x model = torchkeras . Model ( CnnModel ()) print ( model ) CnnModel( (layers): ModuleList( (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (4): Dropout2d(p=0.1, inplace=False) (5): AdaptiveMaxPool2d(output_size=(1, 1)) (6): Flatten() (7): Linear(in_features=64, out_features=32, bias=True) (8): ReLU() (9): Linear(in_features=32, out_features=10, bias=True) ) ) model . summary ( input_shape = ( 1 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 320 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 10] 330 ================================================================ Total params: 53,994 Trainable params: 53,994 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.003906 Forward/backward pass size (MB): 0.359695 Params size (MB): 0.205971 Estimated Total Size (MB): 0.569572 ---------------------------------------------------------------- from sklearn.metrics import accuracy_score def accuracy ( y_pred , y_true ): y_pred_cls = torch . argmax ( nn . Softmax ( dim = 1 )( y_pred ), dim = 1 ) . data return accuracy_score ( y_true . numpy (), y_pred_cls . numpy ()) model . compile ( loss_func = nn . CrossEntropyLoss (), optimizer = torch . optim . Adam ( model . parameters (), lr = 0.02 ), metrics_dict = { \"accuracy\" : accuracy }) dfhistory = model . fit ( 3 , dl_train = dl_train , dl_val = dl_valid , log_step_freq = 100 ) Start Training ... ================================================================================2020-06-26 13:22:39 {'step': 100, 'loss': 0.976, 'accuracy': 0.664} {'step': 200, 'loss': 0.611, 'accuracy': 0.795} {'step': 300, 'loss': 0.478, 'accuracy': 0.841} {'step': 400, 'loss': 0.403, 'accuracy': 0.868} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 1 | 0.371 | 0.879 | 0.087 | 0.972 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-26 13:23:59 {'step': 100, 'loss': 0.182, 'accuracy': 0.948} {'step': 200, 'loss': 0.176, 'accuracy': 0.949} {'step': 300, 'loss': 0.173, 'accuracy': 0.95} {'step': 400, 'loss': 0.174, 'accuracy': 0.951} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 2 | 0.175 | 0.951 | 0.152 | 0.958 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-26 13:25:22 {'step': 100, 'loss': 0.143, 'accuracy': 0.961} {'step': 200, 'loss': 0.151, 'accuracy': 0.959} {'step': 300, 'loss': 0.149, 'accuracy': 0.96} {'step': 400, 'loss': 0.152, 'accuracy': 0.959} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 3 | 0.153 | 0.959 | 0.086 | 0.975 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-26 13:26:48 Finished Training... \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"6-2,\u8bad\u7ec3\u6a21\u578b\u76843\u79cd\u65b9\u6cd5"},{"location":"6.%E9%AB%98%E9%98%B6API/6-2%2C%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/#6-2\u8bad\u7ec3\u6a21\u578b\u76843\u79cd\u65b9\u6cd5","text":"Pytorch\u901a\u5e38\u9700\u8981\u7528\u6237\u7f16\u5199\u81ea\u5b9a\u4e49\u8bad\u7ec3\u5faa\u73af\uff0c\u8bad\u7ec3\u5faa\u73af\u7684\u4ee3\u7801\u98ce\u683c\u56e0\u4eba\u800c\u5f02\u3002 \u67093\u7c7b\u5178\u578b\u7684\u8bad\u7ec3\u5faa\u73af\u4ee3\u7801\u98ce\u683c\uff1a\u811a\u672c\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u51fd\u6570\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\uff0c\u7c7b\u5f62\u5f0f\u8bad\u7ec3\u5faa\u73af\u3002 \u4e0b\u9762\u4ee5minist\u6570\u636e\u96c6\u7684\u5206\u7c7b\u6a21\u578b\u7684\u8bad\u7ec3\u4e3a\u4f8b\uff0c\u6f14\u793a\u8fd93\u79cd\u8bad\u7ec3\u6a21\u578b\u7684\u98ce\u683c\u3002","title":"6-2,\u8bad\u7ec3\u6a21\u578b\u76843\u79cd\u65b9\u6cd5"},{"location":"6.%E9%AB%98%E9%98%B6API/6-2%2C%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/#\u3007\u51c6\u5907\u6570\u636e","text":"import torch from torch import nn from torchkeras import summary , Model import torchvision from torchvision import transforms transform = transforms . Compose ([ transforms . ToTensor ()]) ds_train = torchvision . datasets . MNIST ( root = \"../data/minist/\" , train = True , download = True , transform = transform ) ds_valid = torchvision . datasets . MNIST ( root = \"../data/minist/\" , train = False , download = True , transform = transform ) dl_train = torch . utils . data . DataLoader ( ds_train , batch_size = 128 , shuffle = True , num_workers = 4 ) dl_valid = torch . utils . data . DataLoader ( ds_valid , batch_size = 128 , shuffle = False , num_workers = 4 ) print ( len ( ds_train )) print ( len ( ds_valid )) 60000 10000 % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u67e5\u770b\u90e8\u5206\u6837\u672c from matplotlib import pyplot as plt plt . figure ( figsize = ( 8 , 8 )) for i in range ( 9 ): img , label = ds_train [ i ] img = torch . squeeze ( img ) ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow ( img . numpy ()) ax . set_title ( \"label = %d \" % label ) ax . set_xticks ([]) ax . set_yticks ([]) plt . show ()","title":"\u3007\uff0c\u51c6\u5907\u6570\u636e"},{"location":"6.%E9%AB%98%E9%98%B6API/6-2%2C%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/#\u4e00\u811a\u672c\u98ce\u683c","text":"\u811a\u672c\u98ce\u683c\u7684\u8bad\u7ec3\u5faa\u73af\u6700\u4e3a\u5e38\u89c1\u3002 net = nn . Sequential () net . add_module ( \"conv1\" , nn . Conv2d ( in_channels = 1 , out_channels = 32 , kernel_size = 3 )) net . add_module ( \"pool1\" , nn . MaxPool2d ( kernel_size = 2 , stride = 2 )) net . add_module ( \"conv2\" , nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 )) net . add_module ( \"pool2\" , nn . MaxPool2d ( kernel_size = 2 , stride = 2 )) net . add_module ( \"dropout\" , nn . Dropout2d ( p = 0.1 )) net . add_module ( \"adaptive_pool\" , nn . AdaptiveMaxPool2d (( 1 , 1 ))) net . add_module ( \"flatten\" , nn . Flatten ()) net . add_module ( \"linear1\" , nn . Linear ( 64 , 32 )) net . add_module ( \"relu\" , nn . ReLU ()) net . add_module ( \"linear2\" , nn . Linear ( 32 , 10 )) print ( net ) Sequential( (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1)) (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (dropout): Dropout2d(p=0.1, inplace=False) (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1)) (flatten): Flatten() (linear1): Linear(in_features=64, out_features=32, bias=True) (relu): ReLU() (linear2): Linear(in_features=32, out_features=10, bias=True) ) summary ( net , input_shape = ( 1 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 320 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 10] 330 ================================================================ Total params: 53,994 Trainable params: 53,994 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.003906 Forward/backward pass size (MB): 0.359695 Params size (MB): 0.205971 Estimated Total Size (MB): 0.569572 ---------------------------------------------------------------- import datetime import numpy as np import pandas as pd from sklearn.metrics import accuracy_score def accuracy ( y_pred , y_true ): y_pred_cls = torch . argmax ( nn . Softmax ( dim = 1 )( y_pred ), dim = 1 ) . data return accuracy_score ( y_true , y_pred_cls ) loss_func = nn . CrossEntropyLoss () optimizer = torch . optim . Adam ( params = net . parameters (), lr = 0.01 ) metric_func = accuracy metric_name = \"accuracy\" epochs = 3 log_step_freq = 100 dfhistory = pd . DataFrame ( columns = [ \"epoch\" , \"loss\" , metric_name , \"val_loss\" , \"val_\" + metric_name ]) print ( \"Start Training...\" ) nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \"==========\" * 8 + \" %s \" % nowtime ) for epoch in range ( 1 , epochs + 1 ): # 1\uff0c\u8bad\u7ec3\u5faa\u73af------------------------------------------------- net . train () loss_sum = 0.0 metric_sum = 0.0 step = 1 for step , ( features , labels ) in enumerate ( dl_train , 1 ): # \u68af\u5ea6\u6e05\u96f6 optimizer . zero_grad () # \u6b63\u5411\u4f20\u64ad\u6c42\u635f\u5931 predictions = net ( features ) loss = loss_func ( predictions , labels ) metric = metric_func ( predictions , labels ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 loss . backward () optimizer . step () # \u6253\u5370batch\u7ea7\u522b\u65e5\u5fd7 loss_sum += loss . item () metric_sum += metric . item () if step % log_step_freq == 0 : print (( \"[step = %d ] loss: %.3f , \" + metric_name + \": %.3f \" ) % ( step , loss_sum / step , metric_sum / step )) # 2\uff0c\u9a8c\u8bc1\u5faa\u73af------------------------------------------------- net . eval () val_loss_sum = 0.0 val_metric_sum = 0.0 val_step = 1 for val_step , ( features , labels ) in enumerate ( dl_valid , 1 ): with torch . no_grad (): predictions = net ( features ) val_loss = loss_func ( predictions , labels ) val_metric = metric_func ( predictions , labels ) val_loss_sum += val_loss . item () val_metric_sum += val_metric . item () # 3\uff0c\u8bb0\u5f55\u65e5\u5fd7------------------------------------------------- info = ( epoch , loss_sum / step , metric_sum / step , val_loss_sum / val_step , val_metric_sum / val_step ) dfhistory . loc [ epoch - 1 ] = info # \u6253\u5370epoch\u7ea7\u522b\u65e5\u5fd7 print (( \" \\n EPOCH = %d , loss = %.3f ,\" + metric_name + \\ \" = %.3f , val_loss = %.3f , \" + \"val_\" + metric_name + \" = %.3f \" ) % info ) nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) print ( 'Finished Training...' ) Start Training... ================================================================================2020-06-26 12:49:16 [step = 100] loss: 0.742, accuracy: 0.745 [step = 200] loss: 0.466, accuracy: 0.843 [step = 300] loss: 0.363, accuracy: 0.880 [step = 400] loss: 0.310, accuracy: 0.898 EPOCH = 1, loss = 0.281,accuracy = 0.908, val_loss = 0.087, val_accuracy = 0.972 ================================================================================2020-06-26 12:50:32 [step = 100] loss: 0.103, accuracy: 0.970 [step = 200] loss: 0.114, accuracy: 0.966 [step = 300] loss: 0.112, accuracy: 0.967 [step = 400] loss: 0.108, accuracy: 0.968 EPOCH = 2, loss = 0.111,accuracy = 0.967, val_loss = 0.082, val_accuracy = 0.976 ================================================================================2020-06-26 12:51:47 [step = 100] loss: 0.093, accuracy: 0.972 [step = 200] loss: 0.095, accuracy: 0.971 [step = 300] loss: 0.092, accuracy: 0.972 [step = 400] loss: 0.093, accuracy: 0.972 EPOCH = 3, loss = 0.098,accuracy = 0.971, val_loss = 0.113, val_accuracy = 0.970 ================================================================================2020-06-26 12:53:09 Finished Training...","title":"\u4e00\uff0c\u811a\u672c\u98ce\u683c"},{"location":"6.%E9%AB%98%E9%98%B6API/6-2%2C%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/#\u4e8c\u51fd\u6570\u98ce\u683c","text":"\u8be5\u98ce\u683c\u5728\u811a\u672c\u5f62\u5f0f\u4e0a\u4f5c\u4e86\u7b80\u5355\u7684\u51fd\u6570\u5c01\u88c5\u3002 class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . layers = nn . ModuleList ([ nn . Conv2d ( in_channels = 1 , out_channels = 32 , kernel_size = 3 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Dropout2d ( p = 0.1 ), nn . AdaptiveMaxPool2d (( 1 , 1 )), nn . Flatten (), nn . Linear ( 64 , 32 ), nn . ReLU (), nn . Linear ( 32 , 10 )] ) def forward ( self , x ): for layer in self . layers : x = layer ( x ) return x net = Net () print ( net ) Net( (layers): ModuleList( (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (4): Dropout2d(p=0.1, inplace=False) (5): AdaptiveMaxPool2d(output_size=(1, 1)) (6): Flatten() (7): Linear(in_features=64, out_features=32, bias=True) (8): ReLU() (9): Linear(in_features=32, out_features=10, bias=True) ) ) summary ( net , input_shape = ( 1 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 320 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 10] 330 ================================================================ Total params: 53,994 Trainable params: 53,994 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.003906 Forward/backward pass size (MB): 0.359695 Params size (MB): 0.205971 Estimated Total Size (MB): 0.569572 ---------------------------------------------------------------- import datetime import numpy as np import pandas as pd from sklearn.metrics import accuracy_score def accuracy ( y_pred , y_true ): y_pred_cls = torch . argmax ( nn . Softmax ( dim = 1 )( y_pred ), dim = 1 ) . data return accuracy_score ( y_true , y_pred_cls ) model = net model . optimizer = torch . optim . SGD ( model . parameters (), lr = 0.01 ) model . loss_func = nn . CrossEntropyLoss () model . metric_func = accuracy model . metric_name = \"accuracy\" def train_step ( model , features , labels ): # \u8bad\u7ec3\u6a21\u5f0f\uff0cdropout\u5c42\u53d1\u751f\u4f5c\u7528 model . train () # \u68af\u5ea6\u6e05\u96f6 model . optimizer . zero_grad () # \u6b63\u5411\u4f20\u64ad\u6c42\u635f\u5931 predictions = model ( features ) loss = model . loss_func ( predictions , labels ) metric = model . metric_func ( predictions , labels ) # \u53cd\u5411\u4f20\u64ad\u6c42\u68af\u5ea6 loss . backward () model . optimizer . step () return loss . item (), metric . item () @torch . no_grad () def valid_step ( model , features , labels ): # \u9884\u6d4b\u6a21\u5f0f\uff0cdropout\u5c42\u4e0d\u53d1\u751f\u4f5c\u7528 model . eval () predictions = model ( features ) loss = model . loss_func ( predictions , labels ) metric = model . metric_func ( predictions , labels ) return loss . item (), metric . item () # \u6d4b\u8bd5train_step\u6548\u679c features , labels = next ( iter ( dl_train )) train_step ( model , features , labels ) (2.32741117477417, 0.1015625) def train_model ( model , epochs , dl_train , dl_valid , log_step_freq ): metric_name = model . metric_name dfhistory = pd . DataFrame ( columns = [ \"epoch\" , \"loss\" , metric_name , \"val_loss\" , \"val_\" + metric_name ]) print ( \"Start Training...\" ) nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \"==========\" * 8 + \" %s \" % nowtime ) for epoch in range ( 1 , epochs + 1 ): # 1\uff0c\u8bad\u7ec3\u5faa\u73af------------------------------------------------- loss_sum = 0.0 metric_sum = 0.0 step = 1 for step , ( features , labels ) in enumerate ( dl_train , 1 ): loss , metric = train_step ( model , features , labels ) # \u6253\u5370batch\u7ea7\u522b\u65e5\u5fd7 loss_sum += loss metric_sum += metric if step % log_step_freq == 0 : print (( \"[step = %d ] loss: %.3f , \" + metric_name + \": %.3f \" ) % ( step , loss_sum / step , metric_sum / step )) # 2\uff0c\u9a8c\u8bc1\u5faa\u73af------------------------------------------------- val_loss_sum = 0.0 val_metric_sum = 0.0 val_step = 1 for val_step , ( features , labels ) in enumerate ( dl_valid , 1 ): val_loss , val_metric = valid_step ( model , features , labels ) val_loss_sum += val_loss val_metric_sum += val_metric # 3\uff0c\u8bb0\u5f55\u65e5\u5fd7------------------------------------------------- info = ( epoch , loss_sum / step , metric_sum / step , val_loss_sum / val_step , val_metric_sum / val_step ) dfhistory . loc [ epoch - 1 ] = info # \u6253\u5370epoch\u7ea7\u522b\u65e5\u5fd7 print (( \" \\n EPOCH = %d , loss = %.3f ,\" + metric_name + \\ \" = %.3f , val_loss = %.3f , \" + \"val_\" + metric_name + \" = %.3f \" ) % info ) nowtime = datetime . datetime . now () . strftime ( '%Y-%m- %d %H:%M:%S' ) print ( \" \\n \" + \"==========\" * 8 + \" %s \" % nowtime ) print ( 'Finished Training...' ) return dfhistory epochs = 3 dfhistory = train_model ( model , epochs , dl_train , dl_valid , log_step_freq = 100 ) Start Training... ================================================================================2020-06-26 13:10:00 [step = 100] loss: 2.298, accuracy: 0.137 [step = 200] loss: 2.288, accuracy: 0.145 [step = 300] loss: 2.278, accuracy: 0.165 [step = 400] loss: 2.265, accuracy: 0.183 EPOCH = 1, loss = 2.254,accuracy = 0.195, val_loss = 2.158, val_accuracy = 0.301 ================================================================================2020-06-26 13:11:23 [step = 100] loss: 2.127, accuracy: 0.302 [step = 200] loss: 2.080, accuracy: 0.338 [step = 300] loss: 2.025, accuracy: 0.374 [step = 400] loss: 1.957, accuracy: 0.411 EPOCH = 2, loss = 1.905,accuracy = 0.435, val_loss = 1.469, val_accuracy = 0.710 ================================================================================2020-06-26 13:12:43 [step = 100] loss: 1.435, accuracy: 0.615 [step = 200] loss: 1.324, accuracy: 0.647 [step = 300] loss: 1.221, accuracy: 0.672 [step = 400] loss: 1.132, accuracy: 0.696 EPOCH = 3, loss = 1.074,accuracy = 0.711, val_loss = 0.582, val_accuracy = 0.878 ================================================================================2020-06-26 13:13:59 Finished Training...","title":"\u4e8c\uff0c\u51fd\u6570\u98ce\u683c"},{"location":"6.%E9%AB%98%E9%98%B6API/6-2%2C%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%843%E7%A7%8D%E6%96%B9%E6%B3%95/#\u4e09\u7c7b\u98ce\u683c","text":"\u6b64\u5904\u4f7f\u7528torchkeras\u4e2d\u5b9a\u4e49\u7684\u6a21\u578b\u63a5\u53e3\u6784\u5efa\u6a21\u578b\uff0c\u5e76\u8c03\u7528compile\u65b9\u6cd5\u548cfit\u65b9\u6cd5\u8bad\u7ec3\u6a21\u578b\u3002 \u4f7f\u7528\u8be5\u5f62\u5f0f\u8bad\u7ec3\u6a21\u578b\u975e\u5e38\u7b80\u6d01\u660e\u4e86\u3002\u63a8\u8350\u4f7f\u7528\u8be5\u5f62\u5f0f\u3002 class CnnModel ( nn . Module ): def __init__ ( self ): super () . __init__ () self . layers = nn . ModuleList ([ nn . Conv2d ( in_channels = 1 , out_channels = 32 , kernel_size = 3 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Dropout2d ( p = 0.1 ), nn . AdaptiveMaxPool2d (( 1 , 1 )), nn . Flatten (), nn . Linear ( 64 , 32 ), nn . ReLU (), nn . Linear ( 32 , 10 )] ) def forward ( self , x ): for layer in self . layers : x = layer ( x ) return x model = torchkeras . Model ( CnnModel ()) print ( model ) CnnModel( (layers): ModuleList( (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1)) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (4): Dropout2d(p=0.1, inplace=False) (5): AdaptiveMaxPool2d(output_size=(1, 1)) (6): Flatten() (7): Linear(in_features=64, out_features=32, bias=True) (8): ReLU() (9): Linear(in_features=32, out_features=10, bias=True) ) ) model . summary ( input_shape = ( 1 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 320 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 10] 330 ================================================================ Total params: 53,994 Trainable params: 53,994 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.003906 Forward/backward pass size (MB): 0.359695 Params size (MB): 0.205971 Estimated Total Size (MB): 0.569572 ---------------------------------------------------------------- from sklearn.metrics import accuracy_score def accuracy ( y_pred , y_true ): y_pred_cls = torch . argmax ( nn . Softmax ( dim = 1 )( y_pred ), dim = 1 ) . data return accuracy_score ( y_true . numpy (), y_pred_cls . numpy ()) model . compile ( loss_func = nn . CrossEntropyLoss (), optimizer = torch . optim . Adam ( model . parameters (), lr = 0.02 ), metrics_dict = { \"accuracy\" : accuracy }) dfhistory = model . fit ( 3 , dl_train = dl_train , dl_val = dl_valid , log_step_freq = 100 ) Start Training ... ================================================================================2020-06-26 13:22:39 {'step': 100, 'loss': 0.976, 'accuracy': 0.664} {'step': 200, 'loss': 0.611, 'accuracy': 0.795} {'step': 300, 'loss': 0.478, 'accuracy': 0.841} {'step': 400, 'loss': 0.403, 'accuracy': 0.868} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 1 | 0.371 | 0.879 | 0.087 | 0.972 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-26 13:23:59 {'step': 100, 'loss': 0.182, 'accuracy': 0.948} {'step': 200, 'loss': 0.176, 'accuracy': 0.949} {'step': 300, 'loss': 0.173, 'accuracy': 0.95} {'step': 400, 'loss': 0.174, 'accuracy': 0.951} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 2 | 0.175 | 0.951 | 0.152 | 0.958 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-26 13:25:22 {'step': 100, 'loss': 0.143, 'accuracy': 0.961} {'step': 200, 'loss': 0.151, 'accuracy': 0.959} {'step': 300, 'loss': 0.149, 'accuracy': 0.96} {'step': 400, 'loss': 0.152, 'accuracy': 0.959} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 3 | 0.153 | 0.959 | 0.086 | 0.975 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-26 13:26:48 Finished Training... \u5982\u679c\u5bf9\u672c\u4e66\u5185\u5bb9\u7406\u89e3\u4e0a\u6709\u9700\u8981\u8fdb\u4e00\u6b65\u548c\u4f5c\u8005\u4ea4\u6d41\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u5728\u516c\u4f17\u53f7\"Python\u4e0e\u7b97\u6cd5\u4e4b\u7f8e\"\u4e0b\u7559\u8a00\u3002\u4f5c\u8005\u65f6\u95f4\u548c\u7cbe\u529b\u6709\u9650\uff0c\u4f1a\u914c\u60c5\u4e88\u4ee5\u56de\u590d\u3002 \u4e5f\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u540e\u53f0\u56de\u590d\u5173\u952e\u5b57\uff1a \u52a0\u7fa4 \uff0c\u52a0\u5165\u8bfb\u8005\u4ea4\u6d41\u7fa4\u548c\u5927\u5bb6\u8ba8\u8bba\u3002","title":"\u4e09\uff0c\u7c7b\u98ce\u683c"},{"location":"6.%E9%AB%98%E9%98%B6API/6-3%2C%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/","text":"6-3,\u4f7f\u7528GPU\u8bad\u7ec3\u6a21\u578b # \u6df1\u5ea6\u5b66\u4e60\u7684\u8bad\u7ec3\u8fc7\u7a0b\u5e38\u5e38\u975e\u5e38\u8017\u65f6\uff0c\u4e00\u4e2a\u6a21\u578b\u8bad\u7ec3\u51e0\u4e2a\u5c0f\u65f6\u662f\u5bb6\u5e38\u4fbf\u996d\uff0c\u8bad\u7ec3\u51e0\u5929\u4e5f\u662f\u5e38\u6709\u7684\u4e8b\u60c5\uff0c\u6709\u65f6\u5019\u751a\u81f3\u8981\u8bad\u7ec3\u51e0\u5341\u5929\u3002 \u8bad\u7ec3\u8fc7\u7a0b\u7684\u8017\u65f6\u4e3b\u8981\u6765\u81ea\u4e8e\u4e24\u4e2a\u90e8\u5206\uff0c\u4e00\u90e8\u5206\u6765\u81ea\u6570\u636e\u51c6\u5907\uff0c\u53e6\u4e00\u90e8\u5206\u6765\u81ea\u53c2\u6570\u8fed\u4ee3\u3002 \u5f53\u6570\u636e\u51c6\u5907\u8fc7\u7a0b\u8fd8\u662f\u6a21\u578b\u8bad\u7ec3\u65f6\u95f4\u7684\u4e3b\u8981\u74f6\u9888\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u66f4\u591a\u8fdb\u7a0b\u6765\u51c6\u5907\u6570\u636e\u3002 \u5f53\u53c2\u6570\u8fed\u4ee3\u8fc7\u7a0b\u6210\u4e3a\u8bad\u7ec3\u65f6\u95f4\u7684\u4e3b\u8981\u74f6\u9888\u65f6\uff0c\u6211\u4eec\u901a\u5e38\u7684\u65b9\u6cd5\u662f\u5e94\u7528GPU\u6765\u8fdb\u884c\u52a0\u901f\u3002 Pytorch\u4e2d\u4f7f\u7528GPU\u52a0\u901f\u6a21\u578b\u975e\u5e38\u7b80\u5355\uff0c\u53ea\u8981\u5c06\u6a21\u578b\u548c\u6570\u636e\u79fb\u52a8\u5230GPU\u4e0a\u3002\u6838\u5fc3\u4ee3\u7801\u53ea\u6709\u4ee5\u4e0b\u51e0\u884c\u3002 # \u5b9a\u4e49\u6a21\u578b ... device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) model . to ( device ) # \u79fb\u52a8\u6a21\u578b\u5230cuda # \u8bad\u7ec3\u6a21\u578b ... features = features . to ( device ) # \u79fb\u52a8\u6570\u636e\u5230cuda labels = labels . to ( device ) # \u6216\u8005 labels = labels.cuda() if torch.cuda.is_available() else labels ... \u5982\u679c\u8981\u4f7f\u7528\u591a\u4e2aGPU\u8bad\u7ec3\u6a21\u578b\uff0c\u4e5f\u975e\u5e38\u7b80\u5355\u3002\u53ea\u9700\u8981\u5728\u5c06\u6a21\u578b\u8bbe\u7f6e\u4e3a\u6570\u636e\u5e76\u884c\u98ce\u683c\u6a21\u578b\u3002 \u5219\u6a21\u578b\u79fb\u52a8\u5230GPU\u4e0a\u4e4b\u540e\uff0c\u4f1a\u5728\u6bcf\u4e00\u4e2aGPU\u4e0a\u62f7\u8d1d\u4e00\u4e2a\u526f\u672c\uff0c\u5e76\u628a\u6570\u636e\u5e73\u5206\u5230\u5404\u4e2aGPU\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u6838\u5fc3\u4ee3\u7801\u5982\u4e0b\u3002 # \u5b9a\u4e49\u6a21\u578b ... if torch . cuda . device_count () > 1 : model = nn . DataParallel ( model ) # \u5305\u88c5\u4e3a\u5e76\u884c\u98ce\u683c\u6a21\u578b # \u8bad\u7ec3\u6a21\u578b ... features = features . to ( device ) # \u79fb\u52a8\u6570\u636e\u5230cuda labels = labels . to ( device ) # \u6216\u8005 labels = labels.cuda() if torch.cuda.is_available() else labels ... \u4ee5\u4e0b\u662f\u4e00\u4e9b\u548cGPU\u6709\u5173\u7684\u57fa\u672c\u64cd\u4f5c\u6c47\u603b \u5728Colab\u7b14\u8bb0\u672c\u4e2d\uff1a\u4fee\u6539->\u7b14\u8bb0\u672c\u8bbe\u7f6e->\u786c\u4ef6\u52a0\u901f\u5668 \u4e2d\u9009\u62e9 GPU \u6ce8\uff1a\u4ee5\u4e0b\u4ee3\u7801\u53ea\u80fd\u5728Colab \u4e0a\u624d\u80fd\u6b63\u786e\u6267\u884c\u3002 \u53ef\u70b9\u51fb\u5982\u4e0b\u94fe\u63a5\uff0c\u76f4\u63a5\u5728colab\u4e2d\u8fd0\u884c\u8303\u4f8b\u4ee3\u7801\u3002 \u300atorch\u4f7f\u7528gpu\u8bad\u7ec3\u6a21\u578b\u300b https://colab.research.google.com/drive/1FDmi44-U3TFRCt9MwGn4HIj2SaaWIjHu?usp=sharing import torch from torch import nn # 1\uff0c\u67e5\u770bgpu\u4fe1\u606f if_cuda = torch . cuda . is_available () print ( \"if_cuda=\" , if_cuda ) gpu_count = torch . cuda . device_count () print ( \"gpu_count=\" , gpu_count ) if_cuda= True gpu_count= 1 # 2\uff0c\u5c06\u5f20\u91cf\u5728gpu\u548ccpu\u95f4\u79fb\u52a8 tensor = torch . rand (( 100 , 100 )) tensor_gpu = tensor . to ( \"cuda:0\" ) # \u6216\u8005 tensor_gpu = tensor.cuda() print ( tensor_gpu . device ) print ( tensor_gpu . is_cuda ) tensor_cpu = tensor_gpu . to ( \"cpu\" ) # \u6216\u8005 tensor_cpu = tensor_gpu.cpu() print ( tensor_cpu . device ) cuda:0 True cpu # 3\uff0c\u5c06\u6a21\u578b\u4e2d\u7684\u5168\u90e8\u5f20\u91cf\u79fb\u52a8\u5230gpu\u4e0a net = nn . Linear ( 2 , 1 ) print ( next ( net . parameters ()) . is_cuda ) net . to ( \"cuda:0\" ) # \u5c06\u6a21\u578b\u4e2d\u7684\u5168\u90e8\u53c2\u6570\u5f20\u91cf\u4f9d\u6b21\u5230GPU\u4e0a\uff0c\u6ce8\u610f\uff0c\u65e0\u9700\u91cd\u65b0\u8d4b\u503c\u4e3a net = net.to(\"cuda:0\") print ( next ( net . parameters ()) . is_cuda ) print ( next ( net . parameters ()) . device ) False True cuda:0 # 4\uff0c\u521b\u5efa\u652f\u6301\u591a\u4e2agpu\u6570\u636e\u5e76\u884c\u7684\u6a21\u578b linear = nn . Linear ( 2 , 1 ) print ( next ( linear . parameters ()) . device ) model = nn . DataParallel ( linear ) print ( model . device_ids ) print ( next ( model . module . parameters ()) . device ) #\u6ce8\u610f\u4fdd\u5b58\u53c2\u6570\u65f6\u8981\u6307\u5b9a\u4fdd\u5b58model.module\u7684\u53c2\u6570 torch . save ( model . module . state_dict (), \"../data/model_parameter.pkl\" ) linear = nn . Linear ( 2 , 1 ) linear . load_state_dict ( torch . load ( \"../data/model_parameter.pkl\" )) cpu [0] cuda:0 # 5\uff0c\u6e05\u7a7acuda\u7f13\u5b58 # \u8be5\u65b9\u6cd5\u5728cuda\u8d85\u5185\u5b58\u65f6\u5341\u5206\u6709\u7528 torch . cuda . empty_cache () \u4e00\uff0c\u77e9\u9635\u4e58\u6cd5\u8303\u4f8b # \u4e0b\u9762\u5206\u522b\u4f7f\u7528CPU\u548cGPU\u4f5c\u4e00\u4e2a\u77e9\u9635\u4e58\u6cd5\uff0c\u5e76\u6bd4\u8f83\u5176\u8ba1\u7b97\u6548\u7387\u3002 import time import torch from torch import nn # \u4f7f\u7528cpu a = torch . rand (( 10000 , 200 )) b = torch . rand (( 200 , 10000 )) tic = time . time () c = torch . matmul ( a , b ) toc = time . time () print ( toc - tic ) print ( a . device ) print ( b . device ) 0.6454010009765625 cpu cpu # \u4f7f\u7528gpu device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) a = torch . rand (( 10000 , 200 ), device = device ) #\u53ef\u4ee5\u6307\u5b9a\u5728GPU\u4e0a\u521b\u5efa\u5f20\u91cf b = torch . rand (( 200 , 10000 )) #\u4e5f\u53ef\u4ee5\u5728CPU\u4e0a\u521b\u5efa\u5f20\u91cf\u540e\u79fb\u52a8\u5230GPU\u4e0a b = b . to ( device ) #\u6216\u8005 b = b.cuda() if torch.cuda.is_available() else b tic = time . time () c = torch . matmul ( a , b ) toc = time . time () print ( toc - tic ) print ( a . device ) print ( b . device ) 0.014541149139404297 cuda:0 cuda:0 \u4e8c\uff0c\u7ebf\u6027\u56de\u5f52\u8303\u4f8b # \u4e0b\u9762\u5bf9\u6bd4\u4f7f\u7528CPU\u548cGPU\u8bad\u7ec3\u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u7684\u6548\u7387 1\uff0c\u4f7f\u7528CPU # \u51c6\u5907\u6570\u636e n = 1000000 #\u6837\u672c\u6570\u91cf X = 10 * torch . rand ([ n , 2 ]) - 5.0 #torch.rand\u662f\u5747\u5300\u5206\u5e03 w0 = torch . tensor ([[ 2.0 , - 3.0 ]]) b0 = torch . tensor ([[ 10.0 ]]) Y = X @w0 . t () + b0 + torch . normal ( 0.0 , 2.0 , size = [ n , 1 ]) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 # \u5b9a\u4e49\u6a21\u578b class LinearRegression ( nn . Module ): def __init__ ( self ): super () . __init__ () self . w = nn . Parameter ( torch . randn_like ( w0 )) self . b = nn . Parameter ( torch . zeros_like ( b0 )) #\u6b63\u5411\u4f20\u64ad def forward ( self , x ): return x @self . w . t () + self . b linear = LinearRegression () # \u8bad\u7ec3\u6a21\u578b optimizer = torch . optim . Adam ( linear . parameters (), lr = 0.1 ) loss_func = nn . MSELoss () def train ( epoches ): tic = time . time () for epoch in range ( epoches ): optimizer . zero_grad () Y_pred = linear ( X ) loss = loss_func ( Y_pred , Y ) loss . backward () optimizer . step () if epoch % 50 == 0 : print ({ \"epoch\" : epoch , \"loss\" : loss . item ()}) toc = time . time () print ( \"time used:\" , toc - tic ) train ( 500 ) {'epoch': 0, 'loss': 3.996487855911255} {'epoch': 50, 'loss': 3.9969770908355713} {'epoch': 100, 'loss': 3.9964890480041504} {'epoch': 150, 'loss': 3.996488332748413} {'epoch': 200, 'loss': 3.996488094329834} {'epoch': 250, 'loss': 3.996488332748413} {'epoch': 300, 'loss': 3.996488332748413} {'epoch': 350, 'loss': 3.996488094329834} {'epoch': 400, 'loss': 3.996488332748413} {'epoch': 450, 'loss': 3.996488094329834} time used: 5.4090576171875 2\uff0c\u4f7f\u7528GPU # \u51c6\u5907\u6570\u636e n = 1000000 #\u6837\u672c\u6570\u91cf X = 10 * torch . rand ([ n , 2 ]) - 5.0 #torch.rand\u662f\u5747\u5300\u5206\u5e03 w0 = torch . tensor ([[ 2.0 , - 3.0 ]]) b0 = torch . tensor ([[ 10.0 ]]) Y = X @w0 . t () + b0 + torch . normal ( 0.0 , 2.0 , size = [ n , 1 ]) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 # \u79fb\u52a8\u5230GPU\u4e0a print ( \"torch.cuda.is_available() = \" , torch . cuda . is_available ()) X = X . cuda () Y = Y . cuda () print ( \"X.device:\" , X . device ) print ( \"Y.device:\" , Y . device ) torch.cuda.is_available() = True X.device: cuda:0 Y.device: cuda:0 # \u5b9a\u4e49\u6a21\u578b class LinearRegression ( nn . Module ): def __init__ ( self ): super () . __init__ () self . w = nn . Parameter ( torch . randn_like ( w0 )) self . b = nn . Parameter ( torch . zeros_like ( b0 )) #\u6b63\u5411\u4f20\u64ad def forward ( self , x ): return x @self . w . t () + self . b linear = LinearRegression () # \u79fb\u52a8\u6a21\u578b\u5230GPU\u4e0a device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) linear . to ( device ) #\u67e5\u770b\u6a21\u578b\u662f\u5426\u5df2\u7ecf\u79fb\u52a8\u5230GPU\u4e0a print ( \"if on cuda:\" , next ( linear . parameters ()) . is_cuda ) if on cuda: True # \u8bad\u7ec3\u6a21\u578b optimizer = torch . optim . Adam ( linear . parameters (), lr = 0.1 ) loss_func = nn . MSELoss () def train ( epoches ): tic = time . time () for epoch in range ( epoches ): optimizer . zero_grad () Y_pred = linear ( X ) loss = loss_func ( Y_pred , Y ) loss . backward () optimizer . step () if epoch % 50 == 0 : print ({ \"epoch\" : epoch , \"loss\" : loss . item ()}) toc = time . time () print ( \"time used:\" , toc - tic ) train ( 500 ) {'epoch': 0, 'loss': 3.9982845783233643} {'epoch': 50, 'loss': 3.998818874359131} {'epoch': 100, 'loss': 3.9982895851135254} {'epoch': 150, 'loss': 3.9982845783233643} {'epoch': 200, 'loss': 3.998284339904785} {'epoch': 250, 'loss': 3.9982845783233643} {'epoch': 300, 'loss': 3.9982845783233643} {'epoch': 350, 'loss': 3.9982845783233643} {'epoch': 400, 'loss': 3.9982845783233643} {'epoch': 450, 'loss': 3.9982845783233643} time used: 0.4889392852783203 \u4e09\uff0ctorchkeras\u4f7f\u7528\u5355GPU\u8303\u4f8b # \u4e0b\u9762\u6f14\u793a\u4f7f\u7528torchkeras\u6765\u5e94\u7528GPU\u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5\u3002 \u5176\u5bf9\u5e94\u7684CPU\u8bad\u7ec3\u6a21\u578b\u4ee3\u7801\u53c2\u89c1\u300a6-2,\u8bad\u7ec3\u6a21\u578b\u76843\u79cd\u65b9\u6cd5\u300b \u672c\u4f8b\u4ec5\u9700\u8981\u5728\u5b83\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e00\u884c\u4ee3\u7801\uff0c\u5728model.compile\u65f6\u6307\u5b9a device\u5373\u53ef\u3002 1\uff0c\u51c6\u5907\u6570\u636e ! pip install - U torchkeras import torch from torch import nn import torchvision from torchvision import transforms import torchkeras transform = transforms . Compose ([ transforms . ToTensor ()]) ds_train = torchvision . datasets . MNIST ( root = \"../data/minist/\" , train = True , download = True , transform = transform ) ds_valid = torchvision . datasets . MNIST ( root = \"../data/minist/\" , train = False , download = True , transform = transform ) dl_train = torch . utils . data . DataLoader ( ds_train , batch_size = 128 , shuffle = True , num_workers = 4 ) dl_valid = torch . utils . data . DataLoader ( ds_valid , batch_size = 128 , shuffle = False , num_workers = 4 ) print ( len ( ds_train )) print ( len ( ds_valid )) % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u67e5\u770b\u90e8\u5206\u6837\u672c from matplotlib import pyplot as plt plt . figure ( figsize = ( 8 , 8 )) for i in range ( 9 ): img , label = ds_train [ i ] img = torch . squeeze ( img ) ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow ( img . numpy ()) ax . set_title ( \"label = %d \" % label ) ax . set_xticks ([]) ax . set_yticks ([]) plt . show () 2\uff0c\u5b9a\u4e49\u6a21\u578b class CnnModel ( nn . Module ): def __init__ ( self ): super () . __init__ () self . layers = nn . ModuleList ([ nn . Conv2d ( in_channels = 1 , out_channels = 32 , kernel_size = 3 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Dropout2d ( p = 0.1 ), nn . AdaptiveMaxPool2d (( 1 , 1 )), nn . Flatten (), nn . Linear ( 64 , 32 ), nn . ReLU (), nn . Linear ( 32 , 10 )] ) def forward ( self , x ): for layer in self . layers : x = layer ( x ) return x net = CnnModel () model = torchkeras . Model ( net ) model . summary ( input_shape = ( 1 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 320 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 10] 330 ================================================================ Total params: 53,994 Trainable params: 53,994 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.003906 Forward/backward pass size (MB): 0.359695 Params size (MB): 0.205971 Estimated Total Size (MB): 0.569572 ---------------------------------------------------------------- 3\uff0c\u8bad\u7ec3\u6a21\u578b from sklearn.metrics import accuracy_score def accuracy ( y_pred , y_true ): y_pred_cls = torch . argmax ( nn . Softmax ( dim = 1 )( y_pred ), dim = 1 ) . data return accuracy_score ( y_true . cpu () . numpy (), y_pred_cls . cpu () . numpy ()) # \u6ce8\u610f\u6b64\u5904\u8981\u5c06\u6570\u636e\u5148\u79fb\u52a8\u5230cpu\u4e0a\uff0c\u7136\u540e\u624d\u80fd\u8f6c\u6362\u6210numpy\u6570\u7ec4 device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) model . compile ( loss_func = nn . CrossEntropyLoss (), optimizer = torch . optim . Adam ( model . parameters (), lr = 0.02 ), metrics_dict = { \"accuracy\" : accuracy }, device = device ) # \u6ce8\u610f\u6b64\u5904compile\u65f6\u6307\u5b9a\u4e86device dfhistory = model . fit ( 3 , dl_train = dl_train , dl_val = dl_valid , log_step_freq = 100 ) Start Training ... ================================================================================2020-06-27 00:24:29 {'step': 100, 'loss': 1.063, 'accuracy': 0.619} {'step': 200, 'loss': 0.681, 'accuracy': 0.764} {'step': 300, 'loss': 0.534, 'accuracy': 0.818} {'step': 400, 'loss': 0.458, 'accuracy': 0.847} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 1 | 0.412 | 0.863 | 0.128 | 0.961 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-27 00:24:35 {'step': 100, 'loss': 0.147, 'accuracy': 0.956} {'step': 200, 'loss': 0.156, 'accuracy': 0.954} {'step': 300, 'loss': 0.156, 'accuracy': 0.954} {'step': 400, 'loss': 0.157, 'accuracy': 0.955} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 2 | 0.153 | 0.956 | 0.085 | 0.976 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-27 00:24:42 {'step': 100, 'loss': 0.126, 'accuracy': 0.965} {'step': 200, 'loss': 0.147, 'accuracy': 0.96} {'step': 300, 'loss': 0.153, 'accuracy': 0.959} {'step': 400, 'loss': 0.147, 'accuracy': 0.96} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 3 | 0.146 | 0.96 | 0.119 | 0.968 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-27 00:24:48 Finished Training... 4\uff0c\u8bc4\u4f30\u6a21\u578b % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( dfhistory , metric ): train_metrics = dfhistory [ metric ] val_metrics = dfhistory [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( dfhistory , \"loss\" ) plot_metric ( dfhistory , \"accuracy\" ) model . evaluate ( dl_valid ) {'val_accuracy': 0.967068829113924, 'val_loss': 0.11601964030650598} 5\uff0c\u4f7f\u7528\u6a21\u578b model . predict ( dl_valid )[ 0 : 10 ] tensor([[ -9.2092, 3.1997, 1.4028, -2.7135, -0.7320, -2.0518, -20.4938, 14.6774, 1.7616, 5.8549], [ 2.8509, 4.9781, 18.0946, 0.0928, -1.6061, -4.1437, 4.8697, 3.8811, 4.3869, -3.5929], [-22.5231, 13.6643, 5.0244, -11.0188, -16.8147, -9.5894, -6.2556, -10.5648, -12.1022, -19.4685], [ 23.2670, -12.0711, -7.3968, -8.2715, -1.0915, -12.6050, 8.0444, -16.9339, 1.8827, -0.2497], [ -4.1159, 3.2102, 0.4971, -11.8064, 12.1460, -5.1650, -6.5918, 1.0088, 0.8362, 2.5132], [-26.1764, 15.6251, 6.1191, -12.2424, -13.9725, -10.0540, -7.8669, -5.9602, -11.1944, -18.7890], [ -5.0602, 3.3779, -0.6647, -8.5185, 10.0320, -5.5107, -6.9579, 2.3811, 0.2542, 3.2860], [ 4.1017, -0.4282, 7.2220, 3.3700, -3.6813, 1.1576, -1.8479, 0.7450, 3.9768, 6.2640], [ 1.9689, -0.3960, 7.4414, -10.4789, 2.7066, 1.7482, 5.7971, -4.5808, 3.0911, -5.1971], [ -2.9680, -1.2369, -0.0829, -1.8577, 1.9380, -0.8374, -8.2207, 3.5060, 3.8735, 13.6762]], device='cuda:0') 6\uff0c\u4fdd\u5b58\u6a21\u578b # save the model parameters torch . save ( model . state_dict (), \"model_parameter.pkl\" ) model_clone = torchkeras . Model ( CnnModel ()) model_clone . load_state_dict ( torch . load ( \"model_parameter.pkl\" )) model_clone . compile ( loss_func = nn . CrossEntropyLoss (), optimizer = torch . optim . Adam ( model . parameters (), lr = 0.02 ), metrics_dict = { \"accuracy\" : accuracy }, device = device ) # \u6ce8\u610f\u6b64\u5904compile\u65f6\u6307\u5b9a\u4e86device model_clone . evaluate ( dl_valid ) {'val_accuracy': 0.967068829113924, 'val_loss': 0.11601964030650598} \u56db\uff0ctorchkeras\u4f7f\u7528\u591aGPU\u8303\u4f8b # \u6ce8\uff1a\u4ee5\u4e0b\u8303\u4f8b\u9700\u8981\u5728\u6709\u591a\u4e2aGPU\u7684\u673a\u5668\u4e0a\u8dd1\u3002\u5982\u679c\u5728\u5355GPU\u7684\u673a\u5668\u4e0a\u8dd1\uff0c\u4e5f\u80fd\u8dd1\u901a\uff0c\u4f46\u662f\u5b9e\u9645\u4e0a\u4f7f\u7528\u7684\u662f\u5355\u4e2aGPU\u3002 1\uff0c\u51c6\u5907\u6570\u636e import torch from torch import nn import torchvision from torchvision import transforms import torchkeras transform = transforms . Compose ([ transforms . ToTensor ()]) ds_train = torchvision . datasets . MNIST ( root = \"../data/minist/\" , train = True , download = True , transform = transform ) ds_valid = torchvision . datasets . MNIST ( root = \"../data/minist/\" , train = False , download = True , transform = transform ) dl_train = torch . utils . data . DataLoader ( ds_train , batch_size = 128 , shuffle = True , num_workers = 4 ) dl_valid = torch . utils . data . DataLoader ( ds_valid , batch_size = 128 , shuffle = False , num_workers = 4 ) print ( len ( ds_train )) print ( len ( ds_valid )) 2\uff0c\u5b9a\u4e49\u6a21\u578b class CnnModule ( nn . Module ): def __init__ ( self ): super () . __init__ () self . layers = nn . ModuleList ([ nn . Conv2d ( in_channels = 1 , out_channels = 32 , kernel_size = 3 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Dropout2d ( p = 0.1 ), nn . AdaptiveMaxPool2d (( 1 , 1 )), nn . Flatten (), nn . Linear ( 64 , 32 ), nn . ReLU (), nn . Linear ( 32 , 10 )] ) def forward ( self , x ): for layer in self . layers : x = layer ( x ) return x net = nn . DataParallel ( CnnModule ()) #Attention this line!!! model = torchkeras . Model ( net ) model . summary ( input_shape = ( 1 , 32 , 32 )) 3\uff0c\u8bad\u7ec3\u6a21\u578b from sklearn.metrics import accuracy_score def accuracy ( y_pred , y_true ): y_pred_cls = torch . argmax ( nn . Softmax ( dim = 1 )( y_pred ), dim = 1 ) . data return accuracy_score ( y_true . cpu () . numpy (), y_pred_cls . cpu () . numpy ()) # \u6ce8\u610f\u6b64\u5904\u8981\u5c06\u6570\u636e\u5148\u79fb\u52a8\u5230cpu\u4e0a\uff0c\u7136\u540e\u624d\u80fd\u8f6c\u6362\u6210numpy\u6570\u7ec4 device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) model . compile ( loss_func = nn . CrossEntropyLoss (), optimizer = torch . optim . Adam ( model . parameters (), lr = 0.02 ), metrics_dict = { \"accuracy\" : accuracy }, device = device ) # \u6ce8\u610f\u6b64\u5904compile\u65f6\u6307\u5b9a\u4e86device dfhistory = model . fit ( 3 , dl_train = dl_train , dl_val = dl_valid , log_step_freq = 100 ) Start Training ... ================================================================================2020-06-27 00:24:29 {'step': 100, 'loss': 1.063, 'accuracy': 0.619} {'step': 200, 'loss': 0.681, 'accuracy': 0.764} {'step': 300, 'loss': 0.534, 'accuracy': 0.818} {'step': 400, 'loss': 0.458, 'accuracy': 0.847} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 1 | 0.412 | 0.863 | 0.128 | 0.961 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-27 00:24:35 {'step': 100, 'loss': 0.147, 'accuracy': 0.956} {'step': 200, 'loss': 0.156, 'accuracy': 0.954} {'step': 300, 'loss': 0.156, 'accuracy': 0.954} {'step': 400, 'loss': 0.157, 'accuracy': 0.955} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 2 | 0.153 | 0.956 | 0.085 | 0.976 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-27 00:24:42 {'step': 100, 'loss': 0.126, 'accuracy': 0.965} {'step': 200, 'loss': 0.147, 'accuracy': 0.96} {'step': 300, 'loss': 0.153, 'accuracy': 0.959} {'step': 400, 'loss': 0.147, 'accuracy': 0.96} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 3 | 0.146 | 0.96 | 0.119 | 0.968 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-27 00:24:48 Finished Training... 4\uff0c\u8bc4\u4f30\u6a21\u578b % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( dfhistory , metric ): train_metrics = dfhistory [ metric ] val_metrics = dfhistory [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( dfhistory , \"loss\" ) plot_metric ( dfhistory , \"accuracy\" ) model . evaluate ( dl_valid ) {'val_accuracy': 0.9603441455696202, 'val_loss': 0.14203246376371081} 5\uff0c\u4f7f\u7528\u6a21\u578b model . predict ( dl_valid )[ 0 : 10 ] tensor([[ -9.2092, 3.1997, 1.4028, -2.7135, -0.7320, -2.0518, -20.4938, 14.6774, 1.7616, 5.8549], [ 2.8509, 4.9781, 18.0946, 0.0928, -1.6061, -4.1437, 4.8697, 3.8811, 4.3869, -3.5929], [-22.5231, 13.6643, 5.0244, -11.0188, -16.8147, -9.5894, -6.2556, -10.5648, -12.1022, -19.4685], [ 23.2670, -12.0711, -7.3968, -8.2715, -1.0915, -12.6050, 8.0444, -16.9339, 1.8827, -0.2497], [ -4.1159, 3.2102, 0.4971, -11.8064, 12.1460, -5.1650, -6.5918, 1.0088, 0.8362, 2.5132], [-26.1764, 15.6251, 6.1191, -12.2424, -13.9725, -10.0540, -7.8669, -5.9602, -11.1944, -18.7890], [ -5.0602, 3.3779, -0.6647, -8.5185, 10.0320, -5.5107, -6.9579, 2.3811, 0.2542, 3.2860], [ 4.1017, -0.4282, 7.2220, 3.3700, -3.6813, 1.1576, -1.8479, 0.7450, 3.9768, 6.2640], [ 1.9689, -0.3960, 7.4414, -10.4789, 2.7066, 1.7482, 5.7971, -4.5808, 3.0911, -5.1971], [ -2.9680, -1.2369, -0.0829, -1.8577, 1.9380, -0.8374, -8.2207, 3.5060, 3.8735, 13.6762]], device='cuda:0') 6\uff0c\u4fdd\u5b58\u6a21\u578b # save the model parameters torch . save ( model . net . module . state_dict (), \"model_parameter.pkl\" ) net_clone = CnnModel () net_clone . load_state_dict ( torch . load ( \"model_parameter.pkl\" )) model_clone = torchkeras . Model ( net_clone ) model_clone . compile ( loss_func = nn . CrossEntropyLoss (), optimizer = torch . optim . Adam ( model . parameters (), lr = 0.02 ), metrics_dict = { \"accuracy\" : accuracy }, device = device ) model_clone . evaluate ( dl_valid ) {'val_accuracy': 0.9603441455696202, 'val_loss': 0.14203246376371081}","title":"6-3,\u4f7f\u7528GPU\u8bad\u7ec3\u6a21\u578b"},{"location":"6.%E9%AB%98%E9%98%B6API/6-3%2C%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#6-3\u4f7f\u7528gpu\u8bad\u7ec3\u6a21\u578b","text":"\u6df1\u5ea6\u5b66\u4e60\u7684\u8bad\u7ec3\u8fc7\u7a0b\u5e38\u5e38\u975e\u5e38\u8017\u65f6\uff0c\u4e00\u4e2a\u6a21\u578b\u8bad\u7ec3\u51e0\u4e2a\u5c0f\u65f6\u662f\u5bb6\u5e38\u4fbf\u996d\uff0c\u8bad\u7ec3\u51e0\u5929\u4e5f\u662f\u5e38\u6709\u7684\u4e8b\u60c5\uff0c\u6709\u65f6\u5019\u751a\u81f3\u8981\u8bad\u7ec3\u51e0\u5341\u5929\u3002 \u8bad\u7ec3\u8fc7\u7a0b\u7684\u8017\u65f6\u4e3b\u8981\u6765\u81ea\u4e8e\u4e24\u4e2a\u90e8\u5206\uff0c\u4e00\u90e8\u5206\u6765\u81ea\u6570\u636e\u51c6\u5907\uff0c\u53e6\u4e00\u90e8\u5206\u6765\u81ea\u53c2\u6570\u8fed\u4ee3\u3002 \u5f53\u6570\u636e\u51c6\u5907\u8fc7\u7a0b\u8fd8\u662f\u6a21\u578b\u8bad\u7ec3\u65f6\u95f4\u7684\u4e3b\u8981\u74f6\u9888\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u66f4\u591a\u8fdb\u7a0b\u6765\u51c6\u5907\u6570\u636e\u3002 \u5f53\u53c2\u6570\u8fed\u4ee3\u8fc7\u7a0b\u6210\u4e3a\u8bad\u7ec3\u65f6\u95f4\u7684\u4e3b\u8981\u74f6\u9888\u65f6\uff0c\u6211\u4eec\u901a\u5e38\u7684\u65b9\u6cd5\u662f\u5e94\u7528GPU\u6765\u8fdb\u884c\u52a0\u901f\u3002 Pytorch\u4e2d\u4f7f\u7528GPU\u52a0\u901f\u6a21\u578b\u975e\u5e38\u7b80\u5355\uff0c\u53ea\u8981\u5c06\u6a21\u578b\u548c\u6570\u636e\u79fb\u52a8\u5230GPU\u4e0a\u3002\u6838\u5fc3\u4ee3\u7801\u53ea\u6709\u4ee5\u4e0b\u51e0\u884c\u3002 # \u5b9a\u4e49\u6a21\u578b ... device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) model . to ( device ) # \u79fb\u52a8\u6a21\u578b\u5230cuda # \u8bad\u7ec3\u6a21\u578b ... features = features . to ( device ) # \u79fb\u52a8\u6570\u636e\u5230cuda labels = labels . to ( device ) # \u6216\u8005 labels = labels.cuda() if torch.cuda.is_available() else labels ... \u5982\u679c\u8981\u4f7f\u7528\u591a\u4e2aGPU\u8bad\u7ec3\u6a21\u578b\uff0c\u4e5f\u975e\u5e38\u7b80\u5355\u3002\u53ea\u9700\u8981\u5728\u5c06\u6a21\u578b\u8bbe\u7f6e\u4e3a\u6570\u636e\u5e76\u884c\u98ce\u683c\u6a21\u578b\u3002 \u5219\u6a21\u578b\u79fb\u52a8\u5230GPU\u4e0a\u4e4b\u540e\uff0c\u4f1a\u5728\u6bcf\u4e00\u4e2aGPU\u4e0a\u62f7\u8d1d\u4e00\u4e2a\u526f\u672c\uff0c\u5e76\u628a\u6570\u636e\u5e73\u5206\u5230\u5404\u4e2aGPU\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u6838\u5fc3\u4ee3\u7801\u5982\u4e0b\u3002 # \u5b9a\u4e49\u6a21\u578b ... if torch . cuda . device_count () > 1 : model = nn . DataParallel ( model ) # \u5305\u88c5\u4e3a\u5e76\u884c\u98ce\u683c\u6a21\u578b # \u8bad\u7ec3\u6a21\u578b ... features = features . to ( device ) # \u79fb\u52a8\u6570\u636e\u5230cuda labels = labels . to ( device ) # \u6216\u8005 labels = labels.cuda() if torch.cuda.is_available() else labels ... \u4ee5\u4e0b\u662f\u4e00\u4e9b\u548cGPU\u6709\u5173\u7684\u57fa\u672c\u64cd\u4f5c\u6c47\u603b \u5728Colab\u7b14\u8bb0\u672c\u4e2d\uff1a\u4fee\u6539->\u7b14\u8bb0\u672c\u8bbe\u7f6e->\u786c\u4ef6\u52a0\u901f\u5668 \u4e2d\u9009\u62e9 GPU \u6ce8\uff1a\u4ee5\u4e0b\u4ee3\u7801\u53ea\u80fd\u5728Colab \u4e0a\u624d\u80fd\u6b63\u786e\u6267\u884c\u3002 \u53ef\u70b9\u51fb\u5982\u4e0b\u94fe\u63a5\uff0c\u76f4\u63a5\u5728colab\u4e2d\u8fd0\u884c\u8303\u4f8b\u4ee3\u7801\u3002 \u300atorch\u4f7f\u7528gpu\u8bad\u7ec3\u6a21\u578b\u300b https://colab.research.google.com/drive/1FDmi44-U3TFRCt9MwGn4HIj2SaaWIjHu?usp=sharing import torch from torch import nn # 1\uff0c\u67e5\u770bgpu\u4fe1\u606f if_cuda = torch . cuda . is_available () print ( \"if_cuda=\" , if_cuda ) gpu_count = torch . cuda . device_count () print ( \"gpu_count=\" , gpu_count ) if_cuda= True gpu_count= 1 # 2\uff0c\u5c06\u5f20\u91cf\u5728gpu\u548ccpu\u95f4\u79fb\u52a8 tensor = torch . rand (( 100 , 100 )) tensor_gpu = tensor . to ( \"cuda:0\" ) # \u6216\u8005 tensor_gpu = tensor.cuda() print ( tensor_gpu . device ) print ( tensor_gpu . is_cuda ) tensor_cpu = tensor_gpu . to ( \"cpu\" ) # \u6216\u8005 tensor_cpu = tensor_gpu.cpu() print ( tensor_cpu . device ) cuda:0 True cpu # 3\uff0c\u5c06\u6a21\u578b\u4e2d\u7684\u5168\u90e8\u5f20\u91cf\u79fb\u52a8\u5230gpu\u4e0a net = nn . Linear ( 2 , 1 ) print ( next ( net . parameters ()) . is_cuda ) net . to ( \"cuda:0\" ) # \u5c06\u6a21\u578b\u4e2d\u7684\u5168\u90e8\u53c2\u6570\u5f20\u91cf\u4f9d\u6b21\u5230GPU\u4e0a\uff0c\u6ce8\u610f\uff0c\u65e0\u9700\u91cd\u65b0\u8d4b\u503c\u4e3a net = net.to(\"cuda:0\") print ( next ( net . parameters ()) . is_cuda ) print ( next ( net . parameters ()) . device ) False True cuda:0 # 4\uff0c\u521b\u5efa\u652f\u6301\u591a\u4e2agpu\u6570\u636e\u5e76\u884c\u7684\u6a21\u578b linear = nn . Linear ( 2 , 1 ) print ( next ( linear . parameters ()) . device ) model = nn . DataParallel ( linear ) print ( model . device_ids ) print ( next ( model . module . parameters ()) . device ) #\u6ce8\u610f\u4fdd\u5b58\u53c2\u6570\u65f6\u8981\u6307\u5b9a\u4fdd\u5b58model.module\u7684\u53c2\u6570 torch . save ( model . module . state_dict (), \"../data/model_parameter.pkl\" ) linear = nn . Linear ( 2 , 1 ) linear . load_state_dict ( torch . load ( \"../data/model_parameter.pkl\" )) cpu [0] cuda:0 # 5\uff0c\u6e05\u7a7acuda\u7f13\u5b58 # \u8be5\u65b9\u6cd5\u5728cuda\u8d85\u5185\u5b58\u65f6\u5341\u5206\u6709\u7528 torch . cuda . empty_cache ()","title":"6-3,\u4f7f\u7528GPU\u8bad\u7ec3\u6a21\u578b"},{"location":"6.%E9%AB%98%E9%98%B6API/6-3%2C%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#\u4e00\u77e9\u9635\u4e58\u6cd5\u8303\u4f8b","text":"\u4e0b\u9762\u5206\u522b\u4f7f\u7528CPU\u548cGPU\u4f5c\u4e00\u4e2a\u77e9\u9635\u4e58\u6cd5\uff0c\u5e76\u6bd4\u8f83\u5176\u8ba1\u7b97\u6548\u7387\u3002 import time import torch from torch import nn # \u4f7f\u7528cpu a = torch . rand (( 10000 , 200 )) b = torch . rand (( 200 , 10000 )) tic = time . time () c = torch . matmul ( a , b ) toc = time . time () print ( toc - tic ) print ( a . device ) print ( b . device ) 0.6454010009765625 cpu cpu # \u4f7f\u7528gpu device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) a = torch . rand (( 10000 , 200 ), device = device ) #\u53ef\u4ee5\u6307\u5b9a\u5728GPU\u4e0a\u521b\u5efa\u5f20\u91cf b = torch . rand (( 200 , 10000 )) #\u4e5f\u53ef\u4ee5\u5728CPU\u4e0a\u521b\u5efa\u5f20\u91cf\u540e\u79fb\u52a8\u5230GPU\u4e0a b = b . to ( device ) #\u6216\u8005 b = b.cuda() if torch.cuda.is_available() else b tic = time . time () c = torch . matmul ( a , b ) toc = time . time () print ( toc - tic ) print ( a . device ) print ( b . device ) 0.014541149139404297 cuda:0 cuda:0","title":"\u4e00\uff0c\u77e9\u9635\u4e58\u6cd5\u8303\u4f8b"},{"location":"6.%E9%AB%98%E9%98%B6API/6-3%2C%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#\u4e8c\u7ebf\u6027\u56de\u5f52\u8303\u4f8b","text":"\u4e0b\u9762\u5bf9\u6bd4\u4f7f\u7528CPU\u548cGPU\u8bad\u7ec3\u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u7684\u6548\u7387 1\uff0c\u4f7f\u7528CPU # \u51c6\u5907\u6570\u636e n = 1000000 #\u6837\u672c\u6570\u91cf X = 10 * torch . rand ([ n , 2 ]) - 5.0 #torch.rand\u662f\u5747\u5300\u5206\u5e03 w0 = torch . tensor ([[ 2.0 , - 3.0 ]]) b0 = torch . tensor ([[ 10.0 ]]) Y = X @w0 . t () + b0 + torch . normal ( 0.0 , 2.0 , size = [ n , 1 ]) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 # \u5b9a\u4e49\u6a21\u578b class LinearRegression ( nn . Module ): def __init__ ( self ): super () . __init__ () self . w = nn . Parameter ( torch . randn_like ( w0 )) self . b = nn . Parameter ( torch . zeros_like ( b0 )) #\u6b63\u5411\u4f20\u64ad def forward ( self , x ): return x @self . w . t () + self . b linear = LinearRegression () # \u8bad\u7ec3\u6a21\u578b optimizer = torch . optim . Adam ( linear . parameters (), lr = 0.1 ) loss_func = nn . MSELoss () def train ( epoches ): tic = time . time () for epoch in range ( epoches ): optimizer . zero_grad () Y_pred = linear ( X ) loss = loss_func ( Y_pred , Y ) loss . backward () optimizer . step () if epoch % 50 == 0 : print ({ \"epoch\" : epoch , \"loss\" : loss . item ()}) toc = time . time () print ( \"time used:\" , toc - tic ) train ( 500 ) {'epoch': 0, 'loss': 3.996487855911255} {'epoch': 50, 'loss': 3.9969770908355713} {'epoch': 100, 'loss': 3.9964890480041504} {'epoch': 150, 'loss': 3.996488332748413} {'epoch': 200, 'loss': 3.996488094329834} {'epoch': 250, 'loss': 3.996488332748413} {'epoch': 300, 'loss': 3.996488332748413} {'epoch': 350, 'loss': 3.996488094329834} {'epoch': 400, 'loss': 3.996488332748413} {'epoch': 450, 'loss': 3.996488094329834} time used: 5.4090576171875 2\uff0c\u4f7f\u7528GPU # \u51c6\u5907\u6570\u636e n = 1000000 #\u6837\u672c\u6570\u91cf X = 10 * torch . rand ([ n , 2 ]) - 5.0 #torch.rand\u662f\u5747\u5300\u5206\u5e03 w0 = torch . tensor ([[ 2.0 , - 3.0 ]]) b0 = torch . tensor ([[ 10.0 ]]) Y = X @w0 . t () + b0 + torch . normal ( 0.0 , 2.0 , size = [ n , 1 ]) # @\u8868\u793a\u77e9\u9635\u4e58\u6cd5,\u589e\u52a0\u6b63\u6001\u6270\u52a8 # \u79fb\u52a8\u5230GPU\u4e0a print ( \"torch.cuda.is_available() = \" , torch . cuda . is_available ()) X = X . cuda () Y = Y . cuda () print ( \"X.device:\" , X . device ) print ( \"Y.device:\" , Y . device ) torch.cuda.is_available() = True X.device: cuda:0 Y.device: cuda:0 # \u5b9a\u4e49\u6a21\u578b class LinearRegression ( nn . Module ): def __init__ ( self ): super () . __init__ () self . w = nn . Parameter ( torch . randn_like ( w0 )) self . b = nn . Parameter ( torch . zeros_like ( b0 )) #\u6b63\u5411\u4f20\u64ad def forward ( self , x ): return x @self . w . t () + self . b linear = LinearRegression () # \u79fb\u52a8\u6a21\u578b\u5230GPU\u4e0a device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) linear . to ( device ) #\u67e5\u770b\u6a21\u578b\u662f\u5426\u5df2\u7ecf\u79fb\u52a8\u5230GPU\u4e0a print ( \"if on cuda:\" , next ( linear . parameters ()) . is_cuda ) if on cuda: True # \u8bad\u7ec3\u6a21\u578b optimizer = torch . optim . Adam ( linear . parameters (), lr = 0.1 ) loss_func = nn . MSELoss () def train ( epoches ): tic = time . time () for epoch in range ( epoches ): optimizer . zero_grad () Y_pred = linear ( X ) loss = loss_func ( Y_pred , Y ) loss . backward () optimizer . step () if epoch % 50 == 0 : print ({ \"epoch\" : epoch , \"loss\" : loss . item ()}) toc = time . time () print ( \"time used:\" , toc - tic ) train ( 500 ) {'epoch': 0, 'loss': 3.9982845783233643} {'epoch': 50, 'loss': 3.998818874359131} {'epoch': 100, 'loss': 3.9982895851135254} {'epoch': 150, 'loss': 3.9982845783233643} {'epoch': 200, 'loss': 3.998284339904785} {'epoch': 250, 'loss': 3.9982845783233643} {'epoch': 300, 'loss': 3.9982845783233643} {'epoch': 350, 'loss': 3.9982845783233643} {'epoch': 400, 'loss': 3.9982845783233643} {'epoch': 450, 'loss': 3.9982845783233643} time used: 0.4889392852783203","title":"\u4e8c\uff0c\u7ebf\u6027\u56de\u5f52\u8303\u4f8b"},{"location":"6.%E9%AB%98%E9%98%B6API/6-3%2C%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#\u4e09torchkeras\u4f7f\u7528\u5355gpu\u8303\u4f8b","text":"\u4e0b\u9762\u6f14\u793a\u4f7f\u7528torchkeras\u6765\u5e94\u7528GPU\u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5\u3002 \u5176\u5bf9\u5e94\u7684CPU\u8bad\u7ec3\u6a21\u578b\u4ee3\u7801\u53c2\u89c1\u300a6-2,\u8bad\u7ec3\u6a21\u578b\u76843\u79cd\u65b9\u6cd5\u300b \u672c\u4f8b\u4ec5\u9700\u8981\u5728\u5b83\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e00\u884c\u4ee3\u7801\uff0c\u5728model.compile\u65f6\u6307\u5b9a device\u5373\u53ef\u3002 1\uff0c\u51c6\u5907\u6570\u636e ! pip install - U torchkeras import torch from torch import nn import torchvision from torchvision import transforms import torchkeras transform = transforms . Compose ([ transforms . ToTensor ()]) ds_train = torchvision . datasets . MNIST ( root = \"../data/minist/\" , train = True , download = True , transform = transform ) ds_valid = torchvision . datasets . MNIST ( root = \"../data/minist/\" , train = False , download = True , transform = transform ) dl_train = torch . utils . data . DataLoader ( ds_train , batch_size = 128 , shuffle = True , num_workers = 4 ) dl_valid = torch . utils . data . DataLoader ( ds_valid , batch_size = 128 , shuffle = False , num_workers = 4 ) print ( len ( ds_train )) print ( len ( ds_valid )) % matplotlib inline % config InlineBackend . figure_format = 'svg' #\u67e5\u770b\u90e8\u5206\u6837\u672c from matplotlib import pyplot as plt plt . figure ( figsize = ( 8 , 8 )) for i in range ( 9 ): img , label = ds_train [ i ] img = torch . squeeze ( img ) ax = plt . subplot ( 3 , 3 , i + 1 ) ax . imshow ( img . numpy ()) ax . set_title ( \"label = %d \" % label ) ax . set_xticks ([]) ax . set_yticks ([]) plt . show () 2\uff0c\u5b9a\u4e49\u6a21\u578b class CnnModel ( nn . Module ): def __init__ ( self ): super () . __init__ () self . layers = nn . ModuleList ([ nn . Conv2d ( in_channels = 1 , out_channels = 32 , kernel_size = 3 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Dropout2d ( p = 0.1 ), nn . AdaptiveMaxPool2d (( 1 , 1 )), nn . Flatten (), nn . Linear ( 64 , 32 ), nn . ReLU (), nn . Linear ( 32 , 10 )] ) def forward ( self , x ): for layer in self . layers : x = layer ( x ) return x net = CnnModel () model = torchkeras . Model ( net ) model . summary ( input_shape = ( 1 , 32 , 32 )) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Conv2d-1 [-1, 32, 30, 30] 320 MaxPool2d-2 [-1, 32, 15, 15] 0 Conv2d-3 [-1, 64, 11, 11] 51,264 MaxPool2d-4 [-1, 64, 5, 5] 0 Dropout2d-5 [-1, 64, 5, 5] 0 AdaptiveMaxPool2d-6 [-1, 64, 1, 1] 0 Flatten-7 [-1, 64] 0 Linear-8 [-1, 32] 2,080 ReLU-9 [-1, 32] 0 Linear-10 [-1, 10] 330 ================================================================ Total params: 53,994 Trainable params: 53,994 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.003906 Forward/backward pass size (MB): 0.359695 Params size (MB): 0.205971 Estimated Total Size (MB): 0.569572 ---------------------------------------------------------------- 3\uff0c\u8bad\u7ec3\u6a21\u578b from sklearn.metrics import accuracy_score def accuracy ( y_pred , y_true ): y_pred_cls = torch . argmax ( nn . Softmax ( dim = 1 )( y_pred ), dim = 1 ) . data return accuracy_score ( y_true . cpu () . numpy (), y_pred_cls . cpu () . numpy ()) # \u6ce8\u610f\u6b64\u5904\u8981\u5c06\u6570\u636e\u5148\u79fb\u52a8\u5230cpu\u4e0a\uff0c\u7136\u540e\u624d\u80fd\u8f6c\u6362\u6210numpy\u6570\u7ec4 device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) model . compile ( loss_func = nn . CrossEntropyLoss (), optimizer = torch . optim . Adam ( model . parameters (), lr = 0.02 ), metrics_dict = { \"accuracy\" : accuracy }, device = device ) # \u6ce8\u610f\u6b64\u5904compile\u65f6\u6307\u5b9a\u4e86device dfhistory = model . fit ( 3 , dl_train = dl_train , dl_val = dl_valid , log_step_freq = 100 ) Start Training ... ================================================================================2020-06-27 00:24:29 {'step': 100, 'loss': 1.063, 'accuracy': 0.619} {'step': 200, 'loss': 0.681, 'accuracy': 0.764} {'step': 300, 'loss': 0.534, 'accuracy': 0.818} {'step': 400, 'loss': 0.458, 'accuracy': 0.847} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 1 | 0.412 | 0.863 | 0.128 | 0.961 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-27 00:24:35 {'step': 100, 'loss': 0.147, 'accuracy': 0.956} {'step': 200, 'loss': 0.156, 'accuracy': 0.954} {'step': 300, 'loss': 0.156, 'accuracy': 0.954} {'step': 400, 'loss': 0.157, 'accuracy': 0.955} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 2 | 0.153 | 0.956 | 0.085 | 0.976 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-27 00:24:42 {'step': 100, 'loss': 0.126, 'accuracy': 0.965} {'step': 200, 'loss': 0.147, 'accuracy': 0.96} {'step': 300, 'loss': 0.153, 'accuracy': 0.959} {'step': 400, 'loss': 0.147, 'accuracy': 0.96} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 3 | 0.146 | 0.96 | 0.119 | 0.968 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-27 00:24:48 Finished Training... 4\uff0c\u8bc4\u4f30\u6a21\u578b % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( dfhistory , metric ): train_metrics = dfhistory [ metric ] val_metrics = dfhistory [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( dfhistory , \"loss\" ) plot_metric ( dfhistory , \"accuracy\" ) model . evaluate ( dl_valid ) {'val_accuracy': 0.967068829113924, 'val_loss': 0.11601964030650598} 5\uff0c\u4f7f\u7528\u6a21\u578b model . predict ( dl_valid )[ 0 : 10 ] tensor([[ -9.2092, 3.1997, 1.4028, -2.7135, -0.7320, -2.0518, -20.4938, 14.6774, 1.7616, 5.8549], [ 2.8509, 4.9781, 18.0946, 0.0928, -1.6061, -4.1437, 4.8697, 3.8811, 4.3869, -3.5929], [-22.5231, 13.6643, 5.0244, -11.0188, -16.8147, -9.5894, -6.2556, -10.5648, -12.1022, -19.4685], [ 23.2670, -12.0711, -7.3968, -8.2715, -1.0915, -12.6050, 8.0444, -16.9339, 1.8827, -0.2497], [ -4.1159, 3.2102, 0.4971, -11.8064, 12.1460, -5.1650, -6.5918, 1.0088, 0.8362, 2.5132], [-26.1764, 15.6251, 6.1191, -12.2424, -13.9725, -10.0540, -7.8669, -5.9602, -11.1944, -18.7890], [ -5.0602, 3.3779, -0.6647, -8.5185, 10.0320, -5.5107, -6.9579, 2.3811, 0.2542, 3.2860], [ 4.1017, -0.4282, 7.2220, 3.3700, -3.6813, 1.1576, -1.8479, 0.7450, 3.9768, 6.2640], [ 1.9689, -0.3960, 7.4414, -10.4789, 2.7066, 1.7482, 5.7971, -4.5808, 3.0911, -5.1971], [ -2.9680, -1.2369, -0.0829, -1.8577, 1.9380, -0.8374, -8.2207, 3.5060, 3.8735, 13.6762]], device='cuda:0') 6\uff0c\u4fdd\u5b58\u6a21\u578b # save the model parameters torch . save ( model . state_dict (), \"model_parameter.pkl\" ) model_clone = torchkeras . Model ( CnnModel ()) model_clone . load_state_dict ( torch . load ( \"model_parameter.pkl\" )) model_clone . compile ( loss_func = nn . CrossEntropyLoss (), optimizer = torch . optim . Adam ( model . parameters (), lr = 0.02 ), metrics_dict = { \"accuracy\" : accuracy }, device = device ) # \u6ce8\u610f\u6b64\u5904compile\u65f6\u6307\u5b9a\u4e86device model_clone . evaluate ( dl_valid ) {'val_accuracy': 0.967068829113924, 'val_loss': 0.11601964030650598}","title":"\u4e09\uff0ctorchkeras\u4f7f\u7528\u5355GPU\u8303\u4f8b"},{"location":"6.%E9%AB%98%E9%98%B6API/6-3%2C%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/#\u56dbtorchkeras\u4f7f\u7528\u591agpu\u8303\u4f8b","text":"\u6ce8\uff1a\u4ee5\u4e0b\u8303\u4f8b\u9700\u8981\u5728\u6709\u591a\u4e2aGPU\u7684\u673a\u5668\u4e0a\u8dd1\u3002\u5982\u679c\u5728\u5355GPU\u7684\u673a\u5668\u4e0a\u8dd1\uff0c\u4e5f\u80fd\u8dd1\u901a\uff0c\u4f46\u662f\u5b9e\u9645\u4e0a\u4f7f\u7528\u7684\u662f\u5355\u4e2aGPU\u3002 1\uff0c\u51c6\u5907\u6570\u636e import torch from torch import nn import torchvision from torchvision import transforms import torchkeras transform = transforms . Compose ([ transforms . ToTensor ()]) ds_train = torchvision . datasets . MNIST ( root = \"../data/minist/\" , train = True , download = True , transform = transform ) ds_valid = torchvision . datasets . MNIST ( root = \"../data/minist/\" , train = False , download = True , transform = transform ) dl_train = torch . utils . data . DataLoader ( ds_train , batch_size = 128 , shuffle = True , num_workers = 4 ) dl_valid = torch . utils . data . DataLoader ( ds_valid , batch_size = 128 , shuffle = False , num_workers = 4 ) print ( len ( ds_train )) print ( len ( ds_valid )) 2\uff0c\u5b9a\u4e49\u6a21\u578b class CnnModule ( nn . Module ): def __init__ ( self ): super () . __init__ () self . layers = nn . ModuleList ([ nn . Conv2d ( in_channels = 1 , out_channels = 32 , kernel_size = 3 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 , stride = 2 ), nn . Dropout2d ( p = 0.1 ), nn . AdaptiveMaxPool2d (( 1 , 1 )), nn . Flatten (), nn . Linear ( 64 , 32 ), nn . ReLU (), nn . Linear ( 32 , 10 )] ) def forward ( self , x ): for layer in self . layers : x = layer ( x ) return x net = nn . DataParallel ( CnnModule ()) #Attention this line!!! model = torchkeras . Model ( net ) model . summary ( input_shape = ( 1 , 32 , 32 )) 3\uff0c\u8bad\u7ec3\u6a21\u578b from sklearn.metrics import accuracy_score def accuracy ( y_pred , y_true ): y_pred_cls = torch . argmax ( nn . Softmax ( dim = 1 )( y_pred ), dim = 1 ) . data return accuracy_score ( y_true . cpu () . numpy (), y_pred_cls . cpu () . numpy ()) # \u6ce8\u610f\u6b64\u5904\u8981\u5c06\u6570\u636e\u5148\u79fb\u52a8\u5230cpu\u4e0a\uff0c\u7136\u540e\u624d\u80fd\u8f6c\u6362\u6210numpy\u6570\u7ec4 device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) model . compile ( loss_func = nn . CrossEntropyLoss (), optimizer = torch . optim . Adam ( model . parameters (), lr = 0.02 ), metrics_dict = { \"accuracy\" : accuracy }, device = device ) # \u6ce8\u610f\u6b64\u5904compile\u65f6\u6307\u5b9a\u4e86device dfhistory = model . fit ( 3 , dl_train = dl_train , dl_val = dl_valid , log_step_freq = 100 ) Start Training ... ================================================================================2020-06-27 00:24:29 {'step': 100, 'loss': 1.063, 'accuracy': 0.619} {'step': 200, 'loss': 0.681, 'accuracy': 0.764} {'step': 300, 'loss': 0.534, 'accuracy': 0.818} {'step': 400, 'loss': 0.458, 'accuracy': 0.847} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 1 | 0.412 | 0.863 | 0.128 | 0.961 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-27 00:24:35 {'step': 100, 'loss': 0.147, 'accuracy': 0.956} {'step': 200, 'loss': 0.156, 'accuracy': 0.954} {'step': 300, 'loss': 0.156, 'accuracy': 0.954} {'step': 400, 'loss': 0.157, 'accuracy': 0.955} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 2 | 0.153 | 0.956 | 0.085 | 0.976 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-27 00:24:42 {'step': 100, 'loss': 0.126, 'accuracy': 0.965} {'step': 200, 'loss': 0.147, 'accuracy': 0.96} {'step': 300, 'loss': 0.153, 'accuracy': 0.959} {'step': 400, 'loss': 0.147, 'accuracy': 0.96} +-------+-------+----------+----------+--------------+ | epoch | loss | accuracy | val_loss | val_accuracy | +-------+-------+----------+----------+--------------+ | 3 | 0.146 | 0.96 | 0.119 | 0.968 | +-------+-------+----------+----------+--------------+ ================================================================================2020-06-27 00:24:48 Finished Training... 4\uff0c\u8bc4\u4f30\u6a21\u578b % matplotlib inline % config InlineBackend . figure_format = 'svg' import matplotlib.pyplot as plt def plot_metric ( dfhistory , metric ): train_metrics = dfhistory [ metric ] val_metrics = dfhistory [ 'val_' + metric ] epochs = range ( 1 , len ( train_metrics ) + 1 ) plt . plot ( epochs , train_metrics , 'bo--' ) plt . plot ( epochs , val_metrics , 'ro-' ) plt . title ( 'Training and validation ' + metric ) plt . xlabel ( \"Epochs\" ) plt . ylabel ( metric ) plt . legend ([ \"train_\" + metric , 'val_' + metric ]) plt . show () plot_metric ( dfhistory , \"loss\" ) plot_metric ( dfhistory , \"accuracy\" ) model . evaluate ( dl_valid ) {'val_accuracy': 0.9603441455696202, 'val_loss': 0.14203246376371081} 5\uff0c\u4f7f\u7528\u6a21\u578b model . predict ( dl_valid )[ 0 : 10 ] tensor([[ -9.2092, 3.1997, 1.4028, -2.7135, -0.7320, -2.0518, -20.4938, 14.6774, 1.7616, 5.8549], [ 2.8509, 4.9781, 18.0946, 0.0928, -1.6061, -4.1437, 4.8697, 3.8811, 4.3869, -3.5929], [-22.5231, 13.6643, 5.0244, -11.0188, -16.8147, -9.5894, -6.2556, -10.5648, -12.1022, -19.4685], [ 23.2670, -12.0711, -7.3968, -8.2715, -1.0915, -12.6050, 8.0444, -16.9339, 1.8827, -0.2497], [ -4.1159, 3.2102, 0.4971, -11.8064, 12.1460, -5.1650, -6.5918, 1.0088, 0.8362, 2.5132], [-26.1764, 15.6251, 6.1191, -12.2424, -13.9725, -10.0540, -7.8669, -5.9602, -11.1944, -18.7890], [ -5.0602, 3.3779, -0.6647, -8.5185, 10.0320, -5.5107, -6.9579, 2.3811, 0.2542, 3.2860], [ 4.1017, -0.4282, 7.2220, 3.3700, -3.6813, 1.1576, -1.8479, 0.7450, 3.9768, 6.2640], [ 1.9689, -0.3960, 7.4414, -10.4789, 2.7066, 1.7482, 5.7971, -4.5808, 3.0911, -5.1971], [ -2.9680, -1.2369, -0.0829, -1.8577, 1.9380, -0.8374, -8.2207, 3.5060, 3.8735, 13.6762]], device='cuda:0') 6\uff0c\u4fdd\u5b58\u6a21\u578b # save the model parameters torch . save ( model . net . module . state_dict (), \"model_parameter.pkl\" ) net_clone = CnnModel () net_clone . load_state_dict ( torch . load ( \"model_parameter.pkl\" )) model_clone = torchkeras . Model ( net_clone ) model_clone . compile ( loss_func = nn . CrossEntropyLoss (), optimizer = torch . optim . Adam ( model . parameters (), lr = 0.02 ), metrics_dict = { \"accuracy\" : accuracy }, device = device ) model_clone . evaluate ( dl_valid ) {'val_accuracy': 0.9603441455696202, 'val_loss': 0.14203246376371081}","title":"\u56db\uff0ctorchkeras\u4f7f\u7528\u591aGPU\u8303\u4f8b"}]}